{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfolio import timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Дано:</b> Есть данные по некоторым ликвидным акциям (OHLCV). Цены по акциям учитывают дивидендные доходности, поэтому могут не совпадать с котировками, которые мы видим в текущий момент на рынке (но динамика ровно та же самая). Есть данные по фонду денежного рынка (OHLCV) - безрисковый актив (аналог накопительного счета). В данной работе котировки синтетические - сгенерированы на основе текущих ставок рефинансирования, так как большинство имеющихся на данный момент фондов ведут свое начало от 22го года и наоборот, фонды, которые были до 22го года прекратили свое существование. Есть котировки по дополнительным рядам, назовем их вспомогательными: IMOEX (индекс мосбиржи), GD (золото), BZ (нефть), USD (доллар США). Рассматриваемые даты 06.16-05.24. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Найти:</b> С помощью модели RL предполагается научиться эффективно распределять денежные средства между рисковыми бумагами и безрисковой.\n",
    "\n",
    " В качестве состояния в среде планируется использовать индикаторы технического анализа, корреляцию активов со вспомогательными рядам. Действие планируется MultiDiscrete - держать i-ю бумагу в портфеле или не держать. Распределение между бумагами отобранными в портфель равномерное (куплены на равные денежные суммы). Обязательно должны быть учтены комиссии за совершение сделок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from FeaturesAdder import FeaturesAdder\n",
    "from PortfolioEnvBox import PortfolioEnv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "df = loader.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>62488</td>\n",
       "      <td>BZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>2366.000000</td>\n",
       "      <td>2366.000000</td>\n",
       "      <td>2366.000000</td>\n",
       "      <td>2366.000000</td>\n",
       "      <td>49519</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>10956.620000</td>\n",
       "      <td>10958.360000</td>\n",
       "      <td>10949.480000</td>\n",
       "      <td>10954.240000</td>\n",
       "      <td>18285800</td>\n",
       "      <td>GMKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>3217.190000</td>\n",
       "      <td>3217.360000</td>\n",
       "      <td>3087.990000</td>\n",
       "      <td>3141.420000</td>\n",
       "      <td>30769</td>\n",
       "      <td>IMOEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>10730.000000</td>\n",
       "      <td>10814.500000</td>\n",
       "      <td>10496.000000</td>\n",
       "      <td>10587.000000</td>\n",
       "      <td>1661232</td>\n",
       "      <td>LKOH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>81.978000</td>\n",
       "      <td>83.258000</td>\n",
       "      <td>80.453000</td>\n",
       "      <td>82.898000</td>\n",
       "      <td>35974230</td>\n",
       "      <td>MAGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>168.532877</td>\n",
       "      <td>168.532877</td>\n",
       "      <td>168.532877</td>\n",
       "      <td>168.532877</td>\n",
       "      <td>1</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>538.060000</td>\n",
       "      <td>543.610000</td>\n",
       "      <td>535.110000</td>\n",
       "      <td>541.510000</td>\n",
       "      <td>5116050</td>\n",
       "      <td>MTSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>1419.720000</td>\n",
       "      <td>1434.320000</td>\n",
       "      <td>1379.520000</td>\n",
       "      <td>1407.920000</td>\n",
       "      <td>2076053</td>\n",
       "      <td>NVTK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>731.690000</td>\n",
       "      <td>739.190000</td>\n",
       "      <td>716.990000</td>\n",
       "      <td>737.440000</td>\n",
       "      <td>7536920</td>\n",
       "      <td>ROSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>411.870000</td>\n",
       "      <td>413.870000</td>\n",
       "      <td>403.370000</td>\n",
       "      <td>409.320000</td>\n",
       "      <td>61548130</td>\n",
       "      <td>SBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>34.685000</td>\n",
       "      <td>32.150000</td>\n",
       "      <td>33.880000</td>\n",
       "      <td>153852300</td>\n",
       "      <td>SNGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>89.318600</td>\n",
       "      <td>89.318600</td>\n",
       "      <td>89.318600</td>\n",
       "      <td>89.318600</td>\n",
       "      <td>8316</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date          open          high           low         close  \\\n",
       "1995 2024-06-03     78.150000     78.150000     78.150000     78.150000   \n",
       "1995 2024-06-03   2366.000000   2366.000000   2366.000000   2366.000000   \n",
       "1995 2024-06-03  10956.620000  10958.360000  10949.480000  10954.240000   \n",
       "1995 2024-06-03   3217.190000   3217.360000   3087.990000   3141.420000   \n",
       "1995 2024-06-03  10730.000000  10814.500000  10496.000000  10587.000000   \n",
       "1995 2024-06-03     81.978000     83.258000     80.453000     82.898000   \n",
       "1995 2024-06-03    168.532877    168.532877    168.532877    168.532877   \n",
       "1995 2024-06-03    538.060000    543.610000    535.110000    541.510000   \n",
       "1995 2024-06-03   1419.720000   1434.320000   1379.520000   1407.920000   \n",
       "1995 2024-06-03    731.690000    739.190000    716.990000    737.440000   \n",
       "1995 2024-06-03    411.870000    413.870000    403.370000    409.320000   \n",
       "1995 2024-06-03     34.230000     34.685000     32.150000     33.880000   \n",
       "1995 2024-06-03     89.318600     89.318600     89.318600     89.318600   \n",
       "\n",
       "         volume    tic  \n",
       "1995      62488     BZ  \n",
       "1995      49519     GD  \n",
       "1995   18285800   GMKN  \n",
       "1995      30769  IMOEX  \n",
       "1995    1661232   LKOH  \n",
       "1995   35974230   MAGN  \n",
       "1995          1     MM  \n",
       "1995    5116050   MTSS  \n",
       "1995    2076053   NVTK  \n",
       "1995    7536920   ROSN  \n",
       "1995   61548130   SBER  \n",
       "1995  153852300   SNGS  \n",
       "1995       8316    USD  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [open, high, low, close, volume, tic]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = df.groupby('date').count()\n",
    "cnt[cnt[\"open\"] > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25949, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df))\n",
    "#df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "df = df.drop(df[df['tic'] == 'BZ'].index)\n",
    "#df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "df = df.drop(df[df['tic'] == 'USD'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume'] = pd.to_numeric(df['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21957 entries, 1 to 25947\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    21957 non-null  datetime64[ns]\n",
      " 1   open    21957 non-null  float64       \n",
      " 2   high    21957 non-null  float64       \n",
      " 3   low     21957 non-null  float64       \n",
      " 4   close   21957 non-null  float64       \n",
      " 5   volume  21957 non-null  int64         \n",
      " 6   tic     21957 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of values (1999) does not match length of index (1997)\n",
      "Length of values (1999) does not match length of index (1997)\n",
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:17<00:00, 113.52it/s]\n"
     ]
    }
   ],
   "source": [
    "fa = FeaturesAdder()\n",
    "df = fa.Process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>rsi_12</th>\n",
       "      <th>cci_12</th>\n",
       "      <th>dx_12</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>cov_xtra</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17761</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>538.06</td>\n",
       "      <td>543.610</td>\n",
       "      <td>535.11</td>\n",
       "      <td>541.51</td>\n",
       "      <td>5116050</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>24.026140</td>\n",
       "      <td>-156.839237</td>\n",
       "      <td>92.666893</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8621921517140547, 0.7537682741242231, 0.190...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX     LKOH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17762</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>1419.72</td>\n",
       "      <td>1434.320</td>\n",
       "      <td>1379.52</td>\n",
       "      <td>1407.92</td>\n",
       "      <td>2076053</td>\n",
       "      <td>NVTK</td>\n",
       "      <td>17.001599</td>\n",
       "      <td>-113.120166</td>\n",
       "      <td>97.394474</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8621921517140547, 0.7537682741242231, 0.190...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX     LKOH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17763</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>731.69</td>\n",
       "      <td>739.190</td>\n",
       "      <td>716.99</td>\n",
       "      <td>737.44</td>\n",
       "      <td>7536920</td>\n",
       "      <td>ROSN</td>\n",
       "      <td>34.850714</td>\n",
       "      <td>-138.073283</td>\n",
       "      <td>88.485347</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8621921517140547, 0.7537682741242231, 0.190...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX     LKOH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>411.87</td>\n",
       "      <td>413.870</td>\n",
       "      <td>403.37</td>\n",
       "      <td>409.32</td>\n",
       "      <td>61548130</td>\n",
       "      <td>SBER</td>\n",
       "      <td>40.349783</td>\n",
       "      <td>-205.860220</td>\n",
       "      <td>60.821344</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8621921517140547, 0.7537682741242231, 0.190...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX     LKOH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>34.23</td>\n",
       "      <td>34.685</td>\n",
       "      <td>32.15</td>\n",
       "      <td>33.88</td>\n",
       "      <td>153852300</td>\n",
       "      <td>SNGS</td>\n",
       "      <td>23.582352</td>\n",
       "      <td>-132.274590</td>\n",
       "      <td>90.427869</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8621921517140547, 0.7537682741242231, 0.190...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX     LKOH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     open      high      low    close     volume   tic  \\\n",
       "17761 2024-06-03   538.06   543.610   535.11   541.51    5116050  MTSS   \n",
       "17762 2024-06-03  1419.72  1434.320  1379.52  1407.92    2076053  NVTK   \n",
       "17763 2024-06-03   731.69   739.190   716.99   737.44    7536920  ROSN   \n",
       "17764 2024-06-03   411.87   413.870   403.37   409.32   61548130  SBER   \n",
       "17765 2024-06-03    34.23    34.685    32.15    33.88  153852300  SNGS   \n",
       "\n",
       "          rsi_12      cci_12      dx_12 cov_list  \\\n",
       "17761  24.026140 -156.839237  92.666893       []   \n",
       "17762  17.001599 -113.120166  97.394474       []   \n",
       "17763  34.850714 -138.073283  88.485347       []   \n",
       "17764  40.349783 -205.860220  60.821344       []   \n",
       "17765  23.582352 -132.274590  90.427869       []   \n",
       "\n",
       "                                                cov_xtra  \\\n",
       "17761  [0.8621921517140547, 0.7537682741242231, 0.190...   \n",
       "17762  [0.8621921517140547, 0.7537682741242231, 0.190...   \n",
       "17763  [0.8621921517140547, 0.7537682741242231, 0.190...   \n",
       "17764  [0.8621921517140547, 0.7537682741242231, 0.190...   \n",
       "17765  [0.8621921517140547, 0.7537682741242231, 0.190...   \n",
       "\n",
       "                                             return_list  \n",
       "17761  tic             GD      GMKN    IMOEX     LKOH...  \n",
       "17762  tic             GD      GMKN    IMOEX     LKOH...  \n",
       "17763  tic             GD      GMKN    IMOEX     LKOH...  \n",
       "17764  tic             GD      GMKN    IMOEX     LKOH...  \n",
       "17765  tic             GD      GMKN    IMOEX     LKOH...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем корректность рассчитанных FinRL индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "sberp_high  = df[df['tic']=='SBER']['high'].to_numpy()\n",
    "sberp_low   = df[df['tic']=='SBER']['low'].to_numpy()\n",
    "sberp_close = df[df['tic']=='SBER']['close'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi12 = ta.RSI(sberp_close, timeperiod=12)\n",
    "cci12 = ta.CCI(sberp_high,sberp_low,sberp_close, timeperiod=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsi_12    40.349783\n",
      "cci_12   -205.86022\n",
      "Name: 17764, dtype: object\n",
      "40.349782550662574 -205.86022042419992\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[17764][['rsi_12','cci_12']])\n",
    "print(rsi12[-1], cci12[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86219215,  0.75376827,  0.19098976, -0.72698068,  0.94901461,\n",
       "        0.88841615,  0.83966724,  0.14126898,  0.82608292, -0.18563108,\n",
       "       -0.28781645,  0.62203695,  0.45002973,  0.04749333, -0.12110855,\n",
       "        0.35105434,  0.69348466, -0.24044705])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-1]['cov_xtra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "       ...\n",
       "       17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763, 17764, 17765],\n",
       "      dtype='int64', length=17766)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.date.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 9, State Space: 9\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(df.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 20,\n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": fa.indicators, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"cov_xtra_names\": fa.cov_xtra_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_gym = PortfolioEnv(df = df, **env_kwargs)\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручная проверка действия в среде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409, 1000000, 1000000, array([0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.day, e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39291012 0.02095526 0.14783607 0.85654515 0.21874408 0.0918261\n",
      " 0.6262958  0.58529353 0.24756992]\n"
     ]
    }
   ],
   "source": [
    "act = e_train_gym.action_space.sample()\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993304.832970959,\n",
       " 14574.831601098063,\n",
       " array([  13,    0,  500, 1890,  144,   15,  284,  520, 1922]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_prices = df.loc[e_train_gym.day]['close'].to_numpy()\n",
    "state, reward, term, _ = e_train_gym.step(act)\n",
    "e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.006695167029040982, 14574.831601098063)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(close_prices * e_train_gym.current_state) + e_train_gym.cash\n",
    "reward, e_train_gym.cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Timestamp('2022-02-09 00:00:00'), Timestamp('2022-02-10 00:00:00')],\n",
       " [1000000, 993304.832970959])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.date_memory, e_train_gym.asset_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47467503 0.0613731  0.37635505 0.202459   0.44452304 0.51550364\n",
      " 0.9187314  0.54571766 0.00973097]\n"
     ]
    }
   ],
   "source": [
    "act2 = e_train_gym.action_space.sample()\n",
    "print(act2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(967301.3219926303,\n",
       " 17763.54565016491,\n",
       " array([  14,    1, 1157,  398,  259,   80,  377,  438,   67]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, term, _ = e_train_gym.step(act2)\n",
    "e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026178782298433678"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(df_daily_return):\n",
    "    DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "    perf_func = timeseries.perf_stats \n",
    "    return perf_func( returns=DRL_strat, \n",
    "                                factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trade(alg, train, trade, optuna_params = None, log_name = None, size = None):\n",
    "    #env_kwargs['lookback'] = lookback\n",
    "    e_train_gym = PortfolioEnv(df = train, **env_kwargs)\n",
    "    env_train, _ = e_train_gym.get_sb_env()\n",
    "    \n",
    "    policy_kwargs = None\n",
    "    if size != None:\n",
    "        policy_kwargs = {\n",
    "            \"net_arch\": dict(pi=size, vf=size, qf=size),\n",
    "        }\n",
    "\n",
    "    agent = DRLAgent(env = env_train)\n",
    "\n",
    "    model_params = None\n",
    "    if optuna_params != None:\n",
    "        model_params = optuna_params\n",
    "\n",
    "    if log_name is None:\n",
    "        log_name = alg\n",
    "\n",
    "    model = agent.get_model(model_name = alg, model_kwargs = optuna_params, policy_kwargs = policy_kwargs, tensorboard_log = 'logs')\n",
    "\n",
    "    trained_a2c = agent.train_model(model = model, \n",
    "                                tb_log_name = log_name,\n",
    "                                total_timesteps = 100_000)\n",
    "\n",
    "    e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "\n",
    "    df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym2)\n",
    "    \n",
    "    return trained_a2c, df_daily_return, df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:719524.5368556973\n",
      "Sharpe:  -0.687220376953859\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1043864.6023834564\n",
      "Sharpe:  1.7178230280318036\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -670         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | -0.003320432 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.0204       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 114           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -809          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -1.36         |\n",
      "|    reward             | 0.00032433114 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.0343        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:647559.3411143187\n",
      "Sharpe:  -0.4488326117057177\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -519        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.54        |\n",
      "|    reward             | 0.003941004 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0473      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -1.68e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -3.83        |\n",
      "|    reward             | 0.0056217792 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.117        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 109           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | -181          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.445        |\n",
      "|    reward             | -0.0051897806 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 0.0174        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:884935.2703463793\n",
      "Sharpe:  0.006527784318891611\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 107        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | -315       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -0.294     |\n",
      "|    reward             | 0.00437011 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.00639    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 109          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -49.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.182       |\n",
      "|    reward             | -0.005432365 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000396     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:878523.572482924\n",
      "Sharpe:  -0.011933184090996298\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 110          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -87.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.581       |\n",
      "|    reward             | -0.011120221 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.00449      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:894216.8220341712\n",
      "Sharpe:  -0.11666488680823306\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -3.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | 0.0026309227 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | -26.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 1.33         |\n",
      "|    reward             | -0.029216357 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.0182       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756213.5210010913\n",
      "Sharpe:  -0.22478495678158456\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 113         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | -5.76       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.0903     |\n",
      "|    reward             | 0.005638011 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000287    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | -0.337       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0986       |\n",
      "|    reward             | 0.0056415154 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 5.72e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 114           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | -4.59         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 1.05          |\n",
      "|    reward             | -0.0010004183 |\n",
      "|    std                | 1.28          |\n",
      "|    value_loss         | 0.00889       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:832469.3770176697\n",
      "Sharpe:  -0.040054161138114205\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 114            |\n",
      "|    iterations         | 1400           |\n",
      "|    time_elapsed       | 61             |\n",
      "|    total_timesteps    | 7000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.3          |\n",
      "|    explained_variance | -0.512         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1399           |\n",
      "|    policy_loss        | 0.166          |\n",
      "|    reward             | -0.00044722285 |\n",
      "|    std                | 1.33           |\n",
      "|    value_loss         | 0.000132       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -5.54        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.53         |\n",
      "|    reward             | 0.0060696555 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.000963     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:670452.5623326506\n",
      "Sharpe:  -0.35866467912056504\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -0.845      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.276      |\n",
      "|    reward             | 0.038189735 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 0.000676    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | -1.93         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.337        |\n",
      "|    reward             | -0.0066255745 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 0.000439      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747876.4905290769\n",
      "Sharpe:  -0.2664354880590675\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.587        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.277        |\n",
      "|    reward             | 0.0019922445 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 0.000286     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:949167.2658241172\n",
      "Sharpe:  -0.014283368122399666\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -0.21        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0757      |\n",
      "|    reward             | -0.016656863 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 4.07e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 86           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | 0.0047774967 |\n",
      "|    std                | 1.72         |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | -0.472      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 0.35        |\n",
      "|    reward             | 0.011370721 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1601103.060691042\n",
      "Sharpe:  0.4883368462194908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1294981.7962398143\n",
      "Sharpe:  3.3953713237674914\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | -3.81        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | -0.029394709 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 0.000363     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761629.1642063643\n",
      "Sharpe:  -0.5379081012204536\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | -55.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 0.288        |\n",
      "|    reward             | -0.007982825 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | -4.88        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | 0.0019093411 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 113         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.7       |\n",
      "|    explained_variance | 0.263       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | 0.002726043 |\n",
      "|    std                | 2.16        |\n",
      "|    value_loss         | 7.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1120879.9880531535\n",
      "Sharpe:  0.22285073825008167\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -1.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | -0.305       |\n",
      "|    reward             | -0.009358113 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 0.000573     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.333        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.213       |\n",
      "|    reward             | 0.0070972266 |\n",
      "|    std                | 2.36         |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1368548.5136845042\n",
      "Sharpe:  0.4413929792661178\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | -4.15        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.242        |\n",
      "|    reward             | 0.0011058036 |\n",
      "|    std                | 2.46         |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1108695.913807366\n",
      "Sharpe:  0.6150460105443784\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | -0.706      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.283       |\n",
      "|    reward             | 0.011584564 |\n",
      "|    std                | 2.56        |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:929808.9868942905\n",
      "Sharpe:  -0.03397680893835531\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 114            |\n",
      "|    iterations         | 3000           |\n",
      "|    time_elapsed       | 131            |\n",
      "|    total_timesteps    | 15000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -21.6          |\n",
      "|    explained_variance | -0.19          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2999           |\n",
      "|    policy_loss        | 0.536          |\n",
      "|    reward             | -0.00083983835 |\n",
      "|    std                | 2.68           |\n",
      "|    value_loss         | 0.00187        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -2.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | 0.0035096982 |\n",
      "|    std                | 2.8          |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1152098.1611142932\n",
      "Sharpe:  0.2567039270126115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 114           |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.4         |\n",
      "|    explained_variance | 0.0816        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | -0.184        |\n",
      "|    reward             | -0.0102109285 |\n",
      "|    std                | 2.92          |\n",
      "|    value_loss         | 9.2e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | -2.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.0664      |\n",
      "|    reward             | 0.011147247 |\n",
      "|    std                | 3.06        |\n",
      "|    value_loss         | 0.000195    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | 0.0008838734 |\n",
      "|    std                | 3.21         |\n",
      "|    value_loss         | 4.49e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1358007.2737611781\n",
      "Sharpe:  0.4051810407488541\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | -4.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -0.152      |\n",
      "|    reward             | 0.018941103 |\n",
      "|    std                | 3.35        |\n",
      "|    value_loss         | 5.64e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | -2.85        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | -0.0644      |\n",
      "|    reward             | 0.0006141852 |\n",
      "|    std                | 3.5          |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:946210.3579053864\n",
      "Sharpe:  0.041370424491112466\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | -2.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | -0.019557517 |\n",
      "|    std                | 3.66         |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 165          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | -0.0309      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | 0.0054814196 |\n",
      "|    std                | 3.83         |\n",
      "|    value_loss         | 8.2e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 169           |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.3         |\n",
      "|    explained_variance | 0.487         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 0.896         |\n",
      "|    reward             | -0.0017439721 |\n",
      "|    std                | 4.01          |\n",
      "|    value_loss         | 0.00143       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:947868.6149244021\n",
      "Sharpe:  0.05063061254922383\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.0952      |\n",
      "|    reward             | 0.016556503 |\n",
      "|    std                | 4.17        |\n",
      "|    value_loss         | 1.59e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1206190.3084079528\n",
      "Sharpe:  1.55836183716544\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | -2.04        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 0.213        |\n",
      "|    reward             | -0.008800977 |\n",
      "|    std                | 4.37         |\n",
      "|    value_loss         | 0.000352     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.4       |\n",
      "|    explained_variance | -2.84       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.874       |\n",
      "|    reward             | 0.008828829 |\n",
      "|    std                | 4.56        |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1275953.902045204\n",
      "Sharpe:  0.37538909799107884\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0.667        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.0792      |\n",
      "|    reward             | -0.011250038 |\n",
      "|    std                | 4.76         |\n",
      "|    value_loss         | 2.14e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:855576.0170015162\n",
      "Sharpe:  -0.3803549236595261\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 115            |\n",
      "|    iterations         | 4400           |\n",
      "|    time_elapsed       | 190            |\n",
      "|    total_timesteps    | 22000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -27.2          |\n",
      "|    explained_variance | 0.421          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4399           |\n",
      "|    policy_loss        | -0.266         |\n",
      "|    reward             | -0.00044512638 |\n",
      "|    std                | 4.96           |\n",
      "|    value_loss         | 0.00025        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:829792.3850123528\n",
      "Sharpe:  -0.25488513521798517\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | -0.0379      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.254        |\n",
      "|    reward             | -0.004360157 |\n",
      "|    std                | 5.17         |\n",
      "|    value_loss         | 0.000624     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783481.1238623501\n",
      "Sharpe:  -0.5689494451774698\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | -0.225       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.321        |\n",
      "|    reward             | 0.0025289052 |\n",
      "|    std                | 5.41         |\n",
      "|    value_loss         | 0.000146     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | -2.47       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -0.344      |\n",
      "|    reward             | 0.007902648 |\n",
      "|    std                | 5.67        |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | 0.311         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | -0.0683       |\n",
      "|    reward             | 0.00024129749 |\n",
      "|    std                | 5.9           |\n",
      "|    value_loss         | 1.42e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1029243.9483951154\n",
      "Sharpe:  0.12394674845096434\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | -0.698      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 0.0021      |\n",
      "|    reward             | 0.003307343 |\n",
      "|    std                | 6.14        |\n",
      "|    value_loss         | 4.87e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1157611.0404681873\n",
      "Sharpe:  0.29806166053704647\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 216           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | -0.409        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | -0.276        |\n",
      "|    reward             | -0.0062087514 |\n",
      "|    std                | 6.41          |\n",
      "|    value_loss         | 0.000221      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 220          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | -31.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0046854415 |\n",
      "|    std                | 6.7          |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 224          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | -0.476       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.31        |\n",
      "|    reward             | 0.0006867831 |\n",
      "|    std                | 7.01         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | -3.34        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0941      |\n",
      "|    reward             | 0.0010852945 |\n",
      "|    std                | 7.31         |\n",
      "|    value_loss         | 5.97e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1193700.5954865755\n",
      "Sharpe:  0.24709448033223605\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | -25.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.466        |\n",
      "|    reward             | 0.0010951142 |\n",
      "|    std                | 7.64         |\n",
      "|    value_loss         | 0.000246     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0.0711       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.0112      |\n",
      "|    reward             | -0.005592306 |\n",
      "|    std                | 7.99         |\n",
      "|    value_loss         | 1.17e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1100009.9016292216\n",
      "Sharpe:  0.18866420150983712\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | -2.1         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.303       |\n",
      "|    reward             | -0.007616959 |\n",
      "|    std                | 8.36         |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:822454.647410699\n",
      "Sharpe:  -0.31732261953592733\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -0.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | -1.17        |\n",
      "|    reward             | -0.013841807 |\n",
      "|    std                | 8.66         |\n",
      "|    value_loss         | 0.00148      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 5800          |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 29000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | 0.516         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5799          |\n",
      "|    policy_loss        | 0.333         |\n",
      "|    reward             | -0.0027042734 |\n",
      "|    std                | 9.02          |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 254           |\n",
      "|    total_timesteps    | 29500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33           |\n",
      "|    explained_variance | -1.48         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5899          |\n",
      "|    policy_loss        | 2.09          |\n",
      "|    reward             | 0.00018363466 |\n",
      "|    std                | 9.42          |\n",
      "|    value_loss         | 0.00428       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.3         |\n",
      "|    explained_variance | -0.0214       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5999          |\n",
      "|    policy_loss        | 0.125         |\n",
      "|    reward             | -0.0029134892 |\n",
      "|    std                | 9.8           |\n",
      "|    value_loss         | 8.21e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1064273.9537968505\n",
      "Sharpe:  0.1474706457588029\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0.566       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.421      |\n",
      "|    reward             | 0.010573662 |\n",
      "|    std                | 10.2        |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 268           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | -0.445        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.0557        |\n",
      "|    reward             | -0.0050270907 |\n",
      "|    std                | 10.6          |\n",
      "|    value_loss         | 0.000109      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | -1.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.0573       |\n",
      "|    reward             | -0.003042553 |\n",
      "|    std                | 11.1         |\n",
      "|    value_loss         | 0.000215     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1064081.9756705018\n",
      "Sharpe:  0.15157826829701182\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.8        |\n",
      "|    explained_variance | -0.0825      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.742        |\n",
      "|    reward             | -0.024455728 |\n",
      "|    std                | 11.6         |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:882688.2704563858\n",
      "Sharpe:  -0.12650660787951332\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 281           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | -19.6         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | -0.0453       |\n",
      "|    reward             | -0.0024985687 |\n",
      "|    std                | 12            |\n",
      "|    value_loss         | 3.66e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:864299.3877175949\n",
      "Sharpe:  -0.2391305733708996\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1075878.0873571022\n",
      "Sharpe:  1.216486248203664\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1092378.0716864597\n",
      "Sharpe:  0.6758923644127611\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0.305        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -3.75        |\n",
      "|    reward             | -0.008493663 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 0.0134       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1174067.7547559529\n",
      "Sharpe:  3.0722327997202012\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0.757       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.78       |\n",
      "|    reward             | 0.009409787 |\n",
      "|    std                | 13.1        |\n",
      "|    value_loss         | 0.00067     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:860003.0164590578\n",
      "Sharpe:  -0.26061361625126767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.3        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.144        |\n",
      "|    reward             | -0.008685337 |\n",
      "|    std                | 13.7         |\n",
      "|    value_loss         | 1.95e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:972592.7721339841\n",
      "Sharpe:  0.05625174344023814\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 298          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | -10.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -0.692       |\n",
      "|    reward             | -0.007853326 |\n",
      "|    std                | 14.3         |\n",
      "|    value_loss         | 0.000424     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.1        |\n",
      "|    explained_variance | -0.38        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.524       |\n",
      "|    reward             | -0.011791137 |\n",
      "|    std                | 14.9         |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:907599.8667391926\n",
      "Sharpe:  -0.004739706168076939\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 306           |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.5         |\n",
      "|    explained_variance | 0.421         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | -0.637        |\n",
      "|    reward             | -0.0005482225 |\n",
      "|    std                | 15.6          |\n",
      "|    value_loss         | 0.000356      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | -2.66       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 0.83        |\n",
      "|    reward             | 0.002826757 |\n",
      "|    std                | 16.2        |\n",
      "|    value_loss         | 0.000573    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.2       |\n",
      "|    explained_variance | -0.262      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | 0.011551008 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 7.33e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:871745.8984282129\n",
      "Sharpe:  -0.0492892175583325\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 115            |\n",
      "|    iterations         | 7400           |\n",
      "|    time_elapsed       | 319            |\n",
      "|    total_timesteps    | 37000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -38.6          |\n",
      "|    explained_variance | -7.15          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7399           |\n",
      "|    policy_loss        | -0.427         |\n",
      "|    reward             | -0.00023299371 |\n",
      "|    std                | 17.7           |\n",
      "|    value_loss         | 0.000195       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39          |\n",
      "|    explained_variance | -6.43        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 0.87         |\n",
      "|    reward             | 0.0009367771 |\n",
      "|    std                | 18.4         |\n",
      "|    value_loss         | 0.000577     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 115            |\n",
      "|    iterations         | 7600           |\n",
      "|    time_elapsed       | 328            |\n",
      "|    total_timesteps    | 38000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -39.4          |\n",
      "|    explained_variance | -0.274         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7599           |\n",
      "|    policy_loss        | -0.145         |\n",
      "|    reward             | -0.00015101035 |\n",
      "|    std                | 19.2           |\n",
      "|    value_loss         | 2.92e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:868226.9033910224\n",
      "Sharpe:  -0.046174467138961006\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.7        |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | 0.0017717162 |\n",
      "|    std                | 20           |\n",
      "|    value_loss         | 0.000736     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.1        |\n",
      "|    explained_variance | -18.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.0665       |\n",
      "|    reward             | 0.0021567722 |\n",
      "|    std                | 20.9         |\n",
      "|    value_loss         | 8.23e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:810631.8149954485\n",
      "Sharpe:  -0.18163522268981544\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 341          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.5        |\n",
      "|    explained_variance | 0.718        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.0581      |\n",
      "|    reward             | -0.006024828 |\n",
      "|    std                | 21.8         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 345           |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.9         |\n",
      "|    explained_variance | -3.45         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | -0.282        |\n",
      "|    reward             | -0.0020474338 |\n",
      "|    std                | 22.8          |\n",
      "|    value_loss         | 6.79e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:694081.5802710387\n",
      "Sharpe:  -0.2753046474399445\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.3        |\n",
      "|    explained_variance | -7.42        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | 0.0015154724 |\n",
      "|    std                | 23.7         |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.6       |\n",
      "|    explained_variance | -0.99       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -0.14       |\n",
      "|    reward             | 0.002211276 |\n",
      "|    std                | 24.7        |\n",
      "|    value_loss         | 9.01e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 357          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42          |\n",
      "|    explained_variance | -8.34        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.188       |\n",
      "|    reward             | -0.010464372 |\n",
      "|    std                | 25.7         |\n",
      "|    value_loss         | 4.66e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:702282.9884464301\n",
      "Sharpe:  -0.34761450888715495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1096927.3004098623\n",
      "Sharpe:  0.744005193902518\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0.393       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -0.319      |\n",
      "|    reward             | 0.009301654 |\n",
      "|    std                | 26.8        |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 366           |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | -13.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -0.829        |\n",
      "|    reward             | -0.0027988998 |\n",
      "|    std                | 27.9          |\n",
      "|    value_loss         | 0.000462      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1113382.540874515\n",
      "Sharpe:  0.21268755402282974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | -5.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | 0.0012061095 |\n",
      "|    std                | 29.1         |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.4        |\n",
      "|    explained_variance | -0.0702      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.0473      |\n",
      "|    reward             | 0.0065147174 |\n",
      "|    std                | 30.2         |\n",
      "|    value_loss         | 2.01e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:664720.5170252244\n",
      "Sharpe:  -0.43775824287051107\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.8       |\n",
      "|    explained_variance | 0.332       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 1.13        |\n",
      "|    reward             | 0.014308008 |\n",
      "|    std                | 31.6        |\n",
      "|    value_loss         | 0.0008      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1057172.4619862859\n",
      "Sharpe:  0.48481471329914233\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.2         |\n",
      "|    explained_variance | -0.097        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.729        |\n",
      "|    reward             | 0.00071726355 |\n",
      "|    std                | 33.1          |\n",
      "|    value_loss         | 0.000294      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 387         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.6       |\n",
      "|    explained_variance | 0.152       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.157      |\n",
      "|    reward             | 0.008134127 |\n",
      "|    std                | 34.4        |\n",
      "|    value_loss         | 6.04e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:600253.016464961\n",
      "Sharpe:  -0.44183758167267034\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 391          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45          |\n",
      "|    explained_variance | -1.59        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -1.61        |\n",
      "|    reward             | -0.009651943 |\n",
      "|    std                | 35.8         |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.4        |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | 0.0018363146 |\n",
      "|    std                | 37.5         |\n",
      "|    value_loss         | 0.000434     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:479636.2000496524\n",
      "Sharpe:  -1.0409390666530647\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 400          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.7        |\n",
      "|    explained_variance | -3.51        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.0653      |\n",
      "|    reward             | 0.0015980523 |\n",
      "|    std                | 39           |\n",
      "|    value_loss         | 2.7e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:494710.28071142547\n",
      "Sharpe:  -0.7982177790237085\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.1        |\n",
      "|    explained_variance | -1.24        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -1.54        |\n",
      "|    reward             | 0.0030669263 |\n",
      "|    std                | 40.6         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.5       |\n",
      "|    explained_variance | 0.0997      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.346      |\n",
      "|    reward             | 0.011575425 |\n",
      "|    std                | 42.5        |\n",
      "|    value_loss         | 7.74e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 413         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.9       |\n",
      "|    explained_variance | 0.786       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.106       |\n",
      "|    reward             | 0.007116728 |\n",
      "|    std                | 44.3        |\n",
      "|    value_loss         | 5.85e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:652470.098078442\n",
      "Sharpe:  -0.2784470302701714\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.3        |\n",
      "|    explained_variance | 0.601        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 1.35         |\n",
      "|    reward             | -0.001472958 |\n",
      "|    std                | 46.3         |\n",
      "|    value_loss         | 0.000877     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1115520.8825175927\n",
      "Sharpe:  0.5563035712076134\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 421           |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.6         |\n",
      "|    explained_variance | -3.14         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | -0.199        |\n",
      "|    reward             | -0.0046517677 |\n",
      "|    std                | 48.2          |\n",
      "|    value_loss         | 3.53e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48           |\n",
      "|    explained_variance | -13.7         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | -1.17         |\n",
      "|    reward             | -0.0029334873 |\n",
      "|    std                | 50.2          |\n",
      "|    value_loss         | 0.000647      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757617.0827274476\n",
      "Sharpe:  -0.4054516287860726\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 429           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.4         |\n",
      "|    explained_variance | -5.15         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -0.598        |\n",
      "|    reward             | -0.0035632972 |\n",
      "|    std                | 52.5          |\n",
      "|    value_loss         | 0.000299      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:662996.9347053687\n",
      "Sharpe:  -0.7887274772955327\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 10100       |\n",
      "|    time_elapsed       | 434         |\n",
      "|    total_timesteps    | 50500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.7       |\n",
      "|    explained_variance | -4.15       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -0.532      |\n",
      "|    reward             | 0.002185687 |\n",
      "|    std                | 54.5        |\n",
      "|    value_loss         | 0.000155    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:679998.5162878803\n",
      "Sharpe:  -0.7538903316530355\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 10200         |\n",
      "|    time_elapsed       | 438           |\n",
      "|    total_timesteps    | 51000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.1         |\n",
      "|    explained_variance | -0.493        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10199         |\n",
      "|    policy_loss        | -0.886        |\n",
      "|    reward             | -0.0054499432 |\n",
      "|    std                | 57            |\n",
      "|    value_loss         | 0.000334      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 10300        |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 51500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.5        |\n",
      "|    explained_variance | -0.434       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -0.329       |\n",
      "|    reward             | -0.036108207 |\n",
      "|    std                | 59.4         |\n",
      "|    value_loss         | 6.85e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 10400        |\n",
      "|    time_elapsed       | 446          |\n",
      "|    total_timesteps    | 52000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.9        |\n",
      "|    explained_variance | 0.33         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | -0.474       |\n",
      "|    reward             | -0.080080524 |\n",
      "|    std                | 61.9         |\n",
      "|    value_loss         | 0.000267     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:675564.7255006041\n",
      "Sharpe:  -0.22816062889706404\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 10500         |\n",
      "|    time_elapsed       | 451           |\n",
      "|    total_timesteps    | 52500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.2         |\n",
      "|    explained_variance | 0.105         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10499         |\n",
      "|    policy_loss        | 1.8           |\n",
      "|    reward             | -0.0009944856 |\n",
      "|    std                | 64.4          |\n",
      "|    value_loss         | 0.00327       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 455         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.6       |\n",
      "|    explained_variance | -16.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -0.153      |\n",
      "|    reward             | 0.004684593 |\n",
      "|    std                | 67          |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:680599.8099407394\n",
      "Sharpe:  -0.35220272751144666\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 459          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.9        |\n",
      "|    explained_variance | 0.248        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | -8.29        |\n",
      "|    reward             | 0.0002840177 |\n",
      "|    std                | 69.5         |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:474265.306155213\n",
      "Sharpe:  -2.440862798646854\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 10800        |\n",
      "|    time_elapsed       | 464          |\n",
      "|    total_timesteps    | 54000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.3        |\n",
      "|    explained_variance | -1.52        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | 0.011        |\n",
      "|    reward             | 0.0015007812 |\n",
      "|    std                | 72.2         |\n",
      "|    value_loss         | 4.74e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.6       |\n",
      "|    explained_variance | -1.48       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | 0.0098      |\n",
      "|    reward             | 0.010503471 |\n",
      "|    std                | 75.1        |\n",
      "|    value_loss         | 9.05e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:481535.2261722104\n",
      "Sharpe:  -0.7487106137209262\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493337.23632136587\n",
      "Sharpe:  -1.981310459956649\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 473          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52          |\n",
      "|    explained_variance | -5.23        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | 0.21         |\n",
      "|    reward             | -0.004997863 |\n",
      "|    std                | 78.2         |\n",
      "|    value_loss         | 6.51e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11100        |\n",
      "|    time_elapsed       | 477          |\n",
      "|    total_timesteps    | 55500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.4        |\n",
      "|    explained_variance | -0.223       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -0.733       |\n",
      "|    reward             | 0.0056245257 |\n",
      "|    std                | 81.5         |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:625666.5395769658\n",
      "Sharpe:  -0.5241676448426029\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11200        |\n",
      "|    time_elapsed       | 481          |\n",
      "|    total_timesteps    | 56000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.7        |\n",
      "|    explained_variance | 0.214        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | 2.15         |\n",
      "|    reward             | 0.0068999873 |\n",
      "|    std                | 84.8         |\n",
      "|    value_loss         | 0.00169      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.1       |\n",
      "|    explained_variance | -0.771      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -0.149      |\n",
      "|    reward             | 0.008558663 |\n",
      "|    std                | 88.5        |\n",
      "|    value_loss         | 1.34e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 11400         |\n",
      "|    time_elapsed       | 489           |\n",
      "|    total_timesteps    | 57000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.5         |\n",
      "|    explained_variance | -0.479        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11399         |\n",
      "|    policy_loss        | -1.51         |\n",
      "|    reward             | -0.0002981387 |\n",
      "|    std                | 92.2          |\n",
      "|    value_loss         | 0.0011        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.8       |\n",
      "|    explained_variance | 0.234       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 0.352       |\n",
      "|    reward             | 0.007594467 |\n",
      "|    std                | 96.2        |\n",
      "|    value_loss         | 4.84e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:882327.5855621924\n",
      "Sharpe:  -0.00010542038444864133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026392.8012745066\n",
      "Sharpe:  0.2883673082248563\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 497          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.2        |\n",
      "|    explained_variance | -3.06        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 0.0211       |\n",
      "|    reward             | 0.0039256304 |\n",
      "|    std                | 100          |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496493.2520922408\n",
      "Sharpe:  -1.1152370601821155\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11700        |\n",
      "|    time_elapsed       | 502          |\n",
      "|    total_timesteps    | 58500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.6        |\n",
      "|    explained_variance | -0.895       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | 0.584        |\n",
      "|    reward             | -0.025231719 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496368.15077876725\n",
      "Sharpe:  -1.9069106365677444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1132929.9584273098\n",
      "Sharpe:  1.9886533569387863\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 506          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.9        |\n",
      "|    explained_variance | 0.115        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | -0.474       |\n",
      "|    reward             | 0.0011339332 |\n",
      "|    std                | 109          |\n",
      "|    value_loss         | 9.72e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:616630.9709654395\n",
      "Sharpe:  -0.7528339313048438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1044099.1047743303\n",
      "Sharpe:  3.7034200939085977\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 11900       |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 59500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.3       |\n",
      "|    explained_variance | -2.72       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | 0.122       |\n",
      "|    reward             | -0.00078844 |\n",
      "|    std                | 113         |\n",
      "|    value_loss         | 5.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1089578.8639012128\n",
      "Sharpe:  1.7922027969172922\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12000        |\n",
      "|    time_elapsed       | 514          |\n",
      "|    total_timesteps    | 60000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.7        |\n",
      "|    explained_variance | 0.158        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | 2.03         |\n",
      "|    reward             | -0.015274329 |\n",
      "|    std                | 118          |\n",
      "|    value_loss         | 0.00146      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:606252.8537872286\n",
      "Sharpe:  -0.8267580921362052\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12100        |\n",
      "|    time_elapsed       | 519          |\n",
      "|    total_timesteps    | 60500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.1        |\n",
      "|    explained_variance | -0.681       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | 0.751        |\n",
      "|    reward             | 0.0061926967 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 12200         |\n",
      "|    time_elapsed       | 523           |\n",
      "|    total_timesteps    | 61000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.5         |\n",
      "|    explained_variance | 0.202         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12199         |\n",
      "|    policy_loss        | -1.19         |\n",
      "|    reward             | -0.0002927456 |\n",
      "|    std                | 129           |\n",
      "|    value_loss         | 0.000553      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498863.1512661694\n",
      "Sharpe:  -0.6753173329880238\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 527          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.9        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | -0.222       |\n",
      "|    reward             | 0.0151490625 |\n",
      "|    std                | 135          |\n",
      "|    value_loss         | 2.43e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1006709.6169330545\n",
      "Sharpe:  0.12807000268989438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1098584.616359118\n",
      "Sharpe:  1.8994901996207376\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 12400       |\n",
      "|    time_elapsed       | 532         |\n",
      "|    total_timesteps    | 62000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.3       |\n",
      "|    explained_variance | -0.774      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | -0.535      |\n",
      "|    reward             | -0.01831686 |\n",
      "|    std                | 141         |\n",
      "|    value_loss         | 0.00015     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.6        |\n",
      "|    explained_variance | -8.77        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | 0.775        |\n",
      "|    reward             | -0.018974941 |\n",
      "|    std                | 147          |\n",
      "|    value_loss         | 0.000197     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:675532.919359466\n",
      "Sharpe:  -0.39279517415305265\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 12600         |\n",
      "|    time_elapsed       | 540           |\n",
      "|    total_timesteps    | 63000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58           |\n",
      "|    explained_variance | 0.493         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | -0.576        |\n",
      "|    reward             | -0.0040803007 |\n",
      "|    std                | 153           |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:924285.1058456164\n",
      "Sharpe:  -0.3028501173534658\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12700        |\n",
      "|    time_elapsed       | 544          |\n",
      "|    total_timesteps    | 63500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.4        |\n",
      "|    explained_variance | -0.194       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12699        |\n",
      "|    policy_loss        | -0.965       |\n",
      "|    reward             | -0.012749755 |\n",
      "|    std                | 160          |\n",
      "|    value_loss         | 0.000349     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12800        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 64000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.8        |\n",
      "|    explained_variance | -0.0814      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | 0.144        |\n",
      "|    reward             | -0.008554631 |\n",
      "|    std                | 167          |\n",
      "|    value_loss         | 4.13e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 553          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.2        |\n",
      "|    explained_variance | 0.669        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | -0.014104738 |\n",
      "|    std                | 174          |\n",
      "|    value_loss         | 1.72e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761410.2311863841\n",
      "Sharpe:  -0.11191428789820368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:484642.82592003414\n",
      "Sharpe:  -3.1750027119802313\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 13000         |\n",
      "|    time_elapsed       | 557           |\n",
      "|    total_timesteps    | 65000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.6         |\n",
      "|    explained_variance | -0.0497       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12999         |\n",
      "|    policy_loss        | -1.66         |\n",
      "|    reward             | -0.0062722806 |\n",
      "|    std                | 182           |\n",
      "|    value_loss         | 0.000853      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 561         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.9       |\n",
      "|    explained_variance | 0.22        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | 0.988       |\n",
      "|    reward             | 0.004584492 |\n",
      "|    std                | 188         |\n",
      "|    value_loss         | 0.000329    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:849967.1678192813\n",
      "Sharpe:  -0.1106741471330745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 13200         |\n",
      "|    time_elapsed       | 565           |\n",
      "|    total_timesteps    | 66000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -60.2         |\n",
      "|    explained_variance | 0.725         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13199         |\n",
      "|    policy_loss        | 0.635         |\n",
      "|    reward             | -0.0026083174 |\n",
      "|    std                | 195           |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:700977.6020039713\n",
      "Sharpe:  -0.5374718499664741\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 569         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.6       |\n",
      "|    explained_variance | -1.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | -2.28       |\n",
      "|    reward             | 0.007991997 |\n",
      "|    std                | 203         |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:899212.02533782\n",
      "Sharpe:  -0.6501567800857045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1044413.7767763855\n",
      "Sharpe:  2.8355214719249604\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 13400         |\n",
      "|    time_elapsed       | 574           |\n",
      "|    total_timesteps    | 67000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -61           |\n",
      "|    explained_variance | -0.594        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13399         |\n",
      "|    policy_loss        | 0.368         |\n",
      "|    reward             | -0.0026994126 |\n",
      "|    std                | 212           |\n",
      "|    value_loss         | 4.65e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 13500         |\n",
      "|    time_elapsed       | 578           |\n",
      "|    total_timesteps    | 67500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -61.3         |\n",
      "|    explained_variance | -3.11         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13499         |\n",
      "|    policy_loss        | 0.291         |\n",
      "|    reward             | -0.0013013148 |\n",
      "|    std                | 221           |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 13600        |\n",
      "|    time_elapsed       | 582          |\n",
      "|    total_timesteps    | 68000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.7        |\n",
      "|    explained_variance | 0.335        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | -0.341       |\n",
      "|    reward             | -0.001088168 |\n",
      "|    std                | 231          |\n",
      "|    value_loss         | 4.15e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:656231.8952510053\n",
      "Sharpe:  -0.3516888377119218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 13700         |\n",
      "|    time_elapsed       | 587           |\n",
      "|    total_timesteps    | 68500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.1         |\n",
      "|    explained_variance | -0.283        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | -0.854        |\n",
      "|    reward             | -0.0042847525 |\n",
      "|    std                | 240           |\n",
      "|    value_loss         | 0.000371      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:674081.8133752844\n",
      "Sharpe:  -0.5610005417074123\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 13800        |\n",
      "|    time_elapsed       | 591          |\n",
      "|    total_timesteps    | 69000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.5        |\n",
      "|    explained_variance | -2.32        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | -0.335       |\n",
      "|    reward             | 0.0017293255 |\n",
      "|    std                | 250          |\n",
      "|    value_loss         | 4.13e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:855971.5419926279\n",
      "Sharpe:  -0.7617616861151192\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 13900        |\n",
      "|    time_elapsed       | 596          |\n",
      "|    total_timesteps    | 69500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.8        |\n",
      "|    explained_variance | -7.64        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | 0.791        |\n",
      "|    reward             | -0.003992352 |\n",
      "|    std                | 261          |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 14000         |\n",
      "|    time_elapsed       | 600           |\n",
      "|    total_timesteps    | 70000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -63.2         |\n",
      "|    explained_variance | -1.61         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13999         |\n",
      "|    policy_loss        | 0.492         |\n",
      "|    reward             | -0.0022196982 |\n",
      "|    std                | 272           |\n",
      "|    value_loss         | 7.68e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:476708.14410736656\n",
      "Sharpe:  -0.7284039878291312\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 604         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.6       |\n",
      "|    explained_variance | -9.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | 0.014286228 |\n",
      "|    std                | 284         |\n",
      "|    value_loss         | 0.000307    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 116            |\n",
      "|    iterations         | 14200          |\n",
      "|    time_elapsed       | 608            |\n",
      "|    total_timesteps    | 71000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64            |\n",
      "|    explained_variance | 0.23           |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 14199          |\n",
      "|    policy_loss        | -0.457         |\n",
      "|    reward             | -0.00073909527 |\n",
      "|    std                | 296            |\n",
      "|    value_loss         | 7.35e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:574453.9183124732\n",
      "Sharpe:  -0.54272106134663\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 14300        |\n",
      "|    time_elapsed       | 612          |\n",
      "|    total_timesteps    | 71500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.3        |\n",
      "|    explained_variance | 0.569        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 0.697        |\n",
      "|    reward             | 0.0033662627 |\n",
      "|    std                | 308          |\n",
      "|    value_loss         | 0.000144     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493979.11673208\n",
      "Sharpe:  -1.6637631084804931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1048469.7583219041\n",
      "Sharpe:  0.4159095083572868\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.7        |\n",
      "|    explained_variance | -0.065       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | -1.23        |\n",
      "|    reward             | -0.009228881 |\n",
      "|    std                | 321          |\n",
      "|    value_loss         | 0.000428     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 14500       |\n",
      "|    time_elapsed       | 621         |\n",
      "|    total_timesteps    | 72500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65         |\n",
      "|    explained_variance | -0.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | 0.004098833 |\n",
      "|    std                | 334         |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:661132.3510747163\n",
      "Sharpe:  -0.7524020749332\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 14600         |\n",
      "|    time_elapsed       | 625           |\n",
      "|    total_timesteps    | 73000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -65.4         |\n",
      "|    explained_variance | -0.17         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14599         |\n",
      "|    policy_loss        | -1.15         |\n",
      "|    reward             | -0.0066330475 |\n",
      "|    std                | 347           |\n",
      "|    value_loss         | 0.000967      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:613821.7231063723\n",
      "Sharpe:  -0.6066029876854561\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 629         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.7       |\n",
      "|    explained_variance | -4.19       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 0.825       |\n",
      "|    reward             | 0.002969471 |\n",
      "|    std                | 361         |\n",
      "|    value_loss         | 0.000237    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.1       |\n",
      "|    explained_variance | -4.74       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.22        |\n",
      "|    reward             | -0.01445874 |\n",
      "|    std                | 375         |\n",
      "|    value_loss         | 0.000341    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:482678.51216150494\n",
      "Sharpe:  -1.024317881356124\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 638          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.5        |\n",
      "|    explained_variance | -0.0419      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | -0.725       |\n",
      "|    reward             | -0.003653483 |\n",
      "|    std                | 392          |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 15000         |\n",
      "|    time_elapsed       | 642           |\n",
      "|    total_timesteps    | 75000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.9         |\n",
      "|    explained_variance | 0.25          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -0.354        |\n",
      "|    reward             | -0.0022484208 |\n",
      "|    std                | 408           |\n",
      "|    value_loss         | 5.04e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 15100         |\n",
      "|    time_elapsed       | 646           |\n",
      "|    total_timesteps    | 75500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.2         |\n",
      "|    explained_variance | 0.345         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15099         |\n",
      "|    policy_loss        | 0.355         |\n",
      "|    reward             | -0.0009445155 |\n",
      "|    std                | 425           |\n",
      "|    value_loss         | 8.34e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:686110.5472928707\n",
      "Sharpe:  -0.27055765975684193\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:966717.9657800113\n",
      "Sharpe:  -0.17601611394211017\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 15200       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 76000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.6       |\n",
      "|    explained_variance | -0.513      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | -0.647      |\n",
      "|    reward             | 0.037189238 |\n",
      "|    std                | 445         |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764902.7099394491\n",
      "Sharpe:  -0.39744684994910484\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 15300         |\n",
      "|    time_elapsed       | 655           |\n",
      "|    total_timesteps    | 76500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -68           |\n",
      "|    explained_variance | -0.686        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15299         |\n",
      "|    policy_loss        | -1.76         |\n",
      "|    reward             | -0.0010296121 |\n",
      "|    std                | 465           |\n",
      "|    value_loss         | 0.000857      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 15400       |\n",
      "|    time_elapsed       | 660         |\n",
      "|    total_timesteps    | 77000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.4       |\n",
      "|    explained_variance | 0.587       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | 0.157       |\n",
      "|    reward             | -0.02263292 |\n",
      "|    std                | 483         |\n",
      "|    value_loss         | 4.14e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:575550.8773785577\n",
      "Sharpe:  -0.6472084522411196\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 15500       |\n",
      "|    time_elapsed       | 664         |\n",
      "|    total_timesteps    | 77500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.8       |\n",
      "|    explained_variance | 0.238       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15499       |\n",
      "|    policy_loss        | -0.0848     |\n",
      "|    reward             | 0.004653424 |\n",
      "|    std                | 505         |\n",
      "|    value_loss         | 0.000108    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493073.0132720416\n",
      "Sharpe:  -1.8033208813230184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 15600         |\n",
      "|    time_elapsed       | 668           |\n",
      "|    total_timesteps    | 78000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.1         |\n",
      "|    explained_variance | -0.236        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15599         |\n",
      "|    policy_loss        | -0.518        |\n",
      "|    reward             | -0.0069090677 |\n",
      "|    std                | 525           |\n",
      "|    value_loss         | 9.32e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 672          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.5        |\n",
      "|    explained_variance | 0.403        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | 0.24         |\n",
      "|    reward             | -0.007448156 |\n",
      "|    std                | 548          |\n",
      "|    value_loss         | 2.22e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499273.50256341463\n",
      "Sharpe:  -0.5509143015861914\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.9        |\n",
      "|    explained_variance | -66.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | 0.82         |\n",
      "|    reward             | 0.0013147211 |\n",
      "|    std                | 570          |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 15900        |\n",
      "|    time_elapsed       | 681          |\n",
      "|    total_timesteps    | 79500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.2        |\n",
      "|    explained_variance | -6.89        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15899        |\n",
      "|    policy_loss        | -0.0181      |\n",
      "|    reward             | 0.0005107411 |\n",
      "|    std                | 591          |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497169.6432911707\n",
      "Sharpe:  -0.9294235085475561\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 16000         |\n",
      "|    time_elapsed       | 685           |\n",
      "|    total_timesteps    | 80000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -70.5         |\n",
      "|    explained_variance | -0.144        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15999         |\n",
      "|    policy_loss        | 0.549         |\n",
      "|    reward             | 0.00012226634 |\n",
      "|    std                | 615           |\n",
      "|    value_loss         | 6.13e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16100        |\n",
      "|    time_elapsed       | 690          |\n",
      "|    total_timesteps    | 80500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.9        |\n",
      "|    explained_variance | -3.73        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | -2.01        |\n",
      "|    reward             | 0.0029461244 |\n",
      "|    std                | 642          |\n",
      "|    value_loss         | 0.000883     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16200        |\n",
      "|    time_elapsed       | 694          |\n",
      "|    total_timesteps    | 81000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.3        |\n",
      "|    explained_variance | -15.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | -0.468       |\n",
      "|    reward             | 0.0071079494 |\n",
      "|    std                | 670          |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:702772.5339654263\n",
      "Sharpe:  -0.2760809133722087\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 698          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.7        |\n",
      "|    explained_variance | -0.032       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | 0.294        |\n",
      "|    reward             | 0.0039046777 |\n",
      "|    std                | 701          |\n",
      "|    value_loss         | 6.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:620466.0325366578\n",
      "Sharpe:  -0.515392391658434\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 16400       |\n",
      "|    time_elapsed       | 702         |\n",
      "|    total_timesteps    | 82000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.1       |\n",
      "|    explained_variance | -1.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -1.33       |\n",
      "|    reward             | 0.001852183 |\n",
      "|    std                | 731         |\n",
      "|    value_loss         | 0.000412    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16500        |\n",
      "|    time_elapsed       | 707          |\n",
      "|    total_timesteps    | 82500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.5        |\n",
      "|    explained_variance | 0.192        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | 0.0758       |\n",
      "|    reward             | 0.0015058236 |\n",
      "|    std                | 762          |\n",
      "|    value_loss         | 7.72e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:712247.7341859431\n",
      "Sharpe:  -0.342781200451925\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16600        |\n",
      "|    time_elapsed       | 711          |\n",
      "|    total_timesteps    | 83000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.9        |\n",
      "|    explained_variance | -0.301       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | 0.71         |\n",
      "|    reward             | -0.010938815 |\n",
      "|    std                | 796          |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726977.3547899157\n",
      "Sharpe:  -0.5973532307838905\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 715          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.3        |\n",
      "|    explained_variance | -1.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | -0.733       |\n",
      "|    reward             | -0.005395082 |\n",
      "|    std                | 834          |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:717816.6658733404\n",
      "Sharpe:  -0.5759378118726785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 16800         |\n",
      "|    time_elapsed       | 720           |\n",
      "|    total_timesteps    | 84000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.7         |\n",
      "|    explained_variance | -0.301        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16799         |\n",
      "|    policy_loss        | 0.591         |\n",
      "|    reward             | -0.0019645896 |\n",
      "|    std                | 871           |\n",
      "|    value_loss         | 7.18e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 725         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -74.1       |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.137      |\n",
      "|    reward             | 0.008119265 |\n",
      "|    std                | 910         |\n",
      "|    value_loss         | 3.79e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 729          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.5        |\n",
      "|    explained_variance | -1.16        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | -0.008674016 |\n",
      "|    std                | 951          |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496316.93967345695\n",
      "Sharpe:  -0.6216549029539996\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 733           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.9         |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.583         |\n",
      "|    reward             | -0.0077314186 |\n",
      "|    std                | 993           |\n",
      "|    value_loss         | 6.72e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771295.7850707986\n",
      "Sharpe:  -0.36440172898261913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17200         |\n",
      "|    time_elapsed       | 737           |\n",
      "|    total_timesteps    | 86000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -75.2         |\n",
      "|    explained_variance | 0.252         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17199         |\n",
      "|    policy_loss        | -1.13         |\n",
      "|    reward             | -0.0013925682 |\n",
      "|    std                | 1.04e+03      |\n",
      "|    value_loss         | 0.000301      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1015118.7804396237\n",
      "Sharpe:  0.33274398737611777\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17300        |\n",
      "|    time_elapsed       | 742          |\n",
      "|    total_timesteps    | 86500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.6        |\n",
      "|    explained_variance | 0.109        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17299        |\n",
      "|    policy_loss        | -0.289       |\n",
      "|    reward             | -0.019256847 |\n",
      "|    std                | 1.08e+03     |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 746         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76         |\n",
      "|    explained_variance | 0.0328      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | 3.75        |\n",
      "|    reward             | 0.008607043 |\n",
      "|    std                | 1.13e+03    |\n",
      "|    value_loss         | 0.00583     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:490759.7177137846\n",
      "Sharpe:  -0.6799822832984251\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 17500       |\n",
      "|    time_elapsed       | 751         |\n",
      "|    total_timesteps    | 87500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.4       |\n",
      "|    explained_variance | -0.959      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | -1.04       |\n",
      "|    reward             | 0.012116148 |\n",
      "|    std                | 1.18e+03    |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17600         |\n",
      "|    time_elapsed       | 755           |\n",
      "|    total_timesteps    | 88000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -76.8         |\n",
      "|    explained_variance | -0.268        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17599         |\n",
      "|    policy_loss        | -0.315        |\n",
      "|    reward             | -0.0032868371 |\n",
      "|    std                | 1.23e+03      |\n",
      "|    value_loss         | 4.57e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:477056.49157086556\n",
      "Sharpe:  -0.753098375796866\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1040519.7969688028\n",
      "Sharpe:  0.7639957572865759\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 759          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.2        |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | 0.0672       |\n",
      "|    reward             | -0.022912147 |\n",
      "|    std                | 1.29e+03     |\n",
      "|    value_loss         | 8.03e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:728767.5340797864\n",
      "Sharpe:  -0.5050899628107094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 763           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -77.5         |\n",
      "|    explained_variance | 0.255         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | -0.386        |\n",
      "|    reward             | -0.0024682612 |\n",
      "|    std                | 1.34e+03      |\n",
      "|    value_loss         | 5.03e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17900        |\n",
      "|    time_elapsed       | 767          |\n",
      "|    total_timesteps    | 89500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.9        |\n",
      "|    explained_variance | -2.36        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | -0.579       |\n",
      "|    reward             | 0.0022104285 |\n",
      "|    std                | 1.4e+03      |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:461824.14207590953\n",
      "Sharpe:  -1.1797446793689832\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.3        |\n",
      "|    explained_variance | 0.216        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | 0.406        |\n",
      "|    reward             | 0.0030107598 |\n",
      "|    std                | 1.46e+03     |\n",
      "|    value_loss         | 9.21e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:655218.0673505174\n",
      "Sharpe:  -0.8738572825948632\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18100        |\n",
      "|    time_elapsed       | 776          |\n",
      "|    total_timesteps    | 90500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.7        |\n",
      "|    explained_variance | -0.988       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | -0.954       |\n",
      "|    reward             | 0.0034119552 |\n",
      "|    std                | 1.53e+03     |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18200        |\n",
      "|    time_elapsed       | 780          |\n",
      "|    total_timesteps    | 91000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79.2        |\n",
      "|    explained_variance | 0.0847       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | -0.212       |\n",
      "|    reward             | -0.011538719 |\n",
      "|    std                | 1.6e+03      |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:583947.8533276306\n",
      "Sharpe:  -0.5555198584857353\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 785          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79.6        |\n",
      "|    explained_variance | 0.0133       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | 2.12         |\n",
      "|    reward             | 0.0038605263 |\n",
      "|    std                | 1.68e+03     |\n",
      "|    value_loss         | 0.000796     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:704655.2468604131\n",
      "Sharpe:  -1.001478249871507\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1114360.7651109882\n",
      "Sharpe:  0.7176347019766689\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 789          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79.9        |\n",
      "|    explained_variance | -0.0524      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | 0.0013347642 |\n",
      "|    std                | 1.75e+03     |\n",
      "|    value_loss         | 0.000302     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18500        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 92500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -80.3        |\n",
      "|    explained_variance | 0.65         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | 1.22         |\n",
      "|    reward             | 0.0068684076 |\n",
      "|    std                | 1.82e+03     |\n",
      "|    value_loss         | 0.000321     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498972.03618148755\n",
      "Sharpe:  -0.8253174888045661\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 18600       |\n",
      "|    time_elapsed       | 798         |\n",
      "|    total_timesteps    | 93000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80.7       |\n",
      "|    explained_variance | -0.54       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | -0.0374     |\n",
      "|    reward             | 0.006725192 |\n",
      "|    std                | 1.9e+03     |\n",
      "|    value_loss         | 1.44e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 18700         |\n",
      "|    time_elapsed       | 802           |\n",
      "|    total_timesteps    | 93500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81.1         |\n",
      "|    explained_variance | 0.415         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | -0.565        |\n",
      "|    reward             | -0.0072072563 |\n",
      "|    std                | 1.98e+03      |\n",
      "|    value_loss         | 9.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18800        |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 94000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -81.4        |\n",
      "|    explained_variance | 0.376        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18799        |\n",
      "|    policy_loss        | -0.664       |\n",
      "|    reward             | -0.027396515 |\n",
      "|    std                | 2.07e+03     |\n",
      "|    value_loss         | 9.18e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764515.4946272509\n",
      "Sharpe:  -0.13442298652734083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 18900         |\n",
      "|    time_elapsed       | 811           |\n",
      "|    total_timesteps    | 94500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81.8         |\n",
      "|    explained_variance | -1.72         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18899         |\n",
      "|    policy_loss        | 0.459         |\n",
      "|    reward             | -0.0070886426 |\n",
      "|    std                | 2.16e+03      |\n",
      "|    value_loss         | 0.000105      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755843.809009127\n",
      "Sharpe:  -0.33857894099645747\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19000         |\n",
      "|    time_elapsed       | 815           |\n",
      "|    total_timesteps    | 95000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -82.2         |\n",
      "|    explained_variance | -0.555        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18999         |\n",
      "|    policy_loss        | -0.906        |\n",
      "|    reward             | -0.0030100343 |\n",
      "|    std                | 2.25e+03      |\n",
      "|    value_loss         | 0.000137      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498711.3681750414\n",
      "Sharpe:  -2.3286759569667663\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:807467.7039610016\n",
      "Sharpe:  -0.6181641663961346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19100         |\n",
      "|    time_elapsed       | 819           |\n",
      "|    total_timesteps    | 95500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -82.5         |\n",
      "|    explained_variance | -5.34         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19099         |\n",
      "|    policy_loss        | -0.517        |\n",
      "|    reward             | -0.0021092505 |\n",
      "|    std                | 2.33e+03      |\n",
      "|    value_loss         | 7e-05         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:632421.9397583806\n",
      "Sharpe:  -1.0161803750342908\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19200         |\n",
      "|    time_elapsed       | 824           |\n",
      "|    total_timesteps    | 96000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -82.9         |\n",
      "|    explained_variance | -4.63         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19199         |\n",
      "|    policy_loss        | -0.387        |\n",
      "|    reward             | -0.0040263277 |\n",
      "|    std                | 2.44e+03      |\n",
      "|    value_loss         | 4.96e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19300         |\n",
      "|    time_elapsed       | 828           |\n",
      "|    total_timesteps    | 96500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -83.3         |\n",
      "|    explained_variance | -0.562        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | 1.1           |\n",
      "|    reward             | -0.0036232627 |\n",
      "|    std                | 2.55e+03      |\n",
      "|    value_loss         | 0.000621      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 832          |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -83.7        |\n",
      "|    explained_variance | -3.22        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | -0.888       |\n",
      "|    reward             | 0.0029976782 |\n",
      "|    std                | 2.66e+03     |\n",
      "|    value_loss         | 0.000358     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:469702.87569714914\n",
      "Sharpe:  -0.9854320142271984\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 837       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -84.1     |\n",
      "|    explained_variance | -3.21     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 1.36      |\n",
      "|    reward             | 0.0185462 |\n",
      "|    std                | 2.78e+03  |\n",
      "|    value_loss         | 0.000494  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:563200.6005890192\n",
      "Sharpe:  -0.8390164013932753\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19600         |\n",
      "|    time_elapsed       | 841           |\n",
      "|    total_timesteps    | 98000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -84.5         |\n",
      "|    explained_variance | -1.21         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19599         |\n",
      "|    policy_loss        | 1.5           |\n",
      "|    reward             | -0.0010051125 |\n",
      "|    std                | 2.9e+03       |\n",
      "|    value_loss         | 0.000528      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19700         |\n",
      "|    time_elapsed       | 846           |\n",
      "|    total_timesteps    | 98500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -84.9         |\n",
      "|    explained_variance | -8.04         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19699         |\n",
      "|    policy_loss        | -2.01         |\n",
      "|    reward             | -0.0028461423 |\n",
      "|    std                | 3.03e+03      |\n",
      "|    value_loss         | 0.000975      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:973386.8454764563\n",
      "Sharpe:  0.057649997381992446\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85.2       |\n",
      "|    explained_variance | -9.17       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | 0.005897289 |\n",
      "|    std                | 3.15e+03    |\n",
      "|    value_loss         | 0.000342    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19900        |\n",
      "|    time_elapsed       | 855          |\n",
      "|    total_timesteps    | 99500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -85.6        |\n",
      "|    explained_variance | 0.398        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | -0.233       |\n",
      "|    reward             | 0.0024082295 |\n",
      "|    std                | 3.29e+03     |\n",
      "|    value_loss         | 2.19e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498664.36922070314\n",
      "Sharpe:  -0.6905165511630862\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1125154.3749703236\n",
      "Sharpe:  1.562463812258735\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 20000        |\n",
      "|    time_elapsed       | 859          |\n",
      "|    total_timesteps    | 100000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86          |\n",
      "|    explained_variance | -7.91        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19999        |\n",
      "|    policy_loss        | -0.79        |\n",
      "|    reward             | 0.0047646854 |\n",
      "|    std                | 3.43e+03     |\n",
      "|    value_loss         | 0.000116     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1033292.0123153016\n",
      "Sharpe:  3.8331680874939065\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.0332920123153011 -0.01912261916057049 3.833168087493906\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495424.53082368866\n",
      "Sharpe:  -1.5551896847008695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:653728.530948714\n",
      "Sharpe:  -0.24163201816542934\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 158          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 12           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0010504258 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498915.56751732074\n",
      "Sharpe:  -1.023337273440418\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:851602.0871183821\n",
      "Sharpe:  -0.9205809778519459\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:728894.2635986041\n",
      "Sharpe:  -0.790205972145257\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:487364.5052485421\n",
      "Sharpe:  -1.2536980066358783\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.022893019   |\n",
      "|    clip_fraction        | 0.207         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -8.83         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.215        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0579       |\n",
      "|    reward               | 0.00014585016 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.069         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495604.8236955264\n",
      "Sharpe:  -0.852834853971358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:678065.5080424943\n",
      "Sharpe:  -0.24048356969625956\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.025305264  |\n",
      "|    clip_fraction        | 0.251        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.921       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.23        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0678      |\n",
      "|    reward               | 0.0024254327 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00736      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:481392.8256256499\n",
      "Sharpe:  -0.8056127280174449\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:711284.4780646109\n",
      "Sharpe:  -0.5259352446072797\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.028568372  |\n",
      "|    clip_fraction        | 0.285        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.251       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0701      |\n",
      "|    reward               | -0.004457087 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00347      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:853130.3088076356\n",
      "Sharpe:  -0.2749175994338674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1052954.1646904293\n",
      "Sharpe:  0.1450383735870814\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498876.865358501\n",
      "Sharpe:  -2.100040701308687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.031208463  |\n",
      "|    clip_fraction        | 0.325        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.226       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0723      |\n",
      "|    reward               | -0.008338769 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00151      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:705295.3093259461\n",
      "Sharpe:  -0.7911108003072111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:887900.4440655624\n",
      "Sharpe:  0.0032780650395884954\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 96            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.036507107   |\n",
      "|    clip_fraction        | 0.354         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.101         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.223        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.0686       |\n",
      "|    reward               | -0.0061925994 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00345       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:680274.3730503459\n",
      "Sharpe:  -0.2727830574831147\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493363.33386352204\n",
      "Sharpe:  -1.6537303870501452\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.038864758  |\n",
      "|    clip_fraction        | 0.372        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.227       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0778      |\n",
      "|    reward               | 0.0023162758 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00114      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:612380.2209626279\n",
      "Sharpe:  -0.2850869876918101\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:864060.5014880971\n",
      "Sharpe:  -0.18926945542894424\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 124          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.040071446  |\n",
      "|    clip_fraction        | 0.387        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.23        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0763      |\n",
      "|    reward               | 0.0028700223 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00142      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:468070.6217312402\n",
      "Sharpe:  -1.3611035854972322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:669473.8205444675\n",
      "Sharpe:  -0.94323138301465\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:674206.8691002042\n",
      "Sharpe:  -0.5627560253675711\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:682125.5386481783\n",
      "Sharpe:  -0.7483479972340255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040612064 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.233      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0737     |\n",
      "|    reward               | 0.019935459 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.000728    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772822.3930849992\n",
      "Sharpe:  -0.5431888781862392\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:850278.864433225\n",
      "Sharpe:  -0.3635526816212227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:478273.3496791464\n",
      "Sharpe:  -0.610682372922295\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 124          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.04337979   |\n",
      "|    clip_fraction        | 0.398        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.202       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0668      |\n",
      "|    reward               | -0.027542688 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000985     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726354.7519143439\n",
      "Sharpe:  -0.26705155431081856\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:857069.1712266842\n",
      "Sharpe:  -0.08535381428169192\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 123          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.04899717   |\n",
      "|    clip_fraction        | 0.403        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.236       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0803      |\n",
      "|    reward               | -0.006472016 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00118      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:806495.8772123018\n",
      "Sharpe:  -0.6789582571930552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:932801.4599927901\n",
      "Sharpe:  -0.031515874978116094\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 122          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.047456123  |\n",
      "|    clip_fraction        | 0.417        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.223       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0755      |\n",
      "|    reward               | 0.0038641104 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000708     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:689337.434450789\n",
      "Sharpe:  -0.20936665354200246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1033998.6183494378\n",
      "Sharpe:  0.3193077480395304\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 122          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.053754836  |\n",
      "|    clip_fraction        | 0.435        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.235       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0791      |\n",
      "|    reward               | 0.0009730065 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000769     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:674759.4434453482\n",
      "Sharpe:  -0.2858750686747572\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1034124.1561666983\n",
      "Sharpe:  0.43324509632835634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:995837.0187826551\n",
      "Sharpe:  0.03634660110771155\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738284.5535213812\n",
      "Sharpe:  -0.3373343999174265\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 121          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.055619553  |\n",
      "|    clip_fraction        | 0.451        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.251       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0814      |\n",
      "|    reward               | 3.966811e-05 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000646     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:944511.9704800262\n",
      "Sharpe:  0.02829829406883933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:838931.7670395275\n",
      "Sharpe:  -0.29387507925235656\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1098689.955181789\n",
      "Sharpe:  2.1392350831115845\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:828355.8468444525\n",
      "Sharpe:  -0.4809669768475135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:613426.3384291165\n",
      "Sharpe:  -0.8439491715330284\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082554.0508153506\n",
      "Sharpe:  2.020819177651084\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 121           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 253           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.060380027   |\n",
      "|    clip_fraction        | 0.468         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.779         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.256        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.0801       |\n",
      "|    reward               | -0.0063603288 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000644      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:940057.2679843815\n",
      "Sharpe:  -0.03574870900840662\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1056227.3171894918\n",
      "Sharpe:  0.5090799844647738\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:631295.3312927352\n",
      "Sharpe:  -0.34799514190736436\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.05970287   |\n",
      "|    clip_fraction        | 0.452        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.245       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.07        |\n",
      "|    reward               | 0.0012566785 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000609     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:996332.8886321567\n",
      "Sharpe:  0.13066258432878036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:919924.1566286144\n",
      "Sharpe:  0.0010304700576827185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061314844 |\n",
      "|    clip_fraction        | 0.463       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.233      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0815     |\n",
      "|    reward               | 0.014661178 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000521    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:951009.9528789849\n",
      "Sharpe:  0.030023129351865036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1050480.4701123878\n",
      "Sharpe:  1.961547366577242\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1042608.1182782653\n",
      "Sharpe:  0.7872363447158673\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1058253.1176102094\n",
      "Sharpe:  2.2984861216713757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:876283.8359241061\n",
      "Sharpe:  -0.31415120190909346\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:915582.7726884673\n",
      "Sharpe:  -0.06053859337594457\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1236627.8745575957\n",
      "Sharpe:  0.5119583869751686\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 119           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 308           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.06472218    |\n",
      "|    clip_fraction        | 0.486         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.824         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.231        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.079        |\n",
      "|    reward               | -0.0021589843 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000597      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:851971.4952523569\n",
      "Sharpe:  -0.13687516375024988\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:909179.1822049909\n",
      "Sharpe:  -0.17188413970846514\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:962261.8613233439\n",
      "Sharpe:  -0.15696477719398888\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1053441.5649599384\n",
      "Sharpe:  0.9488622097298777\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062882885 |\n",
      "|    clip_fraction        | 0.477       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.221      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0744     |\n",
      "|    reward               | -0.02384309 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0006      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:845426.8311735081\n",
      "Sharpe:  -0.08563244187554721\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07242973  |\n",
      "|    clip_fraction        | 0.493       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.245      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0774     |\n",
      "|    reward               | -0.01879494 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000594    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:812096.7665369072\n",
      "Sharpe:  -0.08751274464719745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:844669.7937433412\n",
      "Sharpe:  -0.060973729119045285\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 119          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07643142   |\n",
      "|    clip_fraction        | 0.503        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.25        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0833      |\n",
      "|    reward               | -0.021518752 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000782     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:926452.7509608503\n",
      "Sharpe:  -0.037442817241582375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1036072.6018405083\n",
      "Sharpe:  0.2927690471526427\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:961806.8195638957\n",
      "Sharpe:  0.039576178988750085\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 378           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.07384526    |\n",
      "|    clip_fraction        | 0.503         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.26         |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.0813       |\n",
      "|    reward               | -0.0032374752 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00061       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:957871.0284162387\n",
      "Sharpe:  0.03438113569286706\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1040163.7551160468\n",
      "Sharpe:  0.12772988099399607\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.06663908   |\n",
      "|    clip_fraction        | 0.483        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.21        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0756      |\n",
      "|    reward               | -0.025694018 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000517     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1044009.6634768614\n",
      "Sharpe:  0.13675187598241764\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 414           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.071817175   |\n",
      "|    clip_fraction        | 0.508         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.245        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0765       |\n",
      "|    reward               | -0.0038739268 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00248       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:868667.639175853\n",
      "Sharpe:  -0.020017711756367067\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1125203.737757379\n",
      "Sharpe:  1.7584562358308555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1197469.4028335437\n",
      "Sharpe:  0.33433192069242845\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1224865.6327616887\n",
      "Sharpe:  1.0240102293266007\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 431           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.07836103    |\n",
      "|    clip_fraction        | 0.512         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | -0.209        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.248        |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.0802       |\n",
      "|    reward               | 4.3123993e-05 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.0011        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:621662.3181418418\n",
      "Sharpe:  -0.9336572078588894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:982114.0951112899\n",
      "Sharpe:  0.07249389975563983\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 448           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.07162526    |\n",
      "|    clip_fraction        | 0.491         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.703         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.259        |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.0763       |\n",
      "|    reward               | -0.0006343758 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.0005        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1086979.2350259766\n",
      "Sharpe:  0.17441967895714214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:988201.7322237655\n",
      "Sharpe:  0.08891426692344068\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08646281  |\n",
      "|    clip_fraction        | 0.516       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.242      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0805     |\n",
      "|    reward               | -0.04480435 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000457    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1131248.3787673987\n",
      "Sharpe:  0.40523762087782117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1041864.5561063631\n",
      "Sharpe:  0.20349436741971985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1029333.7241113133\n",
      "Sharpe:  0.18415702157215155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082597926 |\n",
      "|    clip_fraction        | 0.523       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.253      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0822     |\n",
      "|    reward               | 0.009762774 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00051     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1090339.3356923317\n",
      "Sharpe:  0.18929536101161637\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1043357.3401511803\n",
      "Sharpe:  2.607562542702334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1154510.148617854\n",
      "Sharpe:  4.115696115053991\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1145659.6008060677\n",
      "Sharpe:  0.9271992933410667\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 118            |\n",
      "|    iterations           | 29             |\n",
      "|    time_elapsed         | 500            |\n",
      "|    total_timesteps      | 59392          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.087783955    |\n",
      "|    clip_fraction        | 0.519          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.1          |\n",
      "|    explained_variance   | 0.814          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.217         |\n",
      "|    n_updates            | 280            |\n",
      "|    policy_gradient_loss | -0.0836        |\n",
      "|    reward               | -0.00020793035 |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 0.00034        |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:810219.2510339034\n",
      "Sharpe:  -0.10210766480793004\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1064746.5325305322\n",
      "Sharpe:  0.21596129074613\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 517          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.094212055  |\n",
      "|    clip_fraction        | 0.543        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.255       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0789      |\n",
      "|    reward               | -0.019861683 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000417     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1251818.2646920339\n",
      "Sharpe:  0.2999831003805166\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:891708.165602112\n",
      "Sharpe:  -0.14762280974278447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1004729.5677372928\n",
      "Sharpe:  0.11132408155862485\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 535           |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09462668    |\n",
      "|    clip_fraction        | 0.54          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.785         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.271        |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.0789       |\n",
      "|    reward               | -0.0039804433 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000485      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:885615.0190719115\n",
      "Sharpe:  -0.0481589859715589\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09140979  |\n",
      "|    clip_fraction        | 0.535       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.081      |\n",
      "|    reward               | 0.009585957 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000533    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1165910.1961700202\n",
      "Sharpe:  0.2165411511106351\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1873231.5295379693\n",
      "Sharpe:  0.6138314151394332\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 570           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.10519793    |\n",
      "|    clip_fraction        | 0.553         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.244        |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.0778       |\n",
      "|    reward               | -0.0028459851 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000811      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1056021.2579584522\n",
      "Sharpe:  0.1769980921487311\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:984685.7019555968\n",
      "Sharpe:  0.09673540949722784\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 588           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.11269802    |\n",
      "|    clip_fraction        | 0.556         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.235        |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.0803       |\n",
      "|    reward               | -0.0076449336 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000548      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1210502.3351868163\n",
      "Sharpe:  0.2793661701324913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10052978  |\n",
      "|    clip_fraction        | 0.562       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.25       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0803     |\n",
      "|    reward               | 0.033405542 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000399    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2492888.614856232\n",
      "Sharpe:  0.6210101473206098\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1548895.0781543236\n",
      "Sharpe:  0.49473099556126887\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1011844.2605238175\n",
      "Sharpe:  0.19061069069957498\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 624           |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.117514834   |\n",
      "|    clip_fraction        | 0.591         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.2         |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.252        |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.0703       |\n",
      "|    reward               | -0.0065590017 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00152       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1140835.645478791\n",
      "Sharpe:  0.40970757542252745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1142620.620951389\n",
      "Sharpe:  3.8407687746623522\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:942941.6132597488\n",
      "Sharpe:  -0.02612290276804016\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 118           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 641           |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.098413825   |\n",
      "|    clip_fraction        | 0.548         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.2         |\n",
      "|    explained_variance   | 0.476         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.24         |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.0795       |\n",
      "|    reward               | -0.0049348874 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000794      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:979725.2146306387\n",
      "Sharpe:  0.08192162093882033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1423478.2004277152\n",
      "Sharpe:  0.4612221068604856\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 117            |\n",
      "|    iterations           | 38             |\n",
      "|    time_elapsed         | 659            |\n",
      "|    total_timesteps      | 77824          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.10286856     |\n",
      "|    clip_fraction        | 0.553          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.3          |\n",
      "|    explained_variance   | 0.747          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.262         |\n",
      "|    n_updates            | 370            |\n",
      "|    policy_gradient_loss | -0.0822        |\n",
      "|    reward               | -0.00096140546 |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 0.000439       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1515791.1801418301\n",
      "Sharpe:  0.8857123007000377\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1191233.9390604945\n",
      "Sharpe:  0.28106472299469776\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 117          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 677          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10947389   |\n",
      "|    clip_fraction        | 0.56         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.229       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0804      |\n",
      "|    reward               | 0.0021412813 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00035      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1010390.9200338548\n",
      "Sharpe:  0.12125899079609825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1781414.838495532\n",
      "Sharpe:  0.5676227884861805\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:996259.2455973912\n",
      "Sharpe:  0.11785247196975739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10655773  |\n",
      "|    clip_fraction        | 0.554       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.227      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.079      |\n",
      "|    reward               | 0.005028696 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.000303    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1255279.6820712849\n",
      "Sharpe:  0.3673700496771209\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 117          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 713          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.112210795  |\n",
      "|    clip_fraction        | 0.564        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.249       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0783      |\n",
      "|    reward               | -0.009948803 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.000331     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1037953.9005445694\n",
      "Sharpe:  0.1380606223063154\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11543492  |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.25       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0753     |\n",
      "|    reward               | 0.015388296 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00069     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2132602.229211717\n",
      "Sharpe:  0.6328669622810685\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1113042.1313961847\n",
      "Sharpe:  0.2781212019853053\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:991752.5414524976\n",
      "Sharpe:  0.1024774866401447\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 117           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 749           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.10820821    |\n",
      "|    clip_fraction        | 0.575         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.4         |\n",
      "|    explained_variance   | 0.749         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.266        |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.0829       |\n",
      "|    reward               | -0.0021804324 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.000502      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1209041.5165712868\n",
      "Sharpe:  0.3799389908106314\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1248969.9854500906\n",
      "Sharpe:  0.33326709457643566\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 117            |\n",
      "|    iterations           | 44             |\n",
      "|    time_elapsed         | 766            |\n",
      "|    total_timesteps      | 90112          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.11572494     |\n",
      "|    clip_fraction        | 0.573          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.4          |\n",
      "|    explained_variance   | 0.805          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.244         |\n",
      "|    n_updates            | 430            |\n",
      "|    policy_gradient_loss | -0.077         |\n",
      "|    reward               | -0.00043645405 |\n",
      "|    std                  | 1.08           |\n",
      "|    value_loss           | 0.000428       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:879090.4238761424\n",
      "Sharpe:  -0.06611630240897107\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2053255.3295849909\n",
      "Sharpe:  1.0469383167843516\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11558294  |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.239      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0717     |\n",
      "|    reward               | -0.00293681 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.000529    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1926058.0276692808\n",
      "Sharpe:  0.669519012274505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1866815.8649871035\n",
      "Sharpe:  0.8358370998271052\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 117           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 799           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.1094888     |\n",
      "|    clip_fraction        | 0.581         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.5         |\n",
      "|    explained_variance   | 0.668         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.239        |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.0765       |\n",
      "|    reward               | -0.0023103147 |\n",
      "|    std                  | 1.08          |\n",
      "|    value_loss           | 0.000424      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1168893.0412908758\n",
      "Sharpe:  0.3767363059605401\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1921935.5767011635\n",
      "Sharpe:  0.7628220755253063\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1189191.474383217\n",
      "Sharpe:  1.2356716142006086\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 815          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.11606964   |\n",
      "|    clip_fraction        | 0.573        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.5        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.25        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0755      |\n",
      "|    reward               | -0.015285793 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.000462     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1013690.3008472295\n",
      "Sharpe:  0.11694228210575372\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11352971  |\n",
      "|    clip_fraction        | 0.57        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.239      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0773     |\n",
      "|    reward               | 0.002184472 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00034     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1902039.2475125159\n",
      "Sharpe:  0.642823261023877\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787071.377144544\n",
      "Sharpe:  0.734207787554053\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 848          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.1286766    |\n",
      "|    clip_fraction        | 0.596        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.5        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.219       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0855      |\n",
      "|    reward               | -0.004532194 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.000396     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1039536.2040420147\n",
      "Sharpe:  3.2310244627572664\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.03953620404201441 -0.02651635797445672 3.2310244627572664\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1232438.075748562\n",
      "Sharpe:  3.670904849170572\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1203580.8893079485\n",
      "Sharpe:  1.1537467846731924\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2026107.8338831004\n",
      "Sharpe:  0.8799426044873786\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2154168.5209610392\n",
      "Sharpe:  0.7860219293028676\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 50          |\n",
      "|    time_elapsed    | 65          |\n",
      "|    total_timesteps | 3286        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -1.33       |\n",
      "|    critic_loss     | 0.022       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3185        |\n",
      "|    reward          | 0.008946231 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1055574.3745324702\n",
      "Sharpe:  0.20811011212483133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1170940.4813693187\n",
      "Sharpe:  0.44415827302050204\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1285971.2726608533\n",
      "Sharpe:  0.5267420050027761\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1261679.5123827013\n",
      "Sharpe:  0.45014321061435253\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 49          |\n",
      "|    time_elapsed    | 131         |\n",
      "|    total_timesteps | 6543        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -1.05       |\n",
      "|    critic_loss     | 0.00705     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 6442        |\n",
      "|    reward          | 0.002183955 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2027170.7026772227\n",
      "Sharpe:  0.7153447313690785\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1916543.1086264458\n",
      "Sharpe:  0.6694598751911249\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1563947.1665205203\n",
      "Sharpe:  0.44469982656557033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1273919.130252879\n",
      "Sharpe:  3.018410552286647\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 241          |\n",
      "|    total_timesteps | 11621        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.963       |\n",
      "|    critic_loss     | 0.00549      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 11520        |\n",
      "|    reward          | 0.0071790167 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2516376.6753733526\n",
      "Sharpe:  1.0516489258730655\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1352879.720074924\n",
      "Sharpe:  0.7201765054352365\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1224402.3506441042\n",
      "Sharpe:  0.6811322184425473\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1174288.0523507872\n",
      "Sharpe:  1.5643087759630363\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 305          |\n",
      "|    total_timesteps | 14513        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.951       |\n",
      "|    critic_loss     | 0.00168      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 14412        |\n",
      "|    reward          | 0.0016505537 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:924149.8302519807\n",
      "Sharpe:  -0.19595781697704898\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1403518.11647104\n",
      "Sharpe:  0.4882361774954918\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1460863.3979504844\n",
      "Sharpe:  0.7432342254272699\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2247772.5539711663\n",
      "Sharpe:  0.9179904059666284\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 388          |\n",
      "|    total_timesteps | 18384        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.848       |\n",
      "|    critic_loss     | 0.000792     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 18283        |\n",
      "|    reward          | 0.0024938032 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1951551.981008116\n",
      "Sharpe:  0.6273745622350783\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1876018.8325614203\n",
      "Sharpe:  0.7903641821454022\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1744080.3324470164\n",
      "Sharpe:  0.657524250799797\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1214415.3023680034\n",
      "Sharpe:  1.84989351347032\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 491          |\n",
      "|    total_timesteps | 23112        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.637       |\n",
      "|    critic_loss     | 0.00123      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 23011        |\n",
      "|    reward          | 0.0060562887 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1149329.7238168053\n",
      "Sharpe:  0.470305217687621\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1163246.64837542\n",
      "Sharpe:  0.5176842465083253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2680207.9796645637\n",
      "Sharpe:  1.1324963765666258\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2416632.6604890674\n",
      "Sharpe:  1.0739670580660405\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 566          |\n",
      "|    total_timesteps | 26531        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.552       |\n",
      "|    critic_loss     | 0.000929     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26430        |\n",
      "|    reward          | 0.0061280397 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2156740.1277037184\n",
      "Sharpe:  1.217468902643302\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1256645.853083581\n",
      "Sharpe:  3.065229867748524\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1061570.0219664131\n",
      "Sharpe:  3.388486749886553\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1601626.754715023\n",
      "Sharpe:  0.8229913733173723\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 612          |\n",
      "|    total_timesteps | 28586        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.522       |\n",
      "|    critic_loss     | 0.000651     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 28485        |\n",
      "|    reward          | 0.0045462805 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1329215.047709337\n",
      "Sharpe:  0.8420222807368223\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1312614.6281462521\n",
      "Sharpe:  2.209299269456521\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1099267.6760830977\n",
      "Sharpe:  4.519776164402753\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1217793.308892938\n",
      "Sharpe:  2.222049265286347\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 634         |\n",
      "|    total_timesteps | 29566       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.542      |\n",
      "|    critic_loss     | 0.000517    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29465       |\n",
      "|    reward          | 0.004544147 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2498770.5739706648\n",
      "Sharpe:  1.1604895069564634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3862409.1255798414\n",
      "Sharpe:  1.1225069729384236\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5124731.625505086\n",
      "Sharpe:  1.4382985830094093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2533569.4264705493\n",
      "Sharpe:  1.3843296518134185\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 760          |\n",
      "|    total_timesteps | 35228        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.358       |\n",
      "|    critic_loss     | 0.00023      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 35127        |\n",
      "|    reward          | 0.0070657902 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1423382.8380903602\n",
      "Sharpe:  0.8731831877437077\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1184249.9114265286\n",
      "Sharpe:  0.6603899703988213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1196695.0668892376\n",
      "Sharpe:  3.577184351782185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1354086.7102192782\n",
      "Sharpe:  0.9028411377504438\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 794         |\n",
      "|    total_timesteps | 36887       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.348      |\n",
      "|    critic_loss     | 0.000334    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 36786       |\n",
      "|    reward          | 0.005707545 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1182851.0220724572\n",
      "Sharpe:  1.7416755824987349\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2375235.59859881\n",
      "Sharpe:  1.294191040933635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5466329.378915587\n",
      "Sharpe:  1.4794025552257954\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3542038.0715203797\n",
      "Sharpe:  1.5219285370525801\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 48           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 879          |\n",
      "|    total_timesteps | 41058        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.358       |\n",
      "|    critic_loss     | 0.000224     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 40957        |\n",
      "|    reward          | 0.0057553714 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1802876.5421303518\n",
      "Sharpe:  1.0387343156354834\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2064058.895149975\n",
      "Sharpe:  1.0736981183876373\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1382381.1733206299\n",
      "Sharpe:  1.1170078002344892\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4715569.356098048\n",
      "Sharpe:  1.5170041729055386\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 957         |\n",
      "|    total_timesteps | 44794       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.279      |\n",
      "|    critic_loss     | 0.000243    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 44693       |\n",
      "|    reward          | 0.008105258 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4938400.502136684\n",
      "Sharpe:  1.4975953762023921\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1206605.5890699641\n",
      "Sharpe:  3.80642212780091\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8465334.114353897\n",
      "Sharpe:  1.5699680578553927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1959023.7919982872\n",
      "Sharpe:  1.6091934701762753\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 46         |\n",
      "|    time_elapsed    | 1040       |\n",
      "|    total_timesteps | 48715      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.285     |\n",
      "|    critic_loss     | 0.000277   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 48614      |\n",
      "|    reward          | 0.00743921 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3047722.3031732296\n",
      "Sharpe:  1.3830946467283636\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3132842.062922353\n",
      "Sharpe:  1.6150653024005415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2601036.894048262\n",
      "Sharpe:  1.5072769209498302\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3237595.6883110553\n",
      "Sharpe:  1.5735531115453334\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 60           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 1127         |\n",
      "|    total_timesteps | 52779        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.239       |\n",
      "|    critic_loss     | 0.000113     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 52678        |\n",
      "|    reward          | 0.0073366594 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5434075.9445883315\n",
      "Sharpe:  1.5245954836794375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1665042.8982375702\n",
      "Sharpe:  1.2262592050335388\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1258379.7564409089\n",
      "Sharpe:  4.817734347915635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7520978.911002934\n",
      "Sharpe:  1.8519362646817146\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1207        |\n",
      "|    total_timesteps | 56530       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.232      |\n",
      "|    critic_loss     | 8.89e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 56429       |\n",
      "|    reward          | 0.005774977 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2068898.6540665461\n",
      "Sharpe:  1.6094159588703436\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1351789.0811207327\n",
      "Sharpe:  3.037589968407569\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4621557.666812964\n",
      "Sharpe:  1.9255859623566145\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6559134.485875667\n",
      "Sharpe:  1.918649330317929\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 68           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 1280         |\n",
      "|    total_timesteps | 59781        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.214       |\n",
      "|    critic_loss     | 5.89e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 59680        |\n",
      "|    reward          | 0.0066603594 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1179490.519977331\n",
      "Sharpe:  5.882197666997775\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2164879.593405339\n",
      "Sharpe:  1.838567268301874\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1897208.6536357834\n",
      "Sharpe:  1.9627177433308869\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3169222.7136773765\n",
      "Sharpe:  1.7599790449969357\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1321        |\n",
      "|    total_timesteps | 61624       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.204      |\n",
      "|    critic_loss     | 9.2e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 61523       |\n",
      "|    reward          | 0.007050151 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3365942.8511343207\n",
      "Sharpe:  1.865526511140331\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4520140.208562433\n",
      "Sharpe:  2.080330858350263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5901938.591432506\n",
      "Sharpe:  2.1108492448732172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17618196.488416284\n",
      "Sharpe:  1.97637561766601\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 76          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1421        |\n",
      "|    total_timesteps | 66149       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.207      |\n",
      "|    critic_loss     | 5.88e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 66048       |\n",
      "|    reward          | 0.009760328 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5603740.462464554\n",
      "Sharpe:  2.3976925066475987\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6665732.443731983\n",
      "Sharpe:  2.527849964344579\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3870687.2129710186\n",
      "Sharpe:  2.3301950996471428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17651780.193876196\n",
      "Sharpe:  2.111642915001483\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 80          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1516        |\n",
      "|    total_timesteps | 70369       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.198      |\n",
      "|    critic_loss     | 4.62e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 70268       |\n",
      "|    reward          | 0.009761064 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9833090.61717339\n",
      "Sharpe:  2.329493405271161\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:31343595.93772754\n",
      "Sharpe:  2.1247549058585804\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:16802499.623012025\n",
      "Sharpe:  2.1162350774709933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:44074786.67702283\n",
      "Sharpe:  2.023513374776693\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 84          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1638        |\n",
      "|    total_timesteps | 76291       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.198      |\n",
      "|    critic_loss     | 4.91e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 76190       |\n",
      "|    reward          | 0.009927631 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15638093.565223752\n",
      "Sharpe:  2.2171488378421715\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9197022.222188352\n",
      "Sharpe:  2.575611160583612\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6225756.362646757\n",
      "Sharpe:  2.0854111373362967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:47631590.84525021\n",
      "Sharpe:  1.9373652803338997\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1734        |\n",
      "|    total_timesteps | 80876       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.212      |\n",
      "|    critic_loss     | 4.67e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 80775       |\n",
      "|    reward          | 0.007691942 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1309354.2162470876\n",
      "Sharpe:  4.667789998256627\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11469475.156638213\n",
      "Sharpe:  2.2372434987807446\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:12334630.964810558\n",
      "Sharpe:  2.2651264513449423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:32204317.23621168\n",
      "Sharpe:  2.2127342111904893\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1815        |\n",
      "|    total_timesteps | 84640       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.213      |\n",
      "|    critic_loss     | 9.19e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 84539       |\n",
      "|    reward          | 0.012937856 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1240507.3349005652\n",
      "Sharpe:  5.168198683100662\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9624473.989795566\n",
      "Sharpe:  2.396676113291436\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5385711.189592258\n",
      "Sharpe:  2.7588086370968576\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2114607.2049926673\n",
      "Sharpe:  3.4031445059411047\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 96          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 1855        |\n",
      "|    total_timesteps | 86487       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.209      |\n",
      "|    critic_loss     | 9.8e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 86386       |\n",
      "|    reward          | 0.012935888 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:35983895.92066131\n",
      "Sharpe:  2.2538225267365743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6781605.259562289\n",
      "Sharpe:  2.341697252004943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5069219.109346162\n",
      "Sharpe:  2.4376915806668884\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24347765.227280926\n",
      "Sharpe:  2.229436239428196\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 100        |\n",
      "|    fps             | 46         |\n",
      "|    time_elapsed    | 1938       |\n",
      "|    total_timesteps | 90404      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.24      |\n",
      "|    critic_loss     | 9.16e-05   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 90303      |\n",
      "|    reward          | 0.01293682 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24202070.299337946\n",
      "Sharpe:  2.1969758543751263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1108203.3037730006\n",
      "Sharpe:  10.167102956622637\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:50179298.92459494\n",
      "Sharpe:  2.335313273688809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6890170.757814555\n",
      "Sharpe:  2.6042865868444283\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 104         |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 2014        |\n",
      "|    total_timesteps | 93903       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.241      |\n",
      "|    critic_loss     | 4.91e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 93802       |\n",
      "|    reward          | 0.010247247 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:22761976.541766122\n",
      "Sharpe:  2.6407062625414404\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:39899028.11281412\n",
      "Sharpe:  2.517736556329923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24444621.871272545\n",
      "Sharpe:  2.3283351960884358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:39316913.5227108\n",
      "Sharpe:  2.270068019871384\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 2122        |\n",
      "|    total_timesteps | 98897       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.26       |\n",
      "|    critic_loss     | 7.42e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 98796       |\n",
      "|    reward          | 0.012938836 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026988.9956616857\n",
      "Sharpe:  3.4959572702783923\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.026988995661685555 -0.011239425238825804 3.4959572702783923\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1337484.6154504768\n",
      "Sharpe:  0.5604965628896144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2525078.6713488144\n",
      "Sharpe:  0.9562940883786597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2206178.7396145365\n",
      "Sharpe:  1.004216772559439\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3515395.791989664\n",
      "Sharpe:  1.1797216593260784\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 114          |\n",
      "|    total_timesteps | 5347         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.04         |\n",
      "|    critic_loss     | 0.0692       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5246         |\n",
      "|    reward          | 0.0016252438 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1229966.808454318\n",
      "Sharpe:  2.0461963676850323\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2278318.9578142464\n",
      "Sharpe:  1.0646971184731409\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1481555.9063724715\n",
      "Sharpe:  0.5890394447234949\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1957165.0639328326\n",
      "Sharpe:  0.8522342664939947\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 8              |\n",
      "|    fps             | 49             |\n",
      "|    time_elapsed    | 187            |\n",
      "|    total_timesteps | 9308           |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 1.03           |\n",
      "|    critic_loss     | 0.0184         |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 9207           |\n",
      "|    reward          | -0.00030417668 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1292747.9012594684\n",
      "Sharpe:  0.5795565199794401\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1458730.3789393792\n",
      "Sharpe:  0.6062672823177405\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3647935.3382237894\n",
      "Sharpe:  1.0865653904020494\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1099147.215833781\n",
      "Sharpe:  0.9655909819193079\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 51           |\n",
      "|    time_elapsed    | 250          |\n",
      "|    total_timesteps | 12877        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.06         |\n",
      "|    critic_loss     | 0.0136       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 12776        |\n",
      "|    reward          | 0.0046450305 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2084434.2170568488\n",
      "Sharpe:  0.936196909804613\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1236052.3059427012\n",
      "Sharpe:  0.5367276548401968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1147922.1137534676\n",
      "Sharpe:  2.9850383521956654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1772396.126863639\n",
      "Sharpe:  0.8051937932599793\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 52          |\n",
      "|    time_elapsed    | 311         |\n",
      "|    total_timesteps | 16269       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1           |\n",
      "|    critic_loss     | 0.0108      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 16168       |\n",
      "|    reward          | 0.001519757 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2568137.638167479\n",
      "Sharpe:  1.025712502014917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1279592.8949089213\n",
      "Sharpe:  0.8073709934131628\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1100504.4334793577\n",
      "Sharpe:  5.651723634260985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1521254.0686657303\n",
      "Sharpe:  0.8302680775303303\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 52           |\n",
      "|    time_elapsed    | 364          |\n",
      "|    total_timesteps | 19212        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.964        |\n",
      "|    critic_loss     | 0.0101       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 19111        |\n",
      "|    reward          | 0.0013643131 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1294570.25808562\n",
      "Sharpe:  1.7474929329662203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1672080.3253240138\n",
      "Sharpe:  0.9015080961695291\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1279640.471923235\n",
      "Sharpe:  1.5812214139843597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2271110.596202649\n",
      "Sharpe:  1.1730197641799103\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 53           |\n",
      "|    time_elapsed    | 406          |\n",
      "|    total_timesteps | 21572        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.895        |\n",
      "|    critic_loss     | 0.00637      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21471        |\n",
      "|    reward          | 0.0030328159 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2442723.5787097313\n",
      "Sharpe:  0.8870766189042699\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2027599.2430641707\n",
      "Sharpe:  0.8026319790921342\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1146480.0999591684\n",
      "Sharpe:  0.35682280835294583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1422470.1161900358\n",
      "Sharpe:  0.5275831824158813\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 493         |\n",
      "|    total_timesteps | 26198       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.665       |\n",
      "|    critic_loss     | 0.00443     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 26097       |\n",
      "|    reward          | 0.006700264 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4183498.928256149\n",
      "Sharpe:  1.1052568762023158\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2178680.658073096\n",
      "Sharpe:  1.0887505306998406\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1535847.5679436552\n",
      "Sharpe:  1.3837010453974192\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1370183.0798647695\n",
      "Sharpe:  2.5473873345737497\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 554         |\n",
      "|    total_timesteps | 29628       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.636       |\n",
      "|    critic_loss     | 0.00822     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29527       |\n",
      "|    reward          | 0.008068482 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1647792.4713130558\n",
      "Sharpe:  1.1365043519209754\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2122655.908933708\n",
      "Sharpe:  1.2874491932766274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1418888.0382970388\n",
      "Sharpe:  1.1046394229908894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1413293.7351967893\n",
      "Sharpe:  1.047328672838757\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 596         |\n",
      "|    total_timesteps | 31950       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.633       |\n",
      "|    critic_loss     | 0.00437     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 31849       |\n",
      "|    reward          | 0.007226721 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1600170.1398289572\n",
      "Sharpe:  1.0740862367296296\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2297360.2757967548\n",
      "Sharpe:  1.3567546602573992\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3194843.0382474614\n",
      "Sharpe:  1.3700864363040912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2641322.0563853965\n",
      "Sharpe:  1.1238355218524116\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 673         |\n",
      "|    total_timesteps | 36213       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.555       |\n",
      "|    critic_loss     | 0.00203     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 36112       |\n",
      "|    reward          | 0.009262806 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1775817.988118246\n",
      "Sharpe:  1.1301132380461831\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2418443.839503236\n",
      "Sharpe:  1.2209092659987688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1558461.5019530843\n",
      "Sharpe:  2.0031981525536446\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2023446.6398419226\n",
      "Sharpe:  1.6992175744530853\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 53           |\n",
      "|    time_elapsed    | 723          |\n",
      "|    total_timesteps | 39013        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.472        |\n",
      "|    critic_loss     | 0.0018       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 38912        |\n",
      "|    reward          | 0.0062369173 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1467952.996707894\n",
      "Sharpe:  2.3656855018873126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1425565.4220217569\n",
      "Sharpe:  1.1395249232232227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1954880.598002421\n",
      "Sharpe:  1.2666369062550757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1422263.4250712506\n",
      "Sharpe:  1.1638997350222684\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 754         |\n",
      "|    total_timesteps | 40692       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.576       |\n",
      "|    critic_loss     | 0.0018      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 40591       |\n",
      "|    reward          | 0.006340953 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4615709.639101817\n",
      "Sharpe:  1.4309862299053635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4830272.971652359\n",
      "Sharpe:  1.577730055659009\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1316281.5209418146\n",
      "Sharpe:  0.9815610246801814\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1377052.8155868032\n",
      "Sharpe:  0.9656684897052886\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 817         |\n",
      "|    total_timesteps | 44175       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.527       |\n",
      "|    critic_loss     | 0.00266     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 44074       |\n",
      "|    reward          | 0.010659663 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1190000.8174697692\n",
      "Sharpe:  5.96839910387045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4890948.15908741\n",
      "Sharpe:  1.41083670306592\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1103192.4932913163\n",
      "Sharpe:  6.550497518969497\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2258998.952270988\n",
      "Sharpe:  1.2426234774379927\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 56           |\n",
      "|    fps             | 54           |\n",
      "|    time_elapsed    | 858          |\n",
      "|    total_timesteps | 46464        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.498        |\n",
      "|    critic_loss     | 0.00186      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 46363        |\n",
      "|    reward          | 0.0066442504 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3320927.670566534\n",
      "Sharpe:  1.2147509805264165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4095891.03962902\n",
      "Sharpe:  1.2191365486078451\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2866462.0618738784\n",
      "Sharpe:  1.4344154406808922\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1405150.6729169528\n",
      "Sharpe:  1.0372901445421792\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 939         |\n",
      "|    total_timesteps | 50833       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.422       |\n",
      "|    critic_loss     | 0.00225     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 50732       |\n",
      "|    reward          | 0.010027187 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4712102.4555984745\n",
      "Sharpe:  1.5121538767090743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4159410.177062267\n",
      "Sharpe:  2.154988853965099\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1379805.4719443468\n",
      "Sharpe:  2.4814651002666803\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3360996.3579331962\n",
      "Sharpe:  1.8560235984604618\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1003        |\n",
      "|    total_timesteps | 54323       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.338       |\n",
      "|    critic_loss     | 0.00107     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 54222       |\n",
      "|    reward          | 0.014632242 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1071542.4431076716\n",
      "Sharpe:  10.624771178895294\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3542226.1856837086\n",
      "Sharpe:  1.9844688920242468\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1450237.3264939245\n",
      "Sharpe:  3.791588731186715\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1461857.5569114988\n",
      "Sharpe:  2.7592169417901564\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1027        |\n",
      "|    total_timesteps | 55638       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.391       |\n",
      "|    critic_loss     | 0.000909    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 55537       |\n",
      "|    reward          | 0.014298713 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2055915.610636254\n",
      "Sharpe:  3.2164405375281038\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4705096.823786014\n",
      "Sharpe:  2.14539711626291\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7571879.4380884925\n",
      "Sharpe:  1.8061876165889552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5102027.990626228\n",
      "Sharpe:  2.1109063493102638\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1099        |\n",
      "|    total_timesteps | 59491       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.355       |\n",
      "|    critic_loss     | 0.0009      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 59390       |\n",
      "|    reward          | 0.009620785 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3758019.4880775786\n",
      "Sharpe:  2.116423969049824\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6712034.185202174\n",
      "Sharpe:  1.7884472894448074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2654758.110814482\n",
      "Sharpe:  1.6975205119322245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2077093.446890332\n",
      "Sharpe:  2.2416569677404716\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 76           |\n",
      "|    fps             | 54           |\n",
      "|    time_elapsed    | 1162         |\n",
      "|    total_timesteps | 62947        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.313        |\n",
      "|    critic_loss     | 0.000548     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 62846        |\n",
      "|    reward          | 0.0136307925 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4452387.558310081\n",
      "Sharpe:  2.090376797717088\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11138781.67691497\n",
      "Sharpe:  2.114301099474552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2014421.8505943092\n",
      "Sharpe:  2.450868647040111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5670674.166158291\n",
      "Sharpe:  2.6739421850674314\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 80          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1235        |\n",
      "|    total_timesteps | 66832       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.334       |\n",
      "|    critic_loss     | 0.000595    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 66731       |\n",
      "|    reward          | 0.013636738 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2048062.4881288463\n",
      "Sharpe:  2.7044937118776833\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10617763.700842278\n",
      "Sharpe:  1.8886241681072322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1904226.1839827788\n",
      "Sharpe:  3.0652625389688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8580699.691119602\n",
      "Sharpe:  2.0529102700732653\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 84          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1297        |\n",
      "|    total_timesteps | 70171       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.249       |\n",
      "|    critic_loss     | 0.000426    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 70070       |\n",
      "|    reward          | 0.013637671 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1462623.090789306\n",
      "Sharpe:  2.772566065813268\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1067053.718370001\n",
      "Sharpe:  14.906361220611641\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1327338.880050401\n",
      "Sharpe:  4.1383899657683445\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:23331369.030829262\n",
      "Sharpe:  1.5130377668650004\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1333        |\n",
      "|    total_timesteps | 72097       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.289       |\n",
      "|    critic_loss     | 0.000306    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 71996       |\n",
      "|    reward          | 0.013639467 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4740563.267583109\n",
      "Sharpe:  1.9540310923186628\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1048453.3444700008\n",
      "Sharpe:  9.073755298339709\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2386904.3885895284\n",
      "Sharpe:  2.3448335232235324\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4761085.772878359\n",
      "Sharpe:  2.0091462830292577\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 54          |\n",
      "|    time_elapsed    | 1379        |\n",
      "|    total_timesteps | 74544       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.263       |\n",
      "|    critic_loss     | 0.000412    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 74443       |\n",
      "|    reward          | 0.015634583 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4095902.8900200487\n",
      "Sharpe:  1.948929768988818\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18771007.647425905\n",
      "Sharpe:  1.4417700617863656\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8579219.641759658\n",
      "Sharpe:  1.5314718769101852\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1254893.8485604958\n",
      "Sharpe:  3.5281915749478636\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 96          |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1451        |\n",
      "|    total_timesteps | 78309       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.184       |\n",
      "|    critic_loss     | 0.000388    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 78208       |\n",
      "|    reward          | 0.015628094 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:12782513.49870083\n",
      "Sharpe:  1.6279621088980567\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10031648.334847191\n",
      "Sharpe:  1.5787184726135828\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7560641.573950384\n",
      "Sharpe:  1.7917096218271293\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1406494.7017404896\n",
      "Sharpe:  2.4969016882628146\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 100         |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1532        |\n",
      "|    total_timesteps | 82424       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.161       |\n",
      "|    critic_loss     | 0.000337    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 82323       |\n",
      "|    reward          | 0.007102858 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2188675.890590624\n",
      "Sharpe:  2.071586684143225\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:37327614.94495346\n",
      "Sharpe:  1.5210796195323582\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4282237.44768642\n",
      "Sharpe:  1.857756247377577\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1894117.702793753\n",
      "Sharpe:  1.9438907573049857\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 104         |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1595        |\n",
      "|    total_timesteps | 85710       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.175       |\n",
      "|    critic_loss     | 0.000398    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 85609       |\n",
      "|    reward          | 0.007168596 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3253367.2249936913\n",
      "Sharpe:  1.8415864528173511\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:29743501.754752956\n",
      "Sharpe:  1.5776358381969375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15713539.293554043\n",
      "Sharpe:  1.7501088740938393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:48249835.37315943\n",
      "Sharpe:  1.646750697578292\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1700        |\n",
      "|    total_timesteps | 91053       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.119       |\n",
      "|    critic_loss     | 0.000737    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 90952       |\n",
      "|    reward          | 0.008929418 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2583671.696054902\n",
      "Sharpe:  2.215360479755048\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2179804.568000126\n",
      "Sharpe:  2.7703921309068362\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:31425090.059506018\n",
      "Sharpe:  1.5664658824298723\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4363666.705827171\n",
      "Sharpe:  2.084085110328452\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 112        |\n",
      "|    fps             | 53         |\n",
      "|    time_elapsed    | 1761       |\n",
      "|    total_timesteps | 94248      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.138      |\n",
      "|    critic_loss     | 0.000302   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 94147      |\n",
      "|    reward          | 0.00916506 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1477476.2155379958\n",
      "Sharpe:  2.9787045543834765\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7255345.295469806\n",
      "Sharpe:  1.9888533291951154\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2191801.4854686996\n",
      "Sharpe:  2.360801081210186\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5866017.0993473865\n",
      "Sharpe:  2.424663464076523\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 116         |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1809        |\n",
      "|    total_timesteps | 96815       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0986      |\n",
      "|    critic_loss     | 0.000277    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 96714       |\n",
      "|    reward          | 0.011901865 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2440945.4592773346\n",
      "Sharpe:  2.6278880527344497\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1844031.7774663628\n",
      "Sharpe:  3.877292845003111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4888037.826668319\n",
      "Sharpe:  2.6599062183034485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:44352639.89991702\n",
      "Sharpe:  1.7849300942119093\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 120         |\n",
      "|    fps             | 53          |\n",
      "|    time_elapsed    | 1864        |\n",
      "|    total_timesteps | 99673       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0974      |\n",
      "|    critic_loss     | 0.000225    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 99572       |\n",
      "|    reward          | 0.011903663 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:975480.3554410967\n",
      "Sharpe:  -1.9974839389017551\n",
      "=================================\n",
      "hit end!\n",
      "td3 -0.024519644558903098 -0.04096272540703771 -1.9974839389017551\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1109162.2109252962\n",
      "Sharpe:  1.4408296185268907\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 118           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -167          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -1.79         |\n",
      "|    reward             | -0.0053911977 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.0623        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 120          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -295         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.603        |\n",
      "|    reward             | -0.011844954 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.0319       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 121          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -2.43e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 1.94         |\n",
      "|    reward             | -0.002799254 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.119        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1203598.8267311617\n",
      "Sharpe:  0.2636872872914599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1232651.8241123857\n",
      "Sharpe:  4.056801447276936\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 121           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | -104          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -3.04         |\n",
      "|    reward             | -0.0043018186 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.0563        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1346518.9414547319\n",
      "Sharpe:  0.7117067066513145\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 120          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | -204         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 1.61         |\n",
      "|    reward             | 0.0018731791 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.0168       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 120          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | -113         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.828        |\n",
      "|    reward             | 0.0076414184 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.00601      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 121         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -20.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.391       |\n",
      "|    reward             | 0.005011693 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1300259.1300737257\n",
      "Sharpe:  0.39585292502632985\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 120          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 33           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -99.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.431       |\n",
      "|    reward             | 0.0013273075 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 120          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -188         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -1.4         |\n",
      "|    reward             | 0.0021070035 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.0143       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1631013.2363546952\n",
      "Sharpe:  0.5931947577659201\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 120         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | -27.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.102       |\n",
      "|    reward             | 0.006561044 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1092150.20658846\n",
      "Sharpe:  0.5210492345390776\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 120         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -224        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.0268     |\n",
      "|    reward             | 0.007160923 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.00054     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 119          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | -221         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.801       |\n",
      "|    reward             | 0.0052377624 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.00558      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1193596.748035778\n",
      "Sharpe:  0.3377313482550575\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -60.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.271        |\n",
      "|    reward             | 0.0061482415 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 59            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | -10.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.641         |\n",
      "|    reward             | -0.0023311628 |\n",
      "|    std                | 1.23          |\n",
      "|    value_loss         | 0.00252       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -1.33       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.166       |\n",
      "|    reward             | 0.017406981 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.000498    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1695038.704866085\n",
      "Sharpe:  0.6120552759206377\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 68            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | -11.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.523         |\n",
      "|    reward             | -0.0006162095 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 0.0018        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:936689.8953412528\n",
      "Sharpe:  -0.032924272095039044\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -60.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.322       |\n",
      "|    reward             | -0.011506184 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 76           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.314        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0698       |\n",
      "|    reward             | -0.033084095 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -2.08        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.918        |\n",
      "|    reward             | 0.0013015817 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 0.00366      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2565740.4486687724\n",
      "Sharpe:  0.7854670245857907\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | -0.0589       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.00593      |\n",
      "|    reward             | -0.0016002951 |\n",
      "|    std                | 1.48          |\n",
      "|    value_loss         | 7.65e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:964712.4385621622\n",
      "Sharpe:  0.03130025983709177\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.0235       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.876       |\n",
      "|    reward             | -0.010539771 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:888841.8669756977\n",
      "Sharpe:  -0.14325417178418604\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 94            |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | -4.88         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | 0.149         |\n",
      "|    reward             | 8.5118154e-05 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 0.000375      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 98            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | -1.15         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | -0.124        |\n",
      "|    reward             | -0.0016166226 |\n",
      "|    std                | 1.65          |\n",
      "|    value_loss         | 6.55e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0.345        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.282        |\n",
      "|    reward             | -0.011270957 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.000228     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1426555.8779370484\n",
      "Sharpe:  0.44550295174596066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | -8.02         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.539        |\n",
      "|    reward             | -0.0058123176 |\n",
      "|    std                | 1.77          |\n",
      "|    value_loss         | 0.00101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 112           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.3         |\n",
      "|    explained_variance | -20.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -0.512        |\n",
      "|    reward             | -0.0032418196 |\n",
      "|    std                | 1.84          |\n",
      "|    value_loss         | 0.000931      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1037608.0154542325\n",
      "Sharpe:  0.15944791916562795\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | -12.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.004686814 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 0.000252     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | -0.542      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | 0.016480442 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 0.000149    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | -0.87         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.0768       |\n",
      "|    reward             | -0.0035892418 |\n",
      "|    std                | 2.08          |\n",
      "|    value_loss         | 0.000482      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1409984.5012445825\n",
      "Sharpe:  0.36488239354080243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 130           |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | -1.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 1.18          |\n",
      "|    reward             | -0.0016713775 |\n",
      "|    std                | 2.17          |\n",
      "|    value_loss         | 0.00484       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 115        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.1      |\n",
      "|    explained_variance | -0.126     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -0.0367    |\n",
      "|    reward             | 0.00597079 |\n",
      "|    std                | 2.25       |\n",
      "|    value_loss         | 6.27e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1006279.4122860949\n",
      "Sharpe:  0.10874580743098652\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 138           |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | -0.591        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | 0.368         |\n",
      "|    reward             | -0.0001439989 |\n",
      "|    std                | 2.34          |\n",
      "|    value_loss         | 0.000711      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1204494.0080355513\n",
      "Sharpe:  2.9101560150478285\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1076661.7011410692\n",
      "Sharpe:  3.3253486649293134\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0.294        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.309        |\n",
      "|    reward             | 0.0023833003 |\n",
      "|    std                | 2.45         |\n",
      "|    value_loss         | 0.000497     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | -2.7         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.299       |\n",
      "|    reward             | -0.005230111 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.000275     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1294985.593695966\n",
      "Sharpe:  0.3669163067025682\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.5         |\n",
      "|    explained_variance | -1.48         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | -0.635        |\n",
      "|    reward             | -0.0051715267 |\n",
      "|    std                | 2.64          |\n",
      "|    value_loss         | 0.000942      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -0.686       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | 0.0009566605 |\n",
      "|    std                | 2.76         |\n",
      "|    value_loss         | 0.000312     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | -0.136        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.0107       |\n",
      "|    reward             | -0.0017039293 |\n",
      "|    std                | 2.88          |\n",
      "|    value_loss         | 7.77e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1548311.6317303788\n",
      "Sharpe:  0.5149428218672962\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.301        |\n",
      "|    reward             | -0.003627592 |\n",
      "|    std                | 3            |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | -0.827      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | -0.884      |\n",
      "|    reward             | 0.007822906 |\n",
      "|    std                | 3.13        |\n",
      "|    value_loss         | 0.00204     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1283901.2517909787\n",
      "Sharpe:  0.3943788513441884\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.364        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.347        |\n",
      "|    reward             | -0.007951505 |\n",
      "|    std                | 3.27         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | -2.63        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | 0.0056459927 |\n",
      "|    std                | 3.42         |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | -0.365       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.397        |\n",
      "|    reward             | -0.008372278 |\n",
      "|    std                | 3.57         |\n",
      "|    value_loss         | 0.000545     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | -0.399      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 0.139       |\n",
      "|    reward             | 0.014507795 |\n",
      "|    std                | 3.72        |\n",
      "|    value_loss         | 7.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1571482.1025164963\n",
      "Sharpe:  0.40360770505479454\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.9      |\n",
      "|    explained_variance | -0.982     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 0.366      |\n",
      "|    reward             | 0.02348977 |\n",
      "|    std                | 3.86       |\n",
      "|    value_loss         | 0.000295   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.0844      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.566       |\n",
      "|    reward             | 0.002864123 |\n",
      "|    std                | 4.02        |\n",
      "|    value_loss         | 0.000517    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:737865.2616585282\n",
      "Sharpe:  -0.22980895554498565\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 197          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0.177        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.22         |\n",
      "|    reward             | 0.0077712294 |\n",
      "|    std                | 4.18         |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | -25.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.136        |\n",
      "|    reward             | -0.003941808 |\n",
      "|    std                | 4.36         |\n",
      "|    value_loss         | 0.000601     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.4       |\n",
      "|    explained_variance | -0.495      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.784      |\n",
      "|    reward             | 0.009891701 |\n",
      "|    std                | 4.54        |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1172082.7529584388\n",
      "Sharpe:  0.23890461961439893\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | -1.79        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.277       |\n",
      "|    reward             | 0.0011995478 |\n",
      "|    std                | 4.71         |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | -105        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | 0.003205767 |\n",
      "|    std                | 4.91        |\n",
      "|    value_loss         | 0.000229    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:815543.803738352\n",
      "Sharpe:  -0.19975241585387254\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | -0.771       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | -0.639       |\n",
      "|    reward             | 0.0042447234 |\n",
      "|    std                | 5.11         |\n",
      "|    value_loss         | 0.000551     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 222           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.8         |\n",
      "|    explained_variance | -1.45         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | -0.131        |\n",
      "|    reward             | -0.0008821505 |\n",
      "|    std                | 5.3           |\n",
      "|    value_loss         | 5.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | -0.132       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.525        |\n",
      "|    reward             | -0.022428425 |\n",
      "|    std                | 5.5          |\n",
      "|    value_loss         | 0.000349     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1355392.831033994\n",
      "Sharpe:  0.32266594196474724\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | -4.37        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | -0.259       |\n",
      "|    reward             | -0.002522591 |\n",
      "|    std                | 5.72         |\n",
      "|    value_loss         | 0.000215     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:699009.0728925685\n",
      "Sharpe:  -0.7198604651797681\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 234           |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | 0.382         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | -0.238        |\n",
      "|    reward             | -0.0021738247 |\n",
      "|    std                | 5.95          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1027220.7742700656\n",
      "Sharpe:  0.1545223587829333\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0.601        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | 0.21         |\n",
      "|    reward             | 0.0044977283 |\n",
      "|    std                | 6.17         |\n",
      "|    value_loss         | 8.79e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | -4.8         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.0642       |\n",
      "|    reward             | 0.0038228072 |\n",
      "|    std                | 6.41         |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:894955.7221143486\n",
      "Sharpe:  -0.10566294034018495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:856936.8159165705\n",
      "Sharpe:  -0.28040508450622187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 5800          |\n",
      "|    time_elapsed       | 247           |\n",
      "|    total_timesteps    | 29000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.8         |\n",
      "|    explained_variance | -0.135        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5799          |\n",
      "|    policy_loss        | 0.34          |\n",
      "|    reward             | -0.0038153294 |\n",
      "|    std                | 6.68          |\n",
      "|    value_loss         | 0.000152      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | -2.46        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -1.23        |\n",
      "|    reward             | -0.014582671 |\n",
      "|    std                | 6.98         |\n",
      "|    value_loss         | 0.00319      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0.261       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.245       |\n",
      "|    reward             | 0.006096071 |\n",
      "|    std                | 7.28        |\n",
      "|    value_loss         | 0.000164    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:973565.6309722475\n",
      "Sharpe:  0.07169603215330402\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31           |\n",
      "|    explained_variance | -3.33         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -0.107        |\n",
      "|    reward             | -0.0071531283 |\n",
      "|    std                | 7.55          |\n",
      "|    value_loss         | 0.000276      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:943682.5873128055\n",
      "Sharpe:  -0.1761903424287747\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499765.22086031316\n",
      "Sharpe:  -1.8134562954547928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | -1.79        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 0.234        |\n",
      "|    reward             | 0.0016324694 |\n",
      "|    std                | 7.83         |\n",
      "|    value_loss         | 0.000275     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739717.388181973\n",
      "Sharpe:  -0.6720152733168591\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 6300          |\n",
      "|    time_elapsed       | 268           |\n",
      "|    total_timesteps    | 31500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.6         |\n",
      "|    explained_variance | -0.665        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6299          |\n",
      "|    policy_loss        | -0.235        |\n",
      "|    reward             | -0.0031205378 |\n",
      "|    std                | 8.12          |\n",
      "|    value_loss         | 8.62e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:698226.6953543527\n",
      "Sharpe:  -0.5547407109928439\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32        |\n",
      "|    explained_variance | -1.76      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 1.4        |\n",
      "|    reward             | 0.00674702 |\n",
      "|    std                | 8.45       |\n",
      "|    value_loss         | 0.00223    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:708227.8385956215\n",
      "Sharpe:  -0.8559004780221363\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 276        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.3      |\n",
      "|    explained_variance | -0.546     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 0.187      |\n",
      "|    reward             | 0.00863004 |\n",
      "|    std                | 8.77       |\n",
      "|    value_loss         | 0.000164   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1117635.7706625264\n",
      "Sharpe:  1.7889996868051288\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 280          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | -5.09        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 0.144        |\n",
      "|    reward             | -0.012827586 |\n",
      "|    std                | 9.16         |\n",
      "|    value_loss         | 0.000135     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:852849.0584412534\n",
      "Sharpe:  -0.15000503101754256\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 284           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | -18           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | 0.297         |\n",
      "|    reward             | -0.0015763364 |\n",
      "|    std                | 9.55          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0.672       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.008175776 |\n",
      "|    std                | 9.95        |\n",
      "|    value_loss         | 0.000191    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 117            |\n",
      "|    iterations         | 6900           |\n",
      "|    time_elapsed       | 293            |\n",
      "|    total_timesteps    | 34500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -33.8          |\n",
      "|    explained_variance | 0.352          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6899           |\n",
      "|    policy_loss        | -0.177         |\n",
      "|    reward             | -1.7105189e-05 |\n",
      "|    std                | 10.3           |\n",
      "|    value_loss         | 7.32e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:972429.0860212843\n",
      "Sharpe:  0.06879433257600631\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1014462.7922247093\n",
      "Sharpe:  0.19299468633769135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1111311.4871664057\n",
      "Sharpe:  1.8951065202198427\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 297          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | -0.824       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.009971814 |\n",
      "|    std                | 10.8         |\n",
      "|    value_loss         | 6.43e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 301           |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.5         |\n",
      "|    explained_variance | -0.382        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | -0.384        |\n",
      "|    reward             | -0.0051006414 |\n",
      "|    std                | 11.2          |\n",
      "|    value_loss         | 0.000297      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | -0.599       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0006574699 |\n",
      "|    std                | 11.7         |\n",
      "|    value_loss         | 2.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 310           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.3         |\n",
      "|    explained_variance | -6.56         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.0661       |\n",
      "|    reward             | -0.0017598472 |\n",
      "|    std                | 12.2          |\n",
      "|    value_loss         | 1.95e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736181.4508343985\n",
      "Sharpe:  -0.16536418528024216\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | -0.555       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.553        |\n",
      "|    reward             | 0.0018365761 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 0.000282     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | -0.427       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.009378076 |\n",
      "|    std                | 13.2         |\n",
      "|    value_loss         | 6.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | -0.254      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | -0.594      |\n",
      "|    reward             | 0.008586504 |\n",
      "|    std                | 13.8        |\n",
      "|    value_loss         | 0.000337    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:932231.0576241079\n",
      "Sharpe:  0.06886612442178099\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | -1.21        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | -0.6         |\n",
      "|    reward             | 0.0091944905 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 0.000366     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:666702.7850623905\n",
      "Sharpe:  -0.6430428294836127\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.1       |\n",
      "|    explained_variance | -4.6        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -0.498      |\n",
      "|    reward             | 0.008296777 |\n",
      "|    std                | 15          |\n",
      "|    value_loss         | 0.000271    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:917120.3915447518\n",
      "Sharpe:  -0.07589283762982199\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | -0.176       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.14         |\n",
      "|    reward             | 0.0016407189 |\n",
      "|    std                | 15.7         |\n",
      "|    value_loss         | 4.14e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.9       |\n",
      "|    explained_variance | -1.04       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.129       |\n",
      "|    reward             | 0.003119644 |\n",
      "|    std                | 16.3        |\n",
      "|    value_loss         | 9.59e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.3      |\n",
      "|    explained_variance | -0.086     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 0.103      |\n",
      "|    reward             | 0.01720999 |\n",
      "|    std                | 17         |\n",
      "|    value_loss         | 4.77e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757576.382228524\n",
      "Sharpe:  -0.229782833960982\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.7       |\n",
      "|    explained_variance | -2.67       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 0.229       |\n",
      "|    reward             | 0.005688486 |\n",
      "|    std                | 17.8        |\n",
      "|    value_loss         | 9.43e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39         |\n",
      "|    explained_variance | -0.412      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.0476      |\n",
      "|    reward             | -0.02754451 |\n",
      "|    std                | 18.5        |\n",
      "|    value_loss         | 5.5e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 356           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.4         |\n",
      "|    explained_variance | -0.171        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | 0.625         |\n",
      "|    reward             | -0.0040394193 |\n",
      "|    std                | 19.3          |\n",
      "|    value_loss         | 0.000397      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:905374.5222643825\n",
      "Sharpe:  0.012876908498560734\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:933641.8346197518\n",
      "Sharpe:  -0.4728442371188859\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.7        |\n",
      "|    explained_variance | -31.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | 0.0532       |\n",
      "|    reward             | 0.0055862013 |\n",
      "|    std                | 20.1         |\n",
      "|    value_loss         | 3.26e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 365          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.1        |\n",
      "|    explained_variance | -0.012       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -0.724       |\n",
      "|    reward             | -0.007630164 |\n",
      "|    std                | 20.8         |\n",
      "|    value_loss         | 0.000768     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:680933.4167773045\n",
      "Sharpe:  -0.40731655130471706\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.4        |\n",
      "|    explained_variance | 0.00946      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.24        |\n",
      "|    reward             | -0.012840096 |\n",
      "|    std                | 21.7         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.8        |\n",
      "|    explained_variance | -0.25        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.731       |\n",
      "|    reward             | -0.004916788 |\n",
      "|    std                | 22.6         |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.1        |\n",
      "|    explained_variance | -1.14        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 1.95         |\n",
      "|    reward             | 0.0039052714 |\n",
      "|    std                | 23.5         |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:722684.6492055736\n",
      "Sharpe:  -0.18450919578730843\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.5        |\n",
      "|    explained_variance | -1.97        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.0997      |\n",
      "|    reward             | 0.0010893667 |\n",
      "|    std                | 24.4         |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 386          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.9        |\n",
      "|    explained_variance | 0.236        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.217        |\n",
      "|    reward             | -0.018156055 |\n",
      "|    std                | 25.4         |\n",
      "|    value_loss         | 0.000223     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798438.1611674894\n",
      "Sharpe:  -0.18645745113534315\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 391          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -7.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.665        |\n",
      "|    reward             | 0.0066204625 |\n",
      "|    std                | 26.5         |\n",
      "|    value_loss         | 0.000385     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | -0.654      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | -0.00558266 |\n",
      "|    std                | 27.6        |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:728370.1864159992\n",
      "Sharpe:  -0.32804705308468074\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -3.77       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 2.59        |\n",
      "|    reward             | 0.005264401 |\n",
      "|    std                | 28.6        |\n",
      "|    value_loss         | 0.00544     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 117            |\n",
      "|    iterations         | 9500           |\n",
      "|    time_elapsed       | 403            |\n",
      "|    total_timesteps    | 47500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.2          |\n",
      "|    explained_variance | -14.7          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9499           |\n",
      "|    policy_loss        | 0.501          |\n",
      "|    reward             | -0.00057371164 |\n",
      "|    std                | 29.6           |\n",
      "|    value_loss         | 0.000385       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:654749.8204527879\n",
      "Sharpe:  -0.3993771635631604\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.6        |\n",
      "|    explained_variance | -2.14        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.101        |\n",
      "|    reward             | 0.0022325565 |\n",
      "|    std                | 30.7         |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.9       |\n",
      "|    explained_variance | 0.53        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.388       |\n",
      "|    reward             | 0.005260505 |\n",
      "|    std                | 32          |\n",
      "|    value_loss         | 9.16e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.3        |\n",
      "|    explained_variance | -2.38        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.63         |\n",
      "|    reward             | -0.004898069 |\n",
      "|    std                | 33.2         |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:691735.5895594646\n",
      "Sharpe:  -0.21417164739350422\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 420           |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.7         |\n",
      "|    explained_variance | -3.34         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | -0.27         |\n",
      "|    reward             | -0.0067278715 |\n",
      "|    std                | 34.7          |\n",
      "|    value_loss         | 7.58e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45          |\n",
      "|    explained_variance | -0.744       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 1.58         |\n",
      "|    reward             | -0.005020344 |\n",
      "|    std                | 35.9         |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775537.7195128949\n",
      "Sharpe:  -0.14620940177094074\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10100        |\n",
      "|    time_elapsed       | 428          |\n",
      "|    total_timesteps    | 50500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.3        |\n",
      "|    explained_variance | -0.149       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10099        |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | -0.008008821 |\n",
      "|    std                | 37.2         |\n",
      "|    value_loss         | 0.000388     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 432          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.6        |\n",
      "|    explained_variance | 0.0512       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -2.39        |\n",
      "|    reward             | 0.0061468864 |\n",
      "|    std                | 38.6         |\n",
      "|    value_loss         | 0.00779      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:734267.0803116941\n",
      "Sharpe:  -0.29390576904292076\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10300        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 51500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46          |\n",
      "|    explained_variance | -0.429       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -0.429       |\n",
      "|    reward             | 0.0008383668 |\n",
      "|    std                | 40.3         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10400        |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 52000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.4        |\n",
      "|    explained_variance | 0.448        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | -0.607       |\n",
      "|    reward             | -0.001411954 |\n",
      "|    std                | 42           |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 445         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.8       |\n",
      "|    explained_variance | -227        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | -3.43       |\n",
      "|    reward             | -0.09160861 |\n",
      "|    std                | 43.8        |\n",
      "|    value_loss         | 0.00711     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:642833.5359087792\n",
      "Sharpe:  -0.32891731077760966\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10600        |\n",
      "|    time_elapsed       | 450          |\n",
      "|    total_timesteps    | 53000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.2        |\n",
      "|    explained_variance | -1.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | -0.002857883 |\n",
      "|    std                | 45.8         |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 454        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.6      |\n",
      "|    explained_variance | -0.812     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | 0.209      |\n",
      "|    reward             | 0.00792306 |\n",
      "|    std                | 47.8       |\n",
      "|    value_loss         | 0.000122   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 458         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.9       |\n",
      "|    explained_variance | -0.147      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | 0.274       |\n",
      "|    reward             | 0.017958017 |\n",
      "|    std                | 49.9        |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:849883.0590464178\n",
      "Sharpe:  -0.0528937761538155\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 463          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.3        |\n",
      "|    explained_variance | -3.27        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | 0.494        |\n",
      "|    reward             | -0.007368212 |\n",
      "|    std                | 52.1         |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:800533.8242243751\n",
      "Sharpe:  -0.4506203612835548\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.7        |\n",
      "|    explained_variance | 0.313        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | -0.775       |\n",
      "|    reward             | -0.013859695 |\n",
      "|    std                | 54.3         |\n",
      "|    value_loss         | 0.000479     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:488959.0488958298\n",
      "Sharpe:  -1.4150959250738064\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11100        |\n",
      "|    time_elapsed       | 471          |\n",
      "|    total_timesteps    | 55500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49          |\n",
      "|    explained_variance | 0.0148       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | 0.594        |\n",
      "|    reward             | -0.006422058 |\n",
      "|    std                | 56.2         |\n",
      "|    value_loss         | 0.000331     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11200        |\n",
      "|    time_elapsed       | 475          |\n",
      "|    total_timesteps    | 56000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.4        |\n",
      "|    explained_variance | -2.44        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | -0.773       |\n",
      "|    reward             | 0.0002993208 |\n",
      "|    std                | 58.6         |\n",
      "|    value_loss         | 0.00027      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 479          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.8        |\n",
      "|    explained_variance | -0.801       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 0.0715       |\n",
      "|    reward             | 0.0066912156 |\n",
      "|    std                | 61.2         |\n",
      "|    value_loss         | 0.000336     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:683598.6043464367\n",
      "Sharpe:  -0.15376631742189648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082277.2379877318\n",
      "Sharpe:  2.1813208723976025\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11400        |\n",
      "|    time_elapsed       | 484          |\n",
      "|    total_timesteps    | 57000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.1        |\n",
      "|    explained_variance | -4.53        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | -0.592       |\n",
      "|    reward             | 0.0038414558 |\n",
      "|    std                | 63.6         |\n",
      "|    value_loss         | 0.000167     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 11500      |\n",
      "|    time_elapsed       | 488        |\n",
      "|    total_timesteps    | 57500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.5      |\n",
      "|    explained_variance | -2.16      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11499      |\n",
      "|    policy_loss        | -1.06      |\n",
      "|    reward             | 0.01799127 |\n",
      "|    std                | 66.1       |\n",
      "|    value_loss         | 0.000539   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:646416.3317756741\n",
      "Sharpe:  -0.6265850815659355\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:944476.3560858215\n",
      "Sharpe:  -0.2757018939012499\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 11600       |\n",
      "|    time_elapsed       | 492         |\n",
      "|    total_timesteps    | 58000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.8       |\n",
      "|    explained_variance | -1.11       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | -1.14       |\n",
      "|    reward             | 0.011600345 |\n",
      "|    std                | 68.8        |\n",
      "|    value_loss         | 0.000541    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11700        |\n",
      "|    time_elapsed       | 497          |\n",
      "|    total_timesteps    | 58500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.2        |\n",
      "|    explained_variance | -0.281       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | 0.613        |\n",
      "|    reward             | -0.009357034 |\n",
      "|    std                | 71.6         |\n",
      "|    value_loss         | 0.000595     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498996.08338440594\n",
      "Sharpe:  -1.1253014620531456\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 117            |\n",
      "|    iterations         | 11800          |\n",
      "|    time_elapsed       | 501            |\n",
      "|    total_timesteps    | 59000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -51.6          |\n",
      "|    explained_variance | 0.381          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 11799          |\n",
      "|    policy_loss        | -0.719         |\n",
      "|    reward             | -0.00079129747 |\n",
      "|    std                | 74.7           |\n",
      "|    value_loss         | 0.000227       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 505          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52          |\n",
      "|    explained_variance | 0.224        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.251       |\n",
      "|    reward             | -0.005833403 |\n",
      "|    std                | 78.2         |\n",
      "|    value_loss         | 4.25e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495829.4001107065\n",
      "Sharpe:  -0.8386605443977434\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.3       |\n",
      "|    explained_variance | -2.61       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | 0.397       |\n",
      "|    reward             | 0.009585065 |\n",
      "|    std                | 81.2        |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 514         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.7       |\n",
      "|    explained_variance | -6.06       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | 0.628       |\n",
      "|    reward             | 0.005121934 |\n",
      "|    std                | 84.7        |\n",
      "|    value_loss         | 0.000204    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 12200      |\n",
      "|    time_elapsed       | 518        |\n",
      "|    total_timesteps    | 61000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.1      |\n",
      "|    explained_variance | -21.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12199      |\n",
      "|    policy_loss        | 0.0827     |\n",
      "|    reward             | 0.01068671 |\n",
      "|    std                | 88.2       |\n",
      "|    value_loss         | 7.57e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:907168.4454163722\n",
      "Sharpe:  0.02072513470573142\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 117            |\n",
      "|    iterations         | 12300          |\n",
      "|    time_elapsed       | 522            |\n",
      "|    total_timesteps    | 61500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -53.4          |\n",
      "|    explained_variance | -0.839         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12299          |\n",
      "|    policy_loss        | -1.73          |\n",
      "|    reward             | -0.00028056538 |\n",
      "|    std                | 91.9           |\n",
      "|    value_loss         | 0.00108        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 12400       |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 62000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.8       |\n",
      "|    explained_variance | 0.166       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 0.877       |\n",
      "|    reward             | 0.010710887 |\n",
      "|    std                | 96.2        |\n",
      "|    value_loss         | 0.000308    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 12500         |\n",
      "|    time_elapsed       | 531           |\n",
      "|    total_timesteps    | 62500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.2         |\n",
      "|    explained_variance | -0.741        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12499         |\n",
      "|    policy_loss        | 0.725         |\n",
      "|    reward             | -0.0034537094 |\n",
      "|    std                | 100           |\n",
      "|    value_loss         | 0.000287      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:468552.71107886307\n",
      "Sharpe:  -0.7475590433458442\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 12600        |\n",
      "|    time_elapsed       | 535          |\n",
      "|    total_timesteps    | 63000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.6        |\n",
      "|    explained_variance | -0.857       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12599        |\n",
      "|    policy_loss        | 2.12         |\n",
      "|    reward             | -0.021445125 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:621374.61651645\n",
      "Sharpe:  -0.49244863078730017\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 12700        |\n",
      "|    time_elapsed       | 539          |\n",
      "|    total_timesteps    | 63500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55          |\n",
      "|    explained_variance | -0.758       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12699        |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | 0.0011876916 |\n",
      "|    std                | 109          |\n",
      "|    value_loss         | 2.35e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 544         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.4       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.227      |\n",
      "|    reward             | 0.006470321 |\n",
      "|    std                | 114         |\n",
      "|    value_loss         | 2.01e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496894.9892062196\n",
      "Sharpe:  -0.8877267473001836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 12900         |\n",
      "|    time_elapsed       | 548           |\n",
      "|    total_timesteps    | 64500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.7         |\n",
      "|    explained_variance | -2.02         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12899         |\n",
      "|    policy_loss        | -0.0797       |\n",
      "|    reward             | -0.0013959686 |\n",
      "|    std                | 118           |\n",
      "|    value_loss         | 0.00019       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13000         |\n",
      "|    time_elapsed       | 553           |\n",
      "|    total_timesteps    | 65000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.1         |\n",
      "|    explained_variance | -7.36         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12999         |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0025580777 |\n",
      "|    std                | 123           |\n",
      "|    value_loss         | 9.78e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13100         |\n",
      "|    time_elapsed       | 557           |\n",
      "|    total_timesteps    | 65500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.5         |\n",
      "|    explained_variance | -0.898        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13099         |\n",
      "|    policy_loss        | 0.868         |\n",
      "|    reward             | -0.0057343654 |\n",
      "|    std                | 129           |\n",
      "|    value_loss         | 0.000305      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:603435.0248987107\n",
      "Sharpe:  -0.5036213644404635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:477999.4151354204\n",
      "Sharpe:  -2.605016285902907\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 13200       |\n",
      "|    time_elapsed       | 561         |\n",
      "|    total_timesteps    | 66000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.8       |\n",
      "|    explained_variance | -0.00999    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 0.654       |\n",
      "|    reward             | 0.004868695 |\n",
      "|    std                | 134         |\n",
      "|    value_loss         | 0.000164    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13300         |\n",
      "|    time_elapsed       | 565           |\n",
      "|    total_timesteps    | 66500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.2         |\n",
      "|    explained_variance | -8.79         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13299         |\n",
      "|    policy_loss        | 0.23          |\n",
      "|    reward             | -0.0006384243 |\n",
      "|    std                | 140           |\n",
      "|    value_loss         | 2.5e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 13400        |\n",
      "|    time_elapsed       | 570          |\n",
      "|    total_timesteps    | 67000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.5        |\n",
      "|    explained_variance | -0.636       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | -0.95        |\n",
      "|    reward             | -0.002855705 |\n",
      "|    std                | 145          |\n",
      "|    value_loss         | 0.000318     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787449.6720745375\n",
      "Sharpe:  -0.10751928574016226\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 13500       |\n",
      "|    time_elapsed       | 574         |\n",
      "|    total_timesteps    | 67500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.9       |\n",
      "|    explained_variance | 0.203       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | -0.894      |\n",
      "|    reward             | 0.011878022 |\n",
      "|    std                | 151         |\n",
      "|    value_loss         | 0.00046     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:957446.0930508247\n",
      "Sharpe:  -0.15138224613024595\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13600         |\n",
      "|    time_elapsed       | 578           |\n",
      "|    total_timesteps    | 68000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.3         |\n",
      "|    explained_variance | -1.04         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13599         |\n",
      "|    policy_loss        | 0.208         |\n",
      "|    reward             | -0.0030340834 |\n",
      "|    std                | 157           |\n",
      "|    value_loss         | 5.58e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:943846.0965081388\n",
      "Sharpe:  -0.29711116399294535\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1088103.9612662573\n",
      "Sharpe:  1.0986524363661334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13700         |\n",
      "|    time_elapsed       | 583           |\n",
      "|    total_timesteps    | 68500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.6         |\n",
      "|    explained_variance | -0.506        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | 0.0604        |\n",
      "|    reward             | -0.0042048385 |\n",
      "|    std                | 163           |\n",
      "|    value_loss         | 2.59e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:876105.3437455505\n",
      "Sharpe:  -0.377065818685249\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1010992.4357269189\n",
      "Sharpe:  2.0633686806194174\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 13800         |\n",
      "|    time_elapsed       | 587           |\n",
      "|    total_timesteps    | 69000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.9         |\n",
      "|    explained_variance | -2.2          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13799         |\n",
      "|    policy_loss        | 0.649         |\n",
      "|    reward             | -0.0007160394 |\n",
      "|    std                | 170           |\n",
      "|    value_loss         | 0.000184      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 591         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.3       |\n",
      "|    explained_variance | 0.311       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | -0.245      |\n",
      "|    reward             | 0.012371651 |\n",
      "|    std                | 176         |\n",
      "|    value_loss         | 3.66e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:712659.2414838561\n",
      "Sharpe:  -0.3265338743427719\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 14000        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 70000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.6        |\n",
      "|    explained_variance | 0.371        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13999        |\n",
      "|    policy_loss        | 0.393        |\n",
      "|    reward             | 0.0023932217 |\n",
      "|    std                | 183          |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:481915.18145658314\n",
      "Sharpe:  -1.3237742233477319\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 600         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60         |\n",
      "|    explained_variance | -0.16       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 0.782       |\n",
      "|    reward             | 0.019862482 |\n",
      "|    std                | 190         |\n",
      "|    value_loss         | 0.000265    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14200       |\n",
      "|    time_elapsed       | 604         |\n",
      "|    total_timesteps    | 71000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.3       |\n",
      "|    explained_variance | -4.28       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | 0.696       |\n",
      "|    reward             | -0.02508222 |\n",
      "|    std                | 198         |\n",
      "|    value_loss         | 0.000216    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14300       |\n",
      "|    time_elapsed       | 608         |\n",
      "|    total_timesteps    | 71500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.7       |\n",
      "|    explained_variance | 0.0583      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | -0.07662169 |\n",
      "|    std                | 206         |\n",
      "|    value_loss         | 0.000877    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:642459.9950601746\n",
      "Sharpe:  -0.2797731475582705\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14400       |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 72000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.1       |\n",
      "|    explained_variance | -2.13       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | -0.592      |\n",
      "|    reward             | 0.011253892 |\n",
      "|    std                | 215         |\n",
      "|    value_loss         | 0.000164    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:666796.5197578643\n",
      "Sharpe:  -0.7706340392223572\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.4        |\n",
      "|    explained_variance | -13          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 0.502        |\n",
      "|    reward             | 0.0059281816 |\n",
      "|    std                | 224          |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14600       |\n",
      "|    time_elapsed       | 621         |\n",
      "|    total_timesteps    | 73000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.8       |\n",
      "|    explained_variance | -1.27       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | -0.276      |\n",
      "|    reward             | 0.009393328 |\n",
      "|    std                | 233         |\n",
      "|    value_loss         | 5.47e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495205.19995280885\n",
      "Sharpe:  -1.1743498687653724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1018600.9981569911\n",
      "Sharpe:  0.5417902320502783\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 14700        |\n",
      "|    time_elapsed       | 626          |\n",
      "|    total_timesteps    | 73500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.2        |\n",
      "|    explained_variance | 0.685        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14699        |\n",
      "|    policy_loss        | -0.229       |\n",
      "|    reward             | -0.011949655 |\n",
      "|    std                | 242          |\n",
      "|    value_loss         | 3.83e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 630         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.5       |\n",
      "|    explained_variance | -7.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.0856      |\n",
      "|    reward             | 0.021767262 |\n",
      "|    std                | 252         |\n",
      "|    value_loss         | 0.000168    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:695118.4478209908\n",
      "Sharpe:  -0.32160648093267674\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 634          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.9        |\n",
      "|    explained_variance | -1.93        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | 0.0706       |\n",
      "|    reward             | 0.0045945453 |\n",
      "|    std                | 263          |\n",
      "|    value_loss         | 3.17e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 15000         |\n",
      "|    time_elapsed       | 638           |\n",
      "|    total_timesteps    | 75000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -63.2         |\n",
      "|    explained_variance | -1.71         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | 1.83          |\n",
      "|    reward             | 0.00039711432 |\n",
      "|    std                | 273           |\n",
      "|    value_loss         | 0.00141       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493314.92501350737\n",
      "Sharpe:  -0.9522917282564402\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.6       |\n",
      "|    explained_variance | 0.402       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 0.316       |\n",
      "|    reward             | -0.01668272 |\n",
      "|    std                | 283         |\n",
      "|    value_loss         | 5.99e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714383.4608395468\n",
      "Sharpe:  -0.9135781972743113\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1179015.7924033352\n",
      "Sharpe:  3.551242494783207\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 15200         |\n",
      "|    time_elapsed       | 647           |\n",
      "|    total_timesteps    | 76000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -63.9         |\n",
      "|    explained_variance | 0.403         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15199         |\n",
      "|    policy_loss        | 0.192         |\n",
      "|    reward             | -0.0029478988 |\n",
      "|    std                | 295           |\n",
      "|    value_loss         | 0.0001        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:481019.1772791874\n",
      "Sharpe:  -1.4228304648050378\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 652         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.3       |\n",
      "|    explained_variance | -0.68       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | -0.401      |\n",
      "|    reward             | 0.006802043 |\n",
      "|    std                | 307         |\n",
      "|    value_loss         | 0.000289    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:480755.7811920036\n",
      "Sharpe:  -1.1842521440151104\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.7     |\n",
      "|    explained_variance | -3.46     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -0.956    |\n",
      "|    reward             | 0.0074358 |\n",
      "|    std                | 320       |\n",
      "|    value_loss         | 0.000254  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 660          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.1        |\n",
      "|    explained_variance | -2.09        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | 2.15         |\n",
      "|    reward             | 0.0031434721 |\n",
      "|    std                | 335          |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 665         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.5       |\n",
      "|    explained_variance | -2.44       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.013728647 |\n",
      "|    std                | 351         |\n",
      "|    value_loss         | 0.000563    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495191.14992832777\n",
      "Sharpe:  -0.606181898070511\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.8        |\n",
      "|    explained_variance | -0.821       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | -0.179       |\n",
      "|    reward             | -0.005345715 |\n",
      "|    std                | 364          |\n",
      "|    value_loss         | 1.96e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745594.5662716442\n",
      "Sharpe:  -0.36820145654281144\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.2        |\n",
      "|    explained_variance | -0.117       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | -0.086       |\n",
      "|    reward             | -0.003928117 |\n",
      "|    std                | 380          |\n",
      "|    value_loss         | 0.000158     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 15900         |\n",
      "|    time_elapsed       | 678           |\n",
      "|    total_timesteps    | 79500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.6         |\n",
      "|    explained_variance | -0.533        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15899         |\n",
      "|    policy_loss        | -2.26         |\n",
      "|    reward             | -0.0033869322 |\n",
      "|    std                | 397           |\n",
      "|    value_loss         | 0.00164       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 16000       |\n",
      "|    time_elapsed       | 682         |\n",
      "|    total_timesteps    | 80000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67         |\n",
      "|    explained_variance | -0.169      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | -1.82       |\n",
      "|    reward             | 0.008492918 |\n",
      "|    std                | 414         |\n",
      "|    value_loss         | 0.000937    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:665296.3916907067\n",
      "Sharpe:  -0.3101969616299522\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 686         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.3       |\n",
      "|    explained_variance | -0.21       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | -0.0447     |\n",
      "|    reward             | 0.012176814 |\n",
      "|    std                | 430         |\n",
      "|    value_loss         | 6.59e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 16200         |\n",
      "|    time_elapsed       | 691           |\n",
      "|    total_timesteps    | 81000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.7         |\n",
      "|    explained_variance | -0.195        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16199         |\n",
      "|    policy_loss        | -0.261        |\n",
      "|    reward             | -0.0008275285 |\n",
      "|    std                | 446           |\n",
      "|    value_loss         | 3.24e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 695          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68          |\n",
      "|    explained_variance | -2.22        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | -2.6         |\n",
      "|    reward             | 0.0009848744 |\n",
      "|    std                | 464          |\n",
      "|    value_loss         | 0.00156      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 16400        |\n",
      "|    time_elapsed       | 699          |\n",
      "|    total_timesteps    | 82000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.3        |\n",
      "|    explained_variance | -0.141       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16399        |\n",
      "|    policy_loss        | -1.2         |\n",
      "|    reward             | 0.0075676353 |\n",
      "|    std                | 482          |\n",
      "|    value_loss         | 0.000328     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:980795.586552463\n",
      "Sharpe:  0.12088668489211488\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 16500        |\n",
      "|    time_elapsed       | 704          |\n",
      "|    total_timesteps    | 82500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.7        |\n",
      "|    explained_variance | -2.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | 1.28         |\n",
      "|    reward             | -0.030357597 |\n",
      "|    std                | 501          |\n",
      "|    value_loss         | 0.000382     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 16600         |\n",
      "|    time_elapsed       | 708           |\n",
      "|    total_timesteps    | 83000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.1         |\n",
      "|    explained_variance | -0.855        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16599         |\n",
      "|    policy_loss        | -1.23         |\n",
      "|    reward             | -0.0058297627 |\n",
      "|    std                | 524           |\n",
      "|    value_loss         | 0.000471      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:635281.1174040581\n",
      "Sharpe:  -0.4230758759629002\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 16700       |\n",
      "|    time_elapsed       | 713         |\n",
      "|    total_timesteps    | 83500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.5       |\n",
      "|    explained_variance | -0.149      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 0.905       |\n",
      "|    reward             | 0.012451612 |\n",
      "|    std                | 546         |\n",
      "|    value_loss         | 0.000617    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:669044.1047357182\n",
      "Sharpe:  -0.7332158238486677\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 16800         |\n",
      "|    time_elapsed       | 717           |\n",
      "|    total_timesteps    | 84000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.8         |\n",
      "|    explained_variance | 0.0658        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16799         |\n",
      "|    policy_loss        | 0.708         |\n",
      "|    reward             | -0.0011284293 |\n",
      "|    std                | 570           |\n",
      "|    value_loss         | 0.000158      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:917380.7331609239\n",
      "Sharpe:  -0.0512575552512045\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 721          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.2        |\n",
      "|    explained_variance | -0.85        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.425        |\n",
      "|    reward             | 0.0011889448 |\n",
      "|    std                | 594          |\n",
      "|    value_loss         | 4.46e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 726          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.6        |\n",
      "|    explained_variance | 0.0608       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | -0.515       |\n",
      "|    reward             | -0.010159041 |\n",
      "|    std                | 618          |\n",
      "|    value_loss         | 7.34e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 730           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71           |\n",
      "|    explained_variance | -4.26         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.76          |\n",
      "|    reward             | -0.0026084988 |\n",
      "|    std                | 646           |\n",
      "|    value_loss         | 0.000147      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:564100.8828864279\n",
      "Sharpe:  -0.5599143675294757\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 117           |\n",
      "|    iterations         | 17200         |\n",
      "|    time_elapsed       | 734           |\n",
      "|    total_timesteps    | 86000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.3         |\n",
      "|    explained_variance | -3.12         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17199         |\n",
      "|    policy_loss        | -0.76         |\n",
      "|    reward             | -0.0069159176 |\n",
      "|    std                | 672           |\n",
      "|    value_loss         | 0.000296      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 117          |\n",
      "|    iterations         | 17300        |\n",
      "|    time_elapsed       | 739          |\n",
      "|    total_timesteps    | 86500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.7        |\n",
      "|    explained_variance | -0.357       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17299        |\n",
      "|    policy_loss        | -0.00853     |\n",
      "|    reward             | 0.0043228837 |\n",
      "|    std                | 697          |\n",
      "|    value_loss         | 0.000274     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:701086.3185561226\n",
      "Sharpe:  -0.3076307745515116\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1057832.5911292906\n",
      "Sharpe:  2.0521208893923144\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17400         |\n",
      "|    time_elapsed       | 744           |\n",
      "|    total_timesteps    | 87000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72           |\n",
      "|    explained_variance | -18.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17399         |\n",
      "|    policy_loss        | 2.39          |\n",
      "|    reward             | 0.00042174917 |\n",
      "|    std                | 727           |\n",
      "|    value_loss         | 0.00128       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 116            |\n",
      "|    iterations         | 17500          |\n",
      "|    time_elapsed       | 748            |\n",
      "|    total_timesteps    | 87500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.4          |\n",
      "|    explained_variance | -1.61          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17499          |\n",
      "|    policy_loss        | -0.304         |\n",
      "|    reward             | -0.00028990937 |\n",
      "|    std                | 759            |\n",
      "|    value_loss         | 0.000123       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:450236.28719420225\n",
      "Sharpe:  -1.177161223484274\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17600        |\n",
      "|    time_elapsed       | 752          |\n",
      "|    total_timesteps    | 88000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.8        |\n",
      "|    explained_variance | -2.53        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | -0.0245      |\n",
      "|    reward             | 0.0030899982 |\n",
      "|    std                | 793          |\n",
      "|    value_loss         | 8.88e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 757          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.2        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | 1.39         |\n",
      "|    reward             | -0.015418332 |\n",
      "|    std                | 823          |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 761           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.5         |\n",
      "|    explained_variance | 0.21          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | 2.36          |\n",
      "|    reward             | 0.00035551135 |\n",
      "|    std                | 858           |\n",
      "|    value_loss         | 0.0012        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:808011.462753562\n",
      "Sharpe:  -0.09918261629243266\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 17900        |\n",
      "|    time_elapsed       | 765          |\n",
      "|    total_timesteps    | 89500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.9        |\n",
      "|    explained_variance | -1.82        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | 0.197        |\n",
      "|    reward             | -0.008110852 |\n",
      "|    std                | 898          |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:669758.1129465285\n",
      "Sharpe:  -0.4950463808688601\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 770          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.3        |\n",
      "|    explained_variance | -0.811       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.534       |\n",
      "|    reward             | 0.0012682535 |\n",
      "|    std                | 934          |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18100        |\n",
      "|    time_elapsed       | 775          |\n",
      "|    total_timesteps    | 90500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.7        |\n",
      "|    explained_variance | -0.26        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | -3.85        |\n",
      "|    reward             | -0.018644232 |\n",
      "|    std                | 977          |\n",
      "|    value_loss         | 0.00411      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497407.9212389258\n",
      "Sharpe:  -1.0882275817604257\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 18200         |\n",
      "|    time_elapsed       | 779           |\n",
      "|    total_timesteps    | 91000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -75.1         |\n",
      "|    explained_variance | -2.43         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18199         |\n",
      "|    policy_loss        | -0.547        |\n",
      "|    reward             | -0.0005282227 |\n",
      "|    std                | 1.02e+03      |\n",
      "|    value_loss         | 9.04e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:494090.3255464761\n",
      "Sharpe:  -0.9603490427472824\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 783          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.4        |\n",
      "|    explained_variance | -1.7         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | -0.166       |\n",
      "|    reward             | -0.008832315 |\n",
      "|    std                | 1.06e+03     |\n",
      "|    value_loss         | 3.04e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498129.41060324403\n",
      "Sharpe:  -1.0976855316369731\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 18400         |\n",
      "|    time_elapsed       | 788           |\n",
      "|    total_timesteps    | 92000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -75.8         |\n",
      "|    explained_variance | -1.46         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18399         |\n",
      "|    policy_loss        | 0.713         |\n",
      "|    reward             | -0.0032849829 |\n",
      "|    std                | 1.1e+03       |\n",
      "|    value_loss         | 0.000153      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 792         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.1       |\n",
      "|    explained_variance | -6.51       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | 1.07        |\n",
      "|    reward             | 0.011782852 |\n",
      "|    std                | 1.15e+03    |\n",
      "|    value_loss         | 0.000218    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 18600         |\n",
      "|    time_elapsed       | 797           |\n",
      "|    total_timesteps    | 93000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -76.5         |\n",
      "|    explained_variance | 0.779         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18599         |\n",
      "|    policy_loss        | 0.0518        |\n",
      "|    reward             | -0.0026716152 |\n",
      "|    std                | 1.19e+03      |\n",
      "|    value_loss         | 7.6e-06       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:597401.330866012\n",
      "Sharpe:  -0.3581812810591784\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18700        |\n",
      "|    time_elapsed       | 801          |\n",
      "|    total_timesteps    | 93500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.9        |\n",
      "|    explained_variance | -0.393       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | 0.0031507567 |\n",
      "|    std                | 1.24e+03     |\n",
      "|    value_loss         | 2.69e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 18800        |\n",
      "|    time_elapsed       | 806          |\n",
      "|    total_timesteps    | 94000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.3        |\n",
      "|    explained_variance | -0.705       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18799        |\n",
      "|    policy_loss        | 1.62         |\n",
      "|    reward             | -0.009180404 |\n",
      "|    std                | 1.3e+03      |\n",
      "|    value_loss         | 0.000714     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 116            |\n",
      "|    iterations         | 18900          |\n",
      "|    time_elapsed       | 810            |\n",
      "|    total_timesteps    | 94500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -77.7          |\n",
      "|    explained_variance | -15.9          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18899          |\n",
      "|    policy_loss        | 1.24           |\n",
      "|    reward             | -0.00025572916 |\n",
      "|    std                | 1.36e+03       |\n",
      "|    value_loss         | 0.000325       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498788.52884781745\n",
      "Sharpe:  -0.6771268419590076\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19000        |\n",
      "|    time_elapsed       | 815          |\n",
      "|    total_timesteps    | 95000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78          |\n",
      "|    explained_variance | -13.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | -0.677       |\n",
      "|    reward             | -0.015826944 |\n",
      "|    std                | 1.42e+03     |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19100        |\n",
      "|    time_elapsed       | 819          |\n",
      "|    total_timesteps    | 95500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.4        |\n",
      "|    explained_variance | -6.74        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | 0.0013619595 |\n",
      "|    std                | 1.48e+03     |\n",
      "|    value_loss         | 0.000269     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:487460.6366853034\n",
      "Sharpe:  -0.6375380319496319\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 19200       |\n",
      "|    time_elapsed       | 823         |\n",
      "|    total_timesteps    | 96000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -78.7       |\n",
      "|    explained_variance | -0.31       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | 0.0985      |\n",
      "|    reward             | 0.006385768 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 5.97e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19300         |\n",
      "|    time_elapsed       | 828           |\n",
      "|    total_timesteps    | 96500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -79.1         |\n",
      "|    explained_variance | -3.8          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | -0.714        |\n",
      "|    reward             | -0.0032482941 |\n",
      "|    std                | 1.6e+03       |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:655511.6205287466\n",
      "Sharpe:  -0.3207926999289393\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 116            |\n",
      "|    iterations         | 19400          |\n",
      "|    time_elapsed       | 832            |\n",
      "|    total_timesteps    | 97000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -79.5          |\n",
      "|    explained_variance | 0.068          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19399          |\n",
      "|    policy_loss        | 1.98           |\n",
      "|    reward             | -0.00036713987 |\n",
      "|    std                | 1.67e+03       |\n",
      "|    value_loss         | 0.000754       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19500        |\n",
      "|    time_elapsed       | 836          |\n",
      "|    total_timesteps    | 97500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79.9        |\n",
      "|    explained_variance | -16.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | -0.751       |\n",
      "|    reward             | 0.0063555776 |\n",
      "|    std                | 1.74e+03     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:460170.2981419439\n",
      "Sharpe:  -0.8750347645953709\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 19600        |\n",
      "|    time_elapsed       | 841          |\n",
      "|    total_timesteps    | 98000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -80.3        |\n",
      "|    explained_variance | -9.98        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | 0.0047156657 |\n",
      "|    std                | 1.82e+03     |\n",
      "|    value_loss         | 9.75e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 116            |\n",
      "|    iterations         | 19700          |\n",
      "|    time_elapsed       | 846            |\n",
      "|    total_timesteps    | 98500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -80.7          |\n",
      "|    explained_variance | -4.34          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19699          |\n",
      "|    policy_loss        | 0.24           |\n",
      "|    reward             | -0.00015705772 |\n",
      "|    std                | 1.9e+03        |\n",
      "|    value_loss         | 0.000104       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496327.5900475594\n",
      "Sharpe:  -0.8624160974416133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19800         |\n",
      "|    time_elapsed       | 851           |\n",
      "|    total_timesteps    | 99000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81           |\n",
      "|    explained_variance | -0.775        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | -1.07         |\n",
      "|    reward             | -0.0140198935 |\n",
      "|    std                | 1.98e+03      |\n",
      "|    value_loss         | 0.000988      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 19900         |\n",
      "|    time_elapsed       | 856           |\n",
      "|    total_timesteps    | 99500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81.4         |\n",
      "|    explained_variance | -0.102        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19899         |\n",
      "|    policy_loss        | 0.632         |\n",
      "|    reward             | -0.0010073695 |\n",
      "|    std                | 2.06e+03      |\n",
      "|    value_loss         | 0.000119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 20000         |\n",
      "|    time_elapsed       | 861           |\n",
      "|    total_timesteps    | 100000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81.8         |\n",
      "|    explained_variance | -6.79         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19999         |\n",
      "|    policy_loss        | -1.14         |\n",
      "|    reward             | -0.0021805044 |\n",
      "|    std                | 2.15e+03      |\n",
      "|    value_loss         | 0.000204      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1060858.9378029997\n",
      "Sharpe:  8.971236357011112\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.06085893780299956 -0.012374844113516019 8.97123635701111\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:487630.7236384629\n",
      "Sharpe:  -0.8139852434864696\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1044283.2870445832\n",
      "Sharpe:  0.2719022922326578\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:635258.4946172474\n",
      "Sharpe:  -0.6411587219282238\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1049210.623584813\n",
      "Sharpe:  1.7256049311338182\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1106986.1866676144\n",
      "Sharpe:  1.4624734805146686\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 149          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 13           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0063706846 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785852.6787248191\n",
      "Sharpe:  -0.35025639123891955\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:408755.02094489196\n",
      "Sharpe:  -0.7497122425003304\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 134           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 30            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.02331227    |\n",
      "|    clip_fraction        | 0.221         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -10.1         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.211        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0578       |\n",
      "|    reward               | -0.0028290006 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.0365        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:494450.99162102904\n",
      "Sharpe:  -1.1131784221851526\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:673921.2165344553\n",
      "Sharpe:  -0.5320458474933083\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784825.5879583945\n",
      "Sharpe:  -0.3569596383239446\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 47            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.022409078   |\n",
      "|    clip_fraction        | 0.241         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -1.99         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.219        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0646       |\n",
      "|    reward               | -0.0002910235 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.013         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498135.9477811489\n",
      "Sharpe:  -0.9918335175653157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1061425.196023462\n",
      "Sharpe:  0.9241898156574114\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497948.6919459908\n",
      "Sharpe:  -0.9932409144898737\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029200561  |\n",
      "|    clip_fraction        | 0.303        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.214       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0713      |\n",
      "|    reward               | 0.0032696775 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00255      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:477551.0146968218\n",
      "Sharpe:  -0.6328147402642076\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:492867.96570005204\n",
      "Sharpe:  -1.419659606068721\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029899511  |\n",
      "|    clip_fraction        | 0.3          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.228       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0728      |\n",
      "|    reward               | 0.0061599435 |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.00327      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:612713.9863854537\n",
      "Sharpe:  -0.41209668508119235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497240.6599502281\n",
      "Sharpe:  -0.6516018778078562\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033612244 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.238      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0713     |\n",
      "|    reward               | 0.015967298 |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 0.00286     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:848773.4736407332\n",
      "Sharpe:  -0.028535715398451355\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082860.0959774323\n",
      "Sharpe:  1.2446753572822638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1180721.8507432186\n",
      "Sharpe:  1.308212417053714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:849386.4810096273\n",
      "Sharpe:  -0.1962655767613383\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:643605.4109463794\n",
      "Sharpe:  -0.8381573485738615\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03495982   |\n",
      "|    clip_fraction        | 0.355        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.227       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0762      |\n",
      "|    reward               | 0.0023084946 |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.00113      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:653069.5031588133\n",
      "Sharpe:  -0.3092673223118295\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495110.82932390395\n",
      "Sharpe:  -1.0914821121495903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1100609.286629231\n",
      "Sharpe:  1.2900786951247654\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 125           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 130           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.038070038   |\n",
      "|    clip_fraction        | 0.368         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.7         |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.215        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.0698       |\n",
      "|    reward               | -0.0013095081 |\n",
      "|    std                  | 0.993         |\n",
      "|    value_loss           | 0.000875      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763889.7079760452\n",
      "Sharpe:  -0.12756198363828308\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:730381.360535911\n",
      "Sharpe:  -0.793739687756903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1268258.751651779\n",
      "Sharpe:  2.597933442224785\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.04110294   |\n",
      "|    clip_fraction        | 0.371        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.23        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0763      |\n",
      "|    reward               | 0.0043582036 |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.000867     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:841521.602553983\n",
      "Sharpe:  -0.20392949392926138\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1135606.233970518\n",
      "Sharpe:  2.052765912728609\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:807034.6819883151\n",
      "Sharpe:  -0.1364623376522455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:629109.3525902071\n",
      "Sharpe:  -1.2564434541241667\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1087531.7782921165\n",
      "Sharpe:  2.0726657081174564\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493446.0311957791\n",
      "Sharpe:  -2.038430514011727\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 126           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 161           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.04306571    |\n",
      "|    clip_fraction        | 0.375         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.7         |\n",
      "|    explained_variance   | 0.872         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.208        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.0733       |\n",
      "|    reward               | -0.0012493178 |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 0.000725      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:895369.6848696419\n",
      "Sharpe:  -0.11836581491830814\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:683904.2740181176\n",
      "Sharpe:  -0.8025945119894389\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 177           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.042526163   |\n",
      "|    clip_fraction        | 0.399         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.7         |\n",
      "|    explained_variance   | 0.839         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.217        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.0701       |\n",
      "|    reward               | -0.0021813542 |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 0.000817      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:867015.368617903\n",
      "Sharpe:  -0.02605992750434125\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:611719.2854644606\n",
      "Sharpe:  -0.7875027480749491\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:690673.956801958\n",
      "Sharpe:  -0.6703652483701704\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.046211805  |\n",
      "|    clip_fraction        | 0.421        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.241       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0792      |\n",
      "|    reward               | 0.0022530942 |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.00082      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:616709.1479490335\n",
      "Sharpe:  -0.4243260642105957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:702574.3819247221\n",
      "Sharpe:  -0.5791913475492101\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:692872.2356393444\n",
      "Sharpe:  -0.7842198825913523\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.046698287  |\n",
      "|    clip_fraction        | 0.403        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.225       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0763      |\n",
      "|    reward               | 0.0033810304 |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.000678     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493669.03384226153\n",
      "Sharpe:  -0.7836424542328104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1159820.3405776804\n",
      "Sharpe:  2.9315879132147304\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:491993.8905189874\n",
      "Sharpe:  -0.8673206461326554\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052781492 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.233      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0753     |\n",
      "|    reward               | 0.011509324 |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.000551    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:489949.4846259646\n",
      "Sharpe:  -0.6212780833134388\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.057609826  |\n",
      "|    clip_fraction        | 0.453        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.251       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0752      |\n",
      "|    reward               | -0.019495605 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00181      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782549.9708400357\n",
      "Sharpe:  -0.11193491208953382\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498950.1072522755\n",
      "Sharpe:  -1.032846283986566\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.059523635  |\n",
      "|    clip_fraction        | 0.459        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.249       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0824      |\n",
      "|    reward               | 0.0010803929 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000764     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1078159.1448011147\n",
      "Sharpe:  0.161077140142184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:705141.6398304619\n",
      "Sharpe:  -0.27555362021044405\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082969.357489062\n",
      "Sharpe:  1.3673733459270745\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 273           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.060298406   |\n",
      "|    clip_fraction        | 0.45          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.788         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.263        |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0781       |\n",
      "|    reward               | -0.0064171082 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000505      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:952292.6777850769\n",
      "Sharpe:  0.022141191119708206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:937171.962031005\n",
      "Sharpe:  0.04414077103454934\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:927151.2798667843\n",
      "Sharpe:  -0.09742787442187208\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.061534815  |\n",
      "|    clip_fraction        | 0.486        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.235       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0766      |\n",
      "|    reward               | -0.004342466 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000699     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:851297.8053294539\n",
      "Sharpe:  -0.07550975025009522\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.06350938  |\n",
      "|    clip_fraction        | 0.477       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.222      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0793     |\n",
      "|    reward               | 0.001704993 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000439    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:919479.7808200977\n",
      "Sharpe:  0.016464678539264272\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776672.7582876044\n",
      "Sharpe:  -0.23073256514918514\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 127            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 321            |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.07037699     |\n",
      "|    clip_fraction        | 0.48           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | 0.688          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.253         |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.0738        |\n",
      "|    reward               | -0.00062397995 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.000626       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:689936.7634221119\n",
      "Sharpe:  -0.34284949477868343\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:492706.6649150506\n",
      "Sharpe:  -0.7051962155209021\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 337           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.06704751    |\n",
      "|    clip_fraction        | 0.47          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.811         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.249        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0736       |\n",
      "|    reward               | -0.0021991725 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000582      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:923649.2357402581\n",
      "Sharpe:  0.020556107473753867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:863872.2471907957\n",
      "Sharpe:  -0.02554684366371203\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 353           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.070383      |\n",
      "|    clip_fraction        | 0.478         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.769         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.256        |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.0789       |\n",
      "|    reward               | -0.0111807715 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000699      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1571637.9493682487\n",
      "Sharpe:  0.38620454262445547\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.071416095  |\n",
      "|    clip_fraction        | 0.495        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.239       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0713      |\n",
      "|    reward               | 0.0010619162 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00145      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1011910.1070778886\n",
      "Sharpe:  0.14888752405913255\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744041.5345604077\n",
      "Sharpe:  -0.4750812436719035\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:936463.0187822157\n",
      "Sharpe:  0.005530579948542911\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:730254.0356887715\n",
      "Sharpe:  -0.5918494483158782\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06813091 |\n",
      "|    clip_fraction        | 0.485      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13        |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.237     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0786    |\n",
      "|    reward               | 0.00256874 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.000627   |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1039144.2289781765\n",
      "Sharpe:  0.1417302493426431\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:905980.0616132575\n",
      "Sharpe:  -0.10440000488432978\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 127        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 401        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07158747 |\n",
      "|    clip_fraction        | 0.492      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13        |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.25      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0775    |\n",
      "|    reward               | 0.01426966 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.000444   |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1333304.3445212876\n",
      "Sharpe:  0.3908859664279767\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1200258.073692889\n",
      "Sharpe:  1.4665960227976043\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:881316.6109433471\n",
      "Sharpe:  -0.19800230096091506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:986894.7710436311\n",
      "Sharpe:  0.09190677145607282\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0823874    |\n",
      "|    clip_fraction        | 0.511        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.254       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0796      |\n",
      "|    reward               | -0.001740712 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000299     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1328658.6200290332\n",
      "Sharpe:  0.5912554514905635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1211639.1779134907\n",
      "Sharpe:  0.39928368286661864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1121836.9939739145\n",
      "Sharpe:  0.9674039816918784\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1133004.137465606\n",
      "Sharpe:  3.7443765634990305\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07989538  |\n",
      "|    clip_fraction        | 0.501       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.248      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0754     |\n",
      "|    reward               | -0.05842349 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000348    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1150279.5676587208\n",
      "Sharpe:  0.2632818753581825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:971973.3893706993\n",
      "Sharpe:  0.07380379407993311\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 450           |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.08268566    |\n",
      "|    clip_fraction        | 0.517         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.856         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.246        |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.0778       |\n",
      "|    reward               | -0.0011659362 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000376      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1053272.4486095344\n",
      "Sharpe:  0.1822845153641588\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1168332.357989958\n",
      "Sharpe:  1.223536248242008\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1193199.350854743\n",
      "Sharpe:  1.331224585579228\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 466          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.090030074  |\n",
      "|    clip_fraction        | 0.517        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.218       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0767      |\n",
      "|    reward               | 0.0071851998 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000344     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:891588.2629717984\n",
      "Sharpe:  0.009362425198827344\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1127179.077403624\n",
      "Sharpe:  0.2832986813428214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1076931.2914104173\n",
      "Sharpe:  0.4484329112693473\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 482          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08395324   |\n",
      "|    clip_fraction        | 0.508        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.246       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0739      |\n",
      "|    reward               | 0.0073760217 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000434     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1075866.4620452817\n",
      "Sharpe:  0.3060288109154264\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1388530.3624917758\n",
      "Sharpe:  0.5010885064712872\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 498          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08172598   |\n",
      "|    clip_fraction        | 0.527        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.245       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0736      |\n",
      "|    reward               | -0.004802143 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000483     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1664684.2972197547\n",
      "Sharpe:  0.524839382738586\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2122723.8299484\n",
      "Sharpe:  0.6967450035703491\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 514          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.092135385  |\n",
      "|    clip_fraction        | 0.542        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.193       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.075       |\n",
      "|    reward               | -0.005235856 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000727     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1143584.9982524593\n",
      "Sharpe:  0.4461289715952114\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1064589.0133663032\n",
      "Sharpe:  3.092672988402425\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:937707.1046653789\n",
      "Sharpe:  -0.025877041409439867\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.091524474 |\n",
      "|    clip_fraction        | 0.548       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.223      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0775     |\n",
      "|    reward               | -0.0274346  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000434    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1909830.0563260668\n",
      "Sharpe:  0.6315108973700444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1228427.265985489\n",
      "Sharpe:  2.5662241632631537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1094192.6619840334\n",
      "Sharpe:  0.2597235066854964\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 545          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09919162   |\n",
      "|    clip_fraction        | 0.556        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.233       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0788      |\n",
      "|    reward               | 0.0033610913 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000371     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:999591.6195805543\n",
      "Sharpe:  0.11138978663353463\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1462837.3350544719\n",
      "Sharpe:  0.7989238914105543\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1247293.0436080564\n",
      "Sharpe:  1.5047747161481608\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1827309.1920546042\n",
      "Sharpe:  0.7740947061732083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08734455  |\n",
      "|    clip_fraction        | 0.543       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.238      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0748     |\n",
      "|    reward               | 0.002761259 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000344    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1078520.0987959043\n",
      "Sharpe:  0.22403292420270735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1145295.4211089953\n",
      "Sharpe:  2.6995567005460868\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:952410.2195473793\n",
      "Sharpe:  0.043443799502694364\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10243019  |\n",
      "|    clip_fraction        | 0.545       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.244      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0763     |\n",
      "|    reward               | 0.009118875 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000412    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1240148.6540123783\n",
      "Sharpe:  0.49011806127181184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1838463.2512777902\n",
      "Sharpe:  0.6206493744962556\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.092748225  |\n",
      "|    clip_fraction        | 0.532        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.237       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0743      |\n",
      "|    reward               | 0.0103728045 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0004       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1489426.4374560122\n",
      "Sharpe:  0.5013055474351712\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1101053.7692107193\n",
      "Sharpe:  0.2421241315274477\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1172663.0962830468\n",
      "Sharpe:  3.1040303759636885\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10493906  |\n",
      "|    clip_fraction        | 0.554       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.243      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0788     |\n",
      "|    reward               | -0.00448401 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.000373    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1776329.6888943845\n",
      "Sharpe:  0.6543067362413267\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1217940.6193889666\n",
      "Sharpe:  0.5366595689478885\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 628           |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.102356374   |\n",
      "|    clip_fraction        | 0.544         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.851         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.255        |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.0748       |\n",
      "|    reward               | 0.00021131919 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000308      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1120696.5892442141\n",
      "Sharpe:  0.19928550042123114\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1533601.008702342\n",
      "Sharpe:  0.7620700310947763\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1029768   |\n",
      "|    clip_fraction        | 0.543       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.259      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.079      |\n",
      "|    reward               | 0.002021544 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.000362    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:984295.1121165346\n",
      "Sharpe:  -3.5166629691203575\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1536845.60617965\n",
      "Sharpe:  0.46461563268406103\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 126           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 662           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.10413678    |\n",
      "|    clip_fraction        | 0.555         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.834         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.243        |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.0747       |\n",
      "|    reward               | -0.0046751276 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.0004        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1599029.1352334814\n",
      "Sharpe:  0.8875407715226595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1119217.1175418545\n",
      "Sharpe:  0.43694325666372025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1194110.504396578\n",
      "Sharpe:  0.4251454014526643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1275228.4690475324\n",
      "Sharpe:  0.4706394461633226\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 126           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 680           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.11621334    |\n",
      "|    clip_fraction        | 0.56          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.836         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.255        |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.0781       |\n",
      "|    reward               | -0.0015839249 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000432      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1232939.7385960005\n",
      "Sharpe:  1.5068466953166701\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1801459.6765450316\n",
      "Sharpe:  0.6833495767072223\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10861355   |\n",
      "|    clip_fraction        | 0.546        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.219       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0691      |\n",
      "|    reward               | 0.0025304102 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.000272     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1425855.8236576703\n",
      "Sharpe:  0.6273344313231309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1286309.5462914356\n",
      "Sharpe:  3.3452117996739723\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1160497.9248990354\n",
      "Sharpe:  3.369039248051254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1211979.975018252\n",
      "Sharpe:  0.36668964676425364\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 716          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09974052   |\n",
      "|    clip_fraction        | 0.55         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.4        |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.251       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0695      |\n",
      "|    reward               | 0.0042046933 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.000518     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1538293.8095873096\n",
      "Sharpe:  0.576445679379296\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1471737.7353793688\n",
      "Sharpe:  0.7936710679470579\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 733          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.113323465  |\n",
      "|    clip_fraction        | 0.554        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.4        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.241       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0725      |\n",
      "|    reward               | 0.0011215417 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.000447     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2692757.7575914445\n",
      "Sharpe:  0.9423932464339555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2884191.2053701016\n",
      "Sharpe:  0.9062368913955995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1218609.1579279131\n",
      "Sharpe:  1.5411878820623748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11571959  |\n",
      "|    clip_fraction        | 0.563       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.243      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0791     |\n",
      "|    reward               | 0.006852706 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.000365    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1198427.3088799482\n",
      "Sharpe:  4.861173631351583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1184179.4818359918\n",
      "Sharpe:  4.314079985435528\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:962026.5218102577\n",
      "Sharpe:  0.0763850146189235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2587317.4311109213\n",
      "Sharpe:  0.8597581519369317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12438904  |\n",
      "|    clip_fraction        | 0.577       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.249      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0726     |\n",
      "|    reward               | 0.018109482 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.000545    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1220605.358520876\n",
      "Sharpe:  1.471583457839789\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1655404.1063269586\n",
      "Sharpe:  0.5481476593660977\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11785285  |\n",
      "|    clip_fraction        | 0.577       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.248      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0765     |\n",
      "|    reward               | 0.010727411 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.000477    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1433366.0552697857\n",
      "Sharpe:  0.5720390898685347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1548768.448864675\n",
      "Sharpe:  1.9880772346714637\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1238071.5132445223\n",
      "Sharpe:  0.5386926381134669\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1110863.287677667\n",
      "Sharpe:  0.7682466313228403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1136382.0748995927\n",
      "Sharpe:  0.44948022184566117\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 125           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 800           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.12737504    |\n",
      "|    clip_fraction        | 0.571         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.5         |\n",
      "|    explained_variance   | 0.773         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.253        |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.0784       |\n",
      "|    reward               | 3.8425464e-06 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.000346      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1024666.2004554386\n",
      "Sharpe:  3.5105472193801033\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.024666200455438547 -0.012991885032946042 3.5105472193801033\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2538185.401459045\n",
      "Sharpe:  1.2709005292964999\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2238793.219904697\n",
      "Sharpe:  0.9572283160090512\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1238919.053290769\n",
      "Sharpe:  3.538275763837333\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1117237.569203175\n",
      "Sharpe:  0.32364690109593297\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 49           |\n",
      "|    time_elapsed    | 67           |\n",
      "|    total_timesteps | 3339         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -6.65        |\n",
      "|    critic_loss     | 0.0207       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 3238         |\n",
      "|    reward          | 0.0015391117 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1339092.6276681516\n",
      "Sharpe:  0.5424635040584369\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1451987.9607434913\n",
      "Sharpe:  0.4046450454731368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1099306.8166987747\n",
      "Sharpe:  0.23779742445781787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1289635.6513490553\n",
      "Sharpe:  0.46562978780460285\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 160           |\n",
      "|    total_timesteps | 7484          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -5.31         |\n",
      "|    critic_loss     | 0.0233        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 7383          |\n",
      "|    reward          | -0.0014032391 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1356916.1321643195\n",
      "Sharpe:  3.4929776114869355\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1225806.3905177452\n",
      "Sharpe:  1.2209692842444642\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1962275.6782739141\n",
      "Sharpe:  0.6721589010401546\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1156050.5996109887\n",
      "Sharpe:  0.40205827249605514\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 216           |\n",
      "|    total_timesteps | 10197         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -4.68         |\n",
      "|    critic_loss     | 0.00873       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 10096         |\n",
      "|    reward          | 0.00057221524 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1272825.0923215132\n",
      "Sharpe:  0.43232341482923364\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1489788.1655941855\n",
      "Sharpe:  0.5713624816338952\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1017067.3292075959\n",
      "Sharpe:  0.17045009178987836\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1332982.739571756\n",
      "Sharpe:  0.6408437836086713\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 279           |\n",
      "|    total_timesteps | 13270         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -3.93         |\n",
      "|    critic_loss     | 0.00284       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 13169         |\n",
      "|    reward          | 0.00091176195 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1816819.0070716902\n",
      "Sharpe:  0.7660050239529126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1937105.4632893116\n",
      "Sharpe:  0.8511862957749511\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787984.4965366374\n",
      "Sharpe:  0.9994291391293605\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3570681.544191745\n",
      "Sharpe:  1.2185375031739558\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 393          |\n",
      "|    total_timesteps | 18640        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -3.18        |\n",
      "|    critic_loss     | 0.0017       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 18539        |\n",
      "|    reward          | 0.0023953465 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1323513.1978322286\n",
      "Sharpe:  0.7952691262526049\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2914041.8914685864\n",
      "Sharpe:  1.1958143670141548\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1288868.4460175214\n",
      "Sharpe:  4.394683404443165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1837236.3756067364\n",
      "Sharpe:  1.2399083090820995\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 450           |\n",
      "|    total_timesteps | 21293         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.62         |\n",
      "|    critic_loss     | 0.00147       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 21192         |\n",
      "|    reward          | -0.0005912954 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820839.7266407083\n",
      "Sharpe:  0.8934227373862444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2012518.8049678511\n",
      "Sharpe:  0.6693279413657608\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1800742.9744734773\n",
      "Sharpe:  1.0018686711396334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2359246.193346659\n",
      "Sharpe:  1.0694005668736952\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 563           |\n",
      "|    total_timesteps | 26276         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.18         |\n",
      "|    critic_loss     | 0.00178       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 26175         |\n",
      "|    reward          | -0.0028641545 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1304801.356106982\n",
      "Sharpe:  0.6796980249938365\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2182799.745496698\n",
      "Sharpe:  1.227871708737724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4399340.471024068\n",
      "Sharpe:  1.4370527504541881\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4558628.434894024\n",
      "Sharpe:  1.384524730081733\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 663          |\n",
      "|    total_timesteps | 30755        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -1.76        |\n",
      "|    critic_loss     | 0.00086      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 30654        |\n",
      "|    reward          | 0.0018430428 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2254632.282227315\n",
      "Sharpe:  1.1682260908190527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3482489.3790718988\n",
      "Sharpe:  1.2563891115053183\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1009897.6610840001\n",
      "Sharpe:  1.4352466956575174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4723856.437878884\n",
      "Sharpe:  1.2819852909990568\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 738           |\n",
      "|    total_timesteps | 34316         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.43         |\n",
      "|    critic_loss     | 0.000562      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 34215         |\n",
      "|    reward          | -0.0038881616 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1289051.430085733\n",
      "Sharpe:  0.9334230492752167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3284237.821392981\n",
      "Sharpe:  1.1201817223287143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1336214.0870529665\n",
      "Sharpe:  3.6361718505574547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1267361.065253405\n",
      "Sharpe:  0.6935025083139718\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 787           |\n",
      "|    total_timesteps | 36605         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.25         |\n",
      "|    critic_loss     | 0.00167       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 36504         |\n",
      "|    reward          | -0.0048015565 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4193363.1191725084\n",
      "Sharpe:  1.2854054126266212\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4116937.588553052\n",
      "Sharpe:  1.4089792266096037\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:14726194.055001099\n",
      "Sharpe:  1.270905838827137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6073190.280117895\n",
      "Sharpe:  1.47414279865269\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 911         |\n",
      "|    total_timesteps | 42337       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.946      |\n",
      "|    critic_loss     | 0.000464    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 42236       |\n",
      "|    reward          | -0.00435076 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10275506.87954018\n",
      "Sharpe:  1.3752085563544438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2532578.719247289\n",
      "Sharpe:  2.054652359286533\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1445825.1931593479\n",
      "Sharpe:  1.4270825648981167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1541206.462732265\n",
      "Sharpe:  1.9407787290676484\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 48           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 969          |\n",
      "|    total_timesteps | 45176        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.871       |\n",
      "|    critic_loss     | 0.000327     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 45075        |\n",
      "|    reward          | 0.0010593175 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10467792.524814835\n",
      "Sharpe:  1.4105219923097165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1304544.399456058\n",
      "Sharpe:  4.425532031106616\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:27722721.63719778\n",
      "Sharpe:  1.4087022653644523\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1257206.7761769346\n",
      "Sharpe:  2.0196783229826596\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 52            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1049          |\n",
      "|    total_timesteps | 48753         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.715        |\n",
      "|    critic_loss     | 0.000349      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 48652         |\n",
      "|    reward          | -0.0017150687 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:31750469.688983127\n",
      "Sharpe:  1.4422293555916308\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13284387.231839553\n",
      "Sharpe:  1.5949793735248803\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3092940.8453274104\n",
      "Sharpe:  2.09215899825806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1341468.6456382505\n",
      "Sharpe:  4.237230684349674\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 56            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1135          |\n",
      "|    total_timesteps | 52673         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.623        |\n",
      "|    critic_loss     | 0.000225      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 52572         |\n",
      "|    reward          | -0.0017742433 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:21513957.589223977\n",
      "Sharpe:  1.6676329249321724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7747900.767788076\n",
      "Sharpe:  2.1156693879567916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7484684.243206106\n",
      "Sharpe:  2.106223649176536\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1248669.8315126332\n",
      "Sharpe:  3.3918944511090667\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 60            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1215          |\n",
      "|    total_timesteps | 56471         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.542        |\n",
      "|    critic_loss     | 0.000461      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 56370         |\n",
      "|    reward          | -0.0012051027 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3708711.199793795\n",
      "Sharpe:  2.3360709177308654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18614710.84359796\n",
      "Sharpe:  1.6781308771600203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2207221.2738422975\n",
      "Sharpe:  1.8589142146471538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3219034.2097831364\n",
      "Sharpe:  2.152209050897303\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 64            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1285          |\n",
      "|    total_timesteps | 59739         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.45         |\n",
      "|    critic_loss     | 0.000299      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 59638         |\n",
      "|    reward          | -0.0028666968 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:47390877.66721695\n",
      "Sharpe:  1.9710841471258447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1254490.7649106642\n",
      "Sharpe:  3.358735791440137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11853352.706138896\n",
      "Sharpe:  2.0551510858893547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:16865529.374116674\n",
      "Sharpe:  1.8269064333155187\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 68            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1376          |\n",
      "|    total_timesteps | 63855         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.47         |\n",
      "|    critic_loss     | 0.000152      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 63754         |\n",
      "|    reward          | -0.0016189867 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:30011420.814431664\n",
      "Sharpe:  1.907052802359583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3901837.5347855496\n",
      "Sharpe:  2.157824970293226\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:63578389.78394807\n",
      "Sharpe:  1.771550319567709\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1599986.77433283\n",
      "Sharpe:  3.1787768846258198\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 72            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1456          |\n",
      "|    total_timesteps | 67641         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.418        |\n",
      "|    critic_loss     | 0.000247      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 67540         |\n",
      "|    reward          | -0.0015075286 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:39441074.88174061\n",
      "Sharpe:  2.0110449135611153\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:65725034.39859711\n",
      "Sharpe:  1.8133721643306036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6566030.5939611085\n",
      "Sharpe:  2.194256713007235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3809371.1870996146\n",
      "Sharpe:  2.114136137967577\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 76            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1550          |\n",
      "|    total_timesteps | 72222         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.36         |\n",
      "|    critic_loss     | 0.000173      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 72121         |\n",
      "|    reward          | -0.0015026487 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:39150089.153128356\n",
      "Sharpe:  2.006287690007991\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:40968220.76567979\n",
      "Sharpe:  1.8285600565902782\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:42191382.90101281\n",
      "Sharpe:  2.0374448238753717\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4055737.3997200807\n",
      "Sharpe:  2.2948522890628356\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 80            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1650          |\n",
      "|    total_timesteps | 77235         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.369        |\n",
      "|    critic_loss     | 0.000142      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 77134         |\n",
      "|    reward          | -0.0014887633 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1188142.1222758768\n",
      "Sharpe:  5.378906431555566\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1190954.3098085506\n",
      "Sharpe:  3.917138494947619\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:16398649.021343943\n",
      "Sharpe:  2.222256344738327\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2913757.926937826\n",
      "Sharpe:  2.6156366509402122\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 84            |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 1683          |\n",
      "|    total_timesteps | 78939         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.344        |\n",
      "|    critic_loss     | 0.000173      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 78838         |\n",
      "|    reward          | 0.00032383358 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2005934.6799959172\n",
      "Sharpe:  2.855346285655989\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:38657203.182100266\n",
      "Sharpe:  2.257876667223075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3644781.8760716706\n",
      "Sharpe:  2.2921113028153557\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18508373.69078046\n",
      "Sharpe:  2.4247714150586024\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 88            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1745          |\n",
      "|    total_timesteps | 82098         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.329        |\n",
      "|    critic_loss     | 0.000188      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 81997         |\n",
      "|    reward          | -0.0007732918 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2828277.915490421\n",
      "Sharpe:  2.1647943115784165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:122961476.68791239\n",
      "Sharpe:  1.7031525754835726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7490756.437464769\n",
      "Sharpe:  2.3091477540521614\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:73288915.1649567\n",
      "Sharpe:  1.815087638915863\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 92            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1838          |\n",
      "|    total_timesteps | 86695         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.315        |\n",
      "|    critic_loss     | 0.000103      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 86594         |\n",
      "|    reward          | -0.0010522286 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15767232.0519487\n",
      "Sharpe:  2.7219559067138968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7458575.308907565\n",
      "Sharpe:  2.473842943732974\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:22232518.279888175\n",
      "Sharpe:  2.5357319205055426\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:25879664.381104298\n",
      "Sharpe:  2.644470760220241\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 96           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 1934         |\n",
      "|    total_timesteps | 90731        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.321       |\n",
      "|    critic_loss     | 0.000129     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 90630        |\n",
      "|    reward          | -0.001045122 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:146048646.61233523\n",
      "Sharpe:  1.882379277305268\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1143762.87093737\n",
      "Sharpe:  6.500881746783509\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:23506312.487860125\n",
      "Sharpe:  2.5685133589841866\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:20778188.11770538\n",
      "Sharpe:  2.354204906993383\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 100            |\n",
      "|    fps             | 46             |\n",
      "|    time_elapsed    | 2016           |\n",
      "|    total_timesteps | 94635          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | -0.332         |\n",
      "|    critic_loss     | 0.000387       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 94534          |\n",
      "|    reward          | -0.00032845634 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17668526.65704198\n",
      "Sharpe:  2.501233180272206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:35593369.18780662\n",
      "Sharpe:  2.3246778122309033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:42879509.15504633\n",
      "Sharpe:  2.2560276233670438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:21238532.988426864\n",
      "Sharpe:  2.791690353133824\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 104           |\n",
      "|    fps             | 46            |\n",
      "|    time_elapsed    | 2114          |\n",
      "|    total_timesteps | 99355         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.315        |\n",
      "|    critic_loss     | 8.11e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 99254         |\n",
      "|    reward          | 9.5723975e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3548820.526296986\n",
      "Sharpe:  3.9105440107573157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1035048.912451206\n",
      "Sharpe:  4.921885799479011\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.035048912451205894 -0.009172270663675305 4.9218857994790115\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1211531.037561851\n",
      "Sharpe:  0.4822689231492254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1751278.9574590188\n",
      "Sharpe:  0.5847554995322674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1404223.4465979324\n",
      "Sharpe:  0.8498558320099519\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1072486.0404752947\n",
      "Sharpe:  0.2996490875050017\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 52           |\n",
      "|    time_elapsed    | 60           |\n",
      "|    total_timesteps | 3200         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 9.71         |\n",
      "|    critic_loss     | 0.0738       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 3099         |\n",
      "|    reward          | 0.0010309007 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826798.548497802\n",
      "Sharpe:  1.070419228454852\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1132198.892826279\n",
      "Sharpe:  0.631010287006478\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1250842.7160981144\n",
      "Sharpe:  4.038596762095659\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1689593.0076067403\n",
      "Sharpe:  1.090184127580799\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 107          |\n",
      "|    total_timesteps | 5470         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 9.17         |\n",
      "|    critic_loss     | 0.0445       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5369         |\n",
      "|    reward          | 0.0009048376 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2549710.221364597\n",
      "Sharpe:  1.0147942335082982\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1076796.7725287706\n",
      "Sharpe:  0.3011625268718118\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1322301.1016400985\n",
      "Sharpe:  1.8676434721278001\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3247873.0610856893\n",
      "Sharpe:  1.2162966098568107\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 12             |\n",
      "|    fps             | 52             |\n",
      "|    time_elapsed    | 176            |\n",
      "|    total_timesteps | 9207           |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 8.47           |\n",
      "|    critic_loss     | 0.169          |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 9106           |\n",
      "|    reward          | -0.00058067014 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2050118.1214833152\n",
      "Sharpe:  0.6830051635148737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1053184.662834271\n",
      "Sharpe:  0.21415292478493758\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1412877.4817164696\n",
      "Sharpe:  3.22772389406724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1575055.557748428\n",
      "Sharpe:  0.456250239904025\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 52            |\n",
      "|    time_elapsed    | 254           |\n",
      "|    total_timesteps | 13344         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 7.9           |\n",
      "|    critic_loss     | 0.103         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 13243         |\n",
      "|    reward          | -0.0035736128 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1350857.709260952\n",
      "Sharpe:  0.42024067302011026\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1579366.9599515612\n",
      "Sharpe:  0.5224390717541586\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1208799.6549520304\n",
      "Sharpe:  3.36938804218829\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1932741.4386470234\n",
      "Sharpe:  0.8350481602007687\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 51            |\n",
      "|    time_elapsed    | 337           |\n",
      "|    total_timesteps | 17446         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 6.76          |\n",
      "|    critic_loss     | 0.017         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 17345         |\n",
      "|    reward          | -0.0022553832 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1351214.9886480004\n",
      "Sharpe:  0.8445243494833661\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1738338.6533257058\n",
      "Sharpe:  0.6668534651375017\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1532749.9776045517\n",
      "Sharpe:  0.9789925104820568\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1177122.2759183538\n",
      "Sharpe:  0.34952746262609924\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 50            |\n",
      "|    time_elapsed    | 413           |\n",
      "|    total_timesteps | 20919         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 6.14          |\n",
      "|    critic_loss     | 0.0526        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 20818         |\n",
      "|    reward          | -0.0022214325 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1946843.2504958706\n",
      "Sharpe:  1.0715757804554942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2867011.5732228863\n",
      "Sharpe:  1.176193799837139\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1274528.6840878036\n",
      "Sharpe:  0.7115523977360763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1790914.1123393967\n",
      "Sharpe:  0.6654887033600997\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 50            |\n",
      "|    time_elapsed    | 495           |\n",
      "|    total_timesteps | 25155         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 5.62          |\n",
      "|    critic_loss     | 0.0127        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 25054         |\n",
      "|    reward          | -0.0007940045 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1890434.7990502042\n",
      "Sharpe:  0.7362396135706368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1598101.7850199847\n",
      "Sharpe:  0.7054356339983641\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1051757.8362969647\n",
      "Sharpe:  0.2370686138093393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1057635.6276602333\n",
      "Sharpe:  3.069788499823367\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 50            |\n",
      "|    time_elapsed    | 564           |\n",
      "|    total_timesteps | 28426         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 5.32          |\n",
      "|    critic_loss     | 0.0101        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 28325         |\n",
      "|    reward          | -0.0010621438 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1405627.1896892572\n",
      "Sharpe:  0.6266928769391444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1270581.5658562966\n",
      "Sharpe:  0.49638645027240885\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1648815.479295395\n",
      "Sharpe:  0.6038056490475554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1086750.3129768379\n",
      "Sharpe:  0.41135771445515257\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 50            |\n",
      "|    time_elapsed    | 633           |\n",
      "|    total_timesteps | 31838         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 4.36          |\n",
      "|    critic_loss     | 0.0177        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 31737         |\n",
      "|    reward          | -0.0020153734 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1391150.60284128\n",
      "Sharpe:  0.9417942394396995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1739830.762821856\n",
      "Sharpe:  0.8784158179981407\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1257464.7710768934\n",
      "Sharpe:  2.2115307421744395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3191701.352694346\n",
      "Sharpe:  1.176628884976138\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 50            |\n",
      "|    time_elapsed    | 699           |\n",
      "|    total_timesteps | 35035         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 4.26          |\n",
      "|    critic_loss     | 0.00835       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 34934         |\n",
      "|    reward          | -0.0018702114 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2311420.635756141\n",
      "Sharpe:  1.4525134569473834\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2451652.951851621\n",
      "Sharpe:  1.192646651479627\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1182931.3488990066\n",
      "Sharpe:  0.5256350053581309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1277421.621905048\n",
      "Sharpe:  2.0419607814530787\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 761          |\n",
      "|    total_timesteps | 38105        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 4.15         |\n",
      "|    critic_loss     | 0.00705      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 38004        |\n",
      "|    reward          | -0.002665545 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1738609.6259212522\n",
      "Sharpe:  0.9189923031016967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1291832.999648292\n",
      "Sharpe:  2.0510614360331796\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1259697.0871186315\n",
      "Sharpe:  4.725498749756436\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1270619.018807072\n",
      "Sharpe:  0.4706995406144321\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 48             |\n",
      "|    fps             | 50             |\n",
      "|    time_elapsed    | 803            |\n",
      "|    total_timesteps | 40254          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 3.74           |\n",
      "|    critic_loss     | 0.00502        |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 40153          |\n",
      "|    reward          | -0.00028699794 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2249653.538973028\n",
      "Sharpe:  0.8936504259675848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2112922.1883360175\n",
      "Sharpe:  0.9068399998005333\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2001550.0022108282\n",
      "Sharpe:  0.8044917871643575\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2853364.3502437216\n",
      "Sharpe:  1.0963924114956485\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 52            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 916           |\n",
      "|    total_timesteps | 45793         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 3.33          |\n",
      "|    critic_loss     | 0.00384       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 45692         |\n",
      "|    reward          | -0.0039685774 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826779.949786805\n",
      "Sharpe:  0.9511080236930008\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1223828.1215482834\n",
      "Sharpe:  0.609629601089684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1900564.2764503534\n",
      "Sharpe:  1.0349005292167406\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5606301.984159179\n",
      "Sharpe:  1.1953117899574257\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 49          |\n",
      "|    time_elapsed    | 1012        |\n",
      "|    total_timesteps | 50079       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.98        |\n",
      "|    critic_loss     | 0.00594     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 49978       |\n",
      "|    reward          | 0.004247105 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2925225.0230132323\n",
      "Sharpe:  1.1695977972567377\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3123899.308859399\n",
      "Sharpe:  1.405350640522029\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3117732.5250917478\n",
      "Sharpe:  1.2639134936927126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1408663.2477208842\n",
      "Sharpe:  1.351487335362466\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 60            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1099          |\n",
      "|    total_timesteps | 54403         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 2.7           |\n",
      "|    critic_loss     | 0.00245       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 54302         |\n",
      "|    reward          | -0.0024351915 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1686634.9700549752\n",
      "Sharpe:  1.0073481696539486\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:998654.5984985896\n",
      "Sharpe:  -0.17678633365794613\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2420085.1318488857\n",
      "Sharpe:  1.118050005117428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1448209.5534112316\n",
      "Sharpe:  1.1510631856492475\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 64            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1152          |\n",
      "|    total_timesteps | 57117         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 2.39          |\n",
      "|    critic_loss     | 0.00288       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 57016         |\n",
      "|    reward          | -0.0046151765 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2743738.377456417\n",
      "Sharpe:  1.2197071317810817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1302416.6377154149\n",
      "Sharpe:  2.3441282664041583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1385429.2625464583\n",
      "Sharpe:  1.6147181743493497\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1365404.4495865095\n",
      "Sharpe:  3.237257843490142\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 68            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1189          |\n",
      "|    total_timesteps | 59147         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 2.22          |\n",
      "|    critic_loss     | 0.00657       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 59046         |\n",
      "|    reward          | -0.0028891023 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1401414.6265166737\n",
      "Sharpe:  1.9328377600093087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1270989.6274171323\n",
      "Sharpe:  0.9427648169771177\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1236093.035354744\n",
      "Sharpe:  3.2022664357789887\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3726243.3485186584\n",
      "Sharpe:  1.4628230107650912\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 49          |\n",
      "|    time_elapsed    | 1228        |\n",
      "|    total_timesteps | 61234       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.99        |\n",
      "|    critic_loss     | 0.00371     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 61133       |\n",
      "|    reward          | -0.00305883 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2237660.104968886\n",
      "Sharpe:  1.0156572074466172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1273079.597381315\n",
      "Sharpe:  0.8215474112307967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3197233.9542097463\n",
      "Sharpe:  1.1365762288178245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2200898.1511788922\n",
      "Sharpe:  1.0349730091454055\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 76             |\n",
      "|    fps             | 49             |\n",
      "|    time_elapsed    | 1322           |\n",
      "|    total_timesteps | 65998          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 1.97           |\n",
      "|    critic_loss     | 0.00472        |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 65897          |\n",
      "|    reward          | -0.00095857505 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1361396.2732461877\n",
      "Sharpe:  0.8499481042631766\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1302514.4951067404\n",
      "Sharpe:  1.3379900163330771\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1316238.6822582968\n",
      "Sharpe:  0.7448969359470328\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1385144.6135058478\n",
      "Sharpe:  0.8446045186469492\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 80             |\n",
      "|    fps             | 49             |\n",
      "|    time_elapsed    | 1361           |\n",
      "|    total_timesteps | 68000          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 1.84           |\n",
      "|    critic_loss     | 0.00646        |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 67899          |\n",
      "|    reward          | -0.00059288624 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3870548.4671497233\n",
      "Sharpe:  1.3942256590247684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2119081.5466177426\n",
      "Sharpe:  1.143611603930074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1878455.5042844592\n",
      "Sharpe:  1.2343556749065778\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1177087.8753328095\n",
      "Sharpe:  6.17376583292857\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 84           |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 1426         |\n",
      "|    total_timesteps | 71404        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.66         |\n",
      "|    critic_loss     | 0.00181      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 71303        |\n",
      "|    reward          | 0.0015264862 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3739148.5709202113\n",
      "Sharpe:  1.2180081274900623\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1035404.0676289863\n",
      "Sharpe:  3.5815050334937504\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1460884.7459526912\n",
      "Sharpe:  0.8636261003132061\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1595206.3774179856\n",
      "Sharpe:  1.1093019379968547\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 50          |\n",
      "|    time_elapsed    | 1481        |\n",
      "|    total_timesteps | 74236       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.54        |\n",
      "|    critic_loss     | 0.00263     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 74135       |\n",
      "|    reward          | 0.002196083 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1424507.6568206586\n",
      "Sharpe:  0.9921595446314246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1051391.906321001\n",
      "Sharpe:  4.739502773703901\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2159382.3419209314\n",
      "Sharpe:  1.0833021978140729\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1324646.2539416605\n",
      "Sharpe:  2.2634912651810777\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 50          |\n",
      "|    time_elapsed    | 1515        |\n",
      "|    total_timesteps | 75962       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.52        |\n",
      "|    critic_loss     | 0.00176     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 75861       |\n",
      "|    reward          | 0.001589545 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1718398.7660271737\n",
      "Sharpe:  1.0597196990190023\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3147257.9990282203\n",
      "Sharpe:  1.1935673566198413\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1005567.5738968498\n",
      "Sharpe:  1.1119076307908398\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1427412.002462883\n",
      "Sharpe:  0.6554235403330851\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 96           |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 1574         |\n",
      "|    total_timesteps | 78986        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.4          |\n",
      "|    critic_loss     | 0.00283      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 78885        |\n",
      "|    reward          | 0.0015923373 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1596896.0227397385\n",
      "Sharpe:  1.1989285230124793\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2135021.0690079564\n",
      "Sharpe:  0.9570878880806415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2829055.628701467\n",
      "Sharpe:  1.1454251789639058\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1185253.870615695\n",
      "Sharpe:  0.4925717679860488\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 100           |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1654          |\n",
      "|    total_timesteps | 82674         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.21          |\n",
      "|    critic_loss     | 0.00277       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 82573         |\n",
      "|    reward          | -6.054447e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2143315.2559929714\n",
      "Sharpe:  1.0763701563094152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1130632.2357550447\n",
      "Sharpe:  0.4527367767066204\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2758327.339630411\n",
      "Sharpe:  1.2773103790788483\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1498206.4709405357\n",
      "Sharpe:  0.976228708399713\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 104           |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1723          |\n",
      "|    total_timesteps | 86081         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.06          |\n",
      "|    critic_loss     | 0.00225       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 85980         |\n",
      "|    reward          | -6.746194e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1592142.4070772484\n",
      "Sharpe:  1.0450606061240635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1094291.6016121935\n",
      "Sharpe:  0.38643802576210123\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2294968.6764540053\n",
      "Sharpe:  1.0858845639818866\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1515993.6980421278\n",
      "Sharpe:  0.9874001246144976\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 108           |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 1779          |\n",
      "|    total_timesteps | 88942         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.938         |\n",
      "|    critic_loss     | 0.003         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 88841         |\n",
      "|    reward          | -6.379824e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1171705.4783598376\n",
      "Sharpe:  3.2298486502709403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4175077.4358463883\n",
      "Sharpe:  1.3801026132334755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1245452.364509553\n",
      "Sharpe:  2.853020002355835\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2109832.429718803\n",
      "Sharpe:  0.8918032360768571\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 112          |\n",
      "|    fps             | 49           |\n",
      "|    time_elapsed    | 1841         |\n",
      "|    total_timesteps | 91845        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.01         |\n",
      "|    critic_loss     | 0.00132      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 91744        |\n",
      "|    reward          | 0.0014193663 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4752251.737475253\n",
      "Sharpe:  1.1995571626128758\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1947652.80899765\n",
      "Sharpe:  1.0202304155863944\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1283676.3208841705\n",
      "Sharpe:  0.8307258630804379\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4920911.963544568\n",
      "Sharpe:  1.4648610537308293\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 116            |\n",
      "|    fps             | 49             |\n",
      "|    time_elapsed    | 1925           |\n",
      "|    total_timesteps | 96124          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.846          |\n",
      "|    critic_loss     | 0.000716       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 96023          |\n",
      "|    reward          | -0.00040992035 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5733009.386256651\n",
      "Sharpe:  1.2518674874679978\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1108842.092760234\n",
      "Sharpe:  3.9934484983068597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1496910.2139530901\n",
      "Sharpe:  1.8623076517861241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3683451.8455646276\n",
      "Sharpe:  1.4379450556125746\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 120          |\n",
      "|    fps             | 49           |\n",
      "|    time_elapsed    | 1993         |\n",
      "|    total_timesteps | 99310        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.796        |\n",
      "|    critic_loss     | 0.000694     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 99209        |\n",
      "|    reward          | 0.0025650468 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1052019.6537940411\n",
      "Sharpe:  8.541669149776347\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.052019653794041165 -0.009193375016478525 8.541669149776345\n",
      "2023-08-01 00:00:00 2023-09-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_9_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | -766       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -1.15      |\n",
      "|    reward             | 0.00569981 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.0481     |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778895.764966996\n",
      "Sharpe:  -0.1603604256390883\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 101          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -32.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.00444      |\n",
      "|    reward             | 2.637399e-05 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00577      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1100448.7670923546\n",
      "Sharpe:  0.5278140948920753\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 107         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -123        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 2.29        |\n",
      "|    reward             | 0.005914624 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0748      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 110         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -101        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 2.15        |\n",
      "|    reward             | 0.011517824 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0247      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | -31          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.797       |\n",
      "|    reward             | -0.010085221 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.00527      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1165098.3490440804\n",
      "Sharpe:  0.2292764300860988\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | -44.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.15        |\n",
      "|    reward             | 0.0023987617 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.0166       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -464         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | 0.0010070171 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00919      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -33.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | -0.024382109 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.00409      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020082.7864473284\n",
      "Sharpe:  0.1142268508149969\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -201         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.373       |\n",
      "|    reward             | -0.011715862 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00644      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -1.56       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.179       |\n",
      "|    reward             | 0.009776298 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | -1           |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.583       |\n",
      "|    reward             | -0.012400415 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 0.00228      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1095414.9240048155\n",
      "Sharpe:  0.18105176329211495\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | -39           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.738        |\n",
      "|    reward             | -0.0022388946 |\n",
      "|    std                | 1.23          |\n",
      "|    value_loss         | 0.00377       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.342       |\n",
      "|    reward             | 0.011542114 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.000651    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -3.73        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.398       |\n",
      "|    reward             | 0.0016160164 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.000805     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1267530.3751196912\n",
      "Sharpe:  0.33624132337491114\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | -110        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.212       |\n",
      "|    reward             | 0.013578829 |\n",
      "|    std                | 1.35        |\n",
      "|    value_loss         | 0.000694    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:849428.8164264228\n",
      "Sharpe:  -0.24005959826121406\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1086069.8227680232\n",
      "Sharpe:  0.5485007442525408\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 69            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | -0.792        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.167         |\n",
      "|    reward             | -0.0053926744 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 0.000279      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -30.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 9.41e-05    |\n",
      "|    reward             | 0.008903399 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 3.4e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 77            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | -1.52         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.403        |\n",
      "|    reward             | -0.0059840237 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 0.000729      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1379885.9325106451\n",
      "Sharpe:  0.4446591836254587\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | -0.472       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0194      |\n",
      "|    reward             | -0.009675312 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 3.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1006268.2765855026\n",
      "Sharpe:  0.11678449531984221\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | -20.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 2.44         |\n",
      "|    reward             | -0.015389516 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 0.0251       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:876998.8306575172\n",
      "Sharpe:  -0.11539623503498639\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0.128        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.19        |\n",
      "|    reward             | -0.025800148 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 0.000322     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | -0.0426     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.0442     |\n",
      "|    reward             | 0.009377635 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 0.00337     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:809032.1818740718\n",
      "Sharpe:  -0.13751305474552447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1152219.2572641806\n",
      "Sharpe:  5.292599219974247\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 116          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | 0.0011345107 |\n",
      "|    std                | 1.84         |\n",
      "|    value_loss         | 0.000249     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 102           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.6         |\n",
      "|    explained_variance | 0.796         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 0.14          |\n",
      "|    reward             | 0.00051651814 |\n",
      "|    std                | 1.91          |\n",
      "|    value_loss         | 5.74e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | -0.874      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -0.291      |\n",
      "|    reward             | 0.003340896 |\n",
      "|    std                | 1.99        |\n",
      "|    value_loss         | 0.000587    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | -4.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | 0.0568       |\n",
      "|    reward             | 0.0020500773 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 5.19e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:839648.9665806248\n",
      "Sharpe:  -0.014632758926589506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497438.1596890897\n",
      "Sharpe:  -1.7242582478273711\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 115          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | -1.67        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.298       |\n",
      "|    reward             | 0.0041780155 |\n",
      "|    std                | 2.16         |\n",
      "|    value_loss         | 0.000354     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 120        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.1      |\n",
      "|    explained_variance | -5.94      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -0.0529    |\n",
      "|    reward             | 0.01321419 |\n",
      "|    std                | 2.25       |\n",
      "|    value_loss         | 0.000176   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 115           |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 0.74          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.0752       |\n",
      "|    reward             | -0.0010024683 |\n",
      "|    std                | 2.34          |\n",
      "|    value_loss         | 3.71e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1209822.9144624341\n",
      "Sharpe:  0.2606737262466205\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1043087.1962706987\n",
      "Sharpe:  7.626754958854383\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -0.433       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | -0.022190271 |\n",
      "|    std                | 2.44         |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:828281.1512981929\n",
      "Sharpe:  -0.18236129479028232\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0.0346       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.184        |\n",
      "|    reward             | -0.004625044 |\n",
      "|    std                | 2.53         |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0.178        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.95         |\n",
      "|    reward             | 0.0059058033 |\n",
      "|    std                | 2.63         |\n",
      "|    value_loss         | 0.00227      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:844617.4911313236\n",
      "Sharpe:  -0.04625270834307601\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.8    |\n",
      "|    explained_variance | 0.411    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.237    |\n",
      "|    reward             | -0.03287 |\n",
      "|    std                | 2.73     |\n",
      "|    value_loss         | 0.000206 |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 113         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | -1.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 1.81        |\n",
      "|    reward             | 0.027493887 |\n",
      "|    std                | 2.82        |\n",
      "|    value_loss         | 0.00758     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1012638.8949943198\n",
      "Sharpe:  0.15584126187754999\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 154          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | -1.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | -0.012078225 |\n",
      "|    std                | 2.92         |\n",
      "|    value_loss         | 0.00054      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 113          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.448        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.362        |\n",
      "|    reward             | 0.0067261076 |\n",
      "|    std                | 3.02         |\n",
      "|    value_loss         | 0.00044      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1141695.577354781\n",
      "Sharpe:  0.2633495912395218\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 163          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | -0.0703      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -0.00105     |\n",
      "|    reward             | -0.024108868 |\n",
      "|    std                | 3.14         |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 112         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | -0.475      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | 0.39        |\n",
      "|    reward             | 0.022797935 |\n",
      "|    std                | 3.25        |\n",
      "|    value_loss         | 0.000321    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:996153.4664230892\n",
      "Sharpe:  0.13056272553405057\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 112          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | -9.62        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | -0.476       |\n",
      "|    reward             | -0.010282802 |\n",
      "|    std                | 3.35         |\n",
      "|    value_loss         | 0.00047      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | -0.925       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.25        |\n",
      "|    reward             | -0.006684008 |\n",
      "|    std                | 3.46         |\n",
      "|    value_loss         | 0.000294     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 111           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.3         |\n",
      "|    explained_variance | 0.21          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | 0.637         |\n",
      "|    reward             | -0.0023244512 |\n",
      "|    std                | 3.59          |\n",
      "|    value_loss         | 0.000705      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:906279.7605191696\n",
      "Sharpe:  0.04093863375617498\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | -1.6         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.163        |\n",
      "|    reward             | -0.003724705 |\n",
      "|    std                | 3.72         |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | -0.304       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.103       |\n",
      "|    reward             | -0.009128446 |\n",
      "|    std                | 3.86         |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(alg)\n\u001b[0;32m     21\u001b[0m log_name \u001b[38;5;241m=\u001b[39m alg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m7\u001b[39m\u001b[38;5;241m+\u001b[39mi)\n\u001b[1;32m---> 22\u001b[0m model, df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m res11 \u001b[38;5;241m=\u001b[39m get_result(df_daily_return)\n\u001b[0;32m     24\u001b[0m res[alg]\u001b[38;5;241m.\u001b[39mappend(res11)\n",
      "Cell \u001b[1;32mIn[97], line 23\u001b[0m, in \u001b[0;36mtrain_trade\u001b[1;34m(alg, train, trade, optuna_params, log_name, size)\u001b[0m\n\u001b[0;32m     19\u001b[0m     log_name \u001b[38;5;241m=\u001b[39m alg\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_model(model_name \u001b[38;5;241m=\u001b[39m alg, model_kwargs \u001b[38;5;241m=\u001b[39m optuna_params, policy_kwargs \u001b[38;5;241m=\u001b[39m policy_kwargs, tensorboard_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m trained_a2c \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m e_trade_gym2 \u001b[38;5;241m=\u001b[39m PortfolioEnv(df \u001b[38;5;241m=\u001b[39m trade, reset_to_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m     29\u001b[0m df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m DRLAgent\u001b[38;5;241m.\u001b[39mDRL_prediction(model\u001b[38;5;241m=\u001b[39mtrained_a2c,\n\u001b[0;32m     30\u001b[0m                     environment \u001b[38;5;241m=\u001b[39m e_trade_gym2)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    115\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    116\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[0;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:200\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_locals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mon_step():\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:134\u001b[0m, in \u001b[0;36mBaseCallback.update_locals\u001b[1;34m(self, locals_)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_locals\u001b[39m(\u001b[38;5;28mself\u001b[39m, locals_: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    Update the references to the local variables.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    :param locals_: the local variables during rollout collection\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocals_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_child_locals(locals_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algs = ['a2c','ppo','ddpg','td3']\n",
    "res = dict()\n",
    "ret = dict()\n",
    "act = dict()\n",
    "for alg in algs:\n",
    "  res[alg] = []\n",
    "  ret[alg] = []\n",
    "  act[alg] = []\n",
    "\n",
    "for i in range(4):\n",
    "  date0 = datetime.datetime(2016, 7, 1) #date_start + relativedelta(months = -12 * i)\n",
    "  date1 = date_start + relativedelta(months = i)\n",
    "  date2 = date_start + relativedelta(months = i + 1)\n",
    "\n",
    "  train = data_split(df, date0, date1) #'2016-05-10', date1)\n",
    "  trade = data_split(df, date1, date2)\n",
    "\n",
    "  for alg in algs:\n",
    "    print(date1, date2)\n",
    "    print(alg)\n",
    "    log_name = alg + '_' + str(7+i)\n",
    "    model, df_daily_return, df_actions = train_trade(alg, train, trade, None, log_name=log_name, size=[192,128])\n",
    "    res11 = get_result(df_daily_return)\n",
    "    res[alg].append(res11)\n",
    "    ret[alg].append(df_daily_return)\n",
    "    act[alg].append(df_actions)\n",
    "    print(alg, res11['Cumulative returns'], res11['Max drawdown'], res11['Sharpe ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = dict()\n",
    "max_dd = dict()\n",
    "sharp = dict()\n",
    "for alg in algs:\n",
    "    returns[alg] = []\n",
    "    max_dd[alg]  = []\n",
    "    sharp[alg] = []\n",
    "    for result in res[alg]:\n",
    "        returns[alg].append(result['Cumulative returns'])\n",
    "        max_dd[alg].append(result['Max drawdown'])\n",
    "        sharp[alg].append(result['Sharpe ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2c': [0.0332920123153011, 0.06085893780299956],\n",
       " 'ppo': [0.03953620404201441, 0.024666200455438547],\n",
       " 'ddpg': [0.026988995661685555, 0.035048912451205894],\n",
       " 'td3': [-0.024519644558903098, 0.052019653794041165]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2c': [-0.01912261916057049, -0.012374844113516019],\n",
       " 'ppo': [-0.02651635797445672, -0.012991885032946042],\n",
       " 'ddpg': [-0.011239425238825804, -0.009172270663675305],\n",
       " 'td3': [-0.04096272540703771, -0.009193375016478525]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2c': [3.833168087493906, 8.97123635701111],\n",
       " 'ppo': [3.2310244627572664, 3.5105472193801033],\n",
       " 'ddpg': [3.4959572702783923, 4.9218857994790115],\n",
       " 'td3': [-1.9974839389017551, 8.541669149776345]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "res = dict()\n",
    "ret = dict()\n",
    "act = dict()\n",
    "\n",
    "date_start = datetime.datetime(2023, 6, 1)\n",
    "date0 = datetime.datetime(2016, 8, 1) #date_start + relativedelta(months = -12 * i)\n",
    "date1 = date_start + relativedelta(months = 0)\n",
    "date2 = date_start + relativedelta(months = 0 + 1)\n",
    "\n",
    "print(date1, date2)\n",
    "train = data_split(df, date0, date1) #'2016-05-10', date1)\n",
    "trade = data_split(df, date1, date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_final_td3_9_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1997314.546450376\n",
      "Sharpe:  0.7122777451925169\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1117325.570132\n",
      "Sharpe:  0.334220476387253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2127900.881390989\n",
      "Sharpe:  0.7154155888863315\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1277461.7440616605\n",
      "Sharpe:  0.43157322086451216\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 49           |\n",
      "|    time_elapsed    | 93           |\n",
      "|    total_timesteps | 4680         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 2.29         |\n",
      "|    critic_loss     | 0.0414       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4579         |\n",
      "|    reward          | 0.0069790105 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:867188.1873660703\n",
      "Sharpe:  -0.2722223633270397\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1207534.0232728783\n",
      "Sharpe:  0.4826060743281505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1527178.4505230675\n",
      "Sharpe:  0.5269425818836255\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2047324.8144093053\n",
      "Sharpe:  0.9776108882046506\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 172           |\n",
      "|    total_timesteps | 8527          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 2.2           |\n",
      "|    critic_loss     | 0.0331        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 8426          |\n",
      "|    reward          | 0.00018054956 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1201827.8999623726\n",
      "Sharpe:  0.6024883064306882\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1392287.4532775134\n",
      "Sharpe:  0.8845790093219846\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1617562.1358558408\n",
      "Sharpe:  1.1109210818366726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1074764.5600714043\n",
      "Sharpe:  0.2840369714246408\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 230          |\n",
      "|    total_timesteps | 11124        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.95         |\n",
      "|    critic_loss     | 0.0147       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 11023        |\n",
      "|    reward          | 0.0063306736 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1406134.9604299976\n",
      "Sharpe:  0.6547804453228235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1127716.4724597177\n",
      "Sharpe:  0.38379747229093997\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1410163.0072397552\n",
      "Sharpe:  0.5178148987393749\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1003479.0616943747\n",
      "Sharpe:  0.10768573499535736\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 297         |\n",
      "|    total_timesteps | 14247       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2           |\n",
      "|    critic_loss     | 0.0083      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14146       |\n",
      "|    reward          | 0.000972072 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1536584.7993937577\n",
      "Sharpe:  0.7348434344128322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:920514.1821303994\n",
      "Sharpe:  -0.15688678883939025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2355685.046559748\n",
      "Sharpe:  0.9948951502113841\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1189512.6125332627\n",
      "Sharpe:  5.607863754362914\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 363           |\n",
      "|    total_timesteps | 17253         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.75          |\n",
      "|    critic_loss     | 0.00377       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 17152         |\n",
      "|    reward          | 0.00072968163 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:950344.9809694538\n",
      "Sharpe:  -0.06402583126084148\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3768184.9711906947\n",
      "Sharpe:  1.252682462809281\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1150651.9413384655\n",
      "Sharpe:  7.124931955829432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2349965.8261099374\n",
      "Sharpe:  0.9432015386153286\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 433         |\n",
      "|    total_timesteps | 20563       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.72        |\n",
      "|    critic_loss     | 0.00577     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 20462       |\n",
      "|    reward          | 0.005941001 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3860519.983493394\n",
      "Sharpe:  1.1150235466967142\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1267690.5995120576\n",
      "Sharpe:  2.2372137931729155\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1444883.2547320176\n",
      "Sharpe:  0.6938930189238539\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3552670.1048405357\n",
      "Sharpe:  1.186817609259514\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 516         |\n",
      "|    total_timesteps | 24564       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.56        |\n",
      "|    critic_loss     | 0.00199     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24463       |\n",
      "|    reward          | 0.007228099 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2301564.287898738\n",
      "Sharpe:  0.9677441839419656\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2722298.057544412\n",
      "Sharpe:  1.1819669215488584\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2278593.901130607\n",
      "Sharpe:  1.0161781720915863\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2498029.8415617202\n",
      "Sharpe:  1.034703536149868\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 616         |\n",
      "|    total_timesteps | 29711       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.39        |\n",
      "|    critic_loss     | 0.00279     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29610       |\n",
      "|    reward          | 0.007642939 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1541838.3406591823\n",
      "Sharpe:  0.9609165096324982\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3519577.0848419317\n",
      "Sharpe:  1.4667441828866399\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1367848.1321947034\n",
      "Sharpe:  3.055551786965395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1378411.8363997592\n",
      "Sharpe:  1.0461268311694394\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 48         |\n",
      "|    time_elapsed    | 669        |\n",
      "|    total_timesteps | 32275      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.32       |\n",
      "|    critic_loss     | 0.00252    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 32174      |\n",
      "|    reward          | 0.01022391 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3883175.603366258\n",
      "Sharpe:  1.6790219385742693\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2359867.5619783252\n",
      "Sharpe:  1.3036226716389692\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1792059.936328598\n",
      "Sharpe:  1.438041944348526\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1218853.8304869882\n",
      "Sharpe:  4.678276110335747\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 732         |\n",
      "|    total_timesteps | 35410       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.25        |\n",
      "|    critic_loss     | 0.00098     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 35309       |\n",
      "|    reward          | 0.009650105 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1357913.2788661157\n",
      "Sharpe:  1.0500311541901342\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1404522.0048790767\n",
      "Sharpe:  0.9782561257830545\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1216162.9818204541\n",
      "Sharpe:  3.8179832445850077\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2200826.4367144816\n",
      "Sharpe:  1.1715738864692333\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 773         |\n",
      "|    total_timesteps | 37497       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.2         |\n",
      "|    critic_loss     | 0.00295     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 37396       |\n",
      "|    reward          | 0.012347832 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1818930.5938172792\n",
      "Sharpe:  1.4070850321123216\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2541354.059334382\n",
      "Sharpe:  1.4849364869229187\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3292718.7360510505\n",
      "Sharpe:  1.4543269166607635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2179353.933962982\n",
      "Sharpe:  1.9480025830292054\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 847         |\n",
      "|    total_timesteps | 41112       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.06        |\n",
      "|    critic_loss     | 0.0022      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 41011       |\n",
      "|    reward          | 0.008494613 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1198599.608011481\n",
      "Sharpe:  5.559712983451376\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3385535.046087408\n",
      "Sharpe:  1.5835974258180903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2232307.444044925\n",
      "Sharpe:  1.4778750588132952\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4824110.682700861\n",
      "Sharpe:  1.9499607263242582\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 923         |\n",
      "|    total_timesteps | 44710       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.93        |\n",
      "|    critic_loss     | 0.0018      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 44609       |\n",
      "|    reward          | 0.008047936 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5564936.859483208\n",
      "Sharpe:  1.8887637607055014\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1895524.6525498396\n",
      "Sharpe:  2.1898767035817457\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2303178.8130337773\n",
      "Sharpe:  2.3131768108868473\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8269445.010208751\n",
      "Sharpe:  2.1339864326352767\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 1014        |\n",
      "|    total_timesteps | 48762       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.824       |\n",
      "|    critic_loss     | 0.000838    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 48661       |\n",
      "|    reward          | 0.009109895 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11860497.092223832\n",
      "Sharpe:  1.7645559117170413\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1830004.0204382052\n",
      "Sharpe:  2.1349344030675006\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8767400.267037904\n",
      "Sharpe:  1.8262141887865495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5997696.9216882475\n",
      "Sharpe:  2.046869943548639\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 1115        |\n",
      "|    total_timesteps | 53547       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.744       |\n",
      "|    critic_loss     | 0.000486    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 53446       |\n",
      "|    reward          | 0.008793159 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13610385.638796305\n",
      "Sharpe:  1.762129908682915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7749027.654247025\n",
      "Sharpe:  1.8961823509200684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8160650.242946071\n",
      "Sharpe:  1.8867726081123928\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2053083.5955708611\n",
      "Sharpe:  1.874680173572965\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 1210        |\n",
      "|    total_timesteps | 58135       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.626       |\n",
      "|    critic_loss     | 0.000587    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 58034       |\n",
      "|    reward          | 0.010490084 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2875630.344538289\n",
      "Sharpe:  2.3558143504677043\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1377445.3666411687\n",
      "Sharpe:  3.409935537259898\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1354126.6694466483\n",
      "Sharpe:  4.340499201792832\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5466557.139164995\n",
      "Sharpe:  1.9514150970316353\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 1257        |\n",
      "|    total_timesteps | 60224       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.615       |\n",
      "|    critic_loss     | 0.00073     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 60123       |\n",
      "|    reward          | 0.012538496 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13954918.476469086\n",
      "Sharpe:  1.8498383427573626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6225253.495275764\n",
      "Sharpe:  2.028508848848967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2187696.522113317\n",
      "Sharpe:  2.529836914206787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1566920.3829580105\n",
      "Sharpe:  2.3323715056330476\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 72           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 1321         |\n",
      "|    total_timesteps | 63164        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.581        |\n",
      "|    critic_loss     | 0.00137      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 63063        |\n",
      "|    reward          | 0.0066337334 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2790152.146436687\n",
      "Sharpe:  2.304106891305353\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1399053.1370846753\n",
      "Sharpe:  3.4942501016413603\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8298642.814651773\n",
      "Sharpe:  2.2001709299066263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2838200.2171298284\n",
      "Sharpe:  2.183266671268556\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 76          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 1368        |\n",
      "|    total_timesteps | 65431       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.534       |\n",
      "|    critic_loss     | 0.000511    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 65330       |\n",
      "|    reward          | 0.017398782 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1913569.4919560836\n",
      "Sharpe:  2.1220511141875193\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2297228.0304678576\n",
      "Sharpe:  2.3926144869044257\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24635147.87761508\n",
      "Sharpe:  1.8450939766121115\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:38005526.49329837\n",
      "Sharpe:  1.8579597310006222\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 80         |\n",
      "|    fps             | 47         |\n",
      "|    time_elapsed    | 1455       |\n",
      "|    total_timesteps | 69397      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.488      |\n",
      "|    critic_loss     | 0.000481   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 69296      |\n",
      "|    reward          | 0.01319796 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1602683.7945077638\n",
      "Sharpe:  2.6503565434202976\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5602122.393886202\n",
      "Sharpe:  2.5136036645693713\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3427668.21638915\n",
      "Sharpe:  2.5180945227838962\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1262644.1869272224\n",
      "Sharpe:  4.142492143283885\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 84          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 1495        |\n",
      "|    total_timesteps | 71251       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.447       |\n",
      "|    critic_loss     | 0.000455    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 71150       |\n",
      "|    reward          | 0.011461327 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3056883.205883205\n",
      "Sharpe:  2.4552038703848615\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17959820.710031778\n",
      "Sharpe:  1.8949943795237167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8502367.493095186\n",
      "Sharpe:  2.1959033606008873\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:12262713.996368404\n",
      "Sharpe:  1.7207945923050518\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 1581        |\n",
      "|    total_timesteps | 75538       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.391       |\n",
      "|    critic_loss     | 0.000374    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 75437       |\n",
      "|    reward          | 0.011426355 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:30035658.05176077\n",
      "Sharpe:  1.6225543353056473\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2733709.706612217\n",
      "Sharpe:  2.1913190715159794\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:16949244.237532545\n",
      "Sharpe:  1.8239432220056846\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4077165.689579433\n",
      "Sharpe:  2.388559134500567\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 92           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 1665         |\n",
      "|    total_timesteps | 79583        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.314        |\n",
      "|    critic_loss     | 0.000414     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 79482        |\n",
      "|    reward          | 0.0067034326 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1008102.1061509316\n",
      "Sharpe:  3.7276494186563505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24110804.057088442\n",
      "Sharpe:  1.5592020685367\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:43899883.69326144\n",
      "Sharpe:  1.5446231670966273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2138109.2061900855\n",
      "Sharpe:  2.504255476239935\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 96          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 1732        |\n",
      "|    total_timesteps | 83097       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.305       |\n",
      "|    critic_loss     | 0.000597    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 82996       |\n",
      "|    reward          | 0.007834565 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10037929.694372198\n",
      "Sharpe:  1.9291355978962061\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3473432.378363186\n",
      "Sharpe:  2.2431319083278867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:14503602.026129777\n",
      "Sharpe:  1.7954556905345942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4738480.211947092\n",
      "Sharpe:  2.2311601634839477\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 100         |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 1807        |\n",
      "|    total_timesteps | 87180       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.284       |\n",
      "|    critic_loss     | 0.000255    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 87079       |\n",
      "|    reward          | 0.007345858 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3840232.4003406093\n",
      "Sharpe:  2.535680180354972\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4206810.52369311\n",
      "Sharpe:  2.117359683683125\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8333769.017653781\n",
      "Sharpe:  1.9642618620184944\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:19997358.39782509\n",
      "Sharpe:  1.7955103905443763\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 104          |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 1889         |\n",
      "|    total_timesteps | 91195        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.241        |\n",
      "|    critic_loss     | 0.000214     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 91094        |\n",
      "|    reward          | 0.0072551956 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1380180.631593525\n",
      "Sharpe:  4.431460148224289\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6363263.4157878915\n",
      "Sharpe:  2.3793400535758993\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8785142.543261789\n",
      "Sharpe:  2.1024526607323706\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2515944.859463143\n",
      "Sharpe:  2.473618127507307\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 1935        |\n",
      "|    total_timesteps | 93612       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.205       |\n",
      "|    critic_loss     | 0.000379    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 93511       |\n",
      "|    reward          | 0.008319981 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:16296757.872802543\n",
      "Sharpe:  1.8563662134817311\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:79781650.57474014\n",
      "Sharpe:  1.2485363214732743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:85183026.09190938\n",
      "Sharpe:  1.2515158041084578\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2198119.50603798\n",
      "Sharpe:  2.6182285043494873\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 112          |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 2031         |\n",
      "|    total_timesteps | 98554        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.167        |\n",
      "|    critic_loss     | 0.000145     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 98453        |\n",
      "|    reward          | 0.0075072795 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11215106.821290368\n",
      "Sharpe:  2.1204170814454772\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:21617287.779201884\n",
      "Sharpe:  2.0149820337895594\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3058400.9748435016\n",
      "Sharpe:  2.7401730905760524\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:22709536.77054083\n",
      "Sharpe:  2.0723586491421746\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 116         |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 2109        |\n",
      "|    total_timesteps | 102533      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.149       |\n",
      "|    critic_loss     | 0.00017     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 102432      |\n",
      "|    reward          | 0.012335632 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1261854.7140357844\n",
      "Sharpe:  4.839788265874761\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:23196327.239688136\n",
      "Sharpe:  2.0178342510168674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5307854.18972202\n",
      "Sharpe:  2.6460181058176415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13452679.161513958\n",
      "Sharpe:  2.280818860020923\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 120           |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 2172          |\n",
      "|    total_timesteps | 105706        |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.135         |\n",
      "|    critic_loss     | 0.000144      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 105605        |\n",
      "|    reward          | -0.0019947742 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:54911966.758553594\n",
      "Sharpe:  1.8805379716724417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1013018.4708734526\n",
      "Sharpe:  1.6103455875330497\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:123830747.51687732\n",
      "Sharpe:  1.3656611451901197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6784710.932726166\n",
      "Sharpe:  2.67069066054894\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 124           |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 2252          |\n",
      "|    total_timesteps | 109637        |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0992        |\n",
      "|    critic_loss     | 0.000403      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 109536        |\n",
      "|    reward          | -0.0014907137 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:20901269.22337088\n",
      "Sharpe:  2.1517368125580796\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:33286751.474005837\n",
      "Sharpe:  1.9888177256093549\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11364270.247817654\n",
      "Sharpe:  2.705159349314492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:31335020.547641035\n",
      "Sharpe:  2.137581249931668\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 128           |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 2350          |\n",
      "|    total_timesteps | 114443        |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0754        |\n",
      "|    critic_loss     | 0.000246      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 114342        |\n",
      "|    reward          | -0.0009932913 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1487085.2590131478\n",
      "Sharpe:  3.801094341581995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:175573991.95316526\n",
      "Sharpe:  1.4100754983794068\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:139727718.6102122\n",
      "Sharpe:  1.3645034319747935\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:39668198.21693863\n",
      "Sharpe:  2.1561681948433438\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 132           |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 2446          |\n",
      "|    total_timesteps | 119353        |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0312        |\n",
      "|    critic_loss     | 0.000152      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 119252        |\n",
      "|    reward          | 7.4911145e-06 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020130.8032804951\n",
      "Sharpe:  1.8239197304693429\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "alg = ''\n",
    "optuna_params = None\n",
    "#optuna_params = {\"learning_rate\": 1e-2, \"buffer_size\": 100_000, \"action_noise\": \"ornstein_uhlenbeck\", \"target_policy_noise\" : 0.5}\n",
    "#optuna_params = {\"learning_rate\": 2e-5, \"ent_coef\": 0.005}\n",
    "#optuna_params = {\"ent_coef\": 1, \"learning_rate\": 0.001}\n",
    "#optuna_params = {\"batch_size\": 128, \"buffer_size\": 100000, \"learning_rate\": 0.0003, \"learning_starts\": 100, \"ent_coef\": \"auto_0.1\"}\n",
    "log_name = alg + '_final_td3_' + str(9)\n",
    "model, df_daily_return, df_actions = train_trade(alg, train, trade, optuna_params, log_name=log_name, size=[192,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "state = e_trade_gym2.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, rew, term, _ = e_trade_gym2.step(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = df_daily_return['daily_return'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.00079063, -0.00983513,  0.00648143, -0.00202162,\n",
       "       -0.00188254,  0.00154436,  0.0064209 , -0.00249567,  0.00350078,\n",
       "       -0.00142935,  0.00618597, -0.00177391, -0.00159547, -0.00301549,\n",
       "       -0.01714915, -0.00099922,  0.02241922, -0.00190196,  0.02050364,\n",
       "       -0.00149597])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.020130803280495"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(rt+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return           0.270195\n",
       "Cumulative returns      0.020131\n",
       "Annual volatility       0.135994\n",
       "Sharpe ratio            1.823920\n",
       "Calmar ratio           11.079189\n",
       "Stability               0.149051\n",
       "Max drawdown           -0.024388\n",
       "Omega ratio             1.445612\n",
       "Sortino ratio           3.457097\n",
       "Skew                    0.837484\n",
       "Kurtosis                1.693009\n",
       "Tail ratio              2.084736\n",
       "Daily value at risk    -0.016149\n",
       "Alpha                   0.000000\n",
       "Beta                    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(df_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    GMKN\n",
       "0    LKOH\n",
       "0    MAGN\n",
       "0      MM\n",
       "0    MTSS\n",
       "0    NVTK\n",
       "0    ROSN\n",
       "0    SBER\n",
       "0    SNGS\n",
       "Name: tic, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.loc[0]['tic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>rsi_12</th>\n",
       "      <th>cci_12</th>\n",
       "      <th>dx_12</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>cov_xtra</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>10068.330000</td>\n",
       "      <td>10071.630000</td>\n",
       "      <td>10067.150000</td>\n",
       "      <td>10070.390000</td>\n",
       "      <td>25106100</td>\n",
       "      <td>GMKN</td>\n",
       "      <td>76.424845</td>\n",
       "      <td>215.142370</td>\n",
       "      <td>84.088373</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>8830.000000</td>\n",
       "      <td>8937.000000</td>\n",
       "      <td>8771.000000</td>\n",
       "      <td>8896.000000</td>\n",
       "      <td>1324998</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>83.042272</td>\n",
       "      <td>158.752567</td>\n",
       "      <td>82.638239</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>80.048000</td>\n",
       "      <td>80.078000</td>\n",
       "      <td>79.478000</td>\n",
       "      <td>79.818000</td>\n",
       "      <td>17212120</td>\n",
       "      <td>MAGN</td>\n",
       "      <td>75.466668</td>\n",
       "      <td>106.126368</td>\n",
       "      <td>65.791820</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>1</td>\n",
       "      <td>MM</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>129.477912</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>545.110000</td>\n",
       "      <td>546.910000</td>\n",
       "      <td>543.110000</td>\n",
       "      <td>545.010000</td>\n",
       "      <td>4802040</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>45.977731</td>\n",
       "      <td>-40.534283</td>\n",
       "      <td>5.922008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>541.060000</td>\n",
       "      <td>542.110000</td>\n",
       "      <td>537.610000</td>\n",
       "      <td>538.710000</td>\n",
       "      <td>5301270</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>41.667802</td>\n",
       "      <td>-66.093117</td>\n",
       "      <td>33.558085</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>1987.820000</td>\n",
       "      <td>2004.020000</td>\n",
       "      <td>1970.620000</td>\n",
       "      <td>1984.620000</td>\n",
       "      <td>832522</td>\n",
       "      <td>NVTK</td>\n",
       "      <td>67.993667</td>\n",
       "      <td>72.748710</td>\n",
       "      <td>53.094191</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>731.690000</td>\n",
       "      <td>732.940000</td>\n",
       "      <td>728.040000</td>\n",
       "      <td>730.640000</td>\n",
       "      <td>2565110</td>\n",
       "      <td>ROSN</td>\n",
       "      <td>66.340793</td>\n",
       "      <td>120.269856</td>\n",
       "      <td>51.537526</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>363.420000</td>\n",
       "      <td>364.620000</td>\n",
       "      <td>362.670000</td>\n",
       "      <td>363.220000</td>\n",
       "      <td>21957550</td>\n",
       "      <td>SBER</td>\n",
       "      <td>58.652072</td>\n",
       "      <td>94.074527</td>\n",
       "      <td>13.929651</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>36.845000</td>\n",
       "      <td>37.050000</td>\n",
       "      <td>36.675000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>16758600</td>\n",
       "      <td>SNGS</td>\n",
       "      <td>60.599427</td>\n",
       "      <td>138.740569</td>\n",
       "      <td>51.294080</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          open          high           low         close  \\\n",
       "0  2023-08-01  10068.330000  10071.630000  10067.150000  10070.390000   \n",
       "0  2023-08-01   8830.000000   8937.000000   8771.000000   8896.000000   \n",
       "0  2023-08-01     80.048000     80.078000     79.478000     79.818000   \n",
       "0  2023-08-01    156.172603    156.172603    156.172603    156.172603   \n",
       "0  2023-08-01    545.110000    546.910000    543.110000    545.010000   \n",
       "..        ...           ...           ...           ...           ...   \n",
       "22 2023-08-31    541.060000    542.110000    537.610000    538.710000   \n",
       "22 2023-08-31   1987.820000   2004.020000   1970.620000   1984.620000   \n",
       "22 2023-08-31    731.690000    732.940000    728.040000    730.640000   \n",
       "22 2023-08-31    363.420000    364.620000    362.670000    363.220000   \n",
       "22 2023-08-31     36.845000     37.050000     36.675000     36.790000   \n",
       "\n",
       "      volume   tic      rsi_12      cci_12       dx_12 cov_list  \\\n",
       "0   25106100  GMKN   76.424845  215.142370   84.088373       []   \n",
       "0    1324998  LKOH   83.042272  158.752567   82.638239       []   \n",
       "0   17212120  MAGN   75.466668  106.126368   65.791820       []   \n",
       "0          1    MM  100.000000  129.477912  100.000000       []   \n",
       "0    4802040  MTSS   45.977731  -40.534283    5.922008       []   \n",
       "..       ...   ...         ...         ...         ...      ...   \n",
       "22   5301270  MTSS   41.667802  -66.093117   33.558085       []   \n",
       "22    832522  NVTK   67.993667   72.748710   53.094191       []   \n",
       "22   2565110  ROSN   66.340793  120.269856   51.537526       []   \n",
       "22  21957550  SBER   58.652072   94.074527   13.929651       []   \n",
       "22  16758600  SNGS   60.599427  138.740569   51.294080       []   \n",
       "\n",
       "                                             cov_xtra  \\\n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "..                                                ...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "\n",
       "                                          return_list  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "..                                                ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "\n",
       "[207 rows x 13 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_final_a2c_9_4\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | -193          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -4.47         |\n",
      "|    reward             | -0.0020968118 |\n",
      "|    value_loss         | 0.143         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:677590.5788263523\n",
      "Sharpe:  -0.7154921932669398\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 30           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -101         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | 0.0019480594 |\n",
      "|    value_loss         | 0.0532       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 29           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -393         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -7.79        |\n",
      "|    reward             | 0.0016521268 |\n",
      "|    value_loss         | 0.357        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:428203.7352053475\n",
      "Sharpe:  -0.8404597211894865\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 67            |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | -1.42e+03     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -5.46         |\n",
      "|    reward             | -0.0022429526 |\n",
      "|    value_loss         | 0.194         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:658045.664396218\n",
      "Sharpe:  -0.746017116232962\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 29           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | -475         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -4.12        |\n",
      "|    reward             | 0.0031256576 |\n",
      "|    value_loss         | 0.12         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -894        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.942      |\n",
      "|    reward             | -0.01114825 |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714664.9753414551\n",
      "Sharpe:  -0.4718213975510272\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:639694.7563479333\n",
      "Sharpe:  -1.0899738888520887\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -1.83e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.255       |\n",
      "|    reward             | -0.007227374 |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:652614.2183674262\n",
      "Sharpe:  -0.7577239550993623\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | -31.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.712         |\n",
      "|    reward             | -0.0001371379 |\n",
      "|    value_loss         | 0.0043        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497518.51277105656\n",
      "Sharpe:  -1.438902858811296\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -1.44       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | 0.039199274 |\n",
      "|    value_loss         | 0.0281      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:685946.4418351555\n",
      "Sharpe:  -0.9400896570090742\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -22.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -3.16        |\n",
      "|    reward             | -0.012960385 |\n",
      "|    value_loss         | 0.0652       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714296.8951707652\n",
      "Sharpe:  -0.6514035432924666\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1008047.9849799668\n",
      "Sharpe:  19.906367353196487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 192           |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | -247          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.927        |\n",
      "|    reward             | -0.0062725036 |\n",
      "|    value_loss         | 0.00715       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:643419.4187983955\n",
      "Sharpe:  -0.7841971678885284\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 209           |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.5         |\n",
      "|    explained_variance | -349          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -1.73         |\n",
      "|    reward             | -0.0026202763 |\n",
      "|    value_loss         | 0.0437        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -130         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -2.75        |\n",
      "|    reward             | 0.0044023623 |\n",
      "|    value_loss         | 0.0471       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495961.0961472174\n",
      "Sharpe:  -0.954831681224276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1079765.3558981188\n",
      "Sharpe:  2.2027888279320407\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -11.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.876      |\n",
      "|    reward             | 0.011851955 |\n",
      "|    value_loss         | 0.00861     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -540         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.557       |\n",
      "|    reward             | -0.010102015 |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497843.68854857713\n",
      "Sharpe:  -0.9036786732304378\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -221         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.772        |\n",
      "|    reward             | -0.026621936 |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688534.3809074209\n",
      "Sharpe:  -0.6953503517238385\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -32.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -1.19        |\n",
      "|    reward             | -0.009795532 |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:644467.7441858157\n",
      "Sharpe:  -0.8065403651875281\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -1.39e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.592        |\n",
      "|    reward             | -0.005791324 |\n",
      "|    value_loss         | 0.0237       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -2.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.628       |\n",
      "|    reward             | 0.0103809815 |\n",
      "|    value_loss         | 0.00461      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -16.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.327       |\n",
      "|    reward             | -0.009229915 |\n",
      "|    value_loss         | 0.00532      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493957.1615292946\n",
      "Sharpe:  -0.7682968122165356\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -131         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -1.03        |\n",
      "|    reward             | -0.002019496 |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 387          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -731         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.0143      |\n",
      "|    reward             | 0.0045856624 |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497102.7989185725\n",
      "Sharpe:  -0.8077251667884892\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | -397        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | 0.007662638 |\n",
      "|    value_loss         | 0.00988     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 422           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | -82.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 1.41          |\n",
      "|    reward             | -0.0013838344 |\n",
      "|    value_loss         | 0.0143        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:621588.0611263695\n",
      "Sharpe:  -0.5322213240157098\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -50.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.0536      |\n",
      "|    reward             | 0.0015799176 |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718173.3471707416\n",
      "Sharpe:  -0.454710144839988\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 457           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -49.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -0.0333       |\n",
      "|    reward             | -0.0022115605 |\n",
      "|    value_loss         | 0.0012        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 476          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -43.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.43        |\n",
      "|    reward             | -0.009032664 |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 496          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -63.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.301        |\n",
      "|    reward             | -0.010511286 |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497677.4985161336\n",
      "Sharpe:  -0.6326117578831503\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 515           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -34.8         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | 0.628         |\n",
      "|    reward             | -0.0036314253 |\n",
      "|    value_loss         | 0.00332       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 532         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -0.145      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 0.318       |\n",
      "|    reward             | 0.011652762 |\n",
      "|    value_loss         | 0.000703    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498746.4519562575\n",
      "Sharpe:  -0.8604813205194255\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 549          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -62.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.365        |\n",
      "|    reward             | 0.0070009795 |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497140.78115192073\n",
      "Sharpe:  -1.266965929824368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1092665.3715541777\n",
      "Sharpe:  2.7563045181404435\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 567          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -75.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.697        |\n",
      "|    reward             | 0.0043257996 |\n",
      "|    value_loss         | 0.0104       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 586          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -5.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.193        |\n",
      "|    reward             | -0.006376009 |\n",
      "|    value_loss         | 0.000438     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 603           |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -675          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.586         |\n",
      "|    reward             | -0.0035784396 |\n",
      "|    value_loss         | 0.00327       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:641225.7385239308\n",
      "Sharpe:  -0.35105541448570665\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 621          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -46.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.0855       |\n",
      "|    reward             | 0.0003475954 |\n",
      "|    value_loss         | 0.000951     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498772.8835908298\n",
      "Sharpe:  -1.0165774810731998\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 640         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | -0.189      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.026756251 |\n",
      "|    value_loss         | 0.0196      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:612514.5579370301\n",
      "Sharpe:  -1.1606286086963988\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 658          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -120         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.144        |\n",
      "|    reward             | 0.0037523352 |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 674          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -9.02        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.0139       |\n",
      "|    reward             | -0.006655269 |\n",
      "|    value_loss         | 0.000231     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498550.9433546232\n",
      "Sharpe:  -0.8119287500809018\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 691           |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -3            |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | -0.0048318864 |\n",
      "|    value_loss         | 0.000191      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 708          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -0.568       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.611       |\n",
      "|    reward             | 0.0054282374 |\n",
      "|    value_loss         | 0.00241      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496524.137480398\n",
      "Sharpe:  -1.0195081776316404\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 725          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -9.51        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.462       |\n",
      "|    reward             | -0.009008461 |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 743          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -1.49        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | 0.0027022203 |\n",
      "|    value_loss         | 0.000851     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495369.18271021824\n",
      "Sharpe:  -0.9363760189426903\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 28         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 760        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -0.508     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -0.0867    |\n",
      "|    reward             | 0.01506457 |\n",
      "|    value_loss         | 0.000165   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:617462.9781145933\n",
      "Sharpe:  -0.7082991346289276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1079340.4636411471\n",
      "Sharpe:  2.4041830279625027\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 778          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -8.72        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | -0.16        |\n",
      "|    reward             | -0.012872042 |\n",
      "|    value_loss         | 0.000528     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.58        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | 0.009590331 |\n",
      "|    value_loss         | 0.000208    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:486391.2186962529\n",
      "Sharpe:  -1.0908673753965212\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 812           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -1.12         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -0.15         |\n",
      "|    reward             | -0.0015272818 |\n",
      "|    value_loss         | 0.000179      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 0.215       |\n",
      "|    reward             | 0.017340932 |\n",
      "|    value_loss         | 0.000342    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496707.2301635213\n",
      "Sharpe:  -0.877171472724079\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 847          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -4.64        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.156        |\n",
      "|    reward             | -0.005607592 |\n",
      "|    value_loss         | 0.00044      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -1.87         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0024429616 |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496283.8820606534\n",
      "Sharpe:  -0.9141457227795102\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 878         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -6.98       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.337      |\n",
      "|    reward             | 0.014959281 |\n",
      "|    value_loss         | 0.00111     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 895           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -4.72         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.0726        |\n",
      "|    reward             | -0.0048401505 |\n",
      "|    value_loss         | 4.02e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499667.8980029343\n",
      "Sharpe:  -0.6471923541601641\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 912          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -0.645       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.37        |\n",
      "|    reward             | 0.0009143865 |\n",
      "|    value_loss         | 0.000977     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 927          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0.347        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.010286457 |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:593048.4088688253\n",
      "Sharpe:  -0.6525219384947799\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 944         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -0.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.0984     |\n",
      "|    reward             | 0.011792672 |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725575.7673331513\n",
      "Sharpe:  -0.4675438152118888\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 5500           |\n",
      "|    time_elapsed       | 959            |\n",
      "|    total_timesteps    | 27500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.1          |\n",
      "|    explained_variance | -9.86          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5499           |\n",
      "|    policy_loss        | -0.402         |\n",
      "|    reward             | -0.00052906014 |\n",
      "|    value_loss         | 0.00178        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 976          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -0.156       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.16        |\n",
      "|    reward             | 0.0073924884 |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496777.50096947484\n",
      "Sharpe:  -0.9124193301283512\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 992         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -1.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.677      |\n",
      "|    reward             | 0.010774162 |\n",
      "|    value_loss         | 0.00301     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1009        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.528       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.157       |\n",
      "|    reward             | 0.023440337 |\n",
      "|    value_loss         | 0.000482    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1027        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 0.0188      |\n",
      "|    reward             | 0.029501045 |\n",
      "|    value_loss         | 8.93e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499557.4854872666\n",
      "Sharpe:  -0.7060795685181203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082190.131727652\n",
      "Sharpe:  1.7100913761963197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:932999.0766308173\n",
      "Sharpe:  -0.3251600599731243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 1044          |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -2.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5999          |\n",
      "|    policy_loss        | 0.488         |\n",
      "|    reward             | -0.0026730748 |\n",
      "|    value_loss         | 0.00148       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e_train_gym = PortfolioEnv(df = train, **env_kwargs)\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "agent = DRLAgent(env = env_train)\n",
    "model = agent.get_model(model_name = alg, model_kwargs = optuna_params, policy_kwargs = None, tensorboard_log = 'logs')\n",
    "\n",
    "trained_a2c = agent.train_model(model = model, \n",
    "                                tb_log_name = log_name,\n",
    "                                total_timesteps = 30_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "\n",
    "state = e_trade_gym2.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trained_a2c.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1],\n",
       "       dtype=int64),\n",
       " None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, rew, term, _ = e_trade_gym2.step(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007766173104209378"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[alg] = []\n",
    "ret[alg] = []\n",
    "act[alg] = []\n",
    "res[alg].append(get_result(df_daily_return))\n",
    "ret[alg].append(df_daily_return)\n",
    "act[alg].append(df_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'td3': [Annual return         -0.165986\n",
       "  Cumulative returns    -0.015012\n",
       "  Annual volatility      0.150527\n",
       "  Sharpe ratio          -1.133765\n",
       "  Calmar ratio          -2.711280\n",
       "  Stability              0.427691\n",
       "  Max drawdown          -0.061220\n",
       "  Omega ratio            0.842712\n",
       "  Sortino ratio         -1.616779\n",
       "  Skew                   0.319968\n",
       "  Kurtosis              -0.931438\n",
       "  Tail ratio             1.156678\n",
       "  Daily value at risk   -0.019642\n",
       "  Alpha                  0.000000\n",
       "  Beta                   1.000000\n",
       "  dtype: float64]}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of values (1999) does not match length of index (1997)\n",
      "Length of values (1999) does not match length of index (1997)\n",
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\meta\\preprocessor\\preprocessors.py:171: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill().bfill()\n",
      "100%|██████████| 1974/1974 [00:17<00:00, 114.48it/s]\n"
     ]
    }
   ],
   "source": [
    "loader2 = DataLoader()\n",
    "df2 = loader2.LoadData()\n",
    "\n",
    "df2.index = range(len(df2))\n",
    "#df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "df2 = df2.drop(df2[df2['tic'] == 'BZ'].index)\n",
    "#df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "df2 = df2.drop(df2[df2['tic'] == 'USD'].index)\n",
    "\n",
    "fa2 = FeaturesAdder(22)\n",
    "df2 = fa2.Process(df2)\n",
    "\n",
    "df2.index = df2.date.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 14:26:08,936] A new study created in memory with name: no-name-eda3bef4-e5cb-4542-9e78-966bed97e7fc\n",
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of values (1999) does not match length of index (1997)\n",
      "Length of values (1999) does not match length of index (1997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\meta\\preprocessor\\preprocessors.py:171: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill().bfill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:36<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1328804.5761858234\n",
      "Sharpe:  0.5611658994842432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1103836.133373412\n",
      "Sharpe:  4.10179896083965\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820169.431765897\n",
      "Sharpe:  0.7969255424660227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1333812.7718168045\n",
      "Sharpe:  0.5996255303696812\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 44            |\n",
      "|    time_elapsed    | 67            |\n",
      "|    total_timesteps | 2982          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.47          |\n",
      "|    critic_loss     | 0.114         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 2881          |\n",
      "|    reward          | 0.00090358907 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1107334.4305786227\n",
      "Sharpe:  0.4024363943306529\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1018132.6075719056\n",
      "Sharpe:  0.16940039431961662\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1314329.019413037\n",
      "Sharpe:  0.5688173277248557\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1836113.4298092867\n",
      "Sharpe:  0.9592534866233956\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 45           |\n",
      "|    time_elapsed    | 124          |\n",
      "|    total_timesteps | 5603         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.5          |\n",
      "|    critic_loss     | 0.0437       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5502         |\n",
      "|    reward          | 0.0013497723 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1183768.8523744675\n",
      "Sharpe:  0.5732399416389344\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4452795.7241544435\n",
      "Sharpe:  1.4460968664991039\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3911706.4369267942\n",
      "Sharpe:  1.4627118943964443\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1308272.3170993153\n",
      "Sharpe:  2.7214252270992954\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 12             |\n",
      "|    fps             | 46             |\n",
      "|    time_elapsed    | 202            |\n",
      "|    total_timesteps | 9405           |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 1.6            |\n",
      "|    critic_loss     | 0.0302         |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 9304           |\n",
      "|    reward          | -0.00016633693 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1950747.6560253352\n",
      "Sharpe:  0.9438175131643552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:931776.6141189707\n",
      "Sharpe:  -0.06082695036405172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2286935.25706349\n",
      "Sharpe:  1.0148677603491287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3734946.56557794\n",
      "Sharpe:  0.8939118908196799\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 291           |\n",
      "|    total_timesteps | 13882         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.6           |\n",
      "|    critic_loss     | 0.0144        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 13781         |\n",
      "|    reward          | 0.00042037814 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:866101.5160753474\n",
      "Sharpe:  -0.19551447644116093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:948033.2712875433\n",
      "Sharpe:  0.009076499221343346\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1054613.37315207\n",
      "Sharpe:  0.21426509150782927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1766848.531771442\n",
      "Sharpe:  0.7470436385312387\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 343          |\n",
      "|    total_timesteps | 16544        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.54         |\n",
      "|    critic_loss     | 0.00874      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 16443        |\n",
      "|    reward          | 0.0026483552 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1405851.2925929574\n",
      "Sharpe:  0.6727306888880273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1317100.7628776599\n",
      "Sharpe:  2.158521323948593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1173652.0588240025\n",
      "Sharpe:  1.405255983808238\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1241256.5282445773\n",
      "Sharpe:  4.067337457333297\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 367          |\n",
      "|    total_timesteps | 17823        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.5          |\n",
      "|    critic_loss     | 0.00713      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 17722        |\n",
      "|    reward          | 0.0026428201 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1562646.449235679\n",
      "Sharpe:  0.633380559038114\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1371502.4623127112\n",
      "Sharpe:  0.7367972783991253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1131493.268291758\n",
      "Sharpe:  0.506987186004417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2840504.064695686\n",
      "Sharpe:  1.0470695792709348\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 434          |\n",
      "|    total_timesteps | 21116        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.39         |\n",
      "|    critic_loss     | 0.00496      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21015        |\n",
      "|    reward          | 0.0020960954 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1229490.3030663717\n",
      "Sharpe:  1.9275202386107841\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2350564.8189799865\n",
      "Sharpe:  0.8784439248881407\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1779692.974585341\n",
      "Sharpe:  0.9061137849874381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985209.9501435242\n",
      "Sharpe:  0.9488682037418644\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 530          |\n",
      "|    total_timesteps | 24527        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.31         |\n",
      "|    critic_loss     | 0.00635      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 24426        |\n",
      "|    reward          | 0.0017521542 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2145723.507516834\n",
      "Sharpe:  1.0943008926440432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1640980.3131339182\n",
      "Sharpe:  0.8533855093449112\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302390.2088839714\n",
      "Sharpe:  1.0841225550505527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1140036.191063451\n",
      "Sharpe:  0.5449064122400642\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 44           |\n",
      "|    time_elapsed    | 624          |\n",
      "|    total_timesteps | 27840        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.1          |\n",
      "|    critic_loss     | 0.00488      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 27739        |\n",
      "|    reward          | 0.0015436959 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820282.9834706066\n",
      "Sharpe:  1.136287235554368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2087724.2145517007\n",
      "Sharpe:  0.9960445843173737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1222077.6215655361\n",
      "Sharpe:  0.39000841688463\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4597006.341869871\n",
      "Sharpe:  1.1800078690405984\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 745         |\n",
      "|    total_timesteps | 32169       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1           |\n",
      "|    critic_loss     | 0.0016      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 32068       |\n",
      "|    reward          | 0.001156949 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1238201.3049344996\n",
      "Sharpe:  0.673218212597284\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2066941.5177945103\n",
      "Sharpe:  1.2845728730424915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3844164.781967173\n",
      "Sharpe:  1.310752406598563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1855496.6602841718\n",
      "Sharpe:  1.2141175271754308\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 825         |\n",
      "|    total_timesteps | 35492       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.937       |\n",
      "|    critic_loss     | 0.00239     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 35391       |\n",
      "|    reward          | 0.003426767 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1651215.5070773554\n",
      "Sharpe:  0.8494033512066217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2278208.5879557487\n",
      "Sharpe:  0.9854790050408566\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4646897.673596888\n",
      "Sharpe:  1.5165456763772365\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1320608.9145450208\n",
      "Sharpe:  0.9698333814310819\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 48           |\n",
      "|    fps             | 43           |\n",
      "|    time_elapsed    | 907          |\n",
      "|    total_timesteps | 39159        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.879        |\n",
      "|    critic_loss     | 0.0024       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 39058        |\n",
      "|    reward          | 0.0059507755 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1749223.916471298\n",
      "Sharpe:  1.2687851074394052\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2442465.7781259767\n",
      "Sharpe:  0.9090291362699257\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3837056.12005318\n",
      "Sharpe:  1.3131053048946968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2176718.1066348413\n",
      "Sharpe:  1.4801930383249173\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 52           |\n",
      "|    fps             | 43           |\n",
      "|    time_elapsed    | 992          |\n",
      "|    total_timesteps | 43036        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.715        |\n",
      "|    critic_loss     | 0.001        |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 42935        |\n",
      "|    reward          | 0.0013587814 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3191401.586089331\n",
      "Sharpe:  1.4663440412279218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3308265.502584776\n",
      "Sharpe:  1.3216110845077496\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1307616.1815233608\n",
      "Sharpe:  0.82512987467599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1486411.4193733486\n",
      "Sharpe:  4.3220076376745835\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 1044        |\n",
      "|    total_timesteps | 45535       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.697       |\n",
      "|    critic_loss     | 0.00145     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 45434       |\n",
      "|    reward          | 0.006437955 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3759366.43552654\n",
      "Sharpe:  1.3490063998292297\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1823268.7294768016\n",
      "Sharpe:  2.2979350642115075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3014714.2876265454\n",
      "Sharpe:  1.3347472099476823\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5533166.629001392\n",
      "Sharpe:  1.3176004720572663\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1121        |\n",
      "|    total_timesteps | 49434       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.63        |\n",
      "|    critic_loss     | 0.00161     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 49333       |\n",
      "|    reward          | 0.006632961 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4185283.799920185\n",
      "Sharpe:  1.3267918395226979\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4404197.203408463\n",
      "Sharpe:  1.5992964363145732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3134807.76348591\n",
      "Sharpe:  1.4874607781870686\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5731460.443011691\n",
      "Sharpe:  1.4871835550367283\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1210        |\n",
      "|    total_timesteps | 53891       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.599       |\n",
      "|    critic_loss     | 0.000664    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 53790       |\n",
      "|    reward          | 0.010918282 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1097205.1922230008\n",
      "Sharpe:  5.3869663495769675\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1589799.2722708723\n",
      "Sharpe:  1.1901031529761137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11653783.088012619\n",
      "Sharpe:  1.32633580425348\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1479095.5168959228\n",
      "Sharpe:  2.731231531937861\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1257        |\n",
      "|    total_timesteps | 56212       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.567       |\n",
      "|    critic_loss     | 0.00144     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 56111       |\n",
      "|    reward          | 0.008054283 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5802240.705077837\n",
      "Sharpe:  1.6593319044434025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1590381.2400240623\n",
      "Sharpe:  1.2398679002996726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1269358.7614109737\n",
      "Sharpe:  6.056583828584722\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11200082.426396014\n",
      "Sharpe:  1.5255659336941592\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 72           |\n",
      "|    fps             | 44           |\n",
      "|    time_elapsed    | 1329         |\n",
      "|    total_timesteps | 59740        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.479        |\n",
      "|    critic_loss     | 0.00173      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 59639        |\n",
      "|    reward          | 0.0014642718 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026623.5309537264\n",
      "Sharpe:  3.1750684028905685\n",
      "=================================\n",
      "hit end!\n",
      "Rew, DD, Sh 0.026623530953725938 -0.021978134345193148 3.1750684028905685\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1318650.4135951765\n",
      "Sharpe:  0.5284407138969732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:892724.9130789972\n",
      "Sharpe:  -0.10934792520271971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1552342.927234988\n",
      "Sharpe:  0.5287890287253493\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:989830.0674499976\n",
      "Sharpe:  0.11941069750924747\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 56           |\n",
      "|    total_timesteps | 2869         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -4.04        |\n",
      "|    critic_loss     | 0.108        |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 2768         |\n",
      "|    reward          | -0.001113208 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:942752.0679029975\n",
      "Sharpe:  0.011518549135084648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1727219.4953959861\n",
      "Sharpe:  0.5961475191083743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2021792.929268023\n",
      "Sharpe:  0.6245781748088858\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1925815.8233059854\n",
      "Sharpe:  0.6596968726619067\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 157           |\n",
      "|    total_timesteps | 7788          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.71         |\n",
      "|    critic_loss     | 0.032         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 7687          |\n",
      "|    reward          | -0.0011175167 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1093803.5097770034\n",
      "Sharpe:  0.2840936714628202\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1169744.3359430037\n",
      "Sharpe:  0.3146825275173701\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1762176.5433530144\n",
      "Sharpe:  0.6103728302174665\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1289147.692605001\n",
      "Sharpe:  1.351458514890795\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 220           |\n",
      "|    total_timesteps | 10888         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.22         |\n",
      "|    critic_loss     | 0.018         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 10787         |\n",
      "|    reward          | -0.0011198022 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:993392.2602940019\n",
      "Sharpe:  0.12255996914877115\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:950135.7009329982\n",
      "Sharpe:  0.035656513885465174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1923464.162117011\n",
      "Sharpe:  0.6082939194230987\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1470428.1125509874\n",
      "Sharpe:  0.5029518382425445\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 297           |\n",
      "|    total_timesteps | 14596         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.06         |\n",
      "|    critic_loss     | 0.00968       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 14495         |\n",
      "|    reward          | -0.0011183036 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1735315.4489900174\n",
      "Sharpe:  0.6007949153227594\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1614086.0805639846\n",
      "Sharpe:  0.544743725001608\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1247937.847477999\n",
      "Sharpe:  0.4802559689222678\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1237150.7732739984\n",
      "Sharpe:  1.2468082678442802\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 373           |\n",
      "|    total_timesteps | 18192         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.71         |\n",
      "|    critic_loss     | 0.00573       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 18091         |\n",
      "|    reward          | -0.0011154127 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1114069.550226006\n",
      "Sharpe:  0.26011612027899694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1244322.763987007\n",
      "Sharpe:  0.4646585636846666\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1664952.7403180155\n",
      "Sharpe:  0.5492730036980374\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1638604.0210619897\n",
      "Sharpe:  0.5716709746621218\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 464           |\n",
      "|    total_timesteps | 22420         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.56         |\n",
      "|    critic_loss     | 0.00839       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 22319         |\n",
      "|    reward          | -0.0011163533 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1932850.1361090194\n",
      "Sharpe:  0.598377879189032\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1535299.520385989\n",
      "Sharpe:  0.5132522902067653\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1495882.8542230136\n",
      "Sharpe:  0.5627564293187396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1110201.4211619962\n",
      "Sharpe:  0.25420487383826385\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 566           |\n",
      "|    total_timesteps | 27232         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.3          |\n",
      "|    critic_loss     | 0.00503       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 27131         |\n",
      "|    reward          | -0.0011147878 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1241516.6333480063\n",
      "Sharpe:  0.4027941057764657\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1195504.4139590024\n",
      "Sharpe:  0.3990308243993078\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1958819.3341579859\n",
      "Sharpe:  0.6089566270503579\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020592.4795650021\n",
      "Sharpe:  0.17155607182293875\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 647           |\n",
      "|    total_timesteps | 30954         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.15         |\n",
      "|    critic_loss     | 0.00334       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 30853         |\n",
      "|    reward          | -0.0011157809 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1213795.1222939997\n",
      "Sharpe:  4.2627708481876985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985900.8927120143\n",
      "Sharpe:  0.6801195650826561\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1249927.3770069992\n",
      "Sharpe:  0.9833101736365217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1536309.6517640078\n",
      "Sharpe:  0.5867192804524377\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 713           |\n",
      "|    total_timesteps | 33862         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.935        |\n",
      "|    critic_loss     | 0.00333       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 33761         |\n",
      "|    reward          | -0.0011153751 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1087180.7069060025\n",
      "Sharpe:  0.277307813094664\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:959282.6782200012\n",
      "Sharpe:  0.0566141239582126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1264610.6580320003\n",
      "Sharpe:  1.1310738346676652\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1713625.1904130196\n",
      "Sharpe:  0.5870395118556284\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 769           |\n",
      "|    total_timesteps | 36541         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.832        |\n",
      "|    critic_loss     | 0.00285       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 36440         |\n",
      "|    reward          | -0.0011179155 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639940.9394450155\n",
      "Sharpe:  0.5524960703176339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1731254.6139369896\n",
      "Sharpe:  0.539587476932397\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:988621.3274869996\n",
      "Sharpe:  0.11799788232764691\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:925659.1937699983\n",
      "Sharpe:  -0.021675332346362364\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 847          |\n",
      "|    total_timesteps | 40320        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.672       |\n",
      "|    critic_loss     | 0.00127      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 40219        |\n",
      "|    reward          | -0.001119452 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1313052.9278640004\n",
      "Sharpe:  3.1983921016222214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2099575.804508018\n",
      "Sharpe:  0.7230706691839036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:910852.8165930018\n",
      "Sharpe:  -0.056161840191677956\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1268089.6348409979\n",
      "Sharpe:  1.2248250493316877\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 48            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 896           |\n",
      "|    total_timesteps | 42680         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.593        |\n",
      "|    critic_loss     | 0.00215       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 42579         |\n",
      "|    reward          | -0.0011163106 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639940.9394450155\n",
      "Sharpe:  0.5524960703176339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2016135.0158219868\n",
      "Sharpe:  0.6362168328608206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1605201.4504840157\n",
      "Sharpe:  0.5451501182272538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1105752.542209\n",
      "Sharpe:  5.410546062543867\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 52            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 988           |\n",
      "|    total_timesteps | 47029         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.56         |\n",
      "|    critic_loss     | 0.00182       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 46928         |\n",
      "|    reward          | -0.0011145849 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1728595.61942099\n",
      "Sharpe:  0.5970539282808451\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1645504.602556011\n",
      "Sharpe:  0.5697467917846732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826298.8415059904\n",
      "Sharpe:  0.5905714113479494\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1914390.9274990133\n",
      "Sharpe:  0.6050803119208974\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 56            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1113          |\n",
      "|    total_timesteps | 52859         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.355        |\n",
      "|    critic_loss     | 0.000923      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 52758         |\n",
      "|    reward          | -0.0011181458 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1290451.2204399994\n",
      "Sharpe:  3.905267662114931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1470437.2817110098\n",
      "Sharpe:  0.5206985137254035\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1493911.538356991\n",
      "Sharpe:  0.578964459334561\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1099304.4772550003\n",
      "Sharpe:  5.836169671119692\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 60            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1162          |\n",
      "|    total_timesteps | 55053         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.351        |\n",
      "|    critic_loss     | 0.000523      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 54952         |\n",
      "|    reward          | -0.0011134197 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1246773.209804999\n",
      "Sharpe:  1.0761021014842138\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1498005.0572399872\n",
      "Sharpe:  0.5059413519968269\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1920694.7853860224\n",
      "Sharpe:  0.6353897047526376\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1235093.0817079986\n",
      "Sharpe:  0.4334555312275949\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 64            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1242          |\n",
      "|    total_timesteps | 58841         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.228        |\n",
      "|    critic_loss     | 0.00126       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 58740         |\n",
      "|    reward          | -0.0011152643 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1059357.054332\n",
      "Sharpe:  7.9081414301092865\n",
      "=================================\n",
      "hit end!\n",
      "Rew, DD, Sh 0.059357054332000114 -0.0156859275455648 7.9081414301092865\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_2_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1980415.4168697067\n",
      "Sharpe:  0.8011031745757455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1717016.8685665885\n",
      "Sharpe:  0.9291492766166308\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1469591.0161674125\n",
      "Sharpe:  0.6434573503934055\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1150816.2652700073\n",
      "Sharpe:  0.4576295083108517\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 74          |\n",
      "|    total_timesteps | 3523        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.08        |\n",
      "|    critic_loss     | 0.049       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3422        |\n",
      "|    reward          | 0.017000806 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826971.4826673293\n",
      "Sharpe:  0.7841686187813658\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1277429.8361853443\n",
      "Sharpe:  4.962211899346144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1219378.4685634286\n",
      "Sharpe:  5.080476036550634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020531.1939383592\n",
      "Sharpe:  0.15568747640714065\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 46         |\n",
      "|    time_elapsed    | 118        |\n",
      "|    total_timesteps | 5529       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2          |\n",
      "|    critic_loss     | 0.0244     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5428       |\n",
      "|    reward          | 0.01729235 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1352750.3238479511\n",
      "Sharpe:  2.4988336527294277\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1565224.3421228137\n",
      "Sharpe:  0.5215241504524739\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1607574.0297108036\n",
      "Sharpe:  0.5459016786875458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1213905.4042664145\n",
      "Sharpe:  0.4830204056089441\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 192         |\n",
      "|    total_timesteps | 9129        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.84        |\n",
      "|    critic_loss     | 0.00935     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9028        |\n",
      "|    reward          | 0.017385758 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1160434.1764833617\n",
      "Sharpe:  0.45968397183500126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1160079.37600498\n",
      "Sharpe:  0.5159266529223933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1504260.3342921403\n",
      "Sharpe:  2.9072263392266953\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1479796.4251187576\n",
      "Sharpe:  2.5751521585398143\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 222         |\n",
      "|    total_timesteps | 10668       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.79        |\n",
      "|    critic_loss     | 0.0103      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10567       |\n",
      "|    reward          | 0.016845211 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1290989.9614684638\n",
      "Sharpe:  0.6782675543327175\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1754076.9596391807\n",
      "Sharpe:  0.9898743036814743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302889.1195204086\n",
      "Sharpe:  0.998127576283723\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1494830.371760098\n",
      "Sharpe:  0.8503697580605752\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 294         |\n",
      "|    total_timesteps | 14268       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.65        |\n",
      "|    critic_loss     | 0.00698     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14167       |\n",
      "|    reward          | 0.014286233 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1340425.5091364323\n",
      "Sharpe:  0.5582988798355213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1512652.3930290346\n",
      "Sharpe:  0.65647825457729\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2273424.7816010695\n",
      "Sharpe:  0.8275860314061532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2585173.1994123086\n",
      "Sharpe:  0.9515265430689012\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 392         |\n",
      "|    total_timesteps | 19196       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.54        |\n",
      "|    critic_loss     | 0.00514     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19095       |\n",
      "|    reward          | 0.013498942 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2607737.144842626\n",
      "Sharpe:  0.9795896351268775\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2685515.147204389\n",
      "Sharpe:  1.0758587479292743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2064921.2023646967\n",
      "Sharpe:  1.0810350395018937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1121428.1653979907\n",
      "Sharpe:  0.4675765734226979\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 479         |\n",
      "|    total_timesteps | 23451       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.44        |\n",
      "|    critic_loss     | 0.00233     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 23350       |\n",
      "|    reward          | 0.013867696 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3161265.846518264\n",
      "Sharpe:  1.3502794885210447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2206221.4630808965\n",
      "Sharpe:  1.1664351549535428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1279585.956290057\n",
      "Sharpe:  1.8619437686071902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1093986.9465965494\n",
      "Sharpe:  0.34273262715183395\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 543         |\n",
      "|    total_timesteps | 26565       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.28        |\n",
      "|    critic_loss     | 0.00241     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 26464       |\n",
      "|    reward          | 0.004472833 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1163768.9956416213\n",
      "Sharpe:  0.488189278072325\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1828580.9724078616\n",
      "Sharpe:  1.1757119674074545\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1387406.908356824\n",
      "Sharpe:  0.7353214813069318\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3632183.1430810965\n",
      "Sharpe:  1.259179380249516\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 614         |\n",
      "|    total_timesteps | 29973       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.26        |\n",
      "|    critic_loss     | 0.00152     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29872       |\n",
      "|    reward          | 0.012178719 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2351103.712811755\n",
      "Sharpe:  1.1933516368295358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4488292.261743441\n",
      "Sharpe:  1.4808219215027747\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1629886.4418955138\n",
      "Sharpe:  1.5121928479954903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4050663.2348253275\n",
      "Sharpe:  1.2897595388574803\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 48         |\n",
      "|    time_elapsed    | 705        |\n",
      "|    total_timesteps | 34350      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.14       |\n",
      "|    critic_loss     | 0.00172    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 34249      |\n",
      "|    reward          | 0.01577032 |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-23 15:22:09,944] Trial 0 failed with parameters: {'bsize': 100000, 'noise': 'normal', 'learning_rate': 7.899454013765834e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_45272\\2432288324.py\", line 41, in objective\n",
      "    model, df_daily_return, df_actions = train_trade('td3', train, trade, None, log_name, size)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_45272\\1449868205.py\", line 23, in train_trade\n",
      "    trained_a2c = agent.train_model(model = model,\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py\", line 117, in train_model\n",
      "    model = model.learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 222, in learn\n",
      "    return super().learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 347, in learn\n",
      "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 179, in train\n",
      "    current_q_values = self.critic(replay_data.observations, replay_data.actions)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 976, in forward\n",
      "    qvalue_input = th.cat([features, actions], dim=1)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-23 15:22:09,948] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sum_reward\n\u001b[0;32m     55\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 56\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[59], line 41\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#optuna_params = {\"learning_rate\": learning_rate}#, \"ent_coef\": ent_coef}# \"action_noise\": \"ornstein_uhlenbeck\"}\u001b[39;00m\n\u001b[0;32m     40\u001b[0m log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(lookback) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m---> 41\u001b[0m model, df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtd3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m result \u001b[38;5;241m=\u001b[39m get_result(df_daily_return)\n\u001b[0;32m     44\u001b[0m reward \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[56], line 23\u001b[0m, in \u001b[0;36mtrain_trade\u001b[1;34m(alg, train, trade, optuna_params, log_name, size)\u001b[0m\n\u001b[0;32m     19\u001b[0m     log_name \u001b[38;5;241m=\u001b[39m alg\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_model(model_name \u001b[38;5;241m=\u001b[39m alg, model_kwargs \u001b[38;5;241m=\u001b[39m optuna_params, policy_kwargs \u001b[38;5;241m=\u001b[39m policy_kwargs, tensorboard_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m trained_a2c \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m e_trade_gym2 \u001b[38;5;241m=\u001b[39m PortfolioEnv(df \u001b[38;5;241m=\u001b[39m trade, reset_to_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m     29\u001b[0m df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m DRLAgent\u001b[38;5;241m.\u001b[39mDRL_prediction(model\u001b[38;5;241m=\u001b[39mtrained_a2c,\n\u001b[0;32m     30\u001b[0m                     environment \u001b[38;5;241m=\u001b[39m e_trade_gym2)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    115\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    116\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:179\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    176\u001b[0m     target_q_values \u001b[38;5;241m=\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mdones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Get current Q-values estimates for each critic network\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m current_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Compute critic loss\u001b[39;00m\n\u001b[0;32m    182\u001b[0m critic_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(F\u001b[38;5;241m.\u001b[39mmse_loss(current_q, target_q_values) \u001b[38;5;28;01mfor\u001b[39;00m current_q \u001b[38;5;129;01min\u001b[39;00m current_q_values)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py:976\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor):\n\u001b[0;32m    975\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor)\n\u001b[1;32m--> 976\u001b[0m qvalue_input \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(q_net(qvalue_input) \u001b[38;5;28;01mfor\u001b[39;00m q_net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_networks)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    loader2 = DataLoader()\n",
    "    df2 = loader2.LoadData()\n",
    "\n",
    "    df2.index = range(len(df2))\n",
    "    #df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "    df2 = df2.drop(df2[df2['tic'] == 'BZ'].index)\n",
    "    #df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "    df2 = df2.drop(df2[df2['tic'] == 'USD'].index)\n",
    "    lookback = 22#trial.suggest_categorical('lookback', [252])\n",
    "    fa2 = FeaturesAdder(lookback)\n",
    "    df2 = fa2.Process(df2)\n",
    "    #tau = trial.suggest_categorical('tau', [0.001, 0.005, 0.01])\n",
    "\n",
    "    #sigma = trial.suggest_float('sigma', 0, 1)\n",
    "    bsize = trial.suggest_categorical('bsize', [10000, 50000, 100000])\n",
    "    noise = trial.suggest_categorical('noise', [\"ornstein_uhlenbeck\", \"normal\"])\n",
    "\n",
    "    #n_actions = stock_dimension\n",
    "    #action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=sigma * np.ones(n_actions), theta=theta)\n",
    "    # size1 = trial.suggest_categorical('size1', [32, 64, 128])\n",
    "    # size2 = size1 * 2\n",
    "    size = [128, 64]\n",
    "    #ent_coef = trial.suggest_float('ent_coef', 0, 0.05)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-6, 5e-3, log=True)\n",
    "    #lookback = trial.suggest_categorical('lookback', [5, 10, 15, 22, 44, 66])\n",
    "\n",
    "    sum_reward = 0\n",
    "    sum_maxdd  = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        date1 = date_start + relativedelta(months = i)\n",
    "        date2 = date_start + relativedelta(months = i + 1)\n",
    "        train = data_split(df2, '2016-05-10', date1)\n",
    "        trade = data_split(df2, date1, date2)\n",
    "\n",
    "        optuna_params = {\"learning_rate\": learning_rate, \"buffer_size\": bsize, \"action_noise\": \"ornstein_uhlenbeck\"}\n",
    "        #optuna_params = {\"learning_rate\": learning_rate}#, \"ent_coef\": ent_coef}# \"action_noise\": \"ornstein_uhlenbeck\"}\n",
    "        log_name = str(size) + '_' + str(lookback) + '_' + str(i)\n",
    "        model, df_daily_return, df_actions = train_trade('td3', train, trade, None, log_name, size)\n",
    "        \n",
    "        result = get_result(df_daily_return)\n",
    "        reward = result['Cumulative returns']\n",
    "        max_dd = result['Max drawdown']\n",
    "        sharp  = result['Sharpe ratio']\n",
    "\n",
    "        print(\"Rew, DD, Sh\", reward, max_dd, sharp)\n",
    "        sum_reward += reward\n",
    "        sum_maxdd += max_dd\n",
    "\n",
    "    print(\"Total\", sum_reward, sum_maxdd, sharp)\n",
    "    return sum_reward\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\"])\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
