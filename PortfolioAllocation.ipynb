{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfolio import timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Дано:</b> Есть данные по некоторым ликвидным акциям (OHLCV). Цены по акциям учитывают дивидендные доходности, поэтому могут не совпадать с котировками, которые мы видим в текущий момент на рынке (но динамика ровно та же самая, но без гэпов). Есть данные по фонду денежного рынка (OHLCV) - безрисковый актив (аналог накопительного счета). В данной работе котировки синтетические - сгенерированы на основе текущих ставок рефинансирования, так как большинство имеющихся на данный момент фондов ведут свое начало от 22го года и наоборот, фонды, которые были до 22го года прекратили свое существование. Есть котировки по дополнительным рядам, назовем их вспомогательными: IMOEX (индекс мосбиржи), GD (золото), BZ (нефть). Рассматриваемые даты 06.16-05.24. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фонды денежного рынка это те, график которых вот такой:\n",
    "\n",
    "![alt text](mm_fund.JPG \"Title2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Найти:</b> С помощью модели RL предполагается научиться эффективно распределять денежные средства между имеющимися активами (рисковыми и безрисковым).\n",
    "\n",
    " В качестве состояния в среде планируется использовать индикаторы технического анализа, корреляцию активов со вспомогательными рядам, текущее распределение портфеля. \n",
    " \n",
    " Обязательно должны быть учтены комиссии за совершение сделок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from FeaturesAdder import FeaturesAdder\n",
    "from PortfolioEnvBox import PortfolioEnv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "df = loader.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [open, high, low, close, volume, tic]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = df.groupby('date').count()\n",
    "cnt[cnt[\"open\"] > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25949, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df))\n",
    "#df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "#df = df.drop(df[df['tic'] == 'BZ'].index)\n",
    "#df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "df = df.drop(df[df['tic'] == 'USD'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume'] = pd.to_numeric(df['volume'])\n",
    "df = df.astype({'volume' : 'double'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23953 entries, 0 to 25947\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    23953 non-null  datetime64[ns]\n",
      " 1   open    23953 non-null  float64       \n",
      " 2   high    23953 non-null  float64       \n",
      " 3   low     23953 non-null  float64       \n",
      " 4   close   23953 non-null  float64       \n",
      " 5   volume  23953 non-null  float64       \n",
      " 6   tic     23953 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:19<00:00, 101.36it/s]\n"
     ]
    }
   ],
   "source": [
    "fa = FeaturesAdder()\n",
    "df0 = df.copy()\n",
    "df = fa.Process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>HL_rsi12_up</th>\n",
       "      <th>HL_rsi12_down</th>\n",
       "      <th>rsi12</th>\n",
       "      <th>obv</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>cov_xtra</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17761</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>538.06</td>\n",
       "      <td>543.610</td>\n",
       "      <td>535.11</td>\n",
       "      <td>541.51</td>\n",
       "      <td>5116050.0</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>31.029741</td>\n",
       "      <td>13.551594</td>\n",
       "      <td>24.026140</td>\n",
       "      <td>4.919330</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7013046477435794, 0.6123415407147443, -0.19...</td>\n",
       "      <td>tic            BZ      GD      GMKN    IMOEX  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17762</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>1419.72</td>\n",
       "      <td>1434.320</td>\n",
       "      <td>1379.52</td>\n",
       "      <td>1407.92</td>\n",
       "      <td>2076053.0</td>\n",
       "      <td>NVTK</td>\n",
       "      <td>22.612618</td>\n",
       "      <td>17.001599</td>\n",
       "      <td>17.001599</td>\n",
       "      <td>1.026104</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7013046477435794, 0.6123415407147443, -0.19...</td>\n",
       "      <td>tic            BZ      GD      GMKN    IMOEX  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17763</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>731.69</td>\n",
       "      <td>739.190</td>\n",
       "      <td>716.99</td>\n",
       "      <td>737.44</td>\n",
       "      <td>7536920.0</td>\n",
       "      <td>ROSN</td>\n",
       "      <td>40.545188</td>\n",
       "      <td>26.954882</td>\n",
       "      <td>34.850714</td>\n",
       "      <td>52.135294</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7013046477435794, 0.6123415407147443, -0.19...</td>\n",
       "      <td>tic            BZ      GD      GMKN    IMOEX  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>411.87</td>\n",
       "      <td>413.870</td>\n",
       "      <td>403.37</td>\n",
       "      <td>409.32</td>\n",
       "      <td>61548130.0</td>\n",
       "      <td>SBER</td>\n",
       "      <td>60.360697</td>\n",
       "      <td>40.349783</td>\n",
       "      <td>40.349783</td>\n",
       "      <td>445.295899</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7013046477435794, 0.6123415407147443, -0.19...</td>\n",
       "      <td>tic            BZ      GD      GMKN    IMOEX  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>34.23</td>\n",
       "      <td>34.685</td>\n",
       "      <td>32.15</td>\n",
       "      <td>33.88</td>\n",
       "      <td>153852300.0</td>\n",
       "      <td>SNGS</td>\n",
       "      <td>32.282910</td>\n",
       "      <td>23.582352</td>\n",
       "      <td>23.582352</td>\n",
       "      <td>207.700822</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7013046477435794, 0.6123415407147443, -0.19...</td>\n",
       "      <td>tic            BZ      GD      GMKN    IMOEX  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     open      high      low    close       volume   tic  \\\n",
       "17761 2024-06-03   538.06   543.610   535.11   541.51    5116050.0  MTSS   \n",
       "17762 2024-06-03  1419.72  1434.320  1379.52  1407.92    2076053.0  NVTK   \n",
       "17763 2024-06-03   731.69   739.190   716.99   737.44    7536920.0  ROSN   \n",
       "17764 2024-06-03   411.87   413.870   403.37   409.32   61548130.0  SBER   \n",
       "17765 2024-06-03    34.23    34.685    32.15    33.88  153852300.0  SNGS   \n",
       "\n",
       "       HL_rsi12_up  HL_rsi12_down      rsi12         obv cov_list  \\\n",
       "17761    31.029741      13.551594  24.026140    4.919330       []   \n",
       "17762    22.612618      17.001599  17.001599    1.026104       []   \n",
       "17763    40.545188      26.954882  34.850714   52.135294       []   \n",
       "17764    60.360697      40.349783  40.349783  445.295899       []   \n",
       "17765    32.282910      23.582352  23.582352  207.700822       []   \n",
       "\n",
       "                                                cov_xtra  \\\n",
       "17761  [0.7013046477435794, 0.6123415407147443, -0.19...   \n",
       "17762  [0.7013046477435794, 0.6123415407147443, -0.19...   \n",
       "17763  [0.7013046477435794, 0.6123415407147443, -0.19...   \n",
       "17764  [0.7013046477435794, 0.6123415407147443, -0.19...   \n",
       "17765  [0.7013046477435794, 0.6123415407147443, -0.19...   \n",
       "\n",
       "                                             return_list  \n",
       "17761  tic            BZ      GD      GMKN    IMOEX  ...  \n",
       "17762  tic            BZ      GD      GMKN    IMOEX  ...  \n",
       "17763  tic            BZ      GD      GMKN    IMOEX  ...  \n",
       "17764  tic            BZ      GD      GMKN    IMOEX  ...  \n",
       "17765  tic            BZ      GD      GMKN    IMOEX  ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем корректность рассчитанных FinRL индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "tic_data = df0[df0['tic']=='SBER'].sort_values(by=[\"date\"])\n",
    "_high   = tic_data['high'].to_numpy()\n",
    "_low    = tic_data['low'].to_numpy()\n",
    "_close  = tic_data['close'].to_numpy()\n",
    "_volume = tic_data['volume'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi12 = ta.RSI(_close, timeperiod=fa.rsi_period)\n",
    "obv = ta.OBV(_close, _volume) / 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsi12     40.349783\n",
      "obv      445.295899\n",
      "Name: 17764, dtype: object\n",
      "40.349782550662574 445.2958986\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[17764][['rsi12', 'obv']])\n",
    "print(rsi12[-1], obv[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GMKN', 'LKOH', 'MAGN', 'MM', 'MTSS', 'NVTK', 'ROSN', 'SBER',\n",
       "       'SNGS'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[17368]['cov_xtra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "       ...\n",
       "       17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763, 17764, 17765],\n",
       "      dtype='int64', length=17766)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.date.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 9, State Space: 9\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(df.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 20,\n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": fa.indicators, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"cov_xtra_names\": fa.cov_xtra_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "e_train_gym = PortfolioEnv(df = df, **env_kwargs)\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручная проверка действия в среде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 1000000, 1000000, array([0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.day, e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2652563  0.5192913  0.329495   0.45773244 0.87658024 0.60700244\n",
      " 0.6961824  0.9369841  0.74715316]\n"
     ]
    }
   ],
   "source": [
    "act = e_train_gym.action_space.sample()\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.008909245716712321,\n",
       " 991090.7542832877,\n",
       " 3838.157707945644,\n",
       " array([  64,   31, 1823,  762,  600,  160,  402, 1037, 4590]),\n",
       " 995.1666756164379)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_prices = df.loc[e_train_gym.day]['close'].to_numpy()\n",
    "state, reward, term, _ = e_train_gym.step(act)\n",
    "reward, e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state, e_train_gym.commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.39192086e-03,  8.59804749e-03,  5.45553923e-03,  7.57880151e-03,\n",
       "         1.45137787e-02,  1.00503051e-02,  1.15268826e-02,  1.55139017e-02,\n",
       "         1.23708189e-02, -4.53852885e-03,  7.14469737e-04, -7.50700802e-03,\n",
       "         3.99695102e-03, -1.21562021e-03, -3.96430438e-03, -1.25936130e-03,\n",
       "        -7.84043258e-04, -4.55744715e-03,  3.97695251e-05,  1.70556947e-03,\n",
       "        -2.70189398e-03, -2.51313657e-03,  4.14914079e-03, -2.70748867e-03,\n",
       "         3.14910576e-03, -6.70200320e-03, -4.45712664e-03,  7.76940514e-03,\n",
       "         4.94296767e-03,  7.07607217e-03, -5.46838854e-03,  5.51563443e-03,\n",
       "         7.34434484e-03,  6.12380888e-03,  4.17888907e-03,  2.59416615e-03,\n",
       "         4.01325354e-01,  4.56871878e-01,  3.86980332e-01,  1.00000000e+00,\n",
       "         3.76505008e-01,  4.71669637e-01,  4.71738515e-01,  5.79428626e-01,\n",
       "         6.21448394e-01,  3.28133225e-01,  4.10806447e-01,  2.77913435e-01,\n",
       "         1.00000000e+00,  3.13880017e-01,  3.34885228e-01,  3.82728164e-01,\n",
       "         3.87679687e-01,  3.41054440e-01,  3.32521738e-01,  4.10806447e-01,\n",
       "         3.41250583e-01,  1.00000000e+00,  3.53266965e-01,  3.34885228e-01,\n",
       "         3.82728164e-01,  3.87679687e-01,  6.21448394e-01, -1.85848400e-01,\n",
       "         2.05980000e-03,  2.62683600e-01,  2.54000000e-07,  5.81098000e-03,\n",
       "        -1.50098000e-03,  3.34451300e-02,  1.14472828e+00, -8.05035000e-02]),\n",
       " 72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.008909245716712321, 3838.157707945644)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(close_prices * e_train_gym.current_state) + e_train_gym.cash\n",
    "reward, e_train_gym.cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Timestamp('2017-05-25 00:00:00'), Timestamp('2017-05-26 00:00:00')],\n",
       " [1000000, 991090.7542832877])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.date_memory, e_train_gym.asset_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18991771 0.39101064 0.3148726  0.5051955  0.0128755  0.8839377\n",
      " 0.18799774 0.10866006 0.9698709 ]\n"
     ]
    }
   ],
   "source": [
    "act2 = e_train_gym.action_space.sample()\n",
    "print(act2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008506378286643839,\n",
       " 999521.3471556166,\n",
       " 2695.4551693157932,\n",
       " array([  69,   36, 2699, 1271,   13,  365,  165,  185, 8920]),\n",
       " 743.1329495890409)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, term, _ = e_train_gym.step(act2)\n",
    "reward, e_train_gym.portfolio_value, e_train_gym.cash, e_train_gym.current_state, e_train_gym.commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738.2996252054788"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.total_commission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспресс проверка что комиссия считается не криво. Поставим процент комиссии 10%. Первый день - покупаем равные доли. Второй день всё продаем. Ожидаем cash около 800_000. (Цены считаем примерно равными - всё ушло на комиссии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_gym_perc = PortfolioEnv(df = df, hmax = 20, initial_amount = 1000000, transaction_cost_pct = 0.1, \n",
    "    state_space = state_space, \n",
    "    stock_dim = stock_dimension, \n",
    "    tech_indicator_list = fa.indicators, \n",
    "    action_space = stock_dimension, \n",
    "    reward_scaling = 1e-4,\n",
    "    cov_xtra_names = fa.cov_xtra_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym_perc.cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13121.121767123259, 89716.26165753425)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym_perc.step(np.array([1] * stock_dimension))\n",
    "e_train_gym_perc.cash, e_train_gym_perc.commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829831.4092054793, 180461.84915068495)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym_perc.step(np.array([0] * stock_dimension))\n",
    "e_train_gym_perc.cash, e_train_gym_perc.total_commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(df_daily_return):\n",
    "    DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "    perf_func = timeseries.perf_stats \n",
    "    return perf_func( returns=DRL_strat, \n",
    "                                factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trade(alg, train, trade, optuna_params = None, log_name = None, size = None, trained_model = None, steps = 50_000):\n",
    "    #env_kwargs['lookback'] = lookback\n",
    "    e_train_gym = PortfolioEnv(df = train, **env_kwargs)\n",
    "    env_train, _ = e_train_gym.get_sb_env()\n",
    "    \n",
    "    policy_kwargs = None\n",
    "    if size != None:\n",
    "        policy_kwargs = {\n",
    "            \"net_arch\": dict(pi=size, vf=size, qf=size),\n",
    "        }\n",
    "\n",
    "    agent = DRLAgent(env = env_train)\n",
    "\n",
    "    model_params = None\n",
    "    if optuna_params != None:\n",
    "        model_params = optuna_params\n",
    "\n",
    "    if log_name is None:\n",
    "        log_name = alg\n",
    "\n",
    "    timesteps = steps\n",
    "    if trained_model is None:\n",
    "        model = agent.get_model(model_name = alg, model_kwargs = optuna_params, policy_kwargs = policy_kwargs, tensorboard_log = 'logs')\n",
    "    else:\n",
    "        model = trained_model\n",
    "        timesteps = 25_000\n",
    "\n",
    "\n",
    "    trained_model = agent.train_model(model = model, \n",
    "                                tb_log_name = log_name,\n",
    "                                total_timesteps = timesteps)\n",
    "\n",
    "    e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "\n",
    "    df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_model,\n",
    "                        environment = e_trade_gym2)\n",
    "    \n",
    "    return trained_model, e_trade_gym2.total_commission,  df_daily_return, df_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поисследуем как показывают себя алгоритмы на истории. Будем брать период 12.2016-3.2023, сначала обучаем на всем промежутке алгоритм, затем дообучаем в течение 9ти месяцев (с 6.2023 по 3.2024. В данный период только первые 2 месяца рост, затем коррекции) - добавляем месяц в конце и убираем месяц в начале. Фиксируем результаты на тестовой выборке - следующий месяц за месяцем который добавили. Основная задача понять, как покажет себя каждый из алгоритмов в сравнении с индексом и безрисковым активом.\n",
    "\n",
    "![alt text](imoex.jpg \"Title2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_6_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | 0.788         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0984       |\n",
      "|    reward             | -0.0035701783 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 7.53e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0408      |\n",
      "|    reward             | 0.0107979085 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 3.37e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789784.7781368392\n",
      "Sharpe:  -0.08763741300593579\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775750.4213009991\n",
      "Sharpe:  -1.8507226658487088\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 208           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 0.425         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.0274       |\n",
      "|    reward             | -0.0017617665 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 2.4e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0.481        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.123        |\n",
      "|    reward             | -0.006071494 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792445.0058197662\n",
      "Sharpe:  -0.4826306900082131\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.0623      |\n",
      "|    reward             | -0.007119548 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 2.99e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1022138.1227236781\n",
      "Sharpe:  0.13886679066331603\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.679        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0905       |\n",
      "|    reward             | 0.0016467905 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 4.51e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.688       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.16        |\n",
      "|    reward             | 0.007855783 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -0.0283      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.167        |\n",
      "|    reward             | -0.010652426 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1222128.497819108\n",
      "Sharpe:  0.29275035283298717\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799697.506635\n",
      "Sharpe:  -4.592567819001744\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0.76        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.0404     |\n",
      "|    reward             | 0.003032816 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 1.88e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.137      |\n",
      "|    reward             | 0.007281995 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792083.0389108869\n",
      "Sharpe:  -0.14113788294418428\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0.633         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0317        |\n",
      "|    reward             | -0.0007622665 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 4.72e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0.704        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | 0.0039838394 |\n",
      "|    std                | 1.84         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746784.375231703\n",
      "Sharpe:  -0.18687420152503784\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.122        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.118        |\n",
      "|    reward             | -0.005411991 |\n",
      "|    std                | 1.93         |\n",
      "|    value_loss         | 5.68e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787419.0186512186\n",
      "Sharpe:  -2.3974169055524976\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0.656        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.0211      |\n",
      "|    reward             | -0.012957157 |\n",
      "|    std                | 2.03         |\n",
      "|    value_loss         | 1.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0.344        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0821      |\n",
      "|    reward             | -0.011449997 |\n",
      "|    std                | 2.14         |\n",
      "|    value_loss         | 8.05e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1130155.162793721\n",
      "Sharpe:  0.21594784395883754\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0.426        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.0694      |\n",
      "|    reward             | -0.009397634 |\n",
      "|    std                | 2.25         |\n",
      "|    value_loss         | 4.67e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790834.7599375347\n",
      "Sharpe:  -2.813313910285564\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.5         |\n",
      "|    explained_variance | 0.658         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.293        |\n",
      "|    reward             | -0.0019849737 |\n",
      "|    std                | 2.37          |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | -0.281      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -0.0502     |\n",
      "|    reward             | 0.001678888 |\n",
      "|    std                | 2.5         |\n",
      "|    value_loss         | 7.71e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783216.9489400889\n",
      "Sharpe:  -0.15500245274710145\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 46            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.4         |\n",
      "|    explained_variance | 0.979         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.0619       |\n",
      "|    reward             | -0.0009993832 |\n",
      "|    std                | 2.62          |\n",
      "|    value_loss         | 7.93e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.194        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.375       |\n",
      "|    reward             | -0.006142522 |\n",
      "|    std                | 2.76         |\n",
      "|    value_loss         | 0.000365     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 0.375        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | 0.0021116028 |\n",
      "|    std                | 2.9          |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1202908.2262881298\n",
      "Sharpe:  0.2961175053678407\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0.378        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 0.0749       |\n",
      "|    reward             | 0.0055286977 |\n",
      "|    std                | 3.05         |\n",
      "|    value_loss         | 3.08e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0.839       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.042       |\n",
      "|    reward             | 0.005850614 |\n",
      "|    std                | 3.21        |\n",
      "|    value_loss         | 8.84e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:918556.0164732827\n",
      "Sharpe:  -0.0342386748966143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799603.1621015754\n",
      "Sharpe:  -5.195259798346973\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.286       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.0862      |\n",
      "|    reward             | 0.005427151 |\n",
      "|    std                | 3.38        |\n",
      "|    value_loss         | 3.46e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791714.3815434816\n",
      "Sharpe:  -0.32407459429094004\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.2     |\n",
      "|    explained_variance | -2.1      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.524    |\n",
      "|    reward             | 0.0132922 |\n",
      "|    std                | 3.57      |\n",
      "|    value_loss         | 0.000683  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.7        |\n",
      "|    explained_variance | 0.249        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | 0.00688      |\n",
      "|    reward             | 0.0085195545 |\n",
      "|    std                | 3.76         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 66          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0.243       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -0.0781     |\n",
      "|    reward             | -0.01703041 |\n",
      "|    std                | 3.95        |\n",
      "|    value_loss         | 0.000139    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:910818.6724129678\n",
      "Sharpe:  -0.0122818125460513\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | 0.015477745 |\n",
      "|    std                | 4.17        |\n",
      "|    value_loss         | 8.05e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 70            |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.1         |\n",
      "|    explained_variance | 0.564         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.0144       |\n",
      "|    reward             | -0.0075079394 |\n",
      "|    std                | 4.4           |\n",
      "|    value_loss         | 1.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0.66         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.214        |\n",
      "|    reward             | 0.0030463517 |\n",
      "|    std                | 4.65         |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:939098.3133321017\n",
      "Sharpe:  0.0336823662339019\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 75            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.1         |\n",
      "|    explained_variance | -0.595        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | -0.102        |\n",
      "|    reward             | -0.0021061713 |\n",
      "|    std                | 4.91          |\n",
      "|    value_loss         | 1.4e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0.265        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.224       |\n",
      "|    reward             | 0.0027564676 |\n",
      "|    std                | 5.18         |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794564.574737059\n",
      "Sharpe:  -0.22631017656214764\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0.555       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.00426    |\n",
      "|    reward             | 0.011380351 |\n",
      "|    std                | 5.42        |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0.28        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.216       |\n",
      "|    reward             | 0.005573532 |\n",
      "|    std                | 5.7         |\n",
      "|    value_loss         | 7.95e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735682.2732845092\n",
      "Sharpe:  -0.36665887730095664\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768895.3790669995\n",
      "Sharpe:  -4.548862886198034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | -4.02         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | -0.0509       |\n",
      "|    reward             | -0.0056013656 |\n",
      "|    std                | 5.97          |\n",
      "|    value_loss         | 1.16e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.3       |\n",
      "|    explained_variance | 0.534       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.253      |\n",
      "|    reward             | 0.014458371 |\n",
      "|    std                | 6.27        |\n",
      "|    value_loss         | 8.45e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 90            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.7         |\n",
      "|    explained_variance | 0.343         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | 0.24          |\n",
      "|    reward             | -0.0031098642 |\n",
      "|    std                | 6.59          |\n",
      "|    value_loss         | 8.09e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:952151.3482594128\n",
      "Sharpe:  0.030012476021154498\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791922.2675022304\n",
      "Sharpe:  -1.3503120284254442\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | -2.09         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.177         |\n",
      "|    reward             | -0.0015273764 |\n",
      "|    std                | 6.93          |\n",
      "|    value_loss         | 5.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 0.0288       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | -0.3         |\n",
      "|    reward             | -0.011891438 |\n",
      "|    std                | 7.32         |\n",
      "|    value_loss         | 9.7e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718116.7187858901\n",
      "Sharpe:  -0.3894806952665702\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794683.8958411631\n",
      "Sharpe:  -3.9243769446263537\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | -1.25       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.0618      |\n",
      "|    reward             | 0.013150842 |\n",
      "|    std                | 7.71        |\n",
      "|    value_loss         | 2.28e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.158       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 0.804       |\n",
      "|    reward             | 0.017589608 |\n",
      "|    std                | 8.13        |\n",
      "|    value_loss         | 0.000873    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798358.3133210097\n",
      "Sharpe:  -0.19880021798714825\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0.533       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.218       |\n",
      "|    reward             | 0.003840668 |\n",
      "|    std                | 8.54        |\n",
      "|    value_loss         | 5.45e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 104           |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.5         |\n",
      "|    explained_variance | 0.0591        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | -0.207        |\n",
      "|    reward             | -0.0065774233 |\n",
      "|    std                | 8.95          |\n",
      "|    value_loss         | 8.37e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765225.2559723587\n",
      "Sharpe:  -0.6058410103667506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774987.6153013554\n",
      "Sharpe:  -2.430006858965506\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0.338        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.0127       |\n",
      "|    reward             | -0.037029043 |\n",
      "|    std                | 9.39         |\n",
      "|    value_loss         | 1.21e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791735.9390945043\n",
      "Sharpe:  -0.9168311742443732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761265.21168574\n",
      "Sharpe:  -1.1434456578253644\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795579.101492795\n",
      "Sharpe:  -3.441321048797994\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 108           |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 0.576         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | -0.0811       |\n",
      "|    reward             | -0.0016349609 |\n",
      "|    std                | 9.89          |\n",
      "|    value_loss         | 8.12e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 111           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.8         |\n",
      "|    explained_variance | 0.138         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | 0.111         |\n",
      "|    reward             | -0.0027851346 |\n",
      "|    std                | 10.4          |\n",
      "|    value_loss         | 4.76e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:707445.2770111427\n",
      "Sharpe:  -0.4792088374782556\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.3        |\n",
      "|    explained_variance | 0.15         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.791        |\n",
      "|    reward             | -0.004039359 |\n",
      "|    std                | 10.9         |\n",
      "|    value_loss         | 0.000768     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0.371       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.006      |\n",
      "|    reward             | 0.008837736 |\n",
      "|    std                | 11.5        |\n",
      "|    value_loss         | 2.14e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752826.0286811098\n",
      "Sharpe:  -0.38267317171175247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.1         |\n",
      "|    explained_variance | 0.162         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.894        |\n",
      "|    reward             | 0.00042195964 |\n",
      "|    std                | 12            |\n",
      "|    value_loss         | 0.000686      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787724.5886584652\n",
      "Sharpe:  -0.7637978764206822\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0.272        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.281        |\n",
      "|    reward             | -0.010839525 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 9.47e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770438.8344131225\n",
      "Sharpe:  -0.6676830442207472\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 122           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.1         |\n",
      "|    explained_variance | -0.0281       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | -0.665        |\n",
      "|    reward             | -0.0016591381 |\n",
      "|    std                | 13.3          |\n",
      "|    value_loss         | 0.00041       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0.15        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.333      |\n",
      "|    reward             | 0.010930479 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 0.000125    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785869.4564448646\n",
      "Sharpe:  -0.1467571852853011\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | 0.529        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0647      |\n",
      "|    reward             | -0.015416748 |\n",
      "|    std                | 14.7         |\n",
      "|    value_loss         | 2.1e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.4       |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.307      |\n",
      "|    reward             | 0.012493974 |\n",
      "|    std                | 15.5        |\n",
      "|    value_loss         | 8.65e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793425.8437073294\n",
      "Sharpe:  -0.5488662990815921\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.9       |\n",
      "|    explained_variance | 0.734       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -0.261      |\n",
      "|    reward             | 0.008589572 |\n",
      "|    std                | 16.3        |\n",
      "|    value_loss         | 6.32e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.4        |\n",
      "|    explained_variance | 0.0689       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.942       |\n",
      "|    reward             | -0.006407525 |\n",
      "|    std                | 17.2         |\n",
      "|    value_loss         | 0.000629     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:733008.8407379953\n",
      "Sharpe:  -0.30598570781417184\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.8        |\n",
      "|    explained_variance | 0.644        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.618        |\n",
      "|    reward             | 0.0009262919 |\n",
      "|    std                | 18           |\n",
      "|    value_loss         | 0.000283     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786403.1680575475\n",
      "Sharpe:  -0.8659324229031554\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.3       |\n",
      "|    explained_variance | 0.471       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.263       |\n",
      "|    reward             | -0.03566665 |\n",
      "|    std                | 19          |\n",
      "|    value_loss         | 0.000316    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789028.4623334947\n",
      "Sharpe:  -0.4975368735430735\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.7        |\n",
      "|    explained_variance | -3.18        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.501       |\n",
      "|    reward             | -0.006893679 |\n",
      "|    std                | 20           |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783294.2439551923\n",
      "Sharpe:  -1.564284691653705\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796963.0564407805\n",
      "Sharpe:  -1.8980835302481458\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 208           |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 143           |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.2         |\n",
      "|    explained_variance | 0.0273        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5999          |\n",
      "|    policy_loss        | -0.257        |\n",
      "|    reward             | -0.0109645715 |\n",
      "|    std                | 21            |\n",
      "|    value_loss         | 6.08e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796954.7184846158\n",
      "Sharpe:  -0.6481832271511971\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | -0.115      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | 1.62        |\n",
      "|    reward             | 0.011284135 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.00532     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 208           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 148           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.1         |\n",
      "|    explained_variance | 0.0505        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.834         |\n",
      "|    reward             | -0.0098158065 |\n",
      "|    std                | 23.3          |\n",
      "|    value_loss         | 0.000885      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.5        |\n",
      "|    explained_variance | 0.21         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.648        |\n",
      "|    reward             | 0.0051980824 |\n",
      "|    std                | 24.5         |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779656.729044639\n",
      "Sharpe:  -0.2611640717695241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784731.6383783574\n",
      "Sharpe:  -1.4743966279414589\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 208           |\n",
      "|    iterations         | 6400          |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 32000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42           |\n",
      "|    explained_variance | -0.218        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6399          |\n",
      "|    policy_loss        | 0.0499        |\n",
      "|    reward             | -0.0018629559 |\n",
      "|    std                | 25.7          |\n",
      "|    value_loss         | 1.62e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0.0265      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.371      |\n",
      "|    reward             | 0.007416994 |\n",
      "|    std                | 27.1        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771256.3140170403\n",
      "Sharpe:  -0.34085108061426966\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0.769       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.263      |\n",
      "|    reward             | -0.00387204 |\n",
      "|    std                | 28.5        |\n",
      "|    value_loss         | 4.81e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | 0.403        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.195        |\n",
      "|    reward             | 0.0012053326 |\n",
      "|    std                | 30           |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781314.7545091566\n",
      "Sharpe:  -0.2317926673526913\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.8        |\n",
      "|    explained_variance | -0.0377      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -0.595       |\n",
      "|    reward             | -0.007620199 |\n",
      "|    std                | 31.5         |\n",
      "|    value_loss         | 0.000188     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.2       |\n",
      "|    explained_variance | 0.0631      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.000638    |\n",
      "|    reward             | -0.04311876 |\n",
      "|    std                | 32.9        |\n",
      "|    value_loss         | 6.11e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761029.8083382862\n",
      "Sharpe:  -0.46915683992521456\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 7000          |\n",
      "|    time_elapsed       | 167           |\n",
      "|    total_timesteps    | 35000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.6         |\n",
      "|    explained_variance | 0.396         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6999          |\n",
      "|    policy_loss        | 0.441         |\n",
      "|    reward             | -0.0005006423 |\n",
      "|    std                | 34.6          |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793333.5915429834\n",
      "Sharpe:  -0.6436735637975641\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.1       |\n",
      "|    explained_variance | 0.634       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -0.0116     |\n",
      "|    reward             | 0.004216567 |\n",
      "|    std                | 36.4        |\n",
      "|    value_loss         | 5.32e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:696775.4255189357\n",
      "Sharpe:  -0.6086319682904708\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799737.297238288\n",
      "Sharpe:  -1.2736105418029573\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.5       |\n",
      "|    explained_variance | 0.458       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 0.0179      |\n",
      "|    reward             | 0.005430275 |\n",
      "|    std                | 38.2        |\n",
      "|    value_loss         | 3.83e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795004.2691345036\n",
      "Sharpe:  -0.5891596386418138\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 208          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46          |\n",
      "|    explained_variance | 0.782        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.0548      |\n",
      "|    reward             | -0.009426199 |\n",
      "|    std                | 40.4         |\n",
      "|    value_loss         | 4.1e-06      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786430.8080738626\n",
      "Sharpe:  -1.3116298065214322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.5        |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -0.64        |\n",
      "|    reward             | 0.0039204108 |\n",
      "|    std                | 42.4         |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783471.9231384675\n",
      "Sharpe:  -0.7615710446934105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 179           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.9         |\n",
      "|    explained_variance | -0.535        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.589         |\n",
      "|    reward             | -0.0005642415 |\n",
      "|    std                | 44.6          |\n",
      "|    value_loss         | 0.000173      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.4        |\n",
      "|    explained_variance | 0.104        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | 0.0086315805 |\n",
      "|    std                | 46.9         |\n",
      "|    value_loss         | 0.000768     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787065.4707732539\n",
      "Sharpe:  -0.20984954309715717\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787807.4546168617\n",
      "Sharpe:  -2.483264834355976\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.8         |\n",
      "|    explained_variance | -0.548        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | 0.155         |\n",
      "|    reward             | 0.00048811367 |\n",
      "|    std                | 49.3          |\n",
      "|    value_loss         | 2.96e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.3       |\n",
      "|    explained_variance | 0.18        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -1.26       |\n",
      "|    reward             | -0.00367474 |\n",
      "|    std                | 51.9        |\n",
      "|    value_loss         | 0.000877    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -48.7      |\n",
      "|    explained_variance | 0.47       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -0.874     |\n",
      "|    reward             | 0.00828645 |\n",
      "|    std                | 54.5       |\n",
      "|    value_loss         | 0.000378   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769647.0345597077\n",
      "Sharpe:  -0.2222421121094069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 191           |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.2         |\n",
      "|    explained_variance | 0.217         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | 0.002         |\n",
      "|    reward             | -0.0047418526 |\n",
      "|    std                | 57.2          |\n",
      "|    value_loss         | 6.61e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799427.9732119717\n",
      "Sharpe:  -0.7117461771210848\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.6       |\n",
      "|    explained_variance | 0.682       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.014176357 |\n",
      "|    std                | 60.2        |\n",
      "|    value_loss         | 0.000502    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.1        |\n",
      "|    explained_variance | 0.359        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.805       |\n",
      "|    reward             | -0.024988174 |\n",
      "|    std                | 63.5         |\n",
      "|    value_loss         | 0.000456     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784429.9787163183\n",
      "Sharpe:  -0.25889089732271875\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777411.1457845063\n",
      "Sharpe:  -0.8215865683020341\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.5        |\n",
      "|    explained_variance | 0.299        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 1.69         |\n",
      "|    reward             | -0.008394933 |\n",
      "|    std                | 66.7         |\n",
      "|    value_loss         | 0.00492      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798946.0137521228\n",
      "Sharpe:  -1.2673281598914152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795776.5500730681\n",
      "Sharpe:  -6.713479276909947\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798503.7799323284\n",
      "Sharpe:  -3.5858335431066646\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51          |\n",
      "|    explained_variance | 0.296        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.307        |\n",
      "|    reward             | -0.003449882 |\n",
      "|    std                | 70.3         |\n",
      "|    value_loss         | 4.2e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794647.8591645485\n",
      "Sharpe:  -1.4932053248744983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799168.4632933019\n",
      "Sharpe:  -1.3412680647181094\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.5        |\n",
      "|    explained_variance | 0.454        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | -0.062       |\n",
      "|    reward             | -0.010599137 |\n",
      "|    std                | 73.9         |\n",
      "|    value_loss         | 1.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.9        |\n",
      "|    explained_variance | 0.439        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | -0.019590983 |\n",
      "|    std                | 77.7         |\n",
      "|    value_loss         | 8.19e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799002.6411665638\n",
      "Sharpe:  -0.3836081292248861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52.3         |\n",
      "|    explained_variance | 0.263         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 0.16          |\n",
      "|    reward             | -0.0031045014 |\n",
      "|    std                | 81.4          |\n",
      "|    value_loss         | 2.47e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788337.7863339651\n",
      "Sharpe:  -0.472046203572774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745876.603935012\n",
      "Sharpe:  -3.8592725029150876\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.8        |\n",
      "|    explained_variance | 0.0772       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.466       |\n",
      "|    reward             | -0.007336518 |\n",
      "|    std                | 85.6         |\n",
      "|    value_loss         | 0.000207     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764876.2483790679\n",
      "Sharpe:  -2.0040209653979226\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.2        |\n",
      "|    explained_variance | 0.267        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -1.36        |\n",
      "|    reward             | -0.015754022 |\n",
      "|    std                | 89.8         |\n",
      "|    value_loss         | 0.000773     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794134.9065653961\n",
      "Sharpe:  -0.3515370932950757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768719.1397171916\n",
      "Sharpe:  -2.9162794579887947\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.7      |\n",
      "|    explained_variance | 0.625      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 0.092      |\n",
      "|    reward             | 0.00208205 |\n",
      "|    std                | 94.5       |\n",
      "|    value_loss         | 1.62e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779813.5131118722\n",
      "Sharpe:  -0.8321595390297375\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.1        |\n",
      "|    explained_variance | 0.515        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.53         |\n",
      "|    reward             | -0.033028163 |\n",
      "|    std                | 99.4         |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792667.6285528736\n",
      "Sharpe:  -2.0854330786577555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769763.160486837\n",
      "Sharpe:  -2.4990025880741\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773631.7685411794\n",
      "Sharpe:  -2.24332951553326\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.6        |\n",
      "|    explained_variance | 0.143        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -0.472       |\n",
      "|    reward             | 0.0008811751 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782380.4159643155\n",
      "Sharpe:  -0.8533734679745949\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787197.6228213994\n",
      "Sharpe:  -1.419654301553028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 9300          |\n",
      "|    time_elapsed       | 221           |\n",
      "|    total_timesteps    | 46500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55           |\n",
      "|    explained_variance | 0.339         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9299          |\n",
      "|    policy_loss        | -0.278        |\n",
      "|    reward             | -0.0091297235 |\n",
      "|    std                | 110           |\n",
      "|    value_loss         | 5.02e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.5       |\n",
      "|    explained_variance | 0.646       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 0.442       |\n",
      "|    reward             | 0.008157261 |\n",
      "|    std                | 115         |\n",
      "|    value_loss         | 7.29e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 226           |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.9         |\n",
      "|    explained_variance | -2.29         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | -0.282        |\n",
      "|    reward             | -0.0025465905 |\n",
      "|    std                | 121           |\n",
      "|    value_loss         | 2.85e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:593176.9363022888\n",
      "Sharpe:  -0.38985352624024516\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.4         |\n",
      "|    explained_variance | 0.936         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9599          |\n",
      "|    policy_loss        | -0.00175      |\n",
      "|    reward             | -0.0012134113 |\n",
      "|    std                | 127           |\n",
      "|    value_loss         | 9.94e-07      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799309.0882651232\n",
      "Sharpe:  -0.9981408090632741\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.8        |\n",
      "|    explained_variance | -2.02        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.284        |\n",
      "|    reward             | 0.0012597118 |\n",
      "|    std                | 134          |\n",
      "|    value_loss         | 4.64e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736720.5834233717\n",
      "Sharpe:  -0.706728117533913\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.3         |\n",
      "|    explained_variance | 0.145         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | -0.36         |\n",
      "|    reward             | -0.0038492617 |\n",
      "|    std                | 141           |\n",
      "|    value_loss         | 5.36e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781643.7182189195\n",
      "Sharpe:  -0.39035761512116024\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.7        |\n",
      "|    explained_variance | 0.532        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.288       |\n",
      "|    reward             | -0.007181366 |\n",
      "|    std                | 148          |\n",
      "|    value_loss         | 2.88e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.2         |\n",
      "|    explained_variance | -0.0907       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -1.16         |\n",
      "|    reward             | 0.00048100544 |\n",
      "|    std                | 156           |\n",
      "|    value_loss         | 0.000529      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1022154.1221538774\n",
      "Sharpe:  3.09776351609773\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.02215412215387702 -0.017458129634559998 3.09776351609773 0\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -3.62        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.000842    |\n",
      "|    reward             | 0.0073433686 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000542     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798866.6785616687\n",
      "Sharpe:  -0.5256463481118399\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | -4.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.393       |\n",
      "|    reward             | 0.015674694 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000981    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799347.9996144755\n",
      "Sharpe:  -0.5377251259428049\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794537.1728365744\n",
      "Sharpe:  -2.113676432773787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 0.62          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.104        |\n",
      "|    reward             | -0.0032637867 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 8.5e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795924.0823313425\n",
      "Sharpe:  -1.6341615293687495\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -0.0426      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.109       |\n",
      "|    reward             | -0.006681265 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 8.71e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 210         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.449       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | 0.020186853 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794162.2588082176\n",
      "Sharpe:  -0.20817355514556507\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0762      |\n",
      "|    reward             | 0.0009040608 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792533.5516523265\n",
      "Sharpe:  -0.4300158878350113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 0.17          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.124        |\n",
      "|    reward             | -0.0023973829 |\n",
      "|    std                | 1.4           |\n",
      "|    value_loss         | 7.59e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | -1.16       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.228       |\n",
      "|    reward             | 0.006237889 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798404.4644600675\n",
      "Sharpe:  -0.3095450477091278\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0.518        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0383       |\n",
      "|    reward             | -0.001113619 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:701354.0402722222\n",
      "Sharpe:  -0.5641619912042167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 211           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | 0.234         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0507       |\n",
      "|    reward             | -0.0058031282 |\n",
      "|    std                | 1.64          |\n",
      "|    value_loss         | 1.33e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.398       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.0604      |\n",
      "|    reward             | 0.010845874 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 4.24e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 213           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0.222         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.215         |\n",
      "|    reward             | -0.0017379882 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 0.000355      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1327353.0846461977\n",
      "Sharpe:  0.4021156650739924\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.8         |\n",
      "|    explained_variance | 0.486         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.031        |\n",
      "|    reward             | -0.0033933527 |\n",
      "|    std                | 1.95          |\n",
      "|    value_loss         | 7.32e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | -1.71        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.259        |\n",
      "|    reward             | 0.0061285826 |\n",
      "|    std                | 2.06         |\n",
      "|    value_loss         | 0.000196     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783086.3815842072\n",
      "Sharpe:  -0.2818253273954102\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | -0.208       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0729      |\n",
      "|    reward             | 0.0012044221 |\n",
      "|    std                | 2.17         |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.051       |\n",
      "|    reward             | -0.008492526 |\n",
      "|    std                | 2.29         |\n",
      "|    value_loss         | 1.19e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1064221.474633797\n",
      "Sharpe:  0.16847653866904816\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.0353      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.201      |\n",
      "|    reward             | 0.004523342 |\n",
      "|    std                | 2.42        |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.374        |\n",
      "|    reward             | 0.0076995073 |\n",
      "|    std                | 2.56         |\n",
      "|    value_loss         | 0.00033      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 44            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | -3.6          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.29          |\n",
      "|    reward             | -0.0043503796 |\n",
      "|    std                | 2.69          |\n",
      "|    value_loss         | 0.000208      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1466769.3211768405\n",
      "Sharpe:  0.4412166569641735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 47            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.1         |\n",
      "|    explained_variance | 0.22          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0931       |\n",
      "|    reward             | -0.0033565278 |\n",
      "|    std                | 2.83          |\n",
      "|    value_loss         | 3.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0.508        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.313       |\n",
      "|    reward             | -0.005197745 |\n",
      "|    std                | 2.99         |\n",
      "|    value_loss         | 0.000262     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770511.7922194233\n",
      "Sharpe:  -0.3138977223422526\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0.385       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 0.0954      |\n",
      "|    reward             | 0.008636067 |\n",
      "|    std                | 3.14        |\n",
      "|    value_loss         | 3.21e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0.662        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 0.322        |\n",
      "|    reward             | 0.0019526506 |\n",
      "|    std                | 3.31         |\n",
      "|    value_loss         | 0.000246     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1027019.4583941\n",
      "Sharpe:  0.11919687879790121\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24           |\n",
      "|    explained_variance | 0.214         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 0.171         |\n",
      "|    reward             | -0.0029816187 |\n",
      "|    std                | 3.48          |\n",
      "|    value_loss         | 7.71e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 0.299        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.196       |\n",
      "|    reward             | -0.006132158 |\n",
      "|    std                | 3.67         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788824.4672411202\n",
      "Sharpe:  -0.2720651804708535\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.159       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.179      |\n",
      "|    reward             | 0.001695283 |\n",
      "|    std                | 3.84        |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.351       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -0.112      |\n",
      "|    reward             | -0.00420152 |\n",
      "|    std                | 4.04        |\n",
      "|    value_loss         | 0.000109    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1285453.6912022496\n",
      "Sharpe:  0.3650782462769484\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792184.54863726\n",
      "Sharpe:  -7.825781947886389\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0.334        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.374        |\n",
      "|    reward             | 0.0065912297 |\n",
      "|    std                | 4.25         |\n",
      "|    value_loss         | 0.000237     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790023.1772445467\n",
      "Sharpe:  -0.4899013511713046\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | -0.0792     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -0.227      |\n",
      "|    reward             | 0.014809367 |\n",
      "|    std                | 4.48        |\n",
      "|    value_loss         | 9.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.585        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.11         |\n",
      "|    reward             | 0.0067126104 |\n",
      "|    std                | 4.71         |\n",
      "|    value_loss         | 1.97e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.372        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.14         |\n",
      "|    reward             | 0.0015721184 |\n",
      "|    std                | 4.97         |\n",
      "|    value_loss         | 5.16e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:977290.9087428733\n",
      "Sharpe:  0.06055874386107998\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -0.498      |\n",
      "|    reward             | 0.009068162 |\n",
      "|    std                | 5.21        |\n",
      "|    value_loss         | 0.000332    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 212            |\n",
      "|    iterations         | 3300           |\n",
      "|    time_elapsed       | 77             |\n",
      "|    total_timesteps    | 16500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -28.1          |\n",
      "|    explained_variance | 0.677          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3299           |\n",
      "|    policy_loss        | -1.04          |\n",
      "|    reward             | -0.00052742485 |\n",
      "|    std                | 5.48           |\n",
      "|    value_loss         | 0.00138        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795668.3394126337\n",
      "Sharpe:  -0.30959313874197164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 212           |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 79            |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.5         |\n",
      "|    explained_variance | 0.633         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.0414        |\n",
      "|    reward             | -0.0050132405 |\n",
      "|    std                | 5.77          |\n",
      "|    value_loss         | 7.3e-06       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 210           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 83            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29           |\n",
      "|    explained_variance | 0.0203        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.0638        |\n",
      "|    reward             | -0.0047661588 |\n",
      "|    std                | 6.09          |\n",
      "|    value_loss         | 7.62e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:893746.322477628\n",
      "Sharpe:  -0.043935245022946094\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | -0.0124      |\n",
      "|    reward             | 0.0045215827 |\n",
      "|    std                | 6.42         |\n",
      "|    value_loss         | 1.73e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 209           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.9         |\n",
      "|    explained_variance | -0.431        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.297        |\n",
      "|    reward             | -0.0065434095 |\n",
      "|    std                | 6.75          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 208           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0.126         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.105         |\n",
      "|    reward             | -0.0025488015 |\n",
      "|    std                | 7.12          |\n",
      "|    value_loss         | 4.27e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1086360.6038191924\n",
      "Sharpe:  0.20028272789056184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789644.1955482871\n",
      "Sharpe:  -0.9103957400719019\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 94            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.9         |\n",
      "|    explained_variance | 0.568         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | -0.111        |\n",
      "|    reward             | 5.9033402e-05 |\n",
      "|    std                | 7.49          |\n",
      "|    value_loss         | 1.85e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0.127       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 1.22        |\n",
      "|    reward             | 0.005997862 |\n",
      "|    std                | 7.89        |\n",
      "|    value_loss         | 0.00193     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 99            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | 0.788         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | 0.182         |\n",
      "|    reward             | -0.0033985593 |\n",
      "|    std                | 8.3           |\n",
      "|    value_loss         | 6.95e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793135.0804527965\n",
      "Sharpe:  -0.2239997988137096\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0.391        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.0526      |\n",
      "|    reward             | -0.008959687 |\n",
      "|    std                | 8.72         |\n",
      "|    value_loss         | 8.03e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | -0.264      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 0.258       |\n",
      "|    reward             | 0.010520645 |\n",
      "|    std                | 9.19        |\n",
      "|    value_loss         | 7.81e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792747.3568738664\n",
      "Sharpe:  -0.20434484556546084\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.2         |\n",
      "|    explained_variance | 0.668         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | -0.163        |\n",
      "|    reward             | -0.0009778402 |\n",
      "|    std                | 9.66          |\n",
      "|    value_loss         | 2.76e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767062.0462098627\n",
      "Sharpe:  -0.9584814134153148\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 203            |\n",
      "|    iterations         | 4500           |\n",
      "|    time_elapsed       | 110            |\n",
      "|    total_timesteps    | 22500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -33.6          |\n",
      "|    explained_variance | -0.171         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4499           |\n",
      "|    policy_loss        | -0.0741        |\n",
      "|    reward             | -0.00031931887 |\n",
      "|    std                | 10.1           |\n",
      "|    value_loss         | 3.07e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 0.164       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -0.183      |\n",
      "|    reward             | -0.01160978 |\n",
      "|    std                | 10.6        |\n",
      "|    value_loss         | 3.81e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769785.8594789124\n",
      "Sharpe:  -0.24672025282429821\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794527.3791473561\n",
      "Sharpe:  -4.574009510265258\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 115           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.4         |\n",
      "|    explained_variance | 0.0961        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | -0.0917       |\n",
      "|    reward             | -0.0054755765 |\n",
      "|    std                | 11.1          |\n",
      "|    value_loss         | 1.89e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793731.2165014498\n",
      "Sharpe:  -1.3229298811916705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.8         |\n",
      "|    explained_variance | 0.281         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | 0.000323      |\n",
      "|    reward             | -0.0006791364 |\n",
      "|    std                | 11.6          |\n",
      "|    value_loss         | 5.58e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786955.3053946733\n",
      "Sharpe:  -0.6785597286250711\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.3        |\n",
      "|    explained_variance | 0.0824       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.0981      |\n",
      "|    reward             | -0.012786515 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 1.62e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796450.8610187817\n",
      "Sharpe:  -0.46968586617749486\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 122           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.7         |\n",
      "|    explained_variance | -5.11         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | 0.537         |\n",
      "|    reward             | -0.0010784356 |\n",
      "|    std                | 12.8          |\n",
      "|    value_loss         | 0.000271      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.2        |\n",
      "|    explained_variance | -0.178       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 0.00425      |\n",
      "|    reward             | -0.007797291 |\n",
      "|    std                | 13.6         |\n",
      "|    value_loss         | 2.13e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798443.3565264406\n",
      "Sharpe:  -0.42429171191750786\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 127           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.7         |\n",
      "|    explained_variance | 0.226         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | -0.186        |\n",
      "|    reward             | -0.0014552128 |\n",
      "|    std                | 14.3          |\n",
      "|    value_loss         | 4.65e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | 0.222        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | -0.017608646 |\n",
      "|    std                | 15.1         |\n",
      "|    value_loss         | 1.44e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:920860.0177316006\n",
      "Sharpe:  -0.022361081021018123\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 132           |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.6         |\n",
      "|    explained_variance | 0.178         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | -0.164        |\n",
      "|    reward             | -0.0034232258 |\n",
      "|    std                | 15.8          |\n",
      "|    value_loss         | 3.58e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790646.5278035763\n",
      "Sharpe:  -1.1968041786849066\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0.208        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.327       |\n",
      "|    reward             | -0.005883521 |\n",
      "|    std                | 16.6         |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782110.0941184526\n",
      "Sharpe:  -1.6046363251629638\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0.582        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.0985      |\n",
      "|    reward             | -0.010043635 |\n",
      "|    std                | 17.5         |\n",
      "|    value_loss         | 1.57e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791316.8058618474\n",
      "Sharpe:  -0.4897275276498267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39           |\n",
      "|    explained_variance | -1.7          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.19         |\n",
      "|    reward             | -0.0017142917 |\n",
      "|    std                | 18.4          |\n",
      "|    value_loss         | 2.59e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.4        |\n",
      "|    explained_variance | -0.0164      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.717        |\n",
      "|    reward             | -0.005794869 |\n",
      "|    std                | 19.4         |\n",
      "|    value_loss         | 0.00048      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796908.6170692479\n",
      "Sharpe:  -0.42015190627398236\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 0.0459       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.0616       |\n",
      "|    reward             | -0.018855572 |\n",
      "|    std                | 20.3         |\n",
      "|    value_loss         | 1.53e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763515.9066248199\n",
      "Sharpe:  -0.42886941895528163\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.3        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.335       |\n",
      "|    reward             | 0.0020611319 |\n",
      "|    std                | 21.3         |\n",
      "|    value_loss         | 7.28e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792043.5602189733\n",
      "Sharpe:  -0.7598666493010959\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793412.9358118202\n",
      "Sharpe:  -1.4229221580533231\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 149           |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.8         |\n",
      "|    explained_variance | 0.618         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -0.0303       |\n",
      "|    reward             | -0.0027124975 |\n",
      "|    std                | 22.5          |\n",
      "|    value_loss         | 1.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.2        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.33        |\n",
      "|    reward             | -0.012663152 |\n",
      "|    std                | 23.6         |\n",
      "|    value_loss         | 7.5e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790210.5337722059\n",
      "Sharpe:  -0.4450047632214594\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790533.0419720531\n",
      "Sharpe:  -1.5328890437142635\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 154          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.6        |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | -0.005736882 |\n",
      "|    std                | 24.8         |\n",
      "|    value_loss         | 1.53e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792506.1206474788\n",
      "Sharpe:  -0.8099516224468157\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | -2.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.388       |\n",
      "|    reward             | 0.0016480902 |\n",
      "|    std                | 26.1         |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797106.8637448237\n",
      "Sharpe:  -1.3585800520214515\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779288.2036891505\n",
      "Sharpe:  -3.472010203269571\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792679.9009130566\n",
      "Sharpe:  -2.6008164516851813\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0.568        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 1.21         |\n",
      "|    reward             | -0.012786924 |\n",
      "|    std                | 27.4         |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795971.3858228218\n",
      "Sharpe:  -1.1104101663063874\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786329.8535104247\n",
      "Sharpe:  -3.512415361783788\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | -1.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -0.109       |\n",
      "|    reward             | -0.002430225 |\n",
      "|    std                | 28.7         |\n",
      "|    value_loss         | 1.46e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799329.4927663694\n",
      "Sharpe:  -1.0460936437683659\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.4         |\n",
      "|    explained_variance | 0.0571        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | -1.04         |\n",
      "|    reward             | -0.0041637556 |\n",
      "|    std                | 30.2          |\n",
      "|    value_loss         | 0.000658      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767328.7071685616\n",
      "Sharpe:  -0.6946989053854168\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.9        |\n",
      "|    explained_variance | 0.59         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -0.723       |\n",
      "|    reward             | -0.007584616 |\n",
      "|    std                | 31.9         |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767664.3366422494\n",
      "Sharpe:  -1.1421928879093175\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.3       |\n",
      "|    explained_variance | 0.082       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | -0.0349     |\n",
      "|    reward             | 0.001388364 |\n",
      "|    std                | 33.5        |\n",
      "|    value_loss         | 1.63e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.8        |\n",
      "|    explained_variance | -0.0918      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | -0.010566879 |\n",
      "|    std                | 35.2         |\n",
      "|    value_loss         | 1.39e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785747.2881396982\n",
      "Sharpe:  -0.19749200076410725\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758689.4600234244\n",
      "Sharpe:  -6.921727577394039\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 204            |\n",
      "|    iterations         | 7100           |\n",
      "|    time_elapsed       | 173            |\n",
      "|    total_timesteps    | 35500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -45.2          |\n",
      "|    explained_variance | -1.05          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7099           |\n",
      "|    policy_loss        | -0.123         |\n",
      "|    reward             | -0.00026590415 |\n",
      "|    std                | 37             |\n",
      "|    value_loss         | 1.8e-05        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796485.4773067944\n",
      "Sharpe:  -2.95557587046274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766876.1676584514\n",
      "Sharpe:  -1.3924573776494231\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 175           |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.6         |\n",
      "|    explained_variance | -0.835        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | 0.388         |\n",
      "|    reward             | 0.00016589188 |\n",
      "|    std                | 38.7          |\n",
      "|    value_loss         | 8.83e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778907.1665862466\n",
      "Sharpe:  -1.5727098628580203\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 204            |\n",
      "|    iterations         | 7300           |\n",
      "|    time_elapsed       | 178            |\n",
      "|    total_timesteps    | 36500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -46.1          |\n",
      "|    explained_variance | 0.399          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7299           |\n",
      "|    policy_loss        | 0.493          |\n",
      "|    reward             | -0.00031960115 |\n",
      "|    std                | 40.5           |\n",
      "|    value_loss         | 0.000156       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757546.493948342\n",
      "Sharpe:  -0.5828612277217161\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789692.5321021766\n",
      "Sharpe:  -2.0968659727002934\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.5        |\n",
      "|    explained_variance | -0.994       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | -0.014901214 |\n",
      "|    std                | 42.6         |\n",
      "|    value_loss         | 3.47e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47           |\n",
      "|    explained_variance | 0.416         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.365         |\n",
      "|    reward             | -0.0034860612 |\n",
      "|    std                | 44.8          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794029.9706895358\n",
      "Sharpe:  -0.7617614337827543\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769638.8231985806\n",
      "Sharpe:  -0.9112183826025857\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.4        |\n",
      "|    explained_variance | 0.377        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | 0.0023752344 |\n",
      "|    std                | 47.2         |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769112.8690713698\n",
      "Sharpe:  -1.726202285612004\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.9        |\n",
      "|    explained_variance | 0.588        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | -0.201       |\n",
      "|    reward             | 0.0026639896 |\n",
      "|    std                | 49.5         |\n",
      "|    value_loss         | 2.73e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788347.1396166467\n",
      "Sharpe:  -0.7657735661507995\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.3        |\n",
      "|    explained_variance | 0.469        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | -0.0372      |\n",
      "|    reward             | 0.0025720377 |\n",
      "|    std                | 51.9         |\n",
      "|    value_loss         | 1.86e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787358.2071612462\n",
      "Sharpe:  -0.4000150654843024\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.8        |\n",
      "|    explained_variance | 0.349        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.458        |\n",
      "|    reward             | -0.004395961 |\n",
      "|    std                | 54.6         |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778040.6055243998\n",
      "Sharpe:  -0.5107655225430912\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.2       |\n",
      "|    explained_variance | 0.16        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.0336      |\n",
      "|    reward             | 0.004836958 |\n",
      "|    std                | 57.6        |\n",
      "|    value_loss         | 2.83e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.7        |\n",
      "|    explained_variance | 0.285        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | 2.76         |\n",
      "|    reward             | 0.0024073052 |\n",
      "|    std                | 60.7         |\n",
      "|    value_loss         | 0.00392      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.2        |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | 0.0012502777 |\n",
      "|    std                | 64           |\n",
      "|    value_loss         | 5.69e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784302.4115542511\n",
      "Sharpe:  -0.22674531674597462\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 203           |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.6         |\n",
      "|    explained_variance | 0.161         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | -0.591        |\n",
      "|    reward             | -9.732638e-05 |\n",
      "|    std                | 67.3          |\n",
      "|    value_loss         | 0.000184      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745124.9502945325\n",
      "Sharpe:  -0.39738265840961773\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -51.1         |\n",
      "|    explained_variance | 0.749         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | 0.182         |\n",
      "|    reward             | -0.0010152507 |\n",
      "|    std                | 70.8          |\n",
      "|    value_loss         | 2.27e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799127.2953779871\n",
      "Sharpe:  -0.7315929487186404\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796916.5782255351\n",
      "Sharpe:  -1.6578899316491946\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.5       |\n",
      "|    explained_variance | 0.329       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -0.705      |\n",
      "|    reward             | 0.013046158 |\n",
      "|    std                | 74.4        |\n",
      "|    value_loss         | 0.000205    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794730.4607154522\n",
      "Sharpe:  -0.71393552467243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 8600          |\n",
      "|    time_elapsed       | 210           |\n",
      "|    total_timesteps    | 43000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52           |\n",
      "|    explained_variance | 0.534         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8599          |\n",
      "|    policy_loss        | 1.01          |\n",
      "|    reward             | -0.0033048582 |\n",
      "|    std                | 78.1          |\n",
      "|    value_loss         | 0.00045       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782834.0064827693\n",
      "Sharpe:  -0.6857269047350885\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 212           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52.4         |\n",
      "|    explained_variance | -2.04         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 1.39          |\n",
      "|    reward             | -0.0014879092 |\n",
      "|    std                | 82.1          |\n",
      "|    value_loss         | 0.000715      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 8800          |\n",
      "|    time_elapsed       | 214           |\n",
      "|    total_timesteps    | 44000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52.8         |\n",
      "|    explained_variance | 0.0623        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8799          |\n",
      "|    policy_loss        | -0.39         |\n",
      "|    reward             | -0.0022538537 |\n",
      "|    std                | 86.1          |\n",
      "|    value_loss         | 9.15e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.3        |\n",
      "|    explained_variance | 0.262        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -0.895       |\n",
      "|    reward             | 0.0025773349 |\n",
      "|    std                | 90.3         |\n",
      "|    value_loss         | 0.000293     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797024.8499136786\n",
      "Sharpe:  -0.2645234189819241\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 204           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 219           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.7         |\n",
      "|    explained_variance | 0.577         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.448         |\n",
      "|    reward             | -0.0029213075 |\n",
      "|    std                | 95            |\n",
      "|    value_loss         | 7.83e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789148.3519128392\n",
      "Sharpe:  -1.0007081815211203\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.2        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.333        |\n",
      "|    reward             | -0.015649796 |\n",
      "|    std                | 100          |\n",
      "|    value_loss         | 7.71e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749142.3885491467\n",
      "Sharpe:  -0.3966648118643348\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.7       |\n",
      "|    explained_variance | 0.408       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -0.341      |\n",
      "|    reward             | 0.010807306 |\n",
      "|    std                | 106         |\n",
      "|    value_loss         | 4.63e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.1        |\n",
      "|    explained_variance | 0.47         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.0375      |\n",
      "|    reward             | -0.005917542 |\n",
      "|    std                | 111          |\n",
      "|    value_loss         | 3.22e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.6        |\n",
      "|    explained_variance | -0.702       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | 0.0013449093 |\n",
      "|    std                | 117          |\n",
      "|    value_loss         | 1.29e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:696903.0734026079\n",
      "Sharpe:  -0.3594994526078203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775418.1798306172\n",
      "Sharpe:  -9.470053474950365\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 231           |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.1         |\n",
      "|    explained_variance | -3.8          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | 0.525         |\n",
      "|    reward             | -0.0020296208 |\n",
      "|    std                | 123           |\n",
      "|    value_loss         | 0.000166      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 234          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.5        |\n",
      "|    explained_variance | -0.751       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | -0.171       |\n",
      "|    reward             | -0.004787569 |\n",
      "|    std                | 129          |\n",
      "|    value_loss         | 1.56e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761876.3571690813\n",
      "Sharpe:  -0.27570079051797763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793441.5194698902\n",
      "Sharpe:  -1.8499716360786604\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798916.8694114526\n",
      "Sharpe:  -2.088245231770408\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768757.8407157806\n",
      "Sharpe:  -3.763598240892025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 236           |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.9         |\n",
      "|    explained_variance | 0.387         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | 0.984         |\n",
      "|    reward             | -0.0023353107 |\n",
      "|    std                | 135           |\n",
      "|    value_loss         | 0.000628      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790353.409092149\n",
      "Sharpe:  -1.3768379942123512\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792796.497519428\n",
      "Sharpe:  -1.0292841832979456\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.3         |\n",
      "|    explained_variance | -0.218        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | -0.415        |\n",
      "|    reward             | -0.0009421099 |\n",
      "|    std                | 141           |\n",
      "|    value_loss         | 8.44e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.7        |\n",
      "|    explained_variance | -5.65        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | 0.186        |\n",
      "|    reward             | -0.009682282 |\n",
      "|    std                | 148          |\n",
      "|    value_loss         | 2.51e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.2        |\n",
      "|    explained_variance | -0.0284      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | 0.0045776507 |\n",
      "|    std                | 156          |\n",
      "|    value_loss         | 9.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1046067.4736032049\n",
      "Sharpe:  9.850282662303087\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.04606747360320562 -0.009065462292508625 9.850282662303087 0\n",
      "2023-08-01 00:00:00 2023-09-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.148       |\n",
      "|    reward             | -0.012526904 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000228     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796303.9360437705\n",
      "Sharpe:  -0.3613103212819038\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0612      |\n",
      "|    reward             | 0.0095963795 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 6.15e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0.383        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.14        |\n",
      "|    reward             | -0.010706037 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.000256     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0.769         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -0.0685       |\n",
      "|    reward             | -0.0022671532 |\n",
      "|    std                | 1.23          |\n",
      "|    value_loss         | 6.34e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1390585.5975473386\n",
      "Sharpe:  0.3654070722906785\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781787.8372002611\n",
      "Sharpe:  -1.5234700230209426\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0.269        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.0703      |\n",
      "|    reward             | 0.0067540063 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 3.45e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.647        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0798       |\n",
      "|    reward             | -0.012791439 |\n",
      "|    std                | 1.37         |\n",
      "|    value_loss         | 3.87e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774199.4971019432\n",
      "Sharpe:  -0.16606254878303822\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.254       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.12       |\n",
      "|    reward             | 0.009871804 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 6.88e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768495.7932931776\n",
      "Sharpe:  -1.4885531876961915\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.356       |\n",
      "|    reward             | 0.009222919 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.000429    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1384083.116944365\n",
      "Sharpe:  0.5508428812735173\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | -2.15         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.528        |\n",
      "|    reward             | 0.00063735474 |\n",
      "|    std                | 1.58          |\n",
      "|    value_loss         | 0.00127       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765132.0896862189\n",
      "Sharpe:  -1.1958439518170716\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790147.3571641799\n",
      "Sharpe:  -0.9516934933510889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | 0.735         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0137       |\n",
      "|    reward             | -0.0021483416 |\n",
      "|    std                | 1.67          |\n",
      "|    value_loss         | 1.26e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791359.6558426442\n",
      "Sharpe:  -1.0618152359760795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780792.1481527798\n",
      "Sharpe:  -1.1080829261476268\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0.75         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | -0.008801092 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 4.93e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | 0.795       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.0207      |\n",
      "|    reward             | 0.008587431 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 3.25e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.8      |\n",
      "|    explained_variance | 0.871      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -1.03      |\n",
      "|    reward             | 0.06016428 |\n",
      "|    std                | 1.95       |\n",
      "|    value_loss         | 0.00338    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794906.1546712398\n",
      "Sharpe:  -0.1070844579934321\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.391       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.0683     |\n",
      "|    reward             | 0.018308714 |\n",
      "|    std                | 2.06        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 36            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | 0.574         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.0601       |\n",
      "|    reward             | 0.00063350523 |\n",
      "|    std                | 2.16          |\n",
      "|    value_loss         | 5.11e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1174750.5932929546\n",
      "Sharpe:  0.2735927972708992\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.601        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | 0.0042816005 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 7.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0.509       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | 0.002637426 |\n",
      "|    std                | 2.38        |\n",
      "|    value_loss         | 5.46e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0706       |\n",
      "|    reward             | -0.014833656 |\n",
      "|    std                | 2.5          |\n",
      "|    value_loss         | 1.45e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1183294.6047225404\n",
      "Sharpe:  0.25265647688391585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 45            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.5         |\n",
      "|    explained_variance | 0.823         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.079         |\n",
      "|    reward             | -0.0072755427 |\n",
      "|    std                | 2.64          |\n",
      "|    value_loss         | 1.89e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -0.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | 0.0017652209 |\n",
      "|    std                | 2.78         |\n",
      "|    value_loss         | 9.18e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780841.3414114618\n",
      "Sharpe:  -0.13430120394103787\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.293       |\n",
      "|    reward             | 0.0022054862 |\n",
      "|    std                | 2.92         |\n",
      "|    value_loss         | 0.000167     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | -1.31        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 0.038        |\n",
      "|    reward             | 0.0033364927 |\n",
      "|    std                | 3.07         |\n",
      "|    value_loss         | 7.32e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 55            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | 0.128         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | 0.0511        |\n",
      "|    reward             | -0.0020398884 |\n",
      "|    std                | 3.22          |\n",
      "|    value_loss         | 1.17e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1299214.7087832193\n",
      "Sharpe:  0.32544808593898844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792112.7889395893\n",
      "Sharpe:  -2.1073419441501855\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.692       |\n",
      "|    reward             | 0.015638152 |\n",
      "|    std                | 3.38        |\n",
      "|    value_loss         | 0.000908    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.365        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.012216203 |\n",
      "|    std                | 3.56         |\n",
      "|    value_loss         | 0.000161     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.6         |\n",
      "|    explained_variance | 0.733         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | 0.246         |\n",
      "|    reward             | -0.0010156393 |\n",
      "|    std                | 3.74          |\n",
      "|    value_loss         | 0.000262      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791502.3600245873\n",
      "Sharpe:  -0.1015641258934928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0.168        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.192       |\n",
      "|    reward             | 0.0012081009 |\n",
      "|    std                | 3.92         |\n",
      "|    value_loss         | 0.000144     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790760.371117658\n",
      "Sharpe:  -0.4136504207928544\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788159.274765726\n",
      "Sharpe:  -1.5706840594466234\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | -0.274       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.0457       |\n",
      "|    reward             | -0.007130059 |\n",
      "|    std                | 4.12         |\n",
      "|    value_loss         | 3.92e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787065.6096499488\n",
      "Sharpe:  -0.7429758920662638\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.0414      |\n",
      "|    reward             | -0.00776834 |\n",
      "|    std                | 4.32        |\n",
      "|    value_loss         | 4.48e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798247.8950201067\n",
      "Sharpe:  -0.47267007168401715\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.4         |\n",
      "|    explained_variance | 0.581         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.0207        |\n",
      "|    reward             | -0.0005433348 |\n",
      "|    std                | 4.55          |\n",
      "|    value_loss         | 1.47e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | 0.722         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | -0.0902       |\n",
      "|    reward             | -0.0071072914 |\n",
      "|    std                | 4.79          |\n",
      "|    value_loss         | 2.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0.335        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.249        |\n",
      "|    reward             | 0.0026197068 |\n",
      "|    std                | 5.04         |\n",
      "|    value_loss         | 9.29e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:711576.7084462132\n",
      "Sharpe:  -0.22921391433129154\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | -0.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.856        |\n",
      "|    reward             | 0.0015784709 |\n",
      "|    std                | 5.31         |\n",
      "|    value_loss         | 0.000956     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753669.6733632637\n",
      "Sharpe:  -0.9751191778277651\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781916.6257680539\n",
      "Sharpe:  -1.4050225368869156\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.0723      |\n",
      "|    reward             | 0.002687911 |\n",
      "|    std                | 5.58        |\n",
      "|    value_loss         | 1.02e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790848.1006350119\n",
      "Sharpe:  -0.6335958702975765\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -0.0407      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | 0.0034331614 |\n",
      "|    std                | 5.85         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:682699.5640639766\n",
      "Sharpe:  -0.47353049340390185\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0.288       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.156      |\n",
      "|    reward             | 0.013089541 |\n",
      "|    std                | 6.15        |\n",
      "|    value_loss         | 5.4e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778386.0478408742\n",
      "Sharpe:  -0.876615257952575\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.6      |\n",
      "|    explained_variance | 0.338      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -0.523     |\n",
      "|    reward             | 0.01113039 |\n",
      "|    std                | 6.47       |\n",
      "|    value_loss         | 0.000341   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 91           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | -0.0334      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.418       |\n",
      "|    reward             | 0.0059274193 |\n",
      "|    std                | 6.81         |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:645214.0131897704\n",
      "Sharpe:  -0.35125010502815274\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 93            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0.437         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 0.124         |\n",
      "|    reward             | -0.0010213084 |\n",
      "|    std                | 7.14          |\n",
      "|    value_loss         | 2.6e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | 0.164       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | -0.0647     |\n",
      "|    reward             | -0.00183361 |\n",
      "|    std                | 7.46        |\n",
      "|    value_loss         | 3.88e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0.197       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.452      |\n",
      "|    reward             | 0.002968271 |\n",
      "|    std                | 7.83        |\n",
      "|    value_loss         | 0.000242    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:703779.3617440795\n",
      "Sharpe:  -0.2754987474124244\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791364.7709381502\n",
      "Sharpe:  -1.0481801118505172\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.264        |\n",
      "|    reward             | 0.0044569424 |\n",
      "|    std                | 8.24         |\n",
      "|    value_loss         | 6.57e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791573.9337134645\n",
      "Sharpe:  -0.579802922489097\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 0.196       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.682      |\n",
      "|    reward             | 0.008044364 |\n",
      "|    std                | 8.66        |\n",
      "|    value_loss         | 0.000532    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799088.843181643\n",
      "Sharpe:  -1.778762775860564\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783240.974766316\n",
      "Sharpe:  -2.452691091629575\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0.276       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -0.147      |\n",
      "|    reward             | 0.009070109 |\n",
      "|    std                | 9.02        |\n",
      "|    value_loss         | 6.71e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780927.7941645875\n",
      "Sharpe:  -0.36750869444471485\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 108           |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.9         |\n",
      "|    explained_variance | 0.141         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | -0.173        |\n",
      "|    reward             | -0.0030755403 |\n",
      "|    std                | 9.43          |\n",
      "|    value_loss         | 4.08e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:644081.286854417\n",
      "Sharpe:  -0.5528696683080986\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 110           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 0.536         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -0.561        |\n",
      "|    reward             | -0.0029833326 |\n",
      "|    std                | 9.88          |\n",
      "|    value_loss         | 0.000317      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791758.3910976577\n",
      "Sharpe:  -0.497194491452853\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794342.3252811516\n",
      "Sharpe:  -1.5932005157779505\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 113           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.8         |\n",
      "|    explained_variance | 0.707         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | -0.0674       |\n",
      "|    reward             | -0.0028880185 |\n",
      "|    std                | 10.4          |\n",
      "|    value_loss         | 7.91e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774290.3641754535\n",
      "Sharpe:  -1.353734967148818\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749549.9590254389\n",
      "Sharpe:  -2.819913977797554\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | -12.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | -0.008537913 |\n",
      "|    std                | 10.8         |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789339.545193726\n",
      "Sharpe:  -1.3490579955536048\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.6        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.934       |\n",
      "|    reward             | 0.0008707394 |\n",
      "|    std                | 11.4         |\n",
      "|    value_loss         | 0.000781     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 120           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35           |\n",
      "|    explained_variance | 0.587         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | 0.0696        |\n",
      "|    reward             | -0.0009373734 |\n",
      "|    std                | 11.9          |\n",
      "|    value_loss         | 5.88e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:717982.5777926419\n",
      "Sharpe:  -0.3017827824198669\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0.304       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.22        |\n",
      "|    reward             | 0.015563835 |\n",
      "|    std                | 12.5        |\n",
      "|    value_loss         | 6.27e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.9         |\n",
      "|    explained_variance | 0.544         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | -0.25         |\n",
      "|    reward             | 0.00030161903 |\n",
      "|    std                | 13.2          |\n",
      "|    value_loss         | 8.05e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 0.485       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | -0.419      |\n",
      "|    reward             | 0.008558573 |\n",
      "|    std                | 13.8        |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:980228.1107685701\n",
      "Sharpe:  0.08276030167256576\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796145.489486081\n",
      "Sharpe:  -1.4470152445154225\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 130           |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.8         |\n",
      "|    explained_variance | -0.13         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | 0.215         |\n",
      "|    reward             | -0.0007779746 |\n",
      "|    std                | 14.5          |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789740.9423675098\n",
      "Sharpe:  -0.45710057502662294\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.2      |\n",
      "|    explained_variance | 0.34       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -0.374     |\n",
      "|    reward             | 0.01332697 |\n",
      "|    std                | 15.2       |\n",
      "|    value_loss         | 0.000179   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.7       |\n",
      "|    explained_variance | 0.23        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -0.281      |\n",
      "|    reward             | 0.012056883 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 6.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773461.1083986856\n",
      "Sharpe:  -0.49883842819246027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793234.8942959891\n",
      "Sharpe:  -1.4874264257733538\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | -0.401       |\n",
      "|    reward             | -0.004714571 |\n",
      "|    std                | 16.8         |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758835.9823492722\n",
      "Sharpe:  -1.5596261973261645\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0.108        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.407       |\n",
      "|    reward             | 0.0003437795 |\n",
      "|    std                | 17.6         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784049.197876821\n",
      "Sharpe:  -0.6817964869072636\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 207           |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 142           |\n",
      "|    total_timesteps    | 29500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39           |\n",
      "|    explained_variance | -0.579        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5899          |\n",
      "|    policy_loss        | -0.149        |\n",
      "|    reward             | -0.0006784796 |\n",
      "|    std                | 18.5          |\n",
      "|    value_loss         | 4.95e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788578.4925649868\n",
      "Sharpe:  -1.5091451701621075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:705068.5539553695\n",
      "Sharpe:  -5.519992764149104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793904.328363161\n",
      "Sharpe:  -1.9849682963257542\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.5        |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.294       |\n",
      "|    reward             | -0.002549567 |\n",
      "|    std                | 19.5         |\n",
      "|    value_loss         | 6.78e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793173.2324649161\n",
      "Sharpe:  -1.2436103061172237\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40          |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -0.0989      |\n",
      "|    reward             | 0.0028845503 |\n",
      "|    std                | 20.6         |\n",
      "|    value_loss         | 1.15e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769274.6849160113\n",
      "Sharpe:  -0.876908302106744\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.5        |\n",
      "|    explained_variance | -2.26        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.826       |\n",
      "|    reward             | -0.004815355 |\n",
      "|    std                | 21.8         |\n",
      "|    value_loss         | 0.000502     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753269.4241449091\n",
      "Sharpe:  -1.2296562669802698\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 207        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.9      |\n",
      "|    explained_variance | 0.475      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 0.414      |\n",
      "|    reward             | 0.00780177 |\n",
      "|    std                | 22.9       |\n",
      "|    value_loss         | 0.000359   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:723578.0517710292\n",
      "Sharpe:  -0.3603337217543131\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | -0.00811    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -0.43       |\n",
      "|    reward             | 0.004580011 |\n",
      "|    std                | 24.1        |\n",
      "|    value_loss         | 0.000156    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773016.2520033591\n",
      "Sharpe:  -1.4026521852325462\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 207          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.8        |\n",
      "|    explained_variance | -0.208       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.578       |\n",
      "|    reward             | -0.004678094 |\n",
      "|    std                | 25.3         |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794397.2657234526\n",
      "Sharpe:  -0.6359415368106554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786808.5115127803\n",
      "Sharpe:  -1.8261408577056326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0.182         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -0.198        |\n",
      "|    reward             | -0.0046954756 |\n",
      "|    std                | 26.3          |\n",
      "|    value_loss         | 2.43e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793737.244379026\n",
      "Sharpe:  -0.6363819953105397\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0.837         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | -0.0853       |\n",
      "|    reward             | -0.0038284152 |\n",
      "|    std                | 27.7          |\n",
      "|    value_loss         | 8.88e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:730959.7466910685\n",
      "Sharpe:  -1.19386718166404\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 164           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.1         |\n",
      "|    explained_variance | -0.0918       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | -0.345        |\n",
      "|    reward             | 0.00027838498 |\n",
      "|    std                | 29            |\n",
      "|    value_loss         | 0.000116      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794997.2167638183\n",
      "Sharpe:  -0.4172332783572927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770581.981449685\n",
      "Sharpe:  -10.179777735965063\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | -0.0512     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | -0.161      |\n",
      "|    reward             | 0.017784758 |\n",
      "|    std                | 30.6        |\n",
      "|    value_loss         | 2.01e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771789.9746473423\n",
      "Sharpe:  -0.7258421106972959\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44          |\n",
      "|    explained_variance | 0.271        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.0261       |\n",
      "|    reward             | -0.007133526 |\n",
      "|    std                | 32.2         |\n",
      "|    value_loss         | 2.06e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792495.7889121263\n",
      "Sharpe:  -0.8182702128588791\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.5       |\n",
      "|    explained_variance | -0.00639    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 0.543       |\n",
      "|    reward             | 0.003985541 |\n",
      "|    std                | 33.9        |\n",
      "|    value_loss         | 0.000186    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:720190.0261568383\n",
      "Sharpe:  -0.5582608253205912\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.9        |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.575       |\n",
      "|    reward             | -0.009214112 |\n",
      "|    std                | 35.7         |\n",
      "|    value_loss         | 0.000169     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780736.0706534799\n",
      "Sharpe:  -1.3425886378451481\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 176           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.4         |\n",
      "|    explained_variance | 0.28          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.307        |\n",
      "|    reward             | 5.7585185e-05 |\n",
      "|    std                | 37.6          |\n",
      "|    value_loss         | 7.72e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.8        |\n",
      "|    explained_variance | -0.423       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | 0.0041253157 |\n",
      "|    std                | 39.5         |\n",
      "|    value_loss         | 3.94e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764805.2098280872\n",
      "Sharpe:  -0.2613712032687062\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780672.4019031376\n",
      "Sharpe:  -1.885286404023655\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.3       |\n",
      "|    explained_variance | 0.672       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | 0.226       |\n",
      "|    reward             | 0.010333217 |\n",
      "|    std                | 41.5        |\n",
      "|    value_loss         | 4.82e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761236.1026694672\n",
      "Sharpe:  -1.3955899644873049\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.7        |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.784        |\n",
      "|    reward             | 0.0030520447 |\n",
      "|    std                | 43.6         |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791416.6947899424\n",
      "Sharpe:  -0.445963828794847\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.2       |\n",
      "|    explained_variance | 0.564       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.309       |\n",
      "|    reward             | 0.003361101 |\n",
      "|    std                | 45.8        |\n",
      "|    value_loss         | 4.6e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776896.6933365783\n",
      "Sharpe:  -0.8315160353628589\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787025.5696123289\n",
      "Sharpe:  -8.274315795443195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 188           |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.6         |\n",
      "|    explained_variance | -0.0431       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | 2.41          |\n",
      "|    reward             | -0.0061355997 |\n",
      "|    std                | 48.1          |\n",
      "|    value_loss         | 0.00427       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.1        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.344        |\n",
      "|    reward             | 0.0025094324 |\n",
      "|    std                | 50.6         |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776223.9198901216\n",
      "Sharpe:  -0.2640132221651806\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 206           |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 193           |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.5         |\n",
      "|    explained_variance | 0.205         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | 0.573         |\n",
      "|    reward             | 0.00047314964 |\n",
      "|    std                | 53.2          |\n",
      "|    value_loss         | 0.000161      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762733.8627523431\n",
      "Sharpe:  -0.661699830309832\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 206          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49          |\n",
      "|    explained_variance | 0.697        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | -0.218       |\n",
      "|    reward             | -0.008081684 |\n",
      "|    std                | 56.1         |\n",
      "|    value_loss         | 3.02e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799089.8443483425\n",
      "Sharpe:  -3.2235902711159765\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769896.4063488352\n",
      "Sharpe:  -4.086793186780439\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.5       |\n",
      "|    explained_variance | 0.179       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.007556464 |\n",
      "|    std                | 59.3        |\n",
      "|    value_loss         | 0.00117     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758115.8915479966\n",
      "Sharpe:  -0.6922950957842773\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782416.5503357525\n",
      "Sharpe:  -7.219853850317237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 201           |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.9         |\n",
      "|    explained_variance | 0.339         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | -0.544        |\n",
      "|    reward             | 0.00029753344 |\n",
      "|    std                | 62.5          |\n",
      "|    value_loss         | 0.000137      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785198.7107325316\n",
      "Sharpe:  -0.6197257243946556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753380.7624850676\n",
      "Sharpe:  -3.1373866270038993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 204           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.4         |\n",
      "|    explained_variance | 0.314         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | -0.231        |\n",
      "|    reward             | -0.0047530658 |\n",
      "|    std                | 65.8          |\n",
      "|    value_loss         | 3.33e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.9         |\n",
      "|    explained_variance | 0.257         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | 0.395         |\n",
      "|    reward             | -0.0016397429 |\n",
      "|    std                | 69.3          |\n",
      "|    value_loss         | 0.000112      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793671.5318655228\n",
      "Sharpe:  -0.41191582636368324\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.3        |\n",
      "|    explained_variance | 0.549        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 1            |\n",
      "|    reward             | -0.010878725 |\n",
      "|    std                | 72.9         |\n",
      "|    value_loss         | 0.000481     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774680.6214631461\n",
      "Sharpe:  -0.9522975091360932\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.8        |\n",
      "|    explained_variance | 0.411        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.669       |\n",
      "|    reward             | 0.0012298883 |\n",
      "|    std                | 76.7         |\n",
      "|    value_loss         | 0.000191     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 214          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.3        |\n",
      "|    explained_variance | -0.0445      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.623       |\n",
      "|    reward             | -0.008235947 |\n",
      "|    std                | 80.7         |\n",
      "|    value_loss         | 0.000449     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:668902.2675931187\n",
      "Sharpe:  -0.35930476685253815\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.7        |\n",
      "|    explained_variance | 0.708        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 0.194        |\n",
      "|    reward             | 0.0028293584 |\n",
      "|    std                | 84.7         |\n",
      "|    value_loss         | 1.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 218           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.1         |\n",
      "|    explained_variance | 0.39          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | -0.65         |\n",
      "|    reward             | -0.0025478138 |\n",
      "|    std                | 89            |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789963.0255417131\n",
      "Sharpe:  -0.1745414472961252\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 221           |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.6         |\n",
      "|    explained_variance | -0.851        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9099          |\n",
      "|    policy_loss        | -0.578        |\n",
      "|    reward             | -0.0014800505 |\n",
      "|    std                | 93.6          |\n",
      "|    value_loss         | 0.000187      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785735.6328704391\n",
      "Sharpe:  -1.388421944869303\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54          |\n",
      "|    explained_variance | 0.286        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.344        |\n",
      "|    reward             | 0.0036822453 |\n",
      "|    std                | 98.1         |\n",
      "|    value_loss         | 7.61e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755570.0973316444\n",
      "Sharpe:  -0.6600432336481767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.5        |\n",
      "|    explained_variance | 0.302        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.549       |\n",
      "|    reward             | 0.0044198525 |\n",
      "|    std                | 103          |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797229.407386971\n",
      "Sharpe:  -0.6575132283916842\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 205        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 228        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -54.9      |\n",
      "|    explained_variance | 0.422      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 0.429      |\n",
      "|    reward             | 0.01377349 |\n",
      "|    std                | 108        |\n",
      "|    value_loss         | 8.3e-05    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755892.4259039615\n",
      "Sharpe:  -0.4947616891556134\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.4       |\n",
      "|    explained_variance | -1.95       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.498       |\n",
      "|    reward             | 0.004927671 |\n",
      "|    std                | 114         |\n",
      "|    value_loss         | 9.71e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795517.4748918491\n",
      "Sharpe:  -4.409747242535292\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 205           |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.8         |\n",
      "|    explained_variance | 0.0448        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9599          |\n",
      "|    policy_loss        | -0.0417       |\n",
      "|    reward             | -0.0069214273 |\n",
      "|    std                | 120           |\n",
      "|    value_loss         | 6.87e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784222.0990301514\n",
      "Sharpe:  -0.4658312327676588\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.3       |\n",
      "|    explained_variance | -0.592      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -0.116      |\n",
      "|    reward             | 0.005480623 |\n",
      "|    std                | 127         |\n",
      "|    value_loss         | 2.16e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.8        |\n",
      "|    explained_variance | -0.216       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.00952      |\n",
      "|    reward             | -0.009942366 |\n",
      "|    std                | 134          |\n",
      "|    value_loss         | 8.13e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792440.2463148953\n",
      "Sharpe:  -0.344053706973704\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795730.0062383285\n",
      "Sharpe:  -2.619917150422493\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 205         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.2       |\n",
      "|    explained_variance | 0.628       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.329       |\n",
      "|    reward             | 0.011941539 |\n",
      "|    std                | 140         |\n",
      "|    value_loss         | 5.15e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799642.3272210989\n",
      "Sharpe:  -0.6539824071884496\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797795.7841550686\n",
      "Sharpe:  -6.3863072584314695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798335.618739603\n",
      "Sharpe:  -5.3075972690137165\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.7        |\n",
      "|    explained_variance | 0.171        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -0.219       |\n",
      "|    reward             | 0.0017927269 |\n",
      "|    std                | 147          |\n",
      "|    value_loss         | 5.46e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1034576.0759379995\n",
      "Sharpe:  3.1145516909590722\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.03457607593800005 -0.025740674780577903 3.1145516909590722 0\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_9_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776771.9270014504\n",
      "Sharpe:  -0.8209771206859762\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 189            |\n",
      "|    iterations         | 100            |\n",
      "|    time_elapsed       | 2              |\n",
      "|    total_timesteps    | 500            |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.3          |\n",
      "|    explained_variance | -3.19          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 99             |\n",
      "|    policy_loss        | -0.229         |\n",
      "|    reward             | -0.00084947306 |\n",
      "|    std                | 1.06           |\n",
      "|    value_loss         | 0.000526       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.309       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.0593      |\n",
      "|    reward             | 0.021205029 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 3.11e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.178        |\n",
      "|    reward             | 0.0076693837 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0.474        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.114        |\n",
      "|    reward             | 0.0047142636 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 5.03e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1008316.5029470712\n",
      "Sharpe:  0.09268633337516981\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792631.5584867136\n",
      "Sharpe:  -2.220090615773064\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0.0071      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | -0.00965885 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797485.3721995133\n",
      "Sharpe:  -0.41893155312525576\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | -8.99         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.129        |\n",
      "|    reward             | -0.0018305898 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 9.69e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -4.9         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.0115      |\n",
      "|    reward             | 0.0034176235 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 2.66e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792761.5740516718\n",
      "Sharpe:  -0.2645463080907189\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0.131        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.512       |\n",
      "|    reward             | 0.0021219882 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797299.1024990828\n",
      "Sharpe:  -0.8689369118443605\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | -0.201       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.21         |\n",
      "|    reward             | 0.0060239765 |\n",
      "|    std                | 1.6          |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799063.0877030408\n",
      "Sharpe:  -1.5841363085284743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 0.359         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0982       |\n",
      "|    reward             | -0.0011097576 |\n",
      "|    std                | 1.68          |\n",
      "|    value_loss         | 4.02e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799616.976344808\n",
      "Sharpe:  -0.5935066171963574\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794567.6952946289\n",
      "Sharpe:  -1.8255103863723945\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.9      |\n",
      "|    explained_variance | 0.668      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -0.177     |\n",
      "|    reward             | 0.00292975 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 0.0001     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0.565       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.173      |\n",
      "|    reward             | 0.009517937 |\n",
      "|    std                | 1.86        |\n",
      "|    value_loss         | 0.000296    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750058.928931327\n",
      "Sharpe:  -0.3792083149428732\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | -1.09       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.115       |\n",
      "|    reward             | -0.01758877 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 4.24e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | -0.529       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.117        |\n",
      "|    reward             | 0.0053743226 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 4.82e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796581.4784288484\n",
      "Sharpe:  -0.22617776603193893\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0.528      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.202     |\n",
      "|    reward             | 0.00666054 |\n",
      "|    std                | 2.18       |\n",
      "|    value_loss         | 0.000162   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.605       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.0216      |\n",
      "|    reward             | 0.006920976 |\n",
      "|    std                | 2.31        |\n",
      "|    value_loss         | 5.58e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0.0647       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.224       |\n",
      "|    reward             | 0.0040725986 |\n",
      "|    std                | 2.44         |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1273558.2508178111\n",
      "Sharpe:  0.3275921634402334\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0.0124      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0145      |\n",
      "|    reward             | 0.013095926 |\n",
      "|    std                | 2.58        |\n",
      "|    value_loss         | 2.79e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770739.9827037784\n",
      "Sharpe:  -0.32912465355014425\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | -0.0228      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | 0.0056554163 |\n",
      "|    std                | 2.71         |\n",
      "|    value_loss         | 5.49e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | -0.0985     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.134      |\n",
      "|    reward             | 0.002044941 |\n",
      "|    std                | 2.86        |\n",
      "|    value_loss         | 8.28e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741081.9551443865\n",
      "Sharpe:  -0.3730423237278669\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | -0.41        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | 0.0011541267 |\n",
      "|    std                | 3.03         |\n",
      "|    value_loss         | 6.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | -0.48       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 0.116       |\n",
      "|    reward             | 0.015936129 |\n",
      "|    std                | 3.2         |\n",
      "|    value_loss         | 5.12e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797455.6852128515\n",
      "Sharpe:  -0.2634638632079229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.7         |\n",
      "|    explained_variance | 0.931         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | 0.0629        |\n",
      "|    reward             | -0.0062765107 |\n",
      "|    std                | 3.38          |\n",
      "|    value_loss         | 8.9e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.00847      |\n",
      "|    reward             | 0.0015398655 |\n",
      "|    std                | 3.57         |\n",
      "|    value_loss         | 3.27e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.7        |\n",
      "|    explained_variance | 0.233        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.137       |\n",
      "|    reward             | -0.004235016 |\n",
      "|    std                | 3.77         |\n",
      "|    value_loss         | 6.77e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1175610.1986047889\n",
      "Sharpe:  0.2511574833026304\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.741        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | 0.0344       |\n",
      "|    reward             | -0.006631411 |\n",
      "|    std                | 3.99         |\n",
      "|    value_loss         | 6.23e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.7         |\n",
      "|    explained_variance | -0.674        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | 0.201         |\n",
      "|    reward             | -0.0036805023 |\n",
      "|    std                | 4.22          |\n",
      "|    value_loss         | 6.97e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | 0.0027708544 |\n",
      "|    std                | 4.45         |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1195625.6376453764\n",
      "Sharpe:  0.2702701963738553\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.566        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.234        |\n",
      "|    reward             | -0.007096774 |\n",
      "|    std                | 4.69         |\n",
      "|    value_loss         | 8.36e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.278        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.634        |\n",
      "|    reward             | 0.0075380467 |\n",
      "|    std                | 4.95         |\n",
      "|    value_loss         | 0.000676     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775664.3823876507\n",
      "Sharpe:  -0.19240803265719236\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 76           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.0624      |\n",
      "|    reward             | -0.008373208 |\n",
      "|    std                | 5.22         |\n",
      "|    value_loss         | 2.26e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.454        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.568       |\n",
      "|    reward             | 0.0019305927 |\n",
      "|    std                | 5.49         |\n",
      "|    value_loss         | 0.000423     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748391.8438809507\n",
      "Sharpe:  -0.28995594991206836\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0.735        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | -0.247       |\n",
      "|    reward             | 0.0014000889 |\n",
      "|    std                | 5.78         |\n",
      "|    value_loss         | 8.6e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:707663.0921703951\n",
      "Sharpe:  -0.6642298297312874\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.0524      |\n",
      "|    reward             | 0.0014153459 |\n",
      "|    std                | 6.09         |\n",
      "|    value_loss         | 9.53e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795387.8911562611\n",
      "Sharpe:  -1.2849689350139224\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 86           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0.319        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | 0.0037297662 |\n",
      "|    std                | 6.42         |\n",
      "|    value_loss         | 3.15e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:719520.3050429203\n",
      "Sharpe:  -0.589067944035176\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.9         |\n",
      "|    explained_variance | 0.247         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | -0.0673       |\n",
      "|    reward             | -0.0012571021 |\n",
      "|    std                | 6.73          |\n",
      "|    value_loss         | 8.27e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0.152         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | 0.0449        |\n",
      "|    reward             | -0.0032002016 |\n",
      "|    std                | 7.07          |\n",
      "|    value_loss         | 2.65e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781249.4493636285\n",
      "Sharpe:  -0.22563156607230275\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.167      |\n",
      "|    reward             | 0.002339221 |\n",
      "|    std                | 7.42        |\n",
      "|    value_loss         | 4.34e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763629.9410304121\n",
      "Sharpe:  -1.192530696215995\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | -1.71        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | -0.003070696 |\n",
      "|    std                | 7.82         |\n",
      "|    value_loss         | 2.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 98            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | 0.319         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | 0.24          |\n",
      "|    reward             | -0.0078066518 |\n",
      "|    std                | 8.25          |\n",
      "|    value_loss         | 9.42e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795005.6253476206\n",
      "Sharpe:  -0.20521214916110955\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 101           |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.2         |\n",
      "|    explained_variance | -0.0303       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | 0.367         |\n",
      "|    reward             | -0.0010926188 |\n",
      "|    std                | 8.69          |\n",
      "|    value_loss         | 0.00013       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797927.9518194267\n",
      "Sharpe:  -0.8061174428593927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769631.1494661636\n",
      "Sharpe:  -1.6313234009092012\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0.522        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.202        |\n",
      "|    reward             | 0.0022376173 |\n",
      "|    std                | 9.13         |\n",
      "|    value_loss         | 4.79e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790794.8616390816\n",
      "Sharpe:  -4.212846564223664\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.581        |\n",
      "|    reward             | -0.021288123 |\n",
      "|    std                | 9.59         |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:705299.3845711483\n",
      "Sharpe:  -0.35806362385810847\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.0691       |\n",
      "|    reward             | 0.0047318274 |\n",
      "|    std                | 10.1         |\n",
      "|    value_loss         | 5.81e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 0.614       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.152       |\n",
      "|    reward             | 0.024839206 |\n",
      "|    std                | 10.6        |\n",
      "|    value_loss         | 2.07e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | 0.0693       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.0555       |\n",
      "|    reward             | 0.0028138838 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 1.28e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764845.3895869363\n",
      "Sharpe:  -0.2594685522135728\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35         |\n",
      "|    explained_variance | -2.94       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -0.0153     |\n",
      "|    reward             | 0.001430465 |\n",
      "|    std                | 11.8        |\n",
      "|    value_loss         | 1.25e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0.121       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 0.275       |\n",
      "|    reward             | 0.017179124 |\n",
      "|    std                | 12.5        |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758243.2928592367\n",
      "Sharpe:  -0.31328229324394524\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0.703        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | 0.0234       |\n",
      "|    reward             | 0.0037185263 |\n",
      "|    std                | 13.1         |\n",
      "|    value_loss         | 4.17e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 123           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.4         |\n",
      "|    explained_variance | -0.0343       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | -0.0772       |\n",
      "|    reward             | -0.0029363567 |\n",
      "|    std                | 13.8          |\n",
      "|    value_loss         | 8.94e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747106.3756231868\n",
      "Sharpe:  -0.2036274360673697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.8         |\n",
      "|    explained_variance | -1.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | -0.0916       |\n",
      "|    reward             | -0.0055159093 |\n",
      "|    std                | 14.5          |\n",
      "|    value_loss         | 1.49e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788619.351802725\n",
      "Sharpe:  -1.348616544070282\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794400.0068601922\n",
      "Sharpe:  -2.251504728832911\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.3        |\n",
      "|    explained_variance | -1.39        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.103       |\n",
      "|    reward             | 0.0028051059 |\n",
      "|    std                | 15.2         |\n",
      "|    value_loss         | 1.72e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774230.4430767262\n",
      "Sharpe:  -1.9420712468278405\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | -0.328       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.283        |\n",
      "|    reward             | -0.013476917 |\n",
      "|    std                | 16           |\n",
      "|    value_loss         | 6.32e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799962.4350891798\n",
      "Sharpe:  -1.1166846161324893\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776713.46140237\n",
      "Sharpe:  -6.697370764166928\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782533.8896849037\n",
      "Sharpe:  -1.3264025459887228\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 133           |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | 0.896         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | -0.14         |\n",
      "|    reward             | -0.0019891905 |\n",
      "|    std                | 16.9          |\n",
      "|    value_loss         | 1.57e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788245.3617022602\n",
      "Sharpe:  -1.607959533947458\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.6        |\n",
      "|    explained_variance | 0.455        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | 0.0020085836 |\n",
      "|    std                | 17.7         |\n",
      "|    value_loss         | 1.59e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 138           |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.1         |\n",
      "|    explained_variance | 0.448         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 1.02          |\n",
      "|    reward             | -0.0059806574 |\n",
      "|    std                | 18.7          |\n",
      "|    value_loss         | 0.000835      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793597.028161339\n",
      "Sharpe:  -0.2560487594975127\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.6        |\n",
      "|    explained_variance | 0.353        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.478        |\n",
      "|    reward             | -0.003910258 |\n",
      "|    std                | 19.7         |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796320.8247873557\n",
      "Sharpe:  -2.084121544791954\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.1        |\n",
      "|    explained_variance | 0.231        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.342        |\n",
      "|    reward             | -0.004561917 |\n",
      "|    std                | 20.8         |\n",
      "|    value_loss         | 9.83e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765189.7483857303\n",
      "Sharpe:  -0.8324574564292083\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0.559       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 0.0869      |\n",
      "|    reward             | 0.008104523 |\n",
      "|    std                | 21.9        |\n",
      "|    value_loss         | 2.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770268.9534393722\n",
      "Sharpe:  -0.7405178137253945\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41         |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.0321      |\n",
      "|    reward             | -0.00861849 |\n",
      "|    std                | 23          |\n",
      "|    value_loss         | 1.59e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.4        |\n",
      "|    explained_variance | 0.336        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -0.39        |\n",
      "|    reward             | 0.0037292144 |\n",
      "|    std                | 24.2         |\n",
      "|    value_loss         | 9.52e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761789.9144326259\n",
      "Sharpe:  -0.30309183164464043\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 153          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.9        |\n",
      "|    explained_variance | 0.0683       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 0.0973       |\n",
      "|    reward             | 0.0021849223 |\n",
      "|    std                | 25.5         |\n",
      "|    value_loss         | 9.79e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759238.3419103698\n",
      "Sharpe:  -0.7297995125909676\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0.439       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -0.497      |\n",
      "|    reward             | 0.004532583 |\n",
      "|    std                | 26.9        |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774402.3468621424\n",
      "Sharpe:  -0.9069489053808089\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0.621       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 0.0701      |\n",
      "|    reward             | 0.007974693 |\n",
      "|    std                | 28.3        |\n",
      "|    value_loss         | 3.43e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0.524         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | 0.00222       |\n",
      "|    reward             | -0.0029791843 |\n",
      "|    std                | 29.8          |\n",
      "|    value_loss         | 3.34e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797426.0038921571\n",
      "Sharpe:  -0.20811075120199796\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.8       |\n",
      "|    explained_variance | -1.45       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.0439     |\n",
      "|    reward             | 0.002145746 |\n",
      "|    std                | 31.4        |\n",
      "|    value_loss         | 1.26e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794364.7087944931\n",
      "Sharpe:  -1.834056556479729\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.3        |\n",
      "|    explained_variance | 0.563        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.012663772 |\n",
      "|    std                | 33.2         |\n",
      "|    value_loss         | 2.1e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788347.6319272338\n",
      "Sharpe:  -1.1764171490451436\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 168           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.8         |\n",
      "|    explained_variance | -0.123        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | 0.535         |\n",
      "|    reward             | -0.0033377826 |\n",
      "|    std                | 35            |\n",
      "|    value_loss         | 0.000164      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754133.238453713\n",
      "Sharpe:  -0.7567543170059793\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791096.8034234917\n",
      "Sharpe:  -1.6402428145029633\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.3        |\n",
      "|    explained_variance | 0.0121       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -0.303       |\n",
      "|    reward             | 0.0046143117 |\n",
      "|    std                | 37           |\n",
      "|    value_loss         | 6.61e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.7       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -0.0378     |\n",
      "|    reward             | 0.014890867 |\n",
      "|    std                | 39          |\n",
      "|    value_loss         | 3.34e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 176          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.2        |\n",
      "|    explained_variance | 0.377        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | -0.006071116 |\n",
      "|    std                | 41.3         |\n",
      "|    value_loss         | 4.18e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798495.5667916771\n",
      "Sharpe:  -0.148045651509501\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.7        |\n",
      "|    explained_variance | 0.455        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | 0.901        |\n",
      "|    reward             | -0.004815624 |\n",
      "|    std                | 43.4         |\n",
      "|    value_loss         | 0.000568     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789180.2596496713\n",
      "Sharpe:  -0.5957136259586121\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.2        |\n",
      "|    explained_variance | 0.744        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.25        |\n",
      "|    reward             | 0.0032490208 |\n",
      "|    std                | 45.8         |\n",
      "|    value_loss         | 3.3e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783967.3557643605\n",
      "Sharpe:  -0.5970774458012974\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.6         |\n",
      "|    explained_variance | 0.0631        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | -0.45         |\n",
      "|    reward             | -0.0017820505 |\n",
      "|    std                | 48.2          |\n",
      "|    value_loss         | 0.000148      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771802.8619339756\n",
      "Sharpe:  -1.654140431207972\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 186           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.1         |\n",
      "|    explained_variance | 0.0177        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 1.26          |\n",
      "|    reward             | -0.0033753593 |\n",
      "|    std                | 50.6          |\n",
      "|    value_loss         | 0.000764      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793847.7292771738\n",
      "Sharpe:  -0.7362409319643014\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785433.2732554803\n",
      "Sharpe:  -1.6833732140776088\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.5       |\n",
      "|    explained_variance | 0.171       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 0.251       |\n",
      "|    reward             | 0.003440154 |\n",
      "|    std                | 53.2        |\n",
      "|    value_loss         | 3.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49         |\n",
      "|    explained_variance | 0.253       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.007211684 |\n",
      "|    std                | 56.1        |\n",
      "|    value_loss         | 0.000932    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.5        |\n",
      "|    explained_variance | 0.23         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.0174       |\n",
      "|    reward             | -0.006038586 |\n",
      "|    std                | 59.1         |\n",
      "|    value_loss         | 1.37e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740423.1268436445\n",
      "Sharpe:  -0.2254300389256287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796995.9748219036\n",
      "Sharpe:  -0.8384196353921964\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 196          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.9        |\n",
      "|    explained_variance | -0.27        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.384        |\n",
      "|    reward             | -0.003605235 |\n",
      "|    std                | 61.9         |\n",
      "|    value_loss         | 6.83e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768692.8953267001\n",
      "Sharpe:  -1.7568856796745147\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.3        |\n",
      "|    explained_variance | 0.539        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | 0.0079827085 |\n",
      "|    std                | 65           |\n",
      "|    value_loss         | 3.67e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780025.818657535\n",
      "Sharpe:  -0.5588673436292754\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.8       |\n",
      "|    explained_variance | 0.0516      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -0.558      |\n",
      "|    reward             | 0.002178821 |\n",
      "|    std                | 68.4        |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793144.2978972081\n",
      "Sharpe:  -0.8907002380057578\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799094.9498865615\n",
      "Sharpe:  -1.9763855378120994\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 201            |\n",
      "|    iterations         | 8200           |\n",
      "|    time_elapsed       | 203            |\n",
      "|    total_timesteps    | 41000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -51.2          |\n",
      "|    explained_variance | 0.907          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8199           |\n",
      "|    policy_loss        | -0.168         |\n",
      "|    reward             | -0.00082436734 |\n",
      "|    std                | 71.8           |\n",
      "|    value_loss         | 1.21e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789182.534639028\n",
      "Sharpe:  -1.0557301876703853\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.7        |\n",
      "|    explained_variance | 0.3          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.578       |\n",
      "|    reward             | 0.0035717122 |\n",
      "|    std                | 75.4         |\n",
      "|    value_loss         | 0.000217     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791566.4778138105\n",
      "Sharpe:  -0.9092778423079886\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.1     |\n",
      "|    explained_variance | 0.529     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 0.212     |\n",
      "|    reward             | 0.0035597 |\n",
      "|    std                | 79.5      |\n",
      "|    value_loss         | 3.76e-05  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797941.1144674373\n",
      "Sharpe:  -0.5182484718150738\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.6       |\n",
      "|    explained_variance | 0.334       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 0.293       |\n",
      "|    reward             | 0.007840327 |\n",
      "|    std                | 83.6        |\n",
      "|    value_loss         | 3.15e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767110.7273843138\n",
      "Sharpe:  -0.4512877699699227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768811.0842441921\n",
      "Sharpe:  -14.905372397641708\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 213          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.1        |\n",
      "|    explained_variance | 0.565        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 11.8         |\n",
      "|    reward             | 0.0003152648 |\n",
      "|    std                | 88.2         |\n",
      "|    value_loss         | 0.0585       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748206.5570226454\n",
      "Sharpe:  -0.7359010146051234\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.5        |\n",
      "|    explained_variance | 0.335        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.0344      |\n",
      "|    reward             | -0.008433982 |\n",
      "|    std                | 92.7         |\n",
      "|    value_loss         | 8.5e-06      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759844.2546918475\n",
      "Sharpe:  -1.4765376137916244\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 200           |\n",
      "|    iterations         | 8800          |\n",
      "|    time_elapsed       | 218           |\n",
      "|    total_timesteps    | 44000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54           |\n",
      "|    explained_variance | -2.62         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8799          |\n",
      "|    policy_loss        | -0.253        |\n",
      "|    reward             | -0.0066303792 |\n",
      "|    std                | 97.4          |\n",
      "|    value_loss         | 6.12e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789494.5325906172\n",
      "Sharpe:  -0.8721727752928143\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 200           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 221           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.4         |\n",
      "|    explained_variance | 0.752         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.503        |\n",
      "|    reward             | -0.0019245261 |\n",
      "|    std                | 103           |\n",
      "|    value_loss         | 8.8e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.9        |\n",
      "|    explained_variance | -0.848       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.33        |\n",
      "|    reward             | -0.009094551 |\n",
      "|    std                | 108          |\n",
      "|    value_loss         | 8.8e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:697436.4919459303\n",
      "Sharpe:  -0.3687637438348573\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796047.3222042627\n",
      "Sharpe:  -1.4105412899984573\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.4       |\n",
      "|    explained_variance | 0.11        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 0.166       |\n",
      "|    reward             | 0.017922947 |\n",
      "|    std                | 114         |\n",
      "|    value_loss         | 6.28e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.8        |\n",
      "|    explained_variance | 0.407        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -0.499       |\n",
      "|    reward             | 0.0049109096 |\n",
      "|    std                | 120          |\n",
      "|    value_loss         | 9.78e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:701037.4483687066\n",
      "Sharpe:  -0.37530026754041057\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.3        |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.555        |\n",
      "|    reward             | 0.0014354369 |\n",
      "|    std                | 126          |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755678.2422365336\n",
      "Sharpe:  -2.088435374233492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799964.3488580568\n",
      "Sharpe:  -0.9238893245061015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 200           |\n",
      "|    iterations         | 9400          |\n",
      "|    time_elapsed       | 234           |\n",
      "|    total_timesteps    | 47000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.7         |\n",
      "|    explained_variance | 0.218         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9399          |\n",
      "|    policy_loss        | 1.13          |\n",
      "|    reward             | -0.0036626018 |\n",
      "|    std                | 132           |\n",
      "|    value_loss         | 0.000429      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780125.3266661067\n",
      "Sharpe:  -0.7190249084525857\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.2        |\n",
      "|    explained_variance | 0.409        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | -0.621       |\n",
      "|    reward             | 0.0020535702 |\n",
      "|    std                | 139          |\n",
      "|    value_loss         | 0.000185     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795344.000615702\n",
      "Sharpe:  -0.5743620507565016\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775554.4628315627\n",
      "Sharpe:  -2.982730538522938\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.6       |\n",
      "|    explained_variance | 0.761       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.279      |\n",
      "|    reward             | 0.002751189 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 2.56e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760633.0307990552\n",
      "Sharpe:  -3.0983842762905067\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58          |\n",
      "|    explained_variance | 0.466        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.0765      |\n",
      "|    reward             | 0.0042180675 |\n",
      "|    std                | 153          |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796175.2247379259\n",
      "Sharpe:  -0.49452220639932853\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 244          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.5        |\n",
      "|    explained_variance | 0.48         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.124        |\n",
      "|    reward             | -0.012210457 |\n",
      "|    std                | 162          |\n",
      "|    value_loss         | 7.87e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59          |\n",
      "|    explained_variance | 0.0212       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.567       |\n",
      "|    reward             | 0.0019392605 |\n",
      "|    std                | 170          |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776287.5324789148\n",
      "Sharpe:  -0.4321009567662983\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.4       |\n",
      "|    explained_variance | -0.00402    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 0.18        |\n",
      "|    reward             | 0.010157156 |\n",
      "|    std                | 179         |\n",
      "|    value_loss         | 1.09e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:988131.5164064931\n",
      "Sharpe:  -1.189577775049533\n",
      "=================================\n",
      "hit end!\n",
      "a2c -0.011868483593506785 -0.049701990593643275 -1.189577775049533 0\n",
      "2023-10-01 00:00:00 2023-11-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0946      |\n",
      "|    reward             | 0.0044543575 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 5.62e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779195.2769937407\n",
      "Sharpe:  -0.5180330392100552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797291.2804219719\n",
      "Sharpe:  -0.7908668377339146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.424        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | -0.009908783 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0.38          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0099        |\n",
      "|    reward             | -0.0145900315 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 7.26e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:680635.5510808381\n",
      "Sharpe:  -0.3912165733653928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.00197     |\n",
      "|    reward             | -0.001834569 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 4.87e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780655.8408396296\n",
      "Sharpe:  -0.6455692314324557\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 198            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 12             |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.1          |\n",
      "|    explained_variance | 0.465          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | 0.0842         |\n",
      "|    reward             | -0.00019125605 |\n",
      "|    std                | 1.29           |\n",
      "|    value_loss         | 4.47e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0.444         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.651         |\n",
      "|    reward             | -0.0006050581 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785518.0893835381\n",
      "Sharpe:  -0.4619719467814954\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795160.7043446165\n",
      "Sharpe:  -1.2549590706226503\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.144      |\n",
      "|    reward             | 0.011604078 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 9.98e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.183       |\n",
      "|    reward             | -0.010613011 |\n",
      "|    std                | 1.51         |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799906.8572319102\n",
      "Sharpe:  -0.2624591572091749\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792317.352253397\n",
      "Sharpe:  -2.280710466326598\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.089       |\n",
      "|    reward             | 0.0003032662 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 2.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0.539        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0412      |\n",
      "|    reward             | -0.015587172 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 1.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.000184    |\n",
      "|    reward             | 0.0018984542 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 9.12e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1079175.952890026\n",
      "Sharpe:  0.16782271812279095\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.4         |\n",
      "|    explained_variance | 0.291         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.2           |\n",
      "|    reward             | -0.0052557318 |\n",
      "|    std                | 1.87          |\n",
      "|    value_loss         | 0.000174      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:706237.6760637951\n",
      "Sharpe:  -0.48887308179153494\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | -17.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.247       |\n",
      "|    reward             | -0.010786709 |\n",
      "|    std                | 1.96         |\n",
      "|    value_loss         | 0.000213     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757860.0431771264\n",
      "Sharpe:  -0.8903200046337835\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791826.9787198496\n",
      "Sharpe:  -2.4100276970784327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 35            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | 0.0884        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.0585       |\n",
      "|    reward             | -0.0066363965 |\n",
      "|    std                | 2.07          |\n",
      "|    value_loss         | 1.44e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | 0.404       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0623      |\n",
      "|    reward             | 0.026636204 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 2.44e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0.239       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.221      |\n",
      "|    reward             | 0.008751359 |\n",
      "|    std                | 2.28        |\n",
      "|    value_loss         | 0.000226    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799356.7914664217\n",
      "Sharpe:  -0.13349322265396374\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0927      |\n",
      "|    reward             | 0.0006965567 |\n",
      "|    std                | 2.41         |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0.00203      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.00494     |\n",
      "|    reward             | 0.0008759151 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 2.74e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 193           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 49            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.6         |\n",
      "|    explained_variance | 0.202         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.0869        |\n",
      "|    reward             | 0.00013526721 |\n",
      "|    std                | 2.67          |\n",
      "|    value_loss         | 4.27e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1124748.9375302026\n",
      "Sharpe:  0.19682897779864403\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 191           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.1         |\n",
      "|    explained_variance | 0.453         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.198        |\n",
      "|    reward             | -0.0019108047 |\n",
      "|    std                | 2.82          |\n",
      "|    value_loss         | 0.000189      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798234.1101801515\n",
      "Sharpe:  -0.48466302043137416\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 192           |\n",
      "|    iterations         | 2100          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 10500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.5         |\n",
      "|    explained_variance | 0.56          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2099          |\n",
      "|    policy_loss        | -0.0364       |\n",
      "|    reward             | -0.0021163416 |\n",
      "|    std                | 2.96          |\n",
      "|    value_loss         | 6.74e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 192           |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 57            |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23           |\n",
      "|    explained_variance | 0.00152       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | 0.0394        |\n",
      "|    reward             | -0.0067357873 |\n",
      "|    std                | 3.12          |\n",
      "|    value_loss         | 1.29e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759624.6962727034\n",
      "Sharpe:  -0.19541174013742182\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 192         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.132      |\n",
      "|    reward             | 0.001406001 |\n",
      "|    std                | 3.28        |\n",
      "|    value_loss         | 3.45e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 192          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | -0.158       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | -0.254       |\n",
      "|    reward             | -0.007940997 |\n",
      "|    std                | 3.45         |\n",
      "|    value_loss         | 0.000315     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1112487.8574902378\n",
      "Sharpe:  0.22695828672261054\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 192           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 64            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | 0.402         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.113        |\n",
      "|    reward             | -0.0030068161 |\n",
      "|    std                | 3.65          |\n",
      "|    value_loss         | 2.24e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 193            |\n",
      "|    iterations         | 2600           |\n",
      "|    time_elapsed       | 67             |\n",
      "|    total_timesteps    | 13000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -24.9          |\n",
      "|    explained_variance | 0.264          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2599           |\n",
      "|    policy_loss        | -0.0537        |\n",
      "|    reward             | -0.00038515072 |\n",
      "|    std                | 3.86           |\n",
      "|    value_loss         | 1.39e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.4       |\n",
      "|    explained_variance | 0.468       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.0879      |\n",
      "|    reward             | 0.007105163 |\n",
      "|    std                | 4.08        |\n",
      "|    value_loss         | 2.46e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1085425.006865498\n",
      "Sharpe:  0.19824135870761708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 193           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | 0.499         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0048605613 |\n",
      "|    std                | 4.33          |\n",
      "|    value_loss         | 1.79e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 193            |\n",
      "|    iterations         | 2900           |\n",
      "|    time_elapsed       | 74             |\n",
      "|    total_timesteps    | 14500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -26.5          |\n",
      "|    explained_variance | -0.394         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2899           |\n",
      "|    policy_loss        | 0.142          |\n",
      "|    reward             | -0.00042008705 |\n",
      "|    std                | 4.58           |\n",
      "|    value_loss         | 4.48e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.9       |\n",
      "|    explained_variance | 0.319       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.152      |\n",
      "|    reward             | 0.009771296 |\n",
      "|    std                | 4.84        |\n",
      "|    value_loss         | 4.36e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1061842.5882260834\n",
      "Sharpe:  0.14637895190880518\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 193            |\n",
      "|    iterations         | 3100           |\n",
      "|    time_elapsed       | 79             |\n",
      "|    total_timesteps    | 15500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -27.4          |\n",
      "|    explained_variance | 0.0918         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3099           |\n",
      "|    policy_loss        | 0.756          |\n",
      "|    reward             | -0.00016728543 |\n",
      "|    std                | 5.1            |\n",
      "|    value_loss         | 0.0007         |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796345.3941250304\n",
      "Sharpe:  -0.2896385735858179\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761484.2206293283\n",
      "Sharpe:  -5.77918249749006\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | -0.33       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -0.063      |\n",
      "|    reward             | 0.008434667 |\n",
      "|    std                | 5.36        |\n",
      "|    value_loss         | 1.91e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0.495       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.00281    |\n",
      "|    reward             | -0.00499168 |\n",
      "|    std                | 5.63        |\n",
      "|    value_loss         | 7.19e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0.486       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.322      |\n",
      "|    reward             | 0.016336305 |\n",
      "|    std                | 5.93        |\n",
      "|    value_loss         | 0.000183    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1147748.0730434326\n",
      "Sharpe:  0.24123685196154995\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 90            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.2         |\n",
      "|    explained_variance | 0.432         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | -0.115        |\n",
      "|    reward             | -0.0057951696 |\n",
      "|    std                | 6.24          |\n",
      "|    value_loss         | 2.76e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.7         |\n",
      "|    explained_variance | 0.53          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | -0.264        |\n",
      "|    reward             | -0.0086307125 |\n",
      "|    std                | 6.6           |\n",
      "|    value_loss         | 7.36e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797007.6976315913\n",
      "Sharpe:  -0.1666435583167727\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 194        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.2      |\n",
      "|    explained_variance | 0.115      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 0.184      |\n",
      "|    reward             | 0.00202471 |\n",
      "|    std                | 6.96       |\n",
      "|    value_loss         | 3.42e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 194        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.7      |\n",
      "|    explained_variance | -0.0912    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -0.344     |\n",
      "|    reward             | 0.00343488 |\n",
      "|    std                | 7.35       |\n",
      "|    value_loss         | 0.00022    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787972.0873801878\n",
      "Sharpe:  -0.19369599761814776\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0.262       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.0652      |\n",
      "|    reward             | 0.010900031 |\n",
      "|    std                | 7.72        |\n",
      "|    value_loss         | 2.29e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740330.0514629568\n",
      "Sharpe:  -0.6259393711478927\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | 8.048382e-05 |\n",
      "|    std                | 8.14         |\n",
      "|    value_loss         | 3.01e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | -0.0262     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.164      |\n",
      "|    reward             | -0.00822447 |\n",
      "|    std                | 8.56        |\n",
      "|    value_loss         | 5.36e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785221.1078797367\n",
      "Sharpe:  -0.22619463226091466\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0.0314      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | -0.167      |\n",
      "|    reward             | -0.00198139 |\n",
      "|    std                | 9.03        |\n",
      "|    value_loss         | 3.53e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.542        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.239        |\n",
      "|    reward             | -0.019593293 |\n",
      "|    std                | 9.55         |\n",
      "|    value_loss         | 6.11e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799215.4625994336\n",
      "Sharpe:  -0.18191846746527934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 113           |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.6         |\n",
      "|    explained_variance | 0.717         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.27          |\n",
      "|    reward             | -0.0013891003 |\n",
      "|    std                | 10.1          |\n",
      "|    value_loss         | 8.78e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | -0.349       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | 0.0015624694 |\n",
      "|    std                | 10.7         |\n",
      "|    value_loss         | 6.84e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792326.5367996229\n",
      "Sharpe:  -0.20114905433688898\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.0867      |\n",
      "|    reward             | -0.044452835 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 9.67e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767471.1042523148\n",
      "Sharpe:  -5.174944551363871\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 120           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35           |\n",
      "|    explained_variance | 0.391         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | -0.226        |\n",
      "|    reward             | -0.0069394936 |\n",
      "|    std                | 11.8          |\n",
      "|    value_loss         | 4.81e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:730135.0211523304\n",
      "Sharpe:  -0.48921136409233373\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 0.57         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.187        |\n",
      "|    reward             | -0.007553364 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 3.81e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788239.6385688778\n",
      "Sharpe:  -0.9615764149162137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790779.3083693152\n",
      "Sharpe:  -2.5557823888936175\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0.714        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | 1.01         |\n",
      "|    reward             | -0.010401499 |\n",
      "|    std                | 13.1         |\n",
      "|    value_loss         | 0.000734     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789056.3093077649\n",
      "Sharpe:  -0.43946797134876403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790937.3536427811\n",
      "Sharpe:  -7.799806076089543\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | 0.642        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.483        |\n",
      "|    reward             | -0.025888512 |\n",
      "|    std                | 13.8         |\n",
      "|    value_loss         | 0.00035      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:669554.5434358602\n",
      "Sharpe:  -0.5629651249482543\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 130           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.8         |\n",
      "|    explained_variance | 0.766         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.0169        |\n",
      "|    reward             | -0.0069409604 |\n",
      "|    std                | 14.5          |\n",
      "|    value_loss         | 2.17e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793341.4438420949\n",
      "Sharpe:  -1.1132342643517434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775290.1350753695\n",
      "Sharpe:  -3.4086429158035045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762856.1360982324\n",
      "Sharpe:  -7.755098040477421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 133           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.3         |\n",
      "|    explained_variance | 0.252         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.316         |\n",
      "|    reward             | -0.0034899344 |\n",
      "|    std                | 15.3          |\n",
      "|    value_loss         | 8.85e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770805.6943915472\n",
      "Sharpe:  -0.6538349903508105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 5300          |\n",
      "|    time_elapsed       | 136           |\n",
      "|    total_timesteps    | 26500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.8         |\n",
      "|    explained_variance | 0.468         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5299          |\n",
      "|    policy_loss        | 0.407         |\n",
      "|    reward             | -0.0022187014 |\n",
      "|    std                | 16.1          |\n",
      "|    value_loss         | 0.000229      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.2       |\n",
      "|    explained_variance | -0.148      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.189      |\n",
      "|    reward             | 0.002490904 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 6.3e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.7        |\n",
      "|    explained_variance | 0.33         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 1.02         |\n",
      "|    reward             | -0.018741438 |\n",
      "|    std                | 17.9         |\n",
      "|    value_loss         | 0.000731     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754165.8439876701\n",
      "Sharpe:  -0.22247625138744018\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.2        |\n",
      "|    explained_variance | -0.366       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.004124796 |\n",
      "|    std                | 18.8         |\n",
      "|    value_loss         | 3.12e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788406.8225858607\n",
      "Sharpe:  -0.6110826801408497\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 146           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.6         |\n",
      "|    explained_variance | 0.564         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.348        |\n",
      "|    reward             | -0.0016191563 |\n",
      "|    std                | 19.8          |\n",
      "|    value_loss         | 8.34e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.1       |\n",
      "|    explained_variance | 0.257       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.177       |\n",
      "|    reward             | 0.010917423 |\n",
      "|    std                | 20.8        |\n",
      "|    value_loss         | 3.76e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784983.5759333234\n",
      "Sharpe:  -0.21854300116532346\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753135.3001486291\n",
      "Sharpe:  -1.4556367060412627\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -0.165      |\n",
      "|    reward             | 0.002080429 |\n",
      "|    std                | 21.9        |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 154          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41          |\n",
      "|    explained_variance | -2.49        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.369       |\n",
      "|    reward             | 0.0054775774 |\n",
      "|    std                | 23.1         |\n",
      "|    value_loss         | 9.76e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 156           |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.5         |\n",
      "|    explained_variance | 0.123         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | -0.179        |\n",
      "|    reward             | -0.0040340307 |\n",
      "|    std                | 24.3          |\n",
      "|    value_loss         | 3.37e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776547.3545569779\n",
      "Sharpe:  -0.19635648949017706\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.9         |\n",
      "|    explained_variance | 0.432         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.92          |\n",
      "|    reward             | -0.0012067268 |\n",
      "|    std                | 25.5          |\n",
      "|    value_loss         | 0.000656      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773516.6506707242\n",
      "Sharpe:  -0.8795995393277297\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 6300          |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 31500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0.393         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6299          |\n",
      "|    policy_loss        | 0.98          |\n",
      "|    reward             | -0.0031004846 |\n",
      "|    std                | 26.9          |\n",
      "|    value_loss         | 0.000875      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781904.4266131745\n",
      "Sharpe:  -0.6687595849161933\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0.0801      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | 0.010858593 |\n",
      "|    std                | 28.4        |\n",
      "|    value_loss         | 1.44e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 166           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0.301         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | 0.0883        |\n",
      "|    reward             | -0.0072998623 |\n",
      "|    std                | 29.9          |\n",
      "|    value_loss         | 2.88e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725764.4420782202\n",
      "Sharpe:  -0.31641114842103546\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.7        |\n",
      "|    explained_variance | -0.01        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -0.157       |\n",
      "|    reward             | 0.0022075465 |\n",
      "|    std                | 31.3         |\n",
      "|    value_loss         | 2.57e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792909.4646262378\n",
      "Sharpe:  -0.481761098162088\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.2       |\n",
      "|    explained_variance | -0.171      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.195      |\n",
      "|    reward             | 0.000810098 |\n",
      "|    std                | 32.8        |\n",
      "|    value_loss         | 5.73e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 174           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.6         |\n",
      "|    explained_variance | -0.337        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | 0.0404        |\n",
      "|    reward             | 2.3148737e-05 |\n",
      "|    std                | 34.5          |\n",
      "|    value_loss         | 2.37e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773597.851839955\n",
      "Sharpe:  -0.16831974902260533\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.1       |\n",
      "|    explained_variance | 0.436       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.164       |\n",
      "|    reward             | -0.09460275 |\n",
      "|    std                | 36.3        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788297.165462904\n",
      "Sharpe:  -0.786569503754064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789593.1625942185\n",
      "Sharpe:  -4.27627349644708\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.5        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.376        |\n",
      "|    reward             | -0.004049709 |\n",
      "|    std                | 38.1         |\n",
      "|    value_loss         | 0.000465     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:737755.4159628634\n",
      "Sharpe:  -0.7223506835163974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.9        |\n",
      "|    explained_variance | -3.66        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | 0.0013037848 |\n",
      "|    std                | 39.9         |\n",
      "|    value_loss         | 5.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.4        |\n",
      "|    explained_variance | 0.367        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.0286      |\n",
      "|    reward             | 0.0035187718 |\n",
      "|    std                | 41.9         |\n",
      "|    value_loss         | 3.47e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:684285.6272793706\n",
      "Sharpe:  -0.5218886322720407\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 187           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.8         |\n",
      "|    explained_variance | -0.432        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.471        |\n",
      "|    reward             | -0.0041485587 |\n",
      "|    std                | 44.1          |\n",
      "|    value_loss         | 0.000146      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799977.5794749607\n",
      "Sharpe:  -1.0624878313261876\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 190           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.3         |\n",
      "|    explained_variance | 0.0716        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.507         |\n",
      "|    reward             | 0.00083440763 |\n",
      "|    std                | 46.3          |\n",
      "|    value_loss         | 0.000139      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739449.7689691768\n",
      "Sharpe:  -0.5316365058405599\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.7        |\n",
      "|    explained_variance | 0.111        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 0.0231       |\n",
      "|    reward             | 0.0046570497 |\n",
      "|    std                | 48.6         |\n",
      "|    value_loss         | 6.21e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779950.0329080392\n",
      "Sharpe:  -0.7046634672782337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793592.5429498634\n",
      "Sharpe:  -4.259319457573056\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.2        |\n",
      "|    explained_variance | 0.449        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -0.637       |\n",
      "|    reward             | 0.0027196072 |\n",
      "|    std                | 51.2         |\n",
      "|    value_loss         | 0.000199     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783731.3990606294\n",
      "Sharpe:  -0.5370466685568571\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.6        |\n",
      "|    explained_variance | -0.545       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.0873       |\n",
      "|    reward             | 0.0009804085 |\n",
      "|    std                | 53.8         |\n",
      "|    value_loss         | 4.28e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794846.0528480125\n",
      "Sharpe:  -1.168535401039292\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.1        |\n",
      "|    explained_variance | -0.847       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | -0.006140464 |\n",
      "|    std                | 56.7         |\n",
      "|    value_loss         | 4.24e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789771.511192809\n",
      "Sharpe:  -1.3010723887242015\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769066.8906888637\n",
      "Sharpe:  -1.0323869398459646\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 202           |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.5         |\n",
      "|    explained_variance | -1.12         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | 0.0576        |\n",
      "|    reward             | -0.0030136206 |\n",
      "|    std                | 59.6          |\n",
      "|    value_loss         | 7.18e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793895.0529648754\n",
      "Sharpe:  -2.2208504139293863\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797756.4113089856\n",
      "Sharpe:  -4.061165897368031\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50          |\n",
      "|    explained_variance | -0.142       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | -0.946       |\n",
      "|    reward             | -0.007285775 |\n",
      "|    std                | 62.6         |\n",
      "|    value_loss         | 0.000421     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797074.9027718082\n",
      "Sharpe:  -0.7148151288998533\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 208           |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.4         |\n",
      "|    explained_variance | 0.724         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | -0.00467      |\n",
      "|    reward             | -0.0020989862 |\n",
      "|    std                | 65.7          |\n",
      "|    value_loss         | 3.12e-07      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776280.7891608078\n",
      "Sharpe:  -0.7711707580708309\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.9        |\n",
      "|    explained_variance | 0.45         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.0501      |\n",
      "|    reward             | -0.008247515 |\n",
      "|    std                | 69.2         |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772727.937812493\n",
      "Sharpe:  -0.7976332278015733\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749880.1453478757\n",
      "Sharpe:  -1.4499067553807992\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.4       |\n",
      "|    explained_variance | -3.09       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.329      |\n",
      "|    reward             | 0.012782183 |\n",
      "|    std                | 72.9        |\n",
      "|    value_loss         | 0.000133    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792325.3811380683\n",
      "Sharpe:  -2.37538094190156\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799004.928919632\n",
      "Sharpe:  -2.725306708807206\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.8        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | -0.0522      |\n",
      "|    reward             | -0.005689914 |\n",
      "|    std                | 76.8         |\n",
      "|    value_loss         | 2.72e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:731168.2267681365\n",
      "Sharpe:  -0.7165167194504638\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 194          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.3        |\n",
      "|    explained_variance | 0.602        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | -0.244       |\n",
      "|    reward             | -0.000261331 |\n",
      "|    std                | 80.9         |\n",
      "|    value_loss         | 5.41e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792247.0452395079\n",
      "Sharpe:  -0.8843290417429727\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 8600          |\n",
      "|    time_elapsed       | 220           |\n",
      "|    total_timesteps    | 43000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -52.7         |\n",
      "|    explained_variance | 0.686         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8599          |\n",
      "|    policy_loss        | 0.173         |\n",
      "|    reward             | -0.0005104117 |\n",
      "|    std                | 84.9          |\n",
      "|    value_loss         | 2.11e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793523.3168803421\n",
      "Sharpe:  -0.5757686805067912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791031.2413481085\n",
      "Sharpe:  -3.2388728418451853\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.2        |\n",
      "|    explained_variance | 0.187        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 0.434        |\n",
      "|    reward             | -0.006468148 |\n",
      "|    std                | 89.1         |\n",
      "|    value_loss         | 8.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 225          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.6        |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.41        |\n",
      "|    reward             | -0.017023535 |\n",
      "|    std                | 93.6         |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.1        |\n",
      "|    explained_variance | 0.32         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -0.0762      |\n",
      "|    reward             | 0.0047219223 |\n",
      "|    std                | 98.5         |\n",
      "|    value_loss         | 0.000197     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765242.2161046421\n",
      "Sharpe:  -0.22742072519993609\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.5        |\n",
      "|    explained_variance | 0.674        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.535       |\n",
      "|    reward             | -0.000972545 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783263.9852568916\n",
      "Sharpe:  -0.511170967710921\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 195            |\n",
      "|    iterations         | 9100           |\n",
      "|    time_elapsed       | 233            |\n",
      "|    total_timesteps    | 45500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -55            |\n",
      "|    explained_variance | 0.683          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9099           |\n",
      "|    policy_loss        | 0.187          |\n",
      "|    reward             | -2.5372065e-05 |\n",
      "|    std                | 109            |\n",
      "|    value_loss         | 2.23e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795967.5393189462\n",
      "Sharpe:  -0.6411924643160247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 235           |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.4         |\n",
      "|    explained_variance | 0.626         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9199          |\n",
      "|    policy_loss        | 0.0268        |\n",
      "|    reward             | -0.0056587337 |\n",
      "|    std                | 115           |\n",
      "|    value_loss         | 1.53e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759650.7959909592\n",
      "Sharpe:  -1.3579854906356648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798631.9242922069\n",
      "Sharpe:  -1.0730048218933814\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.9        |\n",
      "|    explained_variance | 0.402        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.389       |\n",
      "|    reward             | 0.0026961055 |\n",
      "|    std                | 121          |\n",
      "|    value_loss         | 5.87e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 9400          |\n",
      "|    time_elapsed       | 240           |\n",
      "|    total_timesteps    | 47000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.3         |\n",
      "|    explained_variance | 0.348         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9399          |\n",
      "|    policy_loss        | 0.151         |\n",
      "|    reward             | -0.0070585175 |\n",
      "|    std                | 127           |\n",
      "|    value_loss         | 2.37e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790895.5659673176\n",
      "Sharpe:  -0.4404719958892304\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.8        |\n",
      "|    explained_variance | 0.514        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | -0.379       |\n",
      "|    reward             | -0.006060863 |\n",
      "|    std                | 133          |\n",
      "|    value_loss         | 5.81e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796282.6785213986\n",
      "Sharpe:  -0.4634139969842069\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 195            |\n",
      "|    iterations         | 9600           |\n",
      "|    time_elapsed       | 245            |\n",
      "|    total_timesteps    | 48000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -57.2          |\n",
      "|    explained_variance | 0.185          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9599           |\n",
      "|    policy_loss        | 2.97           |\n",
      "|    reward             | -0.00044950465 |\n",
      "|    std                | 140            |\n",
      "|    value_loss         | 0.00438        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798658.7808866263\n",
      "Sharpe:  -0.5329436792673881\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.7        |\n",
      "|    explained_variance | 0.532        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 1.14         |\n",
      "|    reward             | -0.003263271 |\n",
      "|    std                | 147          |\n",
      "|    value_loss         | 0.000421     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784374.0806492028\n",
      "Sharpe:  -0.7457127473657091\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.1         |\n",
      "|    explained_variance | 0.115         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | 2.51          |\n",
      "|    reward             | -0.0064147697 |\n",
      "|    std                | 155           |\n",
      "|    value_loss         | 0.00258       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799526.3790668196\n",
      "Sharpe:  -0.728588744103495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796090.5922561653\n",
      "Sharpe:  -4.131539367803365\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 253           |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.6         |\n",
      "|    explained_variance | 0.421         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | 0.25          |\n",
      "|    reward             | -0.0041408455 |\n",
      "|    std                | 163           |\n",
      "|    value_loss         | 7.41e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793188.4672306856\n",
      "Sharpe:  -1.0564459560197734\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59          |\n",
      "|    explained_variance | -0.786       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 0.361        |\n",
      "|    reward             | -0.007605473 |\n",
      "|    std                | 171          |\n",
      "|    value_loss         | 4.73e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1014743.5590299997\n",
      "Sharpe:  1.8918573372990908\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.014743559030000242 -0.017052036133110866 1.891857337299091 0\n",
      "2023-11-01 00:00:00 2023-12-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_11_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741948.1506842737\n",
      "Sharpe:  -4.514154841012512\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795560.7727912177\n",
      "Sharpe:  -1.478704580756424\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 192           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | -17.9         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | 0.539         |\n",
      "|    reward             | -0.0023018157 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.00156       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799250.6059894258\n",
      "Sharpe:  -1.0801480013733815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794787.1551866315\n",
      "Sharpe:  -1.2180664919492987\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 193          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.506        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.151        |\n",
      "|    reward             | 0.0073909163 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0.404         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.543         |\n",
      "|    reward             | 0.00027396466 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.00129       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754686.8245498987\n",
      "Sharpe:  -0.23460169109204468\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | 0.77          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.0132        |\n",
      "|    reward             | -0.0015233648 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 3.02e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.81        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -0.103      |\n",
      "|    reward             | 0.008967594 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 4.25e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0.839         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.129        |\n",
      "|    reward             | -0.0027011742 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 0.00027       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1112926.9152375942\n",
      "Sharpe:  0.19110488198880252\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | -1.1        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.0429     |\n",
      "|    reward             | 0.007826148 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 3.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.402        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | -0.010111332 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 5.27e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765684.1411564403\n",
      "Sharpe:  -0.21564325594404557\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0.569         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.225        |\n",
      "|    reward             | -0.0034420185 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 0.000263      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790778.3762548754\n",
      "Sharpe:  -0.3025553465549\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0.672       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.0552      |\n",
      "|    reward             | -0.01824064 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 3.9e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798666.9120363678\n",
      "Sharpe:  -0.48868341403374105\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0.477       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.241      |\n",
      "|    reward             | 0.006910597 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 0.000211    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0.398        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.124        |\n",
      "|    reward             | 0.0112986425 |\n",
      "|    std                | 1.84         |\n",
      "|    value_loss         | 8.41e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.504        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0352      |\n",
      "|    reward             | -0.004279832 |\n",
      "|    std                | 1.93         |\n",
      "|    value_loss         | 1.25e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1267718.3731389437\n",
      "Sharpe:  0.31015518412444093\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.463       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.128       |\n",
      "|    reward             | 0.009313257 |\n",
      "|    std                | 2.04        |\n",
      "|    value_loss         | 9.06e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0.035        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.293        |\n",
      "|    reward             | -0.024540164 |\n",
      "|    std                | 2.16         |\n",
      "|    value_loss         | 0.000341     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764792.5304223704\n",
      "Sharpe:  -0.3709255477235312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.2         |\n",
      "|    explained_variance | 0.6           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.171        |\n",
      "|    reward             | -0.0039467104 |\n",
      "|    std                | 2.28          |\n",
      "|    value_loss         | 0.00011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 43            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.7         |\n",
      "|    explained_variance | 0.336         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0211       |\n",
      "|    reward             | -0.0040422287 |\n",
      "|    std                | 2.41          |\n",
      "|    value_loss         | 2.77e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752690.8863074684\n",
      "Sharpe:  -0.24364303318328673\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0.616        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.182       |\n",
      "|    reward             | 0.0069857887 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 0.436        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.314        |\n",
      "|    reward             | 0.0030667807 |\n",
      "|    std                | 2.68         |\n",
      "|    value_loss         | 0.000457     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793839.0562782243\n",
      "Sharpe:  -0.23852869622140324\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | 0.533        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.109       |\n",
      "|    reward             | 0.0013235674 |\n",
      "|    std                | 2.82         |\n",
      "|    value_loss         | 3.04e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794700.2584190558\n",
      "Sharpe:  -0.2995607411914897\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.00668      |\n",
      "|    reward             | 0.0001075053 |\n",
      "|    std                | 2.96         |\n",
      "|    value_loss         | 4.11e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796438.2568719613\n",
      "Sharpe:  -0.3458055484366775\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 197        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23        |\n",
      "|    explained_variance | 0.26       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 0.0827     |\n",
      "|    reward             | -0.0051857 |\n",
      "|    std                | 3.11       |\n",
      "|    value_loss         | 2.47e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:675825.5997680947\n",
      "Sharpe:  -0.8114947665675071\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 58            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.4         |\n",
      "|    explained_variance | -7.38         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | 0.0773        |\n",
      "|    reward             | -0.0051303934 |\n",
      "|    std                | 3.28          |\n",
      "|    value_loss         | 8.66e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0.5          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.0191       |\n",
      "|    reward             | 0.0014096759 |\n",
      "|    std                | 3.45         |\n",
      "|    value_loss         | 1.1e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797414.8739827957\n",
      "Sharpe:  -0.2602236987186919\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | 0.255         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.87         |\n",
      "|    reward             | -0.0036433833 |\n",
      "|    std                | 3.63          |\n",
      "|    value_loss         | 0.00132       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792515.699801508\n",
      "Sharpe:  -1.0044676470815603\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0.471       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.0895     |\n",
      "|    reward             | -0.03994297 |\n",
      "|    std                | 3.82        |\n",
      "|    value_loss         | 2.6e-05     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 197            |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 68             |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -25.3          |\n",
      "|    explained_variance | 0.268          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2699           |\n",
      "|    policy_loss        | 0.155          |\n",
      "|    reward             | -0.00048238473 |\n",
      "|    std                | 4.02           |\n",
      "|    value_loss         | 0.000162       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789817.095067202\n",
      "Sharpe:  -0.17959072716348168\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793891.0932851243\n",
      "Sharpe:  -1.6622115428738102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791833.4632016292\n",
      "Sharpe:  -0.956734237302444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762669.1683481918\n",
      "Sharpe:  -6.2802240900344675\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.423        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.0919      |\n",
      "|    reward             | 0.0013277536 |\n",
      "|    std                | 4.23         |\n",
      "|    value_loss         | 2.67e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0.285       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.199       |\n",
      "|    reward             | -0.00076685 |\n",
      "|    std                | 4.46        |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790404.9952064898\n",
      "Sharpe:  -0.6206822728338489\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763945.7120679729\n",
      "Sharpe:  -3.4652250006636485\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 75            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.7         |\n",
      "|    explained_variance | 0.648         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.0103        |\n",
      "|    reward             | 0.00019381027 |\n",
      "|    std                | 4.68          |\n",
      "|    value_loss         | 1.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.282        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.309        |\n",
      "|    reward             | 0.0007215229 |\n",
      "|    std                | 4.92         |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776851.6119341577\n",
      "Sharpe:  -0.15338448186150444\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.5      |\n",
      "|    explained_variance | 0.132      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -0.323     |\n",
      "|    reward             | 0.01189065 |\n",
      "|    std                | 5.16       |\n",
      "|    value_loss         | 0.000249   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:723178.8512766975\n",
      "Sharpe:  -0.8680602142715815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755758.7301427263\n",
      "Sharpe:  -2.9804463807887607\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | -0.594       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.16         |\n",
      "|    reward             | -0.008392076 |\n",
      "|    std                | 5.37         |\n",
      "|    value_loss         | 5.72e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775480.3521352862\n",
      "Sharpe:  -1.4534985340630102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793863.2370824652\n",
      "Sharpe:  -3.529321992395811\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 0.581        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -1.04        |\n",
      "|    reward             | -0.029097227 |\n",
      "|    std                | 5.63         |\n",
      "|    value_loss         | 0.00182      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779797.7264341353\n",
      "Sharpe:  -1.0473423186944786\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | 0.393         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.459         |\n",
      "|    reward             | -0.0056440714 |\n",
      "|    std                | 5.93          |\n",
      "|    value_loss         | 0.000277      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797295.751516783\n",
      "Sharpe:  -0.4861080882794893\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | -0.409      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 0.188       |\n",
      "|    reward             | 0.012680214 |\n",
      "|    std                | 6.23        |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.737        |\n",
      "|    reward             | 0.0076325005 |\n",
      "|    std                | 6.58         |\n",
      "|    value_loss         | 0.000719     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773728.09285126\n",
      "Sharpe:  -0.25138439805956797\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | 0.404         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.434         |\n",
      "|    reward             | -0.0042591076 |\n",
      "|    std                | 6.93          |\n",
      "|    value_loss         | 0.000232      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783288.8387504135\n",
      "Sharpe:  -0.5930752008562925\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | -0.39       |\n",
      "|    reward             | 0.004254586 |\n",
      "|    std                | 7.3         |\n",
      "|    value_loss         | 0.00015     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 198            |\n",
      "|    iterations         | 4000           |\n",
      "|    time_elapsed       | 100            |\n",
      "|    total_timesteps    | 20000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31.1          |\n",
      "|    explained_variance | -0.249         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3999           |\n",
      "|    policy_loss        | 0.347          |\n",
      "|    reward             | -0.00015770405 |\n",
      "|    std                | 7.68           |\n",
      "|    value_loss         | 0.000143       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:690347.8256914426\n",
      "Sharpe:  -0.3955515186842922\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793585.5078444525\n",
      "Sharpe:  -3.3143426705812358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791364.2325553156\n",
      "Sharpe:  -9.807638029205767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | -0.008770829 |\n",
      "|    std                | 8.05         |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0.54        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | -0.443      |\n",
      "|    reward             | 0.002842604 |\n",
      "|    std                | 8.46        |\n",
      "|    value_loss         | 0.000207    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795768.1361909894\n",
      "Sharpe:  -0.21014198432339726\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0.822        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.0999       |\n",
      "|    reward             | 0.0045736264 |\n",
      "|    std                | 8.88         |\n",
      "|    value_loss         | 1.53e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | -0.157       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | -0.295       |\n",
      "|    reward             | -0.006006102 |\n",
      "|    std                | 9.35         |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797796.1407377137\n",
      "Sharpe:  -0.3461137474869667\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.3      |\n",
      "|    explained_variance | 0.241      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -1.16      |\n",
      "|    reward             | 0.00839849 |\n",
      "|    std                | 9.84       |\n",
      "|    value_loss         | 0.00153    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798169.3371770816\n",
      "Sharpe:  -0.3315936206919349\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 115           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.8         |\n",
      "|    explained_variance | -1.61         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -0.0498       |\n",
      "|    reward             | -0.0026828726 |\n",
      "|    std                | 10.4          |\n",
      "|    value_loss         | 1.88e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792804.806373879\n",
      "Sharpe:  -1.2619555649973377\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779332.2311319717\n",
      "Sharpe:  -2.001293269969869\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0.252        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.215       |\n",
      "|    reward             | 0.0031327854 |\n",
      "|    std                | 10.9         |\n",
      "|    value_loss         | 4.54e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798288.1944399173\n",
      "Sharpe:  -0.729716304566362\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753646.9611666988\n",
      "Sharpe:  -6.371373076927052\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.7        |\n",
      "|    explained_variance | 0.134        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -0.384       |\n",
      "|    reward             | -0.006052693 |\n",
      "|    std                | 11.4         |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | 0.0011981351 |\n",
      "|    std                | 12           |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 126           |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.6         |\n",
      "|    explained_variance | 0.355         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0038422926 |\n",
      "|    std                | 12.7          |\n",
      "|    value_loss         | 0.000196      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796948.1602417176\n",
      "Sharpe:  -0.1716134393026688\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0.256        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | 0.0068344944 |\n",
      "|    std                | 13.2         |\n",
      "|    value_loss         | 9.97e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769013.5347713709\n",
      "Sharpe:  -0.8347156024074428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755041.5599637523\n",
      "Sharpe:  -1.5123095675354625\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749997.2553268486\n",
      "Sharpe:  -3.2060047391998334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791912.5156278361\n",
      "Sharpe:  -3.4228860242860164\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | 0.569        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | -0.004370493 |\n",
      "|    std                | 13.9         |\n",
      "|    value_loss         | 1.89e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 133          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.9        |\n",
      "|    explained_variance | 0.307        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0187      |\n",
      "|    reward             | 0.0044483747 |\n",
      "|    std                | 14.6         |\n",
      "|    value_loss         | 3.56e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781651.1573403276\n",
      "Sharpe:  -0.5598762943916861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 198           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 136           |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.3         |\n",
      "|    explained_variance | -0.763        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | -0.509        |\n",
      "|    reward             | -0.0111349905 |\n",
      "|    std                | 15.3          |\n",
      "|    value_loss         | 0.00023       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.8        |\n",
      "|    explained_variance | 0.279        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.647        |\n",
      "|    reward             | -0.008167045 |\n",
      "|    std                | 16.2         |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:743174.4936661937\n",
      "Sharpe:  -0.35412577242955434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784687.2321787424\n",
      "Sharpe:  -0.9116988095572197\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.2        |\n",
      "|    explained_variance | 0.4          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.385       |\n",
      "|    reward             | 0.0070936615 |\n",
      "|    std                | 17           |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766460.4635179184\n",
      "Sharpe:  -0.6620928482288733\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 198         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.7       |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.0248     |\n",
      "|    reward             | 0.011108482 |\n",
      "|    std                | 17.8        |\n",
      "|    value_loss         | 2.02e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762982.9725687936\n",
      "Sharpe:  -0.9300745282376599\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.1        |\n",
      "|    explained_variance | 0.396        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.0185      |\n",
      "|    reward             | 0.0016502967 |\n",
      "|    std                | 18.7         |\n",
      "|    value_loss         | 2.63e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:716028.8402701238\n",
      "Sharpe:  -0.8154890038359676\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778771.0056675619\n",
      "Sharpe:  -7.22411073796931\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.6        |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.51         |\n",
      "|    reward             | -0.005673167 |\n",
      "|    std                | 19.8         |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791226.8485221541\n",
      "Sharpe:  -0.7692734770153016\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40          |\n",
      "|    explained_variance | 0.196        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.663       |\n",
      "|    reward             | -0.002051858 |\n",
      "|    std                | 20.8         |\n",
      "|    value_loss         | 0.000334     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0.684       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.548      |\n",
      "|    reward             | 0.020673629 |\n",
      "|    std                | 21.8        |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757186.2962169424\n",
      "Sharpe:  -0.38630930276023034\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775941.3979477661\n",
      "Sharpe:  -3.6697249359998567\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781459.8076573976\n",
      "Sharpe:  -1.6851467009886472\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 156           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.9         |\n",
      "|    explained_variance | -0.656        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | -0.34         |\n",
      "|    reward             | -0.0033216565 |\n",
      "|    std                | 22.9          |\n",
      "|    value_loss         | 0.000134      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777878.4351923604\n",
      "Sharpe:  -0.7052769408162343\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0.6         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.005424988 |\n",
      "|    std                | 24.1        |\n",
      "|    value_loss         | 5.23e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768424.6410599024\n",
      "Sharpe:  -0.6636899918251183\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6400          |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 32000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.9         |\n",
      "|    explained_variance | 0.000419      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6399          |\n",
      "|    policy_loss        | 1.01          |\n",
      "|    reward             | -0.0030481045 |\n",
      "|    std                | 25.5          |\n",
      "|    value_loss         | 0.000694      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:742332.0610853004\n",
      "Sharpe:  -3.675331761564957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756818.7724608764\n",
      "Sharpe:  -0.9746676691364714\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.0285       |\n",
      "|    reward             | 0.0050937636 |\n",
      "|    std                | 26.9         |\n",
      "|    value_loss         | 1.69e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 167           |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 0.0619        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -0.231        |\n",
      "|    reward             | -0.0041308594 |\n",
      "|    std                | 28.4          |\n",
      "|    value_loss         | 3.15e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776167.5008055886\n",
      "Sharpe:  -0.5663807733272614\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0.412       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.431      |\n",
      "|    reward             | 0.003541254 |\n",
      "|    std                | 30          |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796958.136909766\n",
      "Sharpe:  -0.556809230632222\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.8         |\n",
      "|    explained_variance | 0.876         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | 0.0797        |\n",
      "|    reward             | -0.0023905572 |\n",
      "|    std                | 31.6          |\n",
      "|    value_loss         | 4.4e-06       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781477.8512630571\n",
      "Sharpe:  -1.598193001288494\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6900          |\n",
      "|    time_elapsed       | 174           |\n",
      "|    total_timesteps    | 34500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.3         |\n",
      "|    explained_variance | 0.334         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6899          |\n",
      "|    policy_loss        | 0.0927        |\n",
      "|    reward             | -0.0012552884 |\n",
      "|    std                | 33.4          |\n",
      "|    value_loss         | 8.07e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.8       |\n",
      "|    explained_variance | 0.49        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -0.83       |\n",
      "|    reward             | 0.009913892 |\n",
      "|    std                | 35.1        |\n",
      "|    value_loss         | 0.000452    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:727976.813322709\n",
      "Sharpe:  -0.3309828667178565\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794964.3071290395\n",
      "Sharpe:  -1.5879862581973956\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.2        |\n",
      "|    explained_variance | -4.87        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | -0.942       |\n",
      "|    reward             | -0.005820239 |\n",
      "|    std                | 36.8         |\n",
      "|    value_loss         | 0.000524     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794234.3902061774\n",
      "Sharpe:  -1.4059087786864295\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794169.3145541232\n",
      "Sharpe:  -4.442268848392102\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 182           |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.6         |\n",
      "|    explained_variance | 0.128         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | -0.148        |\n",
      "|    reward             | -0.0030625039 |\n",
      "|    std                | 38.6          |\n",
      "|    value_loss         | 2.84e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:693434.8431463327\n",
      "Sharpe:  -0.4290394128767174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795849.7176737671\n",
      "Sharpe:  -3.5932802394545784\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.1        |\n",
      "|    explained_variance | 0.549        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | 0.0437       |\n",
      "|    reward             | 0.0025729956 |\n",
      "|    std                | 40.6         |\n",
      "|    value_loss         | 8.93e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798844.3759330153\n",
      "Sharpe:  -1.0904517437966794\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 187           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.6         |\n",
      "|    explained_variance | -0.372        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.997         |\n",
      "|    reward             | -0.0011367246 |\n",
      "|    std                | 42.8          |\n",
      "|    value_loss         | 0.000538      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780096.5559862346\n",
      "Sharpe:  -0.6814961668166657\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47          |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -0.881       |\n",
      "|    reward             | -0.018923562 |\n",
      "|    std                | 45.1         |\n",
      "|    value_loss         | 0.000399     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799096.9430343838\n",
      "Sharpe:  -0.3669877288118303\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.4        |\n",
      "|    explained_variance | 0.828        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | -0.005698262 |\n",
      "|    std                | 47.1         |\n",
      "|    value_loss         | 1.38e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.9       |\n",
      "|    explained_variance | -0.0438     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -0.701      |\n",
      "|    reward             | 0.003010327 |\n",
      "|    std                | 49.4        |\n",
      "|    value_loss         | 0.000255    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783702.9443078038\n",
      "Sharpe:  -0.31507957773188466\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788909.7783620674\n",
      "Sharpe:  -1.7860624660168618\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 197           |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.3         |\n",
      "|    explained_variance | 0.33          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | 0.0288        |\n",
      "|    reward             | -0.0029091144 |\n",
      "|    std                | 51.8          |\n",
      "|    value_loss         | 2.22e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.7       |\n",
      "|    explained_variance | 0.271       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.577       |\n",
      "|    reward             | 0.007510224 |\n",
      "|    std                | 54.4        |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755564.4062769996\n",
      "Sharpe:  -0.5615736450972626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787691.0113336295\n",
      "Sharpe:  -1.6335743756906833\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.1        |\n",
      "|    explained_variance | 0.215        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | -0.749       |\n",
      "|    reward             | -0.006756606 |\n",
      "|    std                | 56.7         |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:698327.6969534552\n",
      "Sharpe:  -0.8656503080265275\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.5       |\n",
      "|    explained_variance | -0.715      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -0.13       |\n",
      "|    reward             | 0.007125616 |\n",
      "|    std                | 59.3        |\n",
      "|    value_loss         | 9.19e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786346.6667223261\n",
      "Sharpe:  -0.714361777812809\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.9        |\n",
      "|    explained_variance | 0.106        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | 3.54         |\n",
      "|    reward             | 0.0013964338 |\n",
      "|    std                | 61.6         |\n",
      "|    value_loss         | 0.00685      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789500.3132304371\n",
      "Sharpe:  -0.42200276352874927\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.2       |\n",
      "|    explained_variance | 0.521       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.518      |\n",
      "|    reward             | 0.008112405 |\n",
      "|    std                | 64.4        |\n",
      "|    value_loss         | 0.00011     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792978.3196720266\n",
      "Sharpe:  -0.7695857750913856\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797551.0544745467\n",
      "Sharpe:  -4.090317324157193\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758377.0088596715\n",
      "Sharpe:  -7.60089998970512\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 197        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.6      |\n",
      "|    explained_variance | -0.0329    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -0.332     |\n",
      "|    reward             | 0.01113539 |\n",
      "|    std                | 67.4       |\n",
      "|    value_loss         | 0.000124   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51         |\n",
      "|    explained_variance | 0.485       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 0.252       |\n",
      "|    reward             | 0.015652744 |\n",
      "|    std                | 70.5        |\n",
      "|    value_loss         | 3.28e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:695118.5183965642\n",
      "Sharpe:  -0.4594239675883292\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.5        |\n",
      "|    explained_variance | 0.195        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.805        |\n",
      "|    reward             | -0.014097616 |\n",
      "|    std                | 74           |\n",
      "|    value_loss         | 0.000288     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:721837.4848904922\n",
      "Sharpe:  -0.6582384107421245\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.9       |\n",
      "|    explained_variance | -0.192      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -0.788      |\n",
      "|    reward             | 0.016009739 |\n",
      "|    std                | 77.7        |\n",
      "|    value_loss         | 0.000547    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.3       |\n",
      "|    explained_variance | 0.0655      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.718      |\n",
      "|    reward             | 0.032828342 |\n",
      "|    std                | 81.2        |\n",
      "|    value_loss         | 0.000227    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782526.2403957337\n",
      "Sharpe:  -0.2512151152931701\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 225          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.8        |\n",
      "|    explained_variance | 0.136        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | -0.011544745 |\n",
      "|    std                | 85.3         |\n",
      "|    value_loss         | 5.78e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796414.733243603\n",
      "Sharpe:  -1.3293525529905859\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783301.0495156851\n",
      "Sharpe:  -1.177012214671634\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 9000           |\n",
      "|    time_elapsed       | 228            |\n",
      "|    total_timesteps    | 45000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -53.2          |\n",
      "|    explained_variance | 0.257          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8999           |\n",
      "|    policy_loss        | 0.506          |\n",
      "|    reward             | -9.6973185e-05 |\n",
      "|    std                | 89.8           |\n",
      "|    value_loss         | 0.000135       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797827.8968276547\n",
      "Sharpe:  -1.9606944420436085\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.7       |\n",
      "|    explained_variance | 0.293       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | 0.005527765 |\n",
      "|    std                | 94.5        |\n",
      "|    value_loss         | 1.28e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784495.8838728343\n",
      "Sharpe:  -0.4588927729236719\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.1       |\n",
      "|    explained_variance | 0.576       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.0621      |\n",
      "|    reward             | 0.003228106 |\n",
      "|    std                | 99.4        |\n",
      "|    value_loss         | 3.88e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785058.8204398202\n",
      "Sharpe:  -0.8063876608681402\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.6        |\n",
      "|    explained_variance | -0.919       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | -0.004719375 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 3.25e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763516.8927023121\n",
      "Sharpe:  -0.817201441413852\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.1        |\n",
      "|    explained_variance | -0.436       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.624       |\n",
      "|    reward             | 0.0025969136 |\n",
      "|    std                | 110          |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793718.7648463835\n",
      "Sharpe:  -0.8084067313512185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757816.6287778371\n",
      "Sharpe:  -1.7393275652917601\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.5        |\n",
      "|    explained_variance | 0.466        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 0.227        |\n",
      "|    reward             | -0.016519241 |\n",
      "|    std                | 116          |\n",
      "|    value_loss         | 3.27e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792630.433084456\n",
      "Sharpe:  -0.4749886101343791\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56          |\n",
      "|    explained_variance | 0.0438       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.988        |\n",
      "|    reward             | -0.006149646 |\n",
      "|    std                | 122          |\n",
      "|    value_loss         | 0.00102      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799400.032106864\n",
      "Sharpe:  -1.8678231052729046\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 246           |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.4         |\n",
      "|    explained_variance | -1.36         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | -0.546        |\n",
      "|    reward             | 5.9185026e-05 |\n",
      "|    std                | 128           |\n",
      "|    value_loss         | 0.000107      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786676.9574226995\n",
      "Sharpe:  -1.1165945814274925\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788969.6134545759\n",
      "Sharpe:  -1.611554895268437\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.8        |\n",
      "|    explained_variance | 0.0625       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.603       |\n",
      "|    reward             | 0.0016711163 |\n",
      "|    std                | 134          |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765538.2713292049\n",
      "Sharpe:  -0.6312780738410714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774797.2951434113\n",
      "Sharpe:  -2.9046682416029626\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.3        |\n",
      "|    explained_variance | 0.283        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.185       |\n",
      "|    reward             | -0.000691562 |\n",
      "|    std                | 141          |\n",
      "|    value_loss         | 1.8e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766783.8068350422\n",
      "Sharpe:  -0.9201592672640285\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.8        |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -0.127       |\n",
      "|    reward             | -0.006284449 |\n",
      "|    std                | 149          |\n",
      "|    value_loss         | 1.12e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:977813.415146671\n",
      "Sharpe:  -4.37876684127245\n",
      "=================================\n",
      "hit end!\n",
      "a2c -0.02218658485332925 -0.022186584853329236 -4.37876684127245 0\n",
      "2023-12-01 00:00:00 2024-01-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_12_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777226.1856380822\n",
      "Sharpe:  -0.40950666351458764\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 184          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.744       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | 0.0065000495 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 9.52e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797042.917356588\n",
      "Sharpe:  -1.0063476233371842\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 190           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | -0.133        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.103        |\n",
      "|    reward             | -0.0010478471 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.000107      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799404.8190738629\n",
      "Sharpe:  -1.495826283319684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797657.5263145744\n",
      "Sharpe:  -1.3344644123408518\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795428.1459096442\n",
      "Sharpe:  -2.9444431226556347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 193           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0.708         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0343        |\n",
      "|    reward             | -0.0019469471 |\n",
      "|    std                | 1.18          |\n",
      "|    value_loss         | 7.95e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795047.4118200676\n",
      "Sharpe:  -0.964724586892959\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0.328       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.49        |\n",
      "|    reward             | 0.008371921 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 193            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 12             |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.2          |\n",
      "|    explained_variance | 0.361          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | 0.168          |\n",
      "|    reward             | -0.00060048205 |\n",
      "|    std                | 1.31           |\n",
      "|    value_loss         | 0.000165       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783563.5736253967\n",
      "Sharpe:  -0.4601638259052738\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798534.8099406305\n",
      "Sharpe:  -1.0806088816240917\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 193          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.454        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.209       |\n",
      "|    reward             | 0.0045221127 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 0.000365     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0.269       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.434      |\n",
      "|    reward             | 0.027153118 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.000885    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741664.8907691778\n",
      "Sharpe:  -0.35209293698454924\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -1.64       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.0527     |\n",
      "|    reward             | 0.016314834 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 1.98e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0.906         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0356       |\n",
      "|    reward             | -0.0054096743 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 5.82e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | 0.545         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0804       |\n",
      "|    reward             | -0.0048535494 |\n",
      "|    std                | 1.7           |\n",
      "|    value_loss         | 2.5e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:913293.4751792459\n",
      "Sharpe:  -0.044910412199198946\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784633.5006582736\n",
      "Sharpe:  -3.2023179203842402\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0417       |\n",
      "|    reward             | 0.0021913995 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 8.36e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0.354        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0092      |\n",
      "|    reward             | 0.0052634855 |\n",
      "|    std                | 1.9          |\n",
      "|    value_loss         | 9.28e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0.686         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.0416       |\n",
      "|    reward             | -0.0016067728 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 6.33e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1012761.2195284435\n",
      "Sharpe:  0.09226636049223383\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 0.463       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0889      |\n",
      "|    reward             | 0.001814039 |\n",
      "|    std                | 2.12        |\n",
      "|    value_loss         | 3.92e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 1500           |\n",
      "|    time_elapsed       | 38             |\n",
      "|    total_timesteps    | 7500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.1          |\n",
      "|    explained_variance | 0.0727         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1499           |\n",
      "|    policy_loss        | -0.237         |\n",
      "|    reward             | -2.8379907e-05 |\n",
      "|    std                | 2.25           |\n",
      "|    value_loss         | 0.000139       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.156        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.0131      |\n",
      "|    reward             | 0.0055004335 |\n",
      "|    std                | 2.37         |\n",
      "|    value_loss         | 1.38e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1155492.3544979473\n",
      "Sharpe:  0.22895873622905938\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0.653        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.003724322 |\n",
      "|    std                | 2.51         |\n",
      "|    value_loss         | 3.66e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797013.7330305523\n",
      "Sharpe:  -0.4584864266815872\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792769.1574803152\n",
      "Sharpe:  -5.444761843059559\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0.381        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.293       |\n",
      "|    reward             | 0.0074662287 |\n",
      "|    std                | 2.64         |\n",
      "|    value_loss         | 0.000225     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0604      |\n",
      "|    reward             | 0.0019542337 |\n",
      "|    std                | 2.79         |\n",
      "|    value_loss         | 3.08e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.5         |\n",
      "|    explained_variance | 0.486         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.146        |\n",
      "|    reward             | -0.0010886368 |\n",
      "|    std                | 2.95          |\n",
      "|    value_loss         | 7.76e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1319995.6229079573\n",
      "Sharpe:  0.4154653326323157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796944.8617482189\n",
      "Sharpe:  -4.940258298011639\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | 0.489        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.272       |\n",
      "|    reward             | 0.0046183635 |\n",
      "|    std                | 3.1          |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.469        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.0774      |\n",
      "|    reward             | -0.024012893 |\n",
      "|    std                | 3.26         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1165883.7248717777\n",
      "Sharpe:  0.2389779058769037\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.000892   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.145       |\n",
      "|    reward             | 0.005977271 |\n",
      "|    std                | 3.44        |\n",
      "|    value_loss         | 5.96e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:700686.5689799892\n",
      "Sharpe:  -0.9060465608653919\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 0.401        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | -0.00413     |\n",
      "|    reward             | 0.0102269715 |\n",
      "|    std                | 3.63         |\n",
      "|    value_loss         | 3.56e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796107.1327794251\n",
      "Sharpe:  -0.45995680298451097\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0.834         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | 0.0221        |\n",
      "|    reward             | -0.0005983381 |\n",
      "|    std                | 3.83          |\n",
      "|    value_loss         | 4.4e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | 0.495        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | -0.0846      |\n",
      "|    reward             | 0.0036909315 |\n",
      "|    std                | 4.03         |\n",
      "|    value_loss         | 2.23e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026322.7115086133\n",
      "Sharpe:  0.11951418858162188\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -1.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | 1.14e-05     |\n",
      "|    reward             | -0.008412596 |\n",
      "|    std                | 4.25         |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | 0.124         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | 0.102         |\n",
      "|    reward             | -0.0007613306 |\n",
      "|    std                | 4.48          |\n",
      "|    value_loss         | 2.46e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | 0.571       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -0.0174     |\n",
      "|    reward             | 0.004524177 |\n",
      "|    std                | 4.72        |\n",
      "|    value_loss         | 1.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1068610.1889109425\n",
      "Sharpe:  0.1745788102127476\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.18       |\n",
      "|    reward             | 0.007348379 |\n",
      "|    std                | 4.98        |\n",
      "|    value_loss         | 7.26e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 0.473        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.15        |\n",
      "|    reward             | 0.0002529498 |\n",
      "|    std                | 5.25         |\n",
      "|    value_loss         | 4.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.512        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | -0.004842254 |\n",
      "|    std                | 5.53         |\n",
      "|    value_loss         | 4.48e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1019021.4326520436\n",
      "Sharpe:  0.10413331119161066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771894.0256180294\n",
      "Sharpe:  -0.6618278851139324\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.6      |\n",
      "|    explained_variance | 0.217      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 1.09       |\n",
      "|    reward             | 0.00978433 |\n",
      "|    std                | 5.84       |\n",
      "|    value_loss         | 0.00216    |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 198            |\n",
      "|    iterations         | 3400           |\n",
      "|    time_elapsed       | 85             |\n",
      "|    total_timesteps    | 17000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.1          |\n",
      "|    explained_variance | 0.154          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3399           |\n",
      "|    policy_loss        | -0.131         |\n",
      "|    reward             | -0.00052002823 |\n",
      "|    std                | 6.14           |\n",
      "|    value_loss         | 5.64e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736875.7858509863\n",
      "Sharpe:  -0.5421884990454449\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | -0.149       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -0.49        |\n",
      "|    reward             | -0.018208304 |\n",
      "|    std                | 6.44         |\n",
      "|    value_loss         | 0.000395     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0.263       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.398      |\n",
      "|    reward             | 0.002603144 |\n",
      "|    std                | 6.76        |\n",
      "|    value_loss         | 0.000411    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:708054.9325588793\n",
      "Sharpe:  -0.40553669981476714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794890.3381514379\n",
      "Sharpe:  -6.077168399891303\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 199           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0.524         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.14         |\n",
      "|    reward             | -0.0030673137 |\n",
      "|    std                | 7.08          |\n",
      "|    value_loss         | 2.66e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 199          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0.0396       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.254       |\n",
      "|    reward             | 0.0035408982 |\n",
      "|    std                | 7.46         |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795253.0510341552\n",
      "Sharpe:  -0.18085258868792242\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 199          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0.736        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.439        |\n",
      "|    reward             | -0.007153313 |\n",
      "|    std                | 7.84         |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797048.7426037402\n",
      "Sharpe:  -0.6214918457741634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761727.1733559044\n",
      "Sharpe:  -6.747464548117851\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782816.0948338619\n",
      "Sharpe:  -1.5363290123305526\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794159.2935904652\n",
      "Sharpe:  -2.249948402415336\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 199          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | -0.155       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.0187       |\n",
      "|    reward             | -0.000854446 |\n",
      "|    std                | 8.24         |\n",
      "|    value_loss         | 2.06e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 0.592       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.389      |\n",
      "|    reward             | 0.004054606 |\n",
      "|    std                | 8.66        |\n",
      "|    value_loss         | 0.000143    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785819.2957706435\n",
      "Sharpe:  -0.32405178745323276\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 104          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.6        |\n",
      "|    explained_variance | 0.657        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.297       |\n",
      "|    reward             | 0.0040976293 |\n",
      "|    std                | 9.11         |\n",
      "|    value_loss         | 8.67e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789281.162187837\n",
      "Sharpe:  -0.6297431210778694\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.0838       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.0263      |\n",
      "|    reward             | 0.0016036092 |\n",
      "|    std                | 9.6          |\n",
      "|    value_loss         | 4.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | -0.416       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.00707      |\n",
      "|    reward             | 0.0018669826 |\n",
      "|    std                | 10.1         |\n",
      "|    value_loss         | 7.21e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773376.6254587253\n",
      "Sharpe:  -0.28651427791696604\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | -0.14        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.0783       |\n",
      "|    reward             | 0.0053625023 |\n",
      "|    std                | 10.6         |\n",
      "|    value_loss         | 1.07e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790563.0520564633\n",
      "Sharpe:  -0.44543756750032504\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.0195      |\n",
      "|    reward             | 0.0032701502 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 5.02e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | 0.446        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.373        |\n",
      "|    reward             | 0.0012113804 |\n",
      "|    std                | 11.8         |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792769.4423412199\n",
      "Sharpe:  -0.3636516848088244\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 200          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 0.378        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -0.302       |\n",
      "|    reward             | 0.0036017098 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 9.95e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0.291        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.114       |\n",
      "|    reward             | -0.016301142 |\n",
      "|    std                | 13           |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784939.5075716565\n",
      "Sharpe:  -0.3971873161892139\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.3       |\n",
      "|    explained_variance | -0.00571    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.37       |\n",
      "|    reward             | 0.007816068 |\n",
      "|    std                | 13.7        |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794910.6730608274\n",
      "Sharpe:  -0.24762537409128318\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 201            |\n",
      "|    iterations         | 5100           |\n",
      "|    time_elapsed       | 126            |\n",
      "|    total_timesteps    | 25500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -36.8          |\n",
      "|    explained_variance | 0.249          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5099           |\n",
      "|    policy_loss        | -0.0462        |\n",
      "|    reward             | -0.00059080974 |\n",
      "|    std                | 14.4           |\n",
      "|    value_loss         | 0.00103        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796660.8417759009\n",
      "Sharpe:  -0.4297461527827362\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.2         |\n",
      "|    explained_variance | 0.34          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.0659        |\n",
      "|    reward             | -0.0008437373 |\n",
      "|    std                | 15.2          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | 0.393        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.178        |\n",
      "|    reward             | 0.0102275815 |\n",
      "|    std                | 16           |\n",
      "|    value_loss         | 5.74e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735212.9991170504\n",
      "Sharpe:  -0.5583518707993279\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 133          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | 0.0037360606 |\n",
      "|    std                | 16.7         |\n",
      "|    value_loss         | 1.6e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772558.4920064935\n",
      "Sharpe:  -0.8960942722001805\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784663.979315203\n",
      "Sharpe:  -1.1200464112803576\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 136           |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.6         |\n",
      "|    explained_variance | 0.255         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | -0.503        |\n",
      "|    reward             | -0.0019316294 |\n",
      "|    std                | 17.6          |\n",
      "|    value_loss         | 0.000181      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793741.9857747135\n",
      "Sharpe:  -0.7370029391115839\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39          |\n",
      "|    explained_variance | 0.484        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | 0.203        |\n",
      "|    reward             | 0.0029740268 |\n",
      "|    std                | 18.5         |\n",
      "|    value_loss         | 4.36e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 141           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.5         |\n",
      "|    explained_variance | 0.258         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.00105      |\n",
      "|    reward             | -0.0048619155 |\n",
      "|    std                | 19.5          |\n",
      "|    value_loss         | 1.22e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776677.0174778524\n",
      "Sharpe:  -0.3595905465325078\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789568.1151114661\n",
      "Sharpe:  -2.169415566541613\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 0.336        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.226       |\n",
      "|    reward             | -0.007945246 |\n",
      "|    std                | 20.5         |\n",
      "|    value_loss         | 3.61e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 145           |\n",
      "|    total_timesteps    | 29500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.4         |\n",
      "|    explained_variance | 0.424         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5899          |\n",
      "|    policy_loss        | 0.646         |\n",
      "|    reward             | -0.0038738772 |\n",
      "|    std                | 21.6          |\n",
      "|    value_loss         | 0.00025       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795826.5564194904\n",
      "Sharpe:  -0.2630324971938034\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.8        |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.356       |\n",
      "|    reward             | 0.0013158688 |\n",
      "|    std                | 22.6         |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:676027.6924593844\n",
      "Sharpe:  -0.869108374708386\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.3        |\n",
      "|    explained_variance | 0.268        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -0.189       |\n",
      "|    reward             | 0.0024080777 |\n",
      "|    std                | 23.8         |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.8         |\n",
      "|    explained_variance | 0.106         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.148         |\n",
      "|    reward             | -0.0036961762 |\n",
      "|    std                | 25.1          |\n",
      "|    value_loss         | 7.58e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726269.2045054951\n",
      "Sharpe:  -0.4143999921375453\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764767.3178985318\n",
      "Sharpe:  -1.9856502081435434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767170.04483874\n",
      "Sharpe:  -2.2933117986437894\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -0.381       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -0.521       |\n",
      "|    reward             | 0.0020027068 |\n",
      "|    std                | 26.2         |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770854.2876824391\n",
      "Sharpe:  -1.9016684001757027\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0.332        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.211       |\n",
      "|    reward             | -0.006637525 |\n",
      "|    std                | 27.4         |\n",
      "|    value_loss         | 3.12e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783664.8257397022\n",
      "Sharpe:  -0.5585722099943892\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778582.9907144383\n",
      "Sharpe:  -3.9128207878013583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751327.782144589\n",
      "Sharpe:  -8.780438485144401\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795639.2919033557\n",
      "Sharpe:  -1.5487016719075595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775335.5224995748\n",
      "Sharpe:  -8.259290084943027\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | -0.495        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | -0.953        |\n",
      "|    reward             | -0.0069511407 |\n",
      "|    std                | 28.6          |\n",
      "|    value_loss         | 0.00057       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769542.5546475482\n",
      "Sharpe:  -2.2289919938185596\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795486.1850999341\n",
      "Sharpe:  -1.1226596151448158\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0.701       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.0971     |\n",
      "|    reward             | 0.008946615 |\n",
      "|    std                | 30          |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779483.7453719636\n",
      "Sharpe:  -0.5946605256917674\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.8       |\n",
      "|    explained_variance | 0.482       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.77       |\n",
      "|    reward             | 0.015865585 |\n",
      "|    std                | 31.3        |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.2        |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.208        |\n",
      "|    reward             | -0.029014295 |\n",
      "|    std                | 33           |\n",
      "|    value_loss         | 3.82e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797538.6947398181\n",
      "Sharpe:  -0.25026287517721263\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 6900          |\n",
      "|    time_elapsed       | 170           |\n",
      "|    total_timesteps    | 34500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.7         |\n",
      "|    explained_variance | -0.122        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6899          |\n",
      "|    policy_loss        | -0.268        |\n",
      "|    reward             | -0.0019422867 |\n",
      "|    std                | 34.7          |\n",
      "|    value_loss         | 5.76e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799197.8205678074\n",
      "Sharpe:  -1.695758041503352\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794690.9906232193\n",
      "Sharpe:  -1.5002896880237495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799666.3589204515\n",
      "Sharpe:  -2.853791733495193\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 7000          |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 35000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.1         |\n",
      "|    explained_variance | 0.783         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6999          |\n",
      "|    policy_loss        | 0.113         |\n",
      "|    reward             | -0.0028162443 |\n",
      "|    std                | 36.4          |\n",
      "|    value_loss         | 2.1e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758761.9731640154\n",
      "Sharpe:  -1.1317082216164844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797286.062722645\n",
      "Sharpe:  -3.5975341602272097\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.6        |\n",
      "|    explained_variance | 0.0393       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.293        |\n",
      "|    reward             | -0.015414496 |\n",
      "|    std                | 38.4         |\n",
      "|    value_loss         | 5.47e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787196.4177636568\n",
      "Sharpe:  -0.7364381919439679\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46          |\n",
      "|    explained_variance | 0.683        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | 0.587        |\n",
      "|    reward             | 0.0017062682 |\n",
      "|    std                | 40.3         |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795981.7751117261\n",
      "Sharpe:  -1.8622630178092352\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791802.8250863143\n",
      "Sharpe:  -1.14341090344459\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 179           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.5         |\n",
      "|    explained_variance | 0.86          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0027238426 |\n",
      "|    std                | 42.5          |\n",
      "|    value_loss         | 1.65e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.9        |\n",
      "|    explained_variance | 0.0734       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -0.0502      |\n",
      "|    reward             | 0.0015394422 |\n",
      "|    std                | 44.5         |\n",
      "|    value_loss         | 3.93e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798563.517712701\n",
      "Sharpe:  -0.3484910126608544\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790819.7497084924\n",
      "Sharpe:  -3.196657113481044\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.3        |\n",
      "|    explained_variance | -1.98        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -0.0401      |\n",
      "|    reward             | 0.0066125114 |\n",
      "|    std                | 46.6         |\n",
      "|    value_loss         | 2.91e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 187           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.8         |\n",
      "|    explained_variance | 0.131         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | 0.758         |\n",
      "|    reward             | -0.0013477253 |\n",
      "|    std                | 49            |\n",
      "|    value_loss         | 0.000352      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797525.882509496\n",
      "Sharpe:  -0.2901562859275837\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780273.2285074792\n",
      "Sharpe:  -10.79287832513512\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 189           |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.2         |\n",
      "|    explained_variance | 0.372         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | -0.393        |\n",
      "|    reward             | -0.0043228455 |\n",
      "|    std                | 51.5          |\n",
      "|    value_loss         | 0.000119      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -48.7      |\n",
      "|    explained_variance | 0.536      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 0.564      |\n",
      "|    reward             | 0.00160202 |\n",
      "|    std                | 54.3       |\n",
      "|    value_loss         | 0.00015    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718881.9867477814\n",
      "Sharpe:  -0.2884033770808746\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.2        |\n",
      "|    explained_variance | 0.34         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.325       |\n",
      "|    reward             | -0.006788775 |\n",
      "|    std                | 57.1         |\n",
      "|    value_loss         | 6.17e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786223.8923521119\n",
      "Sharpe:  -0.929193481999652\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758125.9085585204\n",
      "Sharpe:  -5.724225278681957\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.6       |\n",
      "|    explained_variance | -0.464      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.504       |\n",
      "|    reward             | 0.013141809 |\n",
      "|    std                | 59.9        |\n",
      "|    value_loss         | 0.0001      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796220.4545199455\n",
      "Sharpe:  -1.1004732875412941\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50         |\n",
      "|    explained_variance | 0.0227      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -0.564      |\n",
      "|    reward             | 0.008192387 |\n",
      "|    std                | 63          |\n",
      "|    value_loss         | 0.000244    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688498.7978729049\n",
      "Sharpe:  -0.9349351299676204\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796483.6774001229\n",
      "Sharpe:  -4.678745405769065\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 202        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.4      |\n",
      "|    explained_variance | 0.787      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -0.505     |\n",
      "|    reward             | 0.00730253 |\n",
      "|    std                | 65.9       |\n",
      "|    value_loss         | 0.000101   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.9        |\n",
      "|    explained_variance | 0.2          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.605       |\n",
      "|    reward             | -0.008022986 |\n",
      "|    std                | 69.1         |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799821.6474658704\n",
      "Sharpe:  -0.10781598391969432\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.3     |\n",
      "|    explained_variance | 0.571     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 0.528     |\n",
      "|    reward             | 0.0093968 |\n",
      "|    std                | 72.6      |\n",
      "|    value_loss         | 0.000177  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781764.5186676603\n",
      "Sharpe:  -0.49990652399156155\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.8       |\n",
      "|    explained_variance | 0.331       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 0.315       |\n",
      "|    reward             | 0.012224976 |\n",
      "|    std                | 76.2        |\n",
      "|    value_loss         | 4.07e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799149.0144987834\n",
      "Sharpe:  -1.1956216485321245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779999.5309709045\n",
      "Sharpe:  -3.056413083483379\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.2       |\n",
      "|    explained_variance | 0.593       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 0.267       |\n",
      "|    reward             | -0.00447139 |\n",
      "|    std                | 79.8        |\n",
      "|    value_loss         | 3.74e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795477.743493795\n",
      "Sharpe:  -1.3818284492017274\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 214          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.6        |\n",
      "|    explained_variance | -0.661       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.005955517 |\n",
      "|    std                | 83.6         |\n",
      "|    value_loss         | 3e-05        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53         |\n",
      "|    explained_variance | 0.128       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 0.428       |\n",
      "|    reward             | -0.00247807 |\n",
      "|    std                | 87.6        |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794615.2919863109\n",
      "Sharpe:  -0.11753267324826976\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.4       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | -0.411      |\n",
      "|    reward             | 0.027302846 |\n",
      "|    std                | 91.6        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796540.9832904959\n",
      "Sharpe:  -0.5363195329723732\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 221           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.9         |\n",
      "|    explained_variance | 0.831         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.719         |\n",
      "|    reward             | -0.0043684454 |\n",
      "|    std                | 96.3          |\n",
      "|    value_loss         | 0.000172      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798187.9291992072\n",
      "Sharpe:  -1.3929227858346576\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 224          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.3        |\n",
      "|    explained_variance | 0.0479       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.401       |\n",
      "|    reward             | -0.003768929 |\n",
      "|    std                | 102          |\n",
      "|    value_loss         | 5.91e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797110.4129172743\n",
      "Sharpe:  -0.8746006257632576\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761457.6510926711\n",
      "Sharpe:  -1.6834317571626143\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.8       |\n",
      "|    explained_variance | 0.204       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -0.547      |\n",
      "|    reward             | 0.011119956 |\n",
      "|    std                | 107         |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.2       |\n",
      "|    explained_variance | -0.026      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -0.00766    |\n",
      "|    reward             | 0.008981589 |\n",
      "|    std                | 112         |\n",
      "|    value_loss         | 2.86e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784519.2248380973\n",
      "Sharpe:  -0.6006080413359548\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 203            |\n",
      "|    iterations         | 9400           |\n",
      "|    time_elapsed       | 231            |\n",
      "|    total_timesteps    | 47000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -55.7          |\n",
      "|    explained_variance | 0.308          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9399           |\n",
      "|    policy_loss        | -0.403         |\n",
      "|    reward             | -0.00090906123 |\n",
      "|    std                | 118            |\n",
      "|    value_loss         | 6.63e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784343.555553806\n",
      "Sharpe:  -0.6942982571925372\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768950.8868041373\n",
      "Sharpe:  -3.30001406729874\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761778.8429391504\n",
      "Sharpe:  -5.097845176108861\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.1        |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 0.614        |\n",
      "|    reward             | 0.0070935376 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725260.2785937967\n",
      "Sharpe:  -0.9823411687700071\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -56.6      |\n",
      "|    explained_variance | 0.893      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -0.46      |\n",
      "|    reward             | 0.01939502 |\n",
      "|    std                | 130        |\n",
      "|    value_loss         | 7.16e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764200.195681915\n",
      "Sharpe:  -0.6793242643358604\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.1        |\n",
      "|    explained_variance | -0.943       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.166       |\n",
      "|    reward             | 0.0070559657 |\n",
      "|    std                | 138          |\n",
      "|    value_loss         | 1.97e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797194.3707299726\n",
      "Sharpe:  -1.0596156809317254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775834.0231632193\n",
      "Sharpe:  -3.8200531782412055\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.6       |\n",
      "|    explained_variance | 0.41        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | 0.0883      |\n",
      "|    reward             | -0.00614133 |\n",
      "|    std                | 145         |\n",
      "|    value_loss         | 2.14e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799543.4511024802\n",
      "Sharpe:  -0.8324891656682623\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 243           |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58           |\n",
      "|    explained_variance | 0.207         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | 1.9           |\n",
      "|    reward             | -0.0067397407 |\n",
      "|    std                | 153           |\n",
      "|    value_loss         | 0.00116       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798252.0483944119\n",
      "Sharpe:  -0.8237460819418985\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 245           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.5         |\n",
      "|    explained_variance | 0.65          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -1.72         |\n",
      "|    reward             | -0.0059257466 |\n",
      "|    std                | 161           |\n",
      "|    value_loss         | 0.000933      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1022752.6396299996\n",
      "Sharpe:  2.1425363841762555\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.022752639629999738 -0.02686838304044671 2.142536384176256 0\n",
      "2024-01-01 00:00:00 2024-02-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_13_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738394.2802152997\n",
      "Sharpe:  -0.7001660823285369\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.476       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0195     |\n",
      "|    reward             | 0.005700258 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 1.56e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794805.1921220138\n",
      "Sharpe:  -0.37836149357560683\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 199          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0.685        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0675      |\n",
      "|    reward             | 0.0031477124 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 3.17e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796780.8711412597\n",
      "Sharpe:  -1.3133653022724927\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | -6.38         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.0162       |\n",
      "|    reward             | 0.00029349243 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 6.83e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0.339        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.115        |\n",
      "|    reward             | -0.005486073 |\n",
      "|    std                | 1.26         |\n",
      "|    value_loss         | 6.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0.693         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0216        |\n",
      "|    reward             | -0.0047856565 |\n",
      "|    std                | 1.33          |\n",
      "|    value_loss         | 5.55e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1411899.5999908266\n",
      "Sharpe:  0.40761323741534894\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.013        |\n",
      "|    reward             | -0.017238108 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799582.4622925984\n",
      "Sharpe:  -0.2861886535156196\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | -1.65      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -0.181     |\n",
      "|    reward             | 0.00756407 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 0.000158   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792506.9640414371\n",
      "Sharpe:  -2.0542115746125393\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0.618         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0591        |\n",
      "|    reward             | -0.0015472792 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 4.17e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781502.2923164153\n",
      "Sharpe:  -0.5867340268626782\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | -1.98       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.023613535 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785621.8597049748\n",
      "Sharpe:  -0.5578555990664066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776554.0924078217\n",
      "Sharpe:  -5.66167768127872\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739329.589347972\n",
      "Sharpe:  -2.2701644585588405\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0.718         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0646       |\n",
      "|    reward             | 0.00052686455 |\n",
      "|    std                | 1.74          |\n",
      "|    value_loss         | 1.85e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788972.2054750294\n",
      "Sharpe:  -0.5448239956968942\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0.605      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 0.0163     |\n",
      "|    reward             | 0.02020691 |\n",
      "|    std                | 1.84       |\n",
      "|    value_loss         | 1.31e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.314        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0769      |\n",
      "|    reward             | -0.012844006 |\n",
      "|    std                | 1.93         |\n",
      "|    value_loss         | 2.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.141       |\n",
      "|    reward             | 0.0069662463 |\n",
      "|    std                | 2.04         |\n",
      "|    value_loss         | 7.05e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1231519.1268349197\n",
      "Sharpe:  0.2717135542676897\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791982.1967172597\n",
      "Sharpe:  -1.9220585018218999\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 34            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0.768         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.0525       |\n",
      "|    reward             | -0.0072951433 |\n",
      "|    std                | 2.15          |\n",
      "|    value_loss         | 9.78e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789033.5838951782\n",
      "Sharpe:  -1.8553429340850134\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.0927       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.211       |\n",
      "|    reward             | -0.010620636 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 0.000211     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787839.8541686548\n",
      "Sharpe:  -0.3467864057003205\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 203            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 39             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.6          |\n",
      "|    explained_variance | 0.6            |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | -0.0498        |\n",
      "|    reward             | -0.00013631476 |\n",
      "|    std                | 2.38           |\n",
      "|    value_loss         | 3.39e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788738.0225249748\n",
      "Sharpe:  -0.30046403553779366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21           |\n",
      "|    explained_variance | 0.765         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | 0.0493        |\n",
      "|    reward             | -0.0024681105 |\n",
      "|    std                | 2.51          |\n",
      "|    value_loss         | 9.54e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799126.8182125054\n",
      "Sharpe:  -0.7959190272302252\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.423       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0248      |\n",
      "|    reward             | 0.004794625 |\n",
      "|    std                | 2.64        |\n",
      "|    value_loss         | 4.75e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794541.4630419554\n",
      "Sharpe:  -0.2825628717326334\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22        |\n",
      "|    explained_variance | 0.432      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.0971    |\n",
      "|    reward             | 0.02085494 |\n",
      "|    std                | 2.78       |\n",
      "|    value_loss         | 3.08e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 49            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.4         |\n",
      "|    explained_variance | 0.39          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0738       |\n",
      "|    reward             | -0.0036900695 |\n",
      "|    std                | 2.91          |\n",
      "|    value_loss         | 6.16e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2100          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 10500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | 0.512         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2099          |\n",
      "|    policy_loss        | -0.0463       |\n",
      "|    reward             | -0.0049685114 |\n",
      "|    std                | 3.07          |\n",
      "|    value_loss         | 2.01e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1179430.3434799842\n",
      "Sharpe:  0.24456638714982057\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0.722        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.138       |\n",
      "|    reward             | -0.008367045 |\n",
      "|    std                | 3.23         |\n",
      "|    value_loss         | 5e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797275.1900532764\n",
      "Sharpe:  -0.3708530810727708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | 0.886         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | -0.339        |\n",
      "|    reward             | -0.0011353263 |\n",
      "|    std                | 3.4           |\n",
      "|    value_loss         | 0.000206      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 58            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.2         |\n",
      "|    explained_variance | 0.67          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | -0.0628       |\n",
      "|    reward             | -0.0014929766 |\n",
      "|    std                | 3.58          |\n",
      "|    value_loss         | 3.09e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1211900.5307280077\n",
      "Sharpe:  0.37074095759410136\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.7         |\n",
      "|    explained_variance | 0.173         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.197        |\n",
      "|    reward             | -0.0039802934 |\n",
      "|    std                | 3.77          |\n",
      "|    value_loss         | 6.69e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | -0.0575      |\n",
      "|    reward             | 0.0039053434 |\n",
      "|    std                | 3.98         |\n",
      "|    value_loss         | 1.89e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787558.3885619914\n",
      "Sharpe:  -0.14285111229446013\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 66          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.7       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.115       |\n",
      "|    reward             | -0.06909436 |\n",
      "|    std                | 4.21        |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772937.3487239999\n",
      "Sharpe:  -11.58620857942939\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | 0.0052457093 |\n",
      "|    std                | 4.43         |\n",
      "|    value_loss         | 2.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.7         |\n",
      "|    explained_variance | 0.603         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.169        |\n",
      "|    reward             | -0.0011208063 |\n",
      "|    std                | 4.68          |\n",
      "|    value_loss         | 4.94e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781352.2044920092\n",
      "Sharpe:  -0.13407869479366072\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.1         |\n",
      "|    explained_variance | 0.14          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | -0.23         |\n",
      "|    reward             | -0.0010985126 |\n",
      "|    std                | 4.92          |\n",
      "|    value_loss         | 9.21e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798751.4004150003\n",
      "Sharpe:  -1.2622082797808019\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779442.8532780004\n",
      "Sharpe:  -1.8034095844252986\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768248.6277499995\n",
      "Sharpe:  -2.7728374925805634\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | -0.0157     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 0.00154     |\n",
      "|    reward             | 0.006475088 |\n",
      "|    std                | 5.17        |\n",
      "|    value_loss         | 3.64e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | 0.204        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.43        |\n",
      "|    reward             | 0.0056044403 |\n",
      "|    std                | 5.43         |\n",
      "|    value_loss         | 0.000401     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | 0.392        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.0734       |\n",
      "|    reward             | 0.0035950716 |\n",
      "|    std                | 5.7          |\n",
      "|    value_loss         | 2.12e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1092169.9566148086\n",
      "Sharpe:  0.17930150121278787\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0.362       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.235       |\n",
      "|    reward             | 0.013029424 |\n",
      "|    std                | 6.01        |\n",
      "|    value_loss         | 0.000199    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.4         |\n",
      "|    explained_variance | 0.44          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.0799        |\n",
      "|    reward             | -0.0012061517 |\n",
      "|    std                | 6.35          |\n",
      "|    value_loss         | 0.000236      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796455.416215196\n",
      "Sharpe:  -0.1998387114271906\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780023.8792646272\n",
      "Sharpe:  -0.47257151850515405\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.338       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.0447     |\n",
      "|    reward             | 0.011182714 |\n",
      "|    std                | 6.64        |\n",
      "|    value_loss         | 2.29e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 91           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 0.549        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.873        |\n",
      "|    reward             | -0.009402354 |\n",
      "|    std                | 6.96         |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | -0.081      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | 0.38        |\n",
      "|    reward             | 0.011876955 |\n",
      "|    std                | 7.31        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1027812.2544044282\n",
      "Sharpe:  0.13176043411464763\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0.352        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | -0.29        |\n",
      "|    reward             | -0.013677266 |\n",
      "|    std                | 7.7          |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746494.5044502307\n",
      "Sharpe:  -0.6482277615451403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750656.9100603835\n",
      "Sharpe:  -3.807457815778312\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 203         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | -0.305      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.345       |\n",
      "|    reward             | 0.015057822 |\n",
      "|    std                | 8.09        |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0.0256       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 0.0382       |\n",
      "|    reward             | -0.009563146 |\n",
      "|    std                | 8.46         |\n",
      "|    value_loss         | 4.53e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794026.620494536\n",
      "Sharpe:  -0.1840406460941331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 203           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 103           |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.4         |\n",
      "|    explained_variance | -2.56         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -0.611        |\n",
      "|    reward             | -0.0070484513 |\n",
      "|    std                | 8.88          |\n",
      "|    value_loss         | 0.000432      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 0.18         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.0902       |\n",
      "|    reward             | -0.015329323 |\n",
      "|    std                | 9.32         |\n",
      "|    value_loss         | 8.68e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797983.5569334963\n",
      "Sharpe:  -0.20249715981545036\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.0377       |\n",
      "|    reward             | -0.021398049 |\n",
      "|    std                | 9.79         |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793073.9179007799\n",
      "Sharpe:  -1.7767944712017567\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | -0.401       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | -0.0159      |\n",
      "|    reward             | -0.006450782 |\n",
      "|    std                | 10.2         |\n",
      "|    value_loss         | 3.02e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:729719.7534009743\n",
      "Sharpe:  -0.41766701565962727\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796101.5432195908\n",
      "Sharpe:  -2.2350269702793018\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | -0.0156      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.0388       |\n",
      "|    reward             | 0.0024923198 |\n",
      "|    std                | 10.7         |\n",
      "|    value_loss         | 1.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | -0.723       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.144       |\n",
      "|    reward             | -0.004025217 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 2.04e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786988.4756822855\n",
      "Sharpe:  -0.2357250080150097\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35          |\n",
      "|    explained_variance | -0.223       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.352        |\n",
      "|    reward             | 0.0012507279 |\n",
      "|    std                | 11.8         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767387.1555292216\n",
      "Sharpe:  -0.625460343555216\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.204       |\n",
      "|    reward             | 0.0016500067 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 3.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781627.9626804753\n",
      "Sharpe:  -0.7095437217488296\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 203            |\n",
      "|    iterations         | 5000           |\n",
      "|    time_elapsed       | 123            |\n",
      "|    total_timesteps    | 25000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -35.8          |\n",
      "|    explained_variance | 0.634          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4999           |\n",
      "|    policy_loss        | 1.04           |\n",
      "|    reward             | -0.00031707963 |\n",
      "|    std                | 13             |\n",
      "|    value_loss         | 0.000997       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.3        |\n",
      "|    explained_variance | 0.0811       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | 0.0052411635 |\n",
      "|    std                | 13.6         |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:743448.8064542712\n",
      "Sharpe:  -0.33317091822767336\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | 0.379       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.687      |\n",
      "|    reward             | 0.036716543 |\n",
      "|    std                | 14.4        |\n",
      "|    value_loss         | 0.000672    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767989.5697418781\n",
      "Sharpe:  -0.6362871067117726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794754.2599622324\n",
      "Sharpe:  -0.9343941906766099\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.00978      |\n",
      "|    reward             | 0.0042643733 |\n",
      "|    std                | 15.1         |\n",
      "|    value_loss         | 5.16e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787360.1111228964\n",
      "Sharpe:  -0.5740823192491261\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 133          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | 0.118        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.514        |\n",
      "|    reward             | -0.004302988 |\n",
      "|    std                | 15.9         |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | -0.245       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.0897       |\n",
      "|    reward             | -0.011113486 |\n",
      "|    std                | 16.6         |\n",
      "|    value_loss         | 4.24e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767364.6622934353\n",
      "Sharpe:  -0.41749951762831744\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758275.675713438\n",
      "Sharpe:  -10.834639817678111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780756.363207372\n",
      "Sharpe:  -1.6277193145313409\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0.533        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.221       |\n",
      "|    reward             | 0.0031553407 |\n",
      "|    std                | 17.5         |\n",
      "|    value_loss         | 4.3e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780601.1115052745\n",
      "Sharpe:  -1.0470588280329767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39          |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0037175342 |\n",
      "|    std                | 18.4         |\n",
      "|    value_loss         | 1.01e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751868.917021877\n",
      "Sharpe:  -0.9255739906940276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 5800          |\n",
      "|    time_elapsed       | 143           |\n",
      "|    total_timesteps    | 29000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.4         |\n",
      "|    explained_variance | 0.577         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5799          |\n",
      "|    policy_loss        | -0.307        |\n",
      "|    reward             | -0.0020670407 |\n",
      "|    std                | 19.4          |\n",
      "|    value_loss         | 7.21e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786721.1296343823\n",
      "Sharpe:  -1.0088178682629856\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 0.418        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.553        |\n",
      "|    reward             | 0.0047185174 |\n",
      "|    std                | 20.4         |\n",
      "|    value_loss         | 0.000196     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:647019.6169234795\n",
      "Sharpe:  -0.822900756096372\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.3        |\n",
      "|    explained_variance | 0.109        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | 0.275        |\n",
      "|    reward             | 0.0072063594 |\n",
      "|    std                | 21.4         |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792630.7878119893\n",
      "Sharpe:  -0.6337500332271291\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764379.8415296837\n",
      "Sharpe:  -1.7223255577509895\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.8        |\n",
      "|    explained_variance | 0.427        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | 0.0003381157 |\n",
      "|    std                | 22.4         |\n",
      "|    value_loss         | 2.43e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759738.0906921778\n",
      "Sharpe:  -0.7055258702685117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:679351.7868300962\n",
      "Sharpe:  -1.0717444699681722\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.2         |\n",
      "|    explained_variance | 0.694         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.611         |\n",
      "|    reward             | -0.0030502358 |\n",
      "|    std                | 23.6          |\n",
      "|    value_loss         | 0.000275      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787857.9190949177\n",
      "Sharpe:  -3.915165359094878\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766888.3794283002\n",
      "Sharpe:  -0.9635435137611931\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.7        |\n",
      "|    explained_variance | 0.734        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -0.00932     |\n",
      "|    reward             | 0.0047456324 |\n",
      "|    std                | 24.8         |\n",
      "|    value_loss         | 2.07e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765576.0703762891\n",
      "Sharpe:  -1.3088725398189003\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | -0.972       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.163        |\n",
      "|    reward             | 0.0018350021 |\n",
      "|    std                | 26.1         |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:720392.3859124824\n",
      "Sharpe:  -0.8479861311927751\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785671.3893446043\n",
      "Sharpe:  -1.1176634894361666\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.00801      |\n",
      "|    reward             | 0.0012116296 |\n",
      "|    std                | 27.4         |\n",
      "|    value_loss         | 5.45e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0.517       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.319       |\n",
      "|    reward             | 0.018833632 |\n",
      "|    std                | 28.9        |\n",
      "|    value_loss         | 9.19e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 165           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.5         |\n",
      "|    explained_variance | -3.27         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | -0.373        |\n",
      "|    reward             | -0.0038919514 |\n",
      "|    std                | 30.3          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794481.792136782\n",
      "Sharpe:  -0.17151962199075063\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.9        |\n",
      "|    explained_variance | -0.603       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -0.235       |\n",
      "|    reward             | -0.002547007 |\n",
      "|    std                | 31.9         |\n",
      "|    value_loss         | 4.44e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795543.1190391917\n",
      "Sharpe:  -0.3831157608696472\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 202         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.3       |\n",
      "|    explained_variance | 0.462       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.536       |\n",
      "|    reward             | -0.01614914 |\n",
      "|    std                | 33.4        |\n",
      "|    value_loss         | 0.000207    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797997.6940952579\n",
      "Sharpe:  -0.7512089768189163\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 202           |\n",
      "|    iterations         | 7000          |\n",
      "|    time_elapsed       | 173           |\n",
      "|    total_timesteps    | 35000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.8         |\n",
      "|    explained_variance | 0.226         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6999          |\n",
      "|    policy_loss        | -0.369        |\n",
      "|    reward             | -0.0030992841 |\n",
      "|    std                | 35.1          |\n",
      "|    value_loss         | 7.93e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.3        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.00624      |\n",
      "|    reward             | -0.005353796 |\n",
      "|    std                | 37.1         |\n",
      "|    value_loss         | 1.36e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790359.7116545247\n",
      "Sharpe:  -0.22023013646955825\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 178           |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.8         |\n",
      "|    explained_variance | -0.104        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | 0.166         |\n",
      "|    reward             | -0.0079057235 |\n",
      "|    std                | 39.2          |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795820.8610120969\n",
      "Sharpe:  -0.5946858243931303\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.2        |\n",
      "|    explained_variance | -0.523       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.84        |\n",
      "|    reward             | 0.0038786733 |\n",
      "|    std                | 41.3         |\n",
      "|    value_loss         | 0.000351     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747733.134579751\n",
      "Sharpe:  -0.796251216631986\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.7         |\n",
      "|    explained_variance | 0.342         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | -0.159        |\n",
      "|    reward             | -0.0014911189 |\n",
      "|    std                | 43.4          |\n",
      "|    value_loss         | 3.6e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761387.814763645\n",
      "Sharpe:  -0.630415496619934\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.2       |\n",
      "|    explained_variance | 0.262       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -0.512      |\n",
      "|    reward             | 0.003678498 |\n",
      "|    std                | 45.7        |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768148.0562142994\n",
      "Sharpe:  -0.5739576982481847\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 201            |\n",
      "|    iterations         | 7600           |\n",
      "|    time_elapsed       | 188            |\n",
      "|    total_timesteps    | 38000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -47.6          |\n",
      "|    explained_variance | 0.781          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7599           |\n",
      "|    policy_loss        | 0.0716         |\n",
      "|    reward             | -0.00061211555 |\n",
      "|    std                | 48             |\n",
      "|    value_loss         | 8.61e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48          |\n",
      "|    explained_variance | 0.239        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.403        |\n",
      "|    reward             | -0.029526971 |\n",
      "|    std                | 50.4         |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725844.1672725214\n",
      "Sharpe:  -0.3327917584537737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766506.6833077683\n",
      "Sharpe:  -0.8545788568740972\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 202          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.5        |\n",
      "|    explained_variance | 0.571        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.377        |\n",
      "|    reward             | 0.0024595733 |\n",
      "|    std                | 53           |\n",
      "|    value_loss         | 7.81e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49           |\n",
      "|    explained_variance | 0.662         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | 0.226         |\n",
      "|    reward             | -0.0055062263 |\n",
      "|    std                | 55.8          |\n",
      "|    value_loss         | 3.84e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786629.1390007797\n",
      "Sharpe:  -0.578469725402081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792884.0100020814\n",
      "Sharpe:  -0.9455176210581027\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.4        |\n",
      "|    explained_variance | -1.04        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 4.47         |\n",
      "|    reward             | -0.025888182 |\n",
      "|    std                | 58.7         |\n",
      "|    value_loss         | 0.0186       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757566.3519919856\n",
      "Sharpe:  -0.6858880137136403\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.9        |\n",
      "|    explained_variance | -7.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | -0.715       |\n",
      "|    reward             | 0.0017641603 |\n",
      "|    std                | 61.9         |\n",
      "|    value_loss         | 0.000241     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747966.6791983817\n",
      "Sharpe:  -0.9701369744847452\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797809.7379017393\n",
      "Sharpe:  -2.8125812282511733\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.3        |\n",
      "|    explained_variance | 0.593        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.0888      |\n",
      "|    reward             | 0.0035899216 |\n",
      "|    std                | 65.2         |\n",
      "|    value_loss         | 7.43e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798838.2200316053\n",
      "Sharpe:  -1.320477456250887\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747680.1770000125\n",
      "Sharpe:  -1.9196196218198984\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.8        |\n",
      "|    explained_variance | -0.217       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.801       |\n",
      "|    reward             | -0.012836048 |\n",
      "|    std                | 68.4         |\n",
      "|    value_loss         | 0.000266     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.2        |\n",
      "|    explained_variance | -0.152       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | -0.202       |\n",
      "|    reward             | 0.0006018528 |\n",
      "|    std                | 71.8         |\n",
      "|    value_loss         | 4.25e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796826.0381898069\n",
      "Sharpe:  -0.27094466198711104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770553.7768480546\n",
      "Sharpe:  -9.267273007133197\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.7       |\n",
      "|    explained_variance | 0.34        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -0.0812     |\n",
      "|    reward             | 0.004450346 |\n",
      "|    std                | 75.6        |\n",
      "|    value_loss         | 5.56e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778260.7350216435\n",
      "Sharpe:  -2.2358874597117424\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788414.6176034387\n",
      "Sharpe:  -2.48478200393656\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.1       |\n",
      "|    explained_variance | 0.316       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.010498297 |\n",
      "|    std                | 79.5        |\n",
      "|    value_loss         | 0.000621    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799359.5869539857\n",
      "Sharpe:  -1.3737057780811228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798506.4310711772\n",
      "Sharpe:  -1.2799308555649451\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.6        |\n",
      "|    explained_variance | 0.223        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.337       |\n",
      "|    reward             | -0.010130342 |\n",
      "|    std                | 83.6         |\n",
      "|    value_loss         | 4.7e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798718.785489956\n",
      "Sharpe:  -1.0851742398513338\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778691.1098084521\n",
      "Sharpe:  -2.1162083067455133\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53         |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 0.0748      |\n",
      "|    reward             | 0.008661016 |\n",
      "|    std                | 87.7        |\n",
      "|    value_loss         | 1.95e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.5      |\n",
      "|    explained_variance | 0.199      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 0.965      |\n",
      "|    reward             | 0.00692095 |\n",
      "|    std                | 92.3       |\n",
      "|    value_loss         | 0.0006     |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761432.8615815559\n",
      "Sharpe:  -0.4193432823581943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796263.9043278774\n",
      "Sharpe:  -0.937325582477728\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794074.0806918356\n",
      "Sharpe:  -11.209002820599267\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.9        |\n",
      "|    explained_variance | 0.636        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.531       |\n",
      "|    reward             | 0.0064838114 |\n",
      "|    std                | 96.4         |\n",
      "|    value_loss         | 9.61e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791678.7261130258\n",
      "Sharpe:  -1.600318336703611\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.3        |\n",
      "|    explained_variance | 0.283        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.354        |\n",
      "|    reward             | -0.012643995 |\n",
      "|    std                | 101          |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:695540.2811004112\n",
      "Sharpe:  -0.8018185935370743\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.8       |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -0.275      |\n",
      "|    reward             | 0.000841095 |\n",
      "|    std                | 107         |\n",
      "|    value_loss         | 4.62e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799757.7745428524\n",
      "Sharpe:  -0.5439010936854642\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774136.2714111657\n",
      "Sharpe:  -2.473266697175976\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.2        |\n",
      "|    explained_variance | 0.382        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.461       |\n",
      "|    reward             | -0.011325805 |\n",
      "|    std                | 112          |\n",
      "|    value_loss         | 6.78e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794388.650835231\n",
      "Sharpe:  -0.7908985000734053\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.7        |\n",
      "|    explained_variance | 0.348        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.35        |\n",
      "|    reward             | -0.009101014 |\n",
      "|    std                | 118          |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799531.9916320256\n",
      "Sharpe:  -0.8441623132240851\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.1        |\n",
      "|    explained_variance | -0.151       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | -0.0655      |\n",
      "|    reward             | -0.005801203 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 2.43e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791153.3734142835\n",
      "Sharpe:  -0.4507353291523176\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.6       |\n",
      "|    explained_variance | -0.107      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.0709     |\n",
      "|    reward             | 0.009317701 |\n",
      "|    std                | 130         |\n",
      "|    value_loss         | 1.17e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:704922.2066426172\n",
      "Sharpe:  -0.8477780920621748\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57          |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.136        |\n",
      "|    reward             | 0.0011030604 |\n",
      "|    std                | 137          |\n",
      "|    value_loss         | 5.87e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755126.106964191\n",
      "Sharpe:  -0.7669687923853227\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.5        |\n",
      "|    explained_variance | -0.683       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.0473      |\n",
      "|    reward             | -0.010728292 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 1.92e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788451.5279455745\n",
      "Sharpe:  -1.0766754125321398\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767085.3228001917\n",
      "Sharpe:  -6.792853303230129\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 201          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.9        |\n",
      "|    explained_variance | 0.454        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | -0.009507865 |\n",
      "|    std                | 151          |\n",
      "|    value_loss         | 6.59e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784159.8167615338\n",
      "Sharpe:  -0.7769694953336426\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736617.6190959723\n",
      "Sharpe:  -1.224833053376066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 201           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 248           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.4         |\n",
      "|    explained_variance | -0.127        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -0.626        |\n",
      "|    reward             | -0.0013623402 |\n",
      "|    std                | 159           |\n",
      "|    value_loss         | 0.000233      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1013648.1993272606\n",
      "Sharpe:  3.873416526939719\n",
      "=================================\n",
      "hit end!\n",
      "a2c 0.01364819932726058 -0.010545212482835582 3.8734165269397196 0\n",
      "2024-02-01 00:00:00 2024-03-01 00:00:00\n",
      "a2c\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_14_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796963.5207500691\n",
      "Sharpe:  -2.3171790013519518\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 185         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.358       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0957      |\n",
      "|    reward             | 0.010208851 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 6.41e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773989.3958072999\n",
      "Sharpe:  -0.9910311130100811\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788665.5934836046\n",
      "Sharpe:  -1.390334171384877\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 189         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.11       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.049      |\n",
      "|    reward             | 0.012803231 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 194           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0.945         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0201        |\n",
      "|    reward             | -0.0015712859 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 5.97e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0.741         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.0126        |\n",
      "|    reward             | -0.0029333632 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 1.29e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:966653.2175155467\n",
      "Sharpe:  0.03125815961135243\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 194         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.044       |\n",
      "|    reward             | 0.011646829 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 2.79e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 195       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -0.289    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 0.287     |\n",
      "|    reward             | 0.0040969 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.000371  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799644.6413825329\n",
      "Sharpe:  -0.3681813676548566\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 700            |\n",
      "|    time_elapsed       | 17             |\n",
      "|    total_timesteps    | 3500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.3          |\n",
      "|    explained_variance | -0.225         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 699            |\n",
      "|    policy_loss        | 0.039          |\n",
      "|    reward             | -0.00043067438 |\n",
      "|    std                | 1.48           |\n",
      "|    value_loss         | 9.66e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0.506         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.067         |\n",
      "|    reward             | 0.00089074555 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 3.9e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795423.3759549329\n",
      "Sharpe:  -0.27251282540298133\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0.463       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.0677      |\n",
      "|    reward             | 0.002534926 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 4.12e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799964.2077106604\n",
      "Sharpe:  -0.3519241673801278\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0.822        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.123        |\n",
      "|    reward             | 0.0074892743 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 5.22e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 196        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.3      |\n",
      "|    explained_variance | 0.467      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 0.0397     |\n",
      "|    reward             | 0.01415806 |\n",
      "|    std                | 1.84       |\n",
      "|    value_loss         | 1.32e-05   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 30             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.8          |\n",
      "|    explained_variance | 0.802          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | 0.0731         |\n",
      "|    reward             | -0.00071099214 |\n",
      "|    std                | 1.95           |\n",
      "|    value_loss         | 1.74e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1436124.4276207876\n",
      "Sharpe:  0.48990785618930216\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | 0.0995        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.0135       |\n",
      "|    reward             | -0.0035541812 |\n",
      "|    std                | 2.07          |\n",
      "|    value_loss         | 8.59e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | 0.227       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.0213     |\n",
      "|    reward             | 0.008066646 |\n",
      "|    std                | 2.19        |\n",
      "|    value_loss         | 5.79e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 194            |\n",
      "|    iterations         | 1500           |\n",
      "|    time_elapsed       | 38             |\n",
      "|    total_timesteps    | 7500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.3          |\n",
      "|    explained_variance | 0.847          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1499           |\n",
      "|    policy_loss        | -0.00385       |\n",
      "|    reward             | -0.00086845877 |\n",
      "|    std                | 2.32           |\n",
      "|    value_loss         | 2.82e-06       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1383875.701764438\n",
      "Sharpe:  0.4484909843570467\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -0.467       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.115        |\n",
      "|    reward             | 0.0037942322 |\n",
      "|    std                | 2.45         |\n",
      "|    value_loss         | 4.68e-05     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 195       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.4     |\n",
      "|    explained_variance | 0.47      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 0.178     |\n",
      "|    reward             | 0.0034575 |\n",
      "|    std                | 2.6       |\n",
      "|    value_loss         | 8.84e-05  |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 46            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.9         |\n",
      "|    explained_variance | 0.763         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.0945        |\n",
      "|    reward             | -0.0016706439 |\n",
      "|    std                | 2.75          |\n",
      "|    value_loss         | 2.62e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1315529.1706273716\n",
      "Sharpe:  0.394867487834352\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0.42         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | 0.0040101074 |\n",
      "|    std                | 2.92         |\n",
      "|    value_loss         | 6.26e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | 0.258        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.0344      |\n",
      "|    reward             | 0.0016099319 |\n",
      "|    std                | 3.08         |\n",
      "|    value_loss         | 3.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.214        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | 0.0029138625 |\n",
      "|    std                | 3.26         |\n",
      "|    value_loss         | 6.23e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:929418.7669311775\n",
      "Sharpe:  -0.00644339110495532\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | -0.527       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | 0.0033586512 |\n",
      "|    std                | 3.44         |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | 0.495       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.134      |\n",
      "|    reward             | 0.013297062 |\n",
      "|    std                | 3.64        |\n",
      "|    value_loss         | 0.000155    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1041615.3127946093\n",
      "Sharpe:  0.1373627411437987\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.9         |\n",
      "|    explained_variance | 0.359         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | -0.191        |\n",
      "|    reward             | -0.0071752355 |\n",
      "|    std                | 3.83          |\n",
      "|    value_loss         | 9.48e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792399.501794326\n",
      "Sharpe:  -0.5381259577184184\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.4       |\n",
      "|    explained_variance | 0.0207      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -0.0831     |\n",
      "|    reward             | 0.008499116 |\n",
      "|    std                | 4.06        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | -0.377        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | 0.2           |\n",
      "|    reward             | -0.0026273895 |\n",
      "|    std                | 4.28          |\n",
      "|    value_loss         | 7.56e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799408.3013948742\n",
      "Sharpe:  -0.4204239777457966\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 195           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 68            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | -0.0628       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | 0.463         |\n",
      "|    reward             | -0.0022337923 |\n",
      "|    std                | 4.51          |\n",
      "|    value_loss         | 0.000322      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0.371        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.556        |\n",
      "|    reward             | 0.0068639996 |\n",
      "|    std                | 4.77         |\n",
      "|    value_loss         | 0.000492     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797067.1961809568\n",
      "Sharpe:  -0.29719047434310414\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | -0.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.244       |\n",
      "|    reward             | -0.012202412 |\n",
      "|    std                | 5.02         |\n",
      "|    value_loss         | 0.000196     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794419.5211871089\n",
      "Sharpe:  -0.7121969115726073\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 76           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | 0.676        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.00775      |\n",
      "|    reward             | -0.007627744 |\n",
      "|    std                | 5.3          |\n",
      "|    value_loss         | 8.94e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 195         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0.193       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -0.299      |\n",
      "|    reward             | -0.01437918 |\n",
      "|    std                | 5.6         |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 0.475        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.00488     |\n",
      "|    reward             | -0.011682307 |\n",
      "|    std                | 5.9          |\n",
      "|    value_loss         | 8.05e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1109164.3973913218\n",
      "Sharpe:  0.1854087710068174\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | -0.314       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | 0.0026543748 |\n",
      "|    std                | 6.22         |\n",
      "|    value_loss         | 5.71e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776968.1782477531\n",
      "Sharpe:  -0.32721294791037847\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788819.5022694384\n",
      "Sharpe:  -11.266363468128052\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795494.3955912328\n",
      "Sharpe:  -7.549069393910487\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | -0.0431     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.213       |\n",
      "|    reward             | 0.007867468 |\n",
      "|    std                | 6.56        |\n",
      "|    value_loss         | 7.47e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788909.9722965868\n",
      "Sharpe:  -1.1883383660722688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 3500           |\n",
      "|    time_elapsed       | 89             |\n",
      "|    total_timesteps    | 17500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.1          |\n",
      "|    explained_variance | 0.548          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3499           |\n",
      "|    policy_loss        | 0.206          |\n",
      "|    reward             | -0.00017551807 |\n",
      "|    std                | 6.88           |\n",
      "|    value_loss         | 6.66e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785778.6021188349\n",
      "Sharpe:  -0.634025647098088\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 3600           |\n",
      "|    time_elapsed       | 91             |\n",
      "|    total_timesteps    | 18000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.5          |\n",
      "|    explained_variance | 0.129          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3599           |\n",
      "|    policy_loss        | 0.343          |\n",
      "|    reward             | -0.00059872476 |\n",
      "|    std                | 7.22           |\n",
      "|    value_loss         | 0.000197       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741437.1514420698\n",
      "Sharpe:  -0.7054435631559897\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782685.3071792611\n",
      "Sharpe:  -5.756410296861124\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | -2.23        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | 0.0018052979 |\n",
      "|    std                | 7.59         |\n",
      "|    value_loss         | 6.06e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 96            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.5         |\n",
      "|    explained_variance | 0.292         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.173         |\n",
      "|    reward             | -0.0059423107 |\n",
      "|    std                | 7.99          |\n",
      "|    value_loss         | 8.36e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0.36         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.0571       |\n",
      "|    reward             | -0.008177142 |\n",
      "|    std                | 8.38         |\n",
      "|    value_loss         | 1.06e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:977982.2504845901\n",
      "Sharpe:  0.06815138019412564\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789054.8286589318\n",
      "Sharpe:  -3.1678380939314175\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0.229        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.0826      |\n",
      "|    reward             | -0.008287301 |\n",
      "|    std                | 8.85         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795334.8506113437\n",
      "Sharpe:  -0.9314211739372809\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 104           |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.9         |\n",
      "|    explained_variance | 0.687         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | -0.0669       |\n",
      "|    reward             | -0.0074313623 |\n",
      "|    std                | 9.36          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 0.0972        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | 0.193         |\n",
      "|    reward             | -0.0037953642 |\n",
      "|    std                | 9.89          |\n",
      "|    value_loss         | 5.75e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763672.9628076656\n",
      "Sharpe:  -0.24571748568430293\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 0.292        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.0625      |\n",
      "|    reward             | 0.0014056786 |\n",
      "|    std                | 10.4         |\n",
      "|    value_loss         | 1.74e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783266.6388635208\n",
      "Sharpe:  -2.9450365141695873\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.3        |\n",
      "|    explained_variance | -0.522       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | -0.317       |\n",
      "|    reward             | 0.0009148196 |\n",
      "|    std                | 11           |\n",
      "|    value_loss         | 9.04e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | 0.348       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | 0.032090787 |\n",
      "|    std                | 11.5        |\n",
      "|    value_loss         | 8.3e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797003.9510418597\n",
      "Sharpe:  -0.2078546475071018\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | 0.318         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | 0.137         |\n",
      "|    reward             | -0.0022240642 |\n",
      "|    std                | 12.1          |\n",
      "|    value_loss         | 3.62e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798223.4207886884\n",
      "Sharpe:  -0.5906613684681472\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0.339        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.199       |\n",
      "|    reward             | -0.012038538 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 8.08e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784262.4262474974\n",
      "Sharpe:  -0.3869856187582315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 121           |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.1         |\n",
      "|    explained_variance | 0.102         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | -0.0339       |\n",
      "|    reward             | -0.0013718463 |\n",
      "|    std                | 13.4          |\n",
      "|    value_loss         | 2.06e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797889.5567169595\n",
      "Sharpe:  -0.957509949617079\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 124           |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.5         |\n",
      "|    explained_variance | -0.00827      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.325        |\n",
      "|    reward             | -0.0031824815 |\n",
      "|    std                | 14            |\n",
      "|    value_loss         | 0.000118      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792202.7027505902\n",
      "Sharpe:  -0.7297257372662076\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | 0.487       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.181       |\n",
      "|    reward             | 0.007148272 |\n",
      "|    std                | 14.8        |\n",
      "|    value_loss         | 4.96e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752782.5134408758\n",
      "Sharpe:  -0.7840000074478553\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775817.2201621109\n",
      "Sharpe:  -1.9117029778968198\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | 0.457        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 0.0438       |\n",
      "|    reward             | -0.004043573 |\n",
      "|    std                | 15.5         |\n",
      "|    value_loss         | 2.04e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786958.6356273417\n",
      "Sharpe:  -1.6956421449543917\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.9       |\n",
      "|    explained_variance | 0.427       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.0442     |\n",
      "|    reward             | 0.010589284 |\n",
      "|    std                | 16.3        |\n",
      "|    value_loss         | 1.39e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763542.8774047944\n",
      "Sharpe:  -0.7163797543557142\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.3        |\n",
      "|    explained_variance | -0.0515      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.119       |\n",
      "|    reward             | 0.0043571214 |\n",
      "|    std                | 17.2         |\n",
      "|    value_loss         | 2.47e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783491.6608928934\n",
      "Sharpe:  -0.5468339471180811\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 5400           |\n",
      "|    time_elapsed       | 137            |\n",
      "|    total_timesteps    | 27000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -38.8          |\n",
      "|    explained_variance | 0.118          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5399           |\n",
      "|    policy_loss        | 0.19           |\n",
      "|    reward             | -0.00039419637 |\n",
      "|    std                | 18             |\n",
      "|    value_loss         | 6.6e-05        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764136.0482953554\n",
      "Sharpe:  -1.573504173456933\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 5500           |\n",
      "|    time_elapsed       | 139            |\n",
      "|    total_timesteps    | 27500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -39.3          |\n",
      "|    explained_variance | 0.245          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5499           |\n",
      "|    policy_loss        | 0.331          |\n",
      "|    reward             | -0.00056666665 |\n",
      "|    std                | 19.1           |\n",
      "|    value_loss         | 7.56e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774651.3688014788\n",
      "Sharpe:  -0.5981614728255252\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:734326.1656011922\n",
      "Sharpe:  -5.564676318693978\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.7       |\n",
      "|    explained_variance | 0.2         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | 0.453       |\n",
      "|    reward             | 0.002854493 |\n",
      "|    std                | 20          |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781986.8992296176\n",
      "Sharpe:  -0.3719622060443938\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.1        |\n",
      "|    explained_variance | 0.177        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.00675      |\n",
      "|    reward             | -0.013967797 |\n",
      "|    std                | 21           |\n",
      "|    value_loss         | 5.86e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797603.1462296171\n",
      "Sharpe:  -2.24022889188536\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759206.5987797803\n",
      "Sharpe:  -0.9414801817207261\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | -0.224      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | 0.021167984 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789685.871120223\n",
      "Sharpe:  -0.7319416189982917\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 196            |\n",
      "|    iterations         | 5900           |\n",
      "|    time_elapsed       | 149            |\n",
      "|    total_timesteps    | 29500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -41.1          |\n",
      "|    explained_variance | -0.0895        |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5899           |\n",
      "|    policy_loss        | 0.081          |\n",
      "|    reward             | -0.00013100031 |\n",
      "|    std                | 23.4           |\n",
      "|    value_loss         | 0.000397       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.5        |\n",
      "|    explained_variance | 0.551        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.442       |\n",
      "|    reward             | -0.005051859 |\n",
      "|    std                | 24.5         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774251.7169008492\n",
      "Sharpe:  -0.4989776368217042\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755993.2668639184\n",
      "Sharpe:  -0.853891506736919\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.567      |\n",
      "|    reward             | 0.005867719 |\n",
      "|    std                | 25.8        |\n",
      "|    value_loss         | 0.000193    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797379.2174367531\n",
      "Sharpe:  -1.0725075093196534\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 157          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0.302        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 0.0473       |\n",
      "|    reward             | 0.0058863605 |\n",
      "|    std                | 27.1         |\n",
      "|    value_loss         | 7.8e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765671.2102908479\n",
      "Sharpe:  -0.4596634631550442\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0.0166      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -0.739      |\n",
      "|    reward             | 0.007580446 |\n",
      "|    std                | 28.4        |\n",
      "|    value_loss         | 0.000506    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796894.304244354\n",
      "Sharpe:  -2.393118968069488\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799774.9357623582\n",
      "Sharpe:  -1.150865939764946\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | -0.581       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.0786       |\n",
      "|    reward             | 0.0004286033 |\n",
      "|    std                | 29.8         |\n",
      "|    value_loss         | 1.64e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:728614.475055944\n",
      "Sharpe:  -0.8599590725487064\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.7        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | 0.0007746396 |\n",
      "|    std                | 31.4         |\n",
      "|    value_loss         | 1.02e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771465.321025766\n",
      "Sharpe:  -0.639255986432518\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.2       |\n",
      "|    explained_variance | -1.51       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.875       |\n",
      "|    reward             | 0.005038662 |\n",
      "|    std                | 33          |\n",
      "|    value_loss         | 0.000435    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795404.587711188\n",
      "Sharpe:  -1.1431004212116858\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.7       |\n",
      "|    explained_variance | 0.327       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.0986     |\n",
      "|    reward             | -0.01982355 |\n",
      "|    std                | 34.8        |\n",
      "|    value_loss         | 1.38e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781472.7997683024\n",
      "Sharpe:  -0.524344255328467\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.2         |\n",
      "|    explained_variance | -0.255        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | -1.04         |\n",
      "|    reward             | 0.00029123435 |\n",
      "|    std                | 36.7          |\n",
      "|    value_loss         | 0.000609      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776641.8583999311\n",
      "Sharpe:  -0.8816600341396812\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.6        |\n",
      "|    explained_variance | 0.737        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.831        |\n",
      "|    reward             | 0.0014417723 |\n",
      "|    std                | 38.6         |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775425.0883627565\n",
      "Sharpe:  -0.6721430989770733\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.1        |\n",
      "|    explained_variance | -0.0044      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.242        |\n",
      "|    reward             | -0.014772287 |\n",
      "|    std                | 40.7         |\n",
      "|    value_loss         | 4.06e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764804.1955683279\n",
      "Sharpe:  -0.7266055679686096\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.5        |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | -0.515       |\n",
      "|    reward             | -0.010897225 |\n",
      "|    std                | 42.8         |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718191.1174660673\n",
      "Sharpe:  -0.8317147237956773\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.9        |\n",
      "|    explained_variance | 0.542        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | 0.304        |\n",
      "|    reward             | -0.014562911 |\n",
      "|    std                | 44.7         |\n",
      "|    value_loss         | 6.09e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771166.7184936585\n",
      "Sharpe:  -1.5213889423596783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.4         |\n",
      "|    explained_variance | -0.495        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | -0.437        |\n",
      "|    reward             | -0.0036474722 |\n",
      "|    std                | 46.9          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765872.553793785\n",
      "Sharpe:  -0.5807992494813207\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799489.9174293026\n",
      "Sharpe:  -2.220646322786599\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.8       |\n",
      "|    explained_variance | 0.17        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.177      |\n",
      "|    reward             | 0.005177728 |\n",
      "|    std                | 49.4        |\n",
      "|    value_loss         | 2.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791689.3214803594\n",
      "Sharpe:  -0.7362668497269937\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.3        |\n",
      "|    explained_variance | -0.214       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 0.0352       |\n",
      "|    reward             | -0.010132753 |\n",
      "|    std                | 51.9         |\n",
      "|    value_loss         | 4.02e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791264.9407069226\n",
      "Sharpe:  -1.067995098353879\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791611.5583460277\n",
      "Sharpe:  -11.98046634045619\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.7        |\n",
      "|    explained_variance | -3.68        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | 0.0021709248 |\n",
      "|    std                | 54.6         |\n",
      "|    value_loss         | 3.39e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748739.8767607018\n",
      "Sharpe:  -1.1646522871877552\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.1         |\n",
      "|    explained_variance | 0.36          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | -0.062        |\n",
      "|    reward             | -0.0006861951 |\n",
      "|    std                | 57.2          |\n",
      "|    value_loss         | 1.98e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785747.9781314405\n",
      "Sharpe:  -0.6595622181058542\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 197           |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.6         |\n",
      "|    explained_variance | -3.1          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | -0.133        |\n",
      "|    reward             | -0.0005506408 |\n",
      "|    std                | 60.1          |\n",
      "|    value_loss         | 1.84e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:722294.1436006451\n",
      "Sharpe:  -0.9909472651211058\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777818.7868607943\n",
      "Sharpe:  -1.3503534082583795\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50         |\n",
      "|    explained_variance | 0.657       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -0.0697     |\n",
      "|    reward             | 0.008899006 |\n",
      "|    std                | 63          |\n",
      "|    value_loss         | 2.2e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795432.3699178761\n",
      "Sharpe:  -1.6526483478239462\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792825.2903371775\n",
      "Sharpe:  -2.4871335449569902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746001.4898519587\n",
      "Sharpe:  -7.377848243691646\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.4       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.246       |\n",
      "|    reward             | -0.00485172 |\n",
      "|    std                | 66          |\n",
      "|    value_loss         | 2.69e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.9         |\n",
      "|    explained_variance | 0.37          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | 0.895         |\n",
      "|    reward             | -0.0050409036 |\n",
      "|    std                | 69.3          |\n",
      "|    value_loss         | 0.000341      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741675.3553193561\n",
      "Sharpe:  -0.3956378343588482\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 197            |\n",
      "|    iterations         | 8200           |\n",
      "|    time_elapsed       | 208            |\n",
      "|    total_timesteps    | 41000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -51.3          |\n",
      "|    explained_variance | -1.01          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8199           |\n",
      "|    policy_loss        | -0.171         |\n",
      "|    reward             | -0.00057179737 |\n",
      "|    std                | 72.8           |\n",
      "|    value_loss         | 1.6e-05        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791017.1169761668\n",
      "Sharpe:  -0.7327396879550152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797330.3786946699\n",
      "Sharpe:  -1.792858396320364\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.8        |\n",
      "|    explained_variance | 0.116        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.511       |\n",
      "|    reward             | -0.007013473 |\n",
      "|    std                | 76.5         |\n",
      "|    value_loss         | 0.000347     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790575.5446052223\n",
      "Sharpe:  -0.4234033738912247\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798610.264135068\n",
      "Sharpe:  -10.655140786383688\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.2       |\n",
      "|    explained_variance | 0.618       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -0.273      |\n",
      "|    reward             | 0.013391174 |\n",
      "|    std                | 80.5        |\n",
      "|    value_loss         | 3.61e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.6       |\n",
      "|    explained_variance | -0.697      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -0.7        |\n",
      "|    reward             | 0.015161292 |\n",
      "|    std                | 84.1        |\n",
      "|    value_loss         | 0.000218    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791551.6427760519\n",
      "Sharpe:  -0.4366363964379499\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 197          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.1        |\n",
      "|    explained_variance | 0.341        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.463        |\n",
      "|    reward             | 0.0056129214 |\n",
      "|    std                | 88.5         |\n",
      "|    value_loss         | 8.79e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799475.489375316\n",
      "Sharpe:  -0.29105833008222487\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.5       |\n",
      "|    explained_variance | -0.848      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | 0.168       |\n",
      "|    reward             | 0.008984112 |\n",
      "|    std                | 92.7        |\n",
      "|    value_loss         | 1.34e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 197         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54         |\n",
      "|    explained_variance | 0.268       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 1.21        |\n",
      "|    reward             | 0.004337565 |\n",
      "|    std                | 97.7        |\n",
      "|    value_loss         | 0.000653    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771018.5439153027\n",
      "Sharpe:  -0.5628658012663613\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 225           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.4         |\n",
      "|    explained_variance | -0.19         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | 0.162         |\n",
      "|    reward             | -0.0031104437 |\n",
      "|    std                | 103           |\n",
      "|    value_loss         | 3e-05         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726874.2097244936\n",
      "Sharpe:  -0.7276161853991915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771311.570973877\n",
      "Sharpe:  -1.082145786720201\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.9         |\n",
      "|    explained_variance | 0.0718        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | -0.318        |\n",
      "|    reward             | -0.0036350198 |\n",
      "|    std                | 108           |\n",
      "|    value_loss         | 0.000152      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781435.5848319711\n",
      "Sharpe:  -1.6553126119502826\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 231           |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.3         |\n",
      "|    explained_variance | -0.418        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9099          |\n",
      "|    policy_loss        | -0.382        |\n",
      "|    reward             | -0.0021800625 |\n",
      "|    std                | 113           |\n",
      "|    value_loss         | 5.37e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774456.1503144801\n",
      "Sharpe:  -0.7903459382034713\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.7        |\n",
      "|    explained_variance | -0.0552      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.552        |\n",
      "|    reward             | 0.0069789025 |\n",
      "|    std                | 119          |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:662286.1764423881\n",
      "Sharpe:  -0.6094178515130434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 9300          |\n",
      "|    time_elapsed       | 236           |\n",
      "|    total_timesteps    | 46500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.2         |\n",
      "|    explained_variance | 0.369         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9299          |\n",
      "|    policy_loss        | 0.541         |\n",
      "|    reward             | -0.0037257634 |\n",
      "|    std                | 125           |\n",
      "|    value_loss         | 0.000164      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748515.7084873284\n",
      "Sharpe:  -0.790375888289283\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.6       |\n",
      "|    explained_variance | -0.595      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 0.483       |\n",
      "|    reward             | 0.006809532 |\n",
      "|    std                | 131         |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796401.0316724392\n",
      "Sharpe:  -2.9760748805548727\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797580.6377213289\n",
      "Sharpe:  -3.804502216228444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765467.4794400687\n",
      "Sharpe:  -5.055038072514436\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57         |\n",
      "|    explained_variance | 0.474       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.187       |\n",
      "|    reward             | 0.007535122 |\n",
      "|    std                | 138         |\n",
      "|    value_loss         | 3.37e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.5        |\n",
      "|    explained_variance | 0.421        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | -0.512       |\n",
      "|    reward             | 0.0018837659 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:734703.4967702278\n",
      "Sharpe:  -0.2547070234253515\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.9       |\n",
      "|    explained_variance | -11.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.61        |\n",
      "|    reward             | 0.016542181 |\n",
      "|    std                | 151         |\n",
      "|    value_loss         | 0.000263    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753999.47813841\n",
      "Sharpe:  -0.9339606315357636\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 196          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.4        |\n",
      "|    explained_variance | 0.472        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.494        |\n",
      "|    reward             | -0.011554814 |\n",
      "|    std                | 159          |\n",
      "|    value_loss         | 7.85e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750710.2180243449\n",
      "Sharpe:  -0.6132449563643755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787148.9029397528\n",
      "Sharpe:  -1.3072464101695662\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 196         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -58.8       |\n",
      "|    explained_variance | 0.54        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 3.17        |\n",
      "|    reward             | 0.005292986 |\n",
      "|    std                | 168         |\n",
      "|    value_loss         | 0.0034      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772956.9373198196\n",
      "Sharpe:  -1.8309034148137024\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796889.3270065354\n",
      "Sharpe:  -1.4096372791021892\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 196           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 253           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.3         |\n",
      "|    explained_variance | 0.294         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -0.123        |\n",
      "|    reward             | -0.0019047707 |\n",
      "|    std                | 176           |\n",
      "|    value_loss         | 2.32e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:991499.3944884792\n",
      "Sharpe:  -1.8316319714982328\n",
      "=================================\n",
      "hit end!\n",
      "a2c -0.008500605511520543 -0.027062538664680804 -1.831631971498233 0\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_6_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789308.2397583023\n",
      "Sharpe:  -0.64966156814319\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795241.2252154935\n",
      "Sharpe:  -2.7519839069796483\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787322.8442804803\n",
      "Sharpe:  -3.3018040012297196\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783720.9490600824\n",
      "Sharpe:  -2.932015411975722\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794789.8740951102\n",
      "Sharpe:  -2.4749954358215787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795922.008565042\n",
      "Sharpe:  -0.466225481621444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764984.7819601644\n",
      "Sharpe:  -7.796985461135016\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791438.129868315\n",
      "Sharpe:  -8.524339976112975\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798029.2637009858\n",
      "Sharpe:  -6.000909887231259\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796018.9810427403\n",
      "Sharpe:  -8.901934782991452\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747942.1752486569\n",
      "Sharpe:  -4.813520682899748\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 276          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.031298723 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760155.1307360547\n",
      "Sharpe:  -1.7426821309941902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798085.4753306165\n",
      "Sharpe:  -4.856029451054265\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792289.4294675582\n",
      "Sharpe:  -0.6804663936797865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799294.7130356423\n",
      "Sharpe:  -1.415716699570137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780785.0048166442\n",
      "Sharpe:  -2.3645665370238587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793135.0337344249\n",
      "Sharpe:  -1.1784010854137967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798661.7437872633\n",
      "Sharpe:  -1.060474493824116\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009878297  |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.00755      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.137       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | -0.012439678 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00804      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792519.1930304262\n",
      "Sharpe:  -1.1800413736671502\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763099.6807862334\n",
      "Sharpe:  -2.857662436381936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798853.1437829447\n",
      "Sharpe:  -5.178190944687516\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795016.1189402987\n",
      "Sharpe:  -1.0855542534427045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777965.9246237125\n",
      "Sharpe:  -4.101490540891245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793427.0375993293\n",
      "Sharpe:  -1.802731798062303\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789698.6906869082\n",
      "Sharpe:  -1.042667609522121\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781991.3494445287\n",
      "Sharpe:  -0.42569307375523235\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 232           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0150333615  |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.169         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.156        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0133       |\n",
      "|    reward               | -0.0073147537 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00634       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799162.8769838733\n",
      "Sharpe:  -1.4762079096306229\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797479.8806415508\n",
      "Sharpe:  -1.0341076738704733\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776578.2658681229\n",
      "Sharpe:  -1.7957059015775685\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799195.4706113824\n",
      "Sharpe:  -0.37617699670558863\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758971.4059297655\n",
      "Sharpe:  -0.7526708670231052\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007784163 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 0.004330823 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00293     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799908.2758355342\n",
      "Sharpe:  -0.7727551184649426\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786334.6908048915\n",
      "Sharpe:  -1.052107175519962\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798796.3516538477\n",
      "Sharpe:  -1.0386964640817071\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787322.9019574813\n",
      "Sharpe:  -0.4547074952301958\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754987.4721288909\n",
      "Sharpe:  -6.967754795546889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009261299 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.126      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.013875744 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00134     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787502.7177953566\n",
      "Sharpe:  -0.8926938728612906\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799630.3142223421\n",
      "Sharpe:  -0.8539309029624477\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771591.7851642456\n",
      "Sharpe:  -0.49787481426374236\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 226           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 54            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011700023   |\n",
      "|    clip_fraction        | 0.13          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.89          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.151        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.015        |\n",
      "|    reward               | -7.282653e-06 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.0011        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796449.033169474\n",
      "Sharpe:  -0.1425480042353709\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798278.9600503411\n",
      "Sharpe:  -3.1431497223032423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795437.2007776722\n",
      "Sharpe:  -2.6356732112706824\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777004.5727483022\n",
      "Sharpe:  -4.250886708693793\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747040.0401438468\n",
      "Sharpe:  -3.3947209403180074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756896.7710151916\n",
      "Sharpe:  -8.007440004027522\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776037.0730913841\n",
      "Sharpe:  -0.4056619502151542\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772032.8786185345\n",
      "Sharpe:  -7.689965331578189\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 226           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009656397   |\n",
      "|    clip_fraction        | 0.116         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.884         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.108        |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.0111       |\n",
      "|    reward               | -0.0048982976 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00157       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792950.9299409913\n",
      "Sharpe:  -0.1286074249680687\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754616.2422840021\n",
      "Sharpe:  -1.273333649112813\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788985.6038157522\n",
      "Sharpe:  -5.079747784277622\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798107.3071617119\n",
      "Sharpe:  -2.8682186131153213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797042.5318208905\n",
      "Sharpe:  -2.119059560260971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770895.0867250647\n",
      "Sharpe:  -1.234871891530203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789352.9473380282\n",
      "Sharpe:  -0.8695170456595601\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010990795 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.155      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 0.004752737 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00182     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793676.1578880921\n",
      "Sharpe:  -0.7304367883602306\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789397.3585272465\n",
      "Sharpe:  -9.090440325020111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779720.613289327\n",
      "Sharpe:  -1.3301395698011458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765879.4138269408\n",
      "Sharpe:  -1.5041744681327882\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791869.2620734806\n",
      "Sharpe:  -1.7525639555409254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780575.0467751361\n",
      "Sharpe:  -1.2036904302497395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791019.5626919437\n",
      "Sharpe:  -2.414644914152469\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771627.2893325181\n",
      "Sharpe:  -1.3470711468632166\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774651.465493507\n",
      "Sharpe:  -0.8489891583656952\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010824917  |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.134       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 0.0047967285 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000946     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766642.6529566994\n",
      "Sharpe:  -1.4013802431994313\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796304.9420615612\n",
      "Sharpe:  -0.498580807314056\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795503.204647137\n",
      "Sharpe:  -0.9595569126663835\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785070.1385166566\n",
      "Sharpe:  -2.8489825273650506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787755.822106203\n",
      "Sharpe:  -0.37991885673354\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798493.1863039702\n",
      "Sharpe:  -1.3313804047291644\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010031929 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.159      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.009193154 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000541    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776166.8367977012\n",
      "Sharpe:  -1.1630144599696288\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796637.9397029814\n",
      "Sharpe:  -0.7783138673181265\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790915.6983960668\n",
      "Sharpe:  -1.5413706867673145\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780225.6740365243\n",
      "Sharpe:  -0.5635560121898987\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008721469 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 0.008356343 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000763    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784508.5070714406\n",
      "Sharpe:  -0.48143512242350467\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792554.7061169022\n",
      "Sharpe:  -0.5758519144266423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792321.3847885726\n",
      "Sharpe:  -0.7125266457911937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797216.4787576309\n",
      "Sharpe:  -0.9331125856375684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791443.6917379438\n",
      "Sharpe:  -3.8924137297628323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010752738 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.131      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.00430992  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000679    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736232.5059178614\n",
      "Sharpe:  -0.22604138226972423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797626.6543565836\n",
      "Sharpe:  -0.323354908324342\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 225           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 117           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012222037   |\n",
      "|    clip_fraction        | 0.122         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.815         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.014        |\n",
      "|    reward               | -0.0052990285 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000749      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:729211.4516820177\n",
      "Sharpe:  -0.25493993633019896\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775902.8881917277\n",
      "Sharpe:  -0.9681146986107027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790645.9957093272\n",
      "Sharpe:  -0.5767564968568609\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783713.7040694469\n",
      "Sharpe:  -0.6773524199285311\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011876623  |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.168       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.0025135353 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00102      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783748.8891193246\n",
      "Sharpe:  -0.16512821669677447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792836.4339924256\n",
      "Sharpe:  -2.0329422084971505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798297.5513228868\n",
      "Sharpe:  -1.1679641928417341\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798759.5976799182\n",
      "Sharpe:  -1.4832640670101926\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799701.4324318343\n",
      "Sharpe:  -1.0568631254638763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799063.2454451239\n",
      "Sharpe:  -0.9136506586539399\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792063.5331930823\n",
      "Sharpe:  -1.0563546955840748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01032523  |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.158      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | 0.012953033 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00099     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775332.54325445\n",
      "Sharpe:  -0.3825739726689415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789058.3167158713\n",
      "Sharpe:  -0.11423906917910799\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780605.5823447128\n",
      "Sharpe:  -2.455800215115241\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 225           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010681372   |\n",
      "|    clip_fraction        | 0.135         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.884         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.17         |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0127       |\n",
      "|    reward               | -0.0011783865 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.000402      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783215.0457247855\n",
      "Sharpe:  -0.44545193592664895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785283.2990211643\n",
      "Sharpe:  -1.1454878894685039\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755042.7690064077\n",
      "Sharpe:  -0.582626625530651\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 225           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010740711   |\n",
      "|    clip_fraction        | 0.104         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.4         |\n",
      "|    explained_variance   | 0.892         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.162        |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0106       |\n",
      "|    reward               | -0.0038526282 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.000976      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744872.8071324279\n",
      "Sharpe:  -0.5341737225530414\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798880.8485450692\n",
      "Sharpe:  -2.8866329940299003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761949.881957151\n",
      "Sharpe:  -6.937162122445661\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799920.5608997834\n",
      "Sharpe:  -0.5422615430010133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794927.9128407671\n",
      "Sharpe:  -3.057855094500905\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797292.1877628219\n",
      "Sharpe:  -1.368100255810999\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765363.0269877128\n",
      "Sharpe:  -1.8513579907654063\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797395.3976785304\n",
      "Sharpe:  -1.5085004951451417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780183.6066147541\n",
      "Sharpe:  -1.1453259761230552\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 225           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 163           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01406545    |\n",
      "|    clip_fraction        | 0.14          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.4         |\n",
      "|    explained_variance   | 0.882         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.149        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.0157       |\n",
      "|    reward               | -0.0011548909 |\n",
      "|    std                  | 1.08          |\n",
      "|    value_loss           | 0.000551      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794951.1242437692\n",
      "Sharpe:  -1.205364730275916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794432.6042508514\n",
      "Sharpe:  -0.5503962347448222\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779107.2797278479\n",
      "Sharpe:  -2.5113701867169387\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797997.3399436573\n",
      "Sharpe:  -1.4447583538750957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777367.8324951223\n",
      "Sharpe:  -1.257936803537643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792554.8052499996\n",
      "Sharpe:  -0.9486137372621182\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009702804  |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.5        |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.0020257137 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.000623     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797690.7549060213\n",
      "Sharpe:  -0.20715657413825111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786461.1462247828\n",
      "Sharpe:  -1.6376924331038492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778266.7525145207\n",
      "Sharpe:  -1.8370827807786185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777414.5924961374\n",
      "Sharpe:  -4.46418194673823\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799646.565566575\n",
      "Sharpe:  -1.6802158154091458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782413.5255696577\n",
      "Sharpe:  -3.1255248151948902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797161.8668166175\n",
      "Sharpe:  -1.089356019531267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012887577 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.156      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.009612474 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.000756    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688911.0985205756\n",
      "Sharpe:  -0.48930138928684197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761399.0539575756\n",
      "Sharpe:  -1.6205491963919063\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768942.3836779166\n",
      "Sharpe:  -0.4599840541816674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788180.0201059879\n",
      "Sharpe:  -0.7429581709727965\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787022.0365180277\n",
      "Sharpe:  -3.2979375782698837\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013998769 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.132      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.004995485 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.000595    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799633.934066112\n",
      "Sharpe:  -1.178221356971995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:646152.9931503807\n",
      "Sharpe:  -0.49175984818824386\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799664.5563697689\n",
      "Sharpe:  -0.5837158216732455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796753.2358040679\n",
      "Sharpe:  -1.2248979512855824\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010800167 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.164      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.006114553 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.000826    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798781.4849114398\n",
      "Sharpe:  -5.832420033843368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787736.4889008075\n",
      "Sharpe:  -3.3784449660324833\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779412.8013635633\n",
      "Sharpe:  -1.410060682996796\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790578.022996669\n",
      "Sharpe:  -0.6928357946954311\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792224.164445135\n",
      "Sharpe:  -1.2449410198401807\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794914.4497983707\n",
      "Sharpe:  -0.5775259088844311\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 225           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 209           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013451231   |\n",
      "|    clip_fraction        | 0.155         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.6         |\n",
      "|    explained_variance   | 0.825         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.175        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.00992      |\n",
      "|    reward               | -0.0024660022 |\n",
      "|    std                  | 1.1           |\n",
      "|    value_loss           | 0.000825      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758117.4004485805\n",
      "Sharpe:  -0.10481517288847712\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792050.7875906297\n",
      "Sharpe:  -0.9801432789672262\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770123.432003602\n",
      "Sharpe:  -4.231068304595066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791918.7868654146\n",
      "Sharpe:  -0.8229735468510042\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151034    |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.6        |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    reward               | -0.005412734 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.000992     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797193.4292830942\n",
      "Sharpe:  -0.5582787534174068\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798656.9442810954\n",
      "Sharpe:  -0.692995394179694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799299.9705004798\n",
      "Sharpe:  -1.7810288366790037\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795318.4904461172\n",
      "Sharpe:  -0.24316417105558955\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135920765 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.7        |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.16        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    reward               | 0.0005521776 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.000861     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1027994.6493231783\n",
      "Sharpe:  5.165933783747195\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.02799464932317819 -0.012071681727004653 5.165933783747196 0\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787875.6968949193\n",
      "Sharpe:  -3.2420782750162465\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788001.393845683\n",
      "Sharpe:  -5.255690578774139\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797862.6925724247\n",
      "Sharpe:  -2.871212673105675\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788836.0882705785\n",
      "Sharpe:  -0.4226452178952288\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795909.2801421244\n",
      "Sharpe:  -2.46794939960331\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795250.3977415758\n",
      "Sharpe:  -7.417747355498231\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798956.167429316\n",
      "Sharpe:  -6.520466800006239\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:723783.1910876043\n",
      "Sharpe:  -2.870364941345783\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797755.3214318492\n",
      "Sharpe:  -2.908294026131419\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780721.6221303828\n",
      "Sharpe:  -1.5359730613444502\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774585.5210213969\n",
      "Sharpe:  -1.884560246871847\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 277          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.004801153 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785066.0386275362\n",
      "Sharpe:  -0.8407873095235051\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766591.6180597802\n",
      "Sharpe:  -3.015211761441286\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751134.0069205225\n",
      "Sharpe:  -2.556957639571861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735402.8546183562\n",
      "Sharpe:  -6.94240367280867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799066.2407633963\n",
      "Sharpe:  -1.285725415498973\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794705.5898323419\n",
      "Sharpe:  -0.9804510846266585\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796637.3257684222\n",
      "Sharpe:  -0.6665615448171601\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 227           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007324394   |\n",
      "|    clip_fraction        | 0.0908        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00947       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.154        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0115       |\n",
      "|    reward               | -0.0017165502 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00464       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787725.7497056971\n",
      "Sharpe:  -0.7290823595546074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797533.3644810152\n",
      "Sharpe:  -1.7713999713562838\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795299.1110076604\n",
      "Sharpe:  -0.15453999746795213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798772.2176121633\n",
      "Sharpe:  -3.263560042161549\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797891.3568875908\n",
      "Sharpe:  -0.911993165415637\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 217           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007520334   |\n",
      "|    clip_fraction        | 0.0636        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00424       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.148        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00838      |\n",
      "|    reward               | -0.0055576735 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00172       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799218.4483747528\n",
      "Sharpe:  -0.8036844883102394\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790202.7617896704\n",
      "Sharpe:  -1.3749707329345984\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798916.9102057677\n",
      "Sharpe:  -3.78940440218829\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781608.7098748082\n",
      "Sharpe:  -0.36801845674089423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788356.011119697\n",
      "Sharpe:  -2.4120652723711924\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:706012.2455007813\n",
      "Sharpe:  -3.9102760327555233\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775249.7730996581\n",
      "Sharpe:  -1.5501952219515698\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 207           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011119748   |\n",
      "|    clip_fraction        | 0.112         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.143         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.155        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0127       |\n",
      "|    reward               | -0.0021774613 |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.00205       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793548.5371756848\n",
      "Sharpe:  -3.431729086753441\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798500.7968994122\n",
      "Sharpe:  -1.8379164600808098\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780839.8572749464\n",
      "Sharpe:  -0.46177226823415773\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738304.6605167522\n",
      "Sharpe:  -0.693076165405662\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788834.426109877\n",
      "Sharpe:  -3.724071360158241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779994.5629064109\n",
      "Sharpe:  -0.6956882737266156\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 206           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 49            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012811968   |\n",
      "|    clip_fraction        | 0.136         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.186         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0127       |\n",
      "|    reward               | -0.0023561157 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00126       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799339.1536283412\n",
      "Sharpe:  -0.894903025510206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798753.0785127522\n",
      "Sharpe:  -2.425639401798294\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797709.251875711\n",
      "Sharpe:  -4.0339830130129535\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796806.21081596\n",
      "Sharpe:  -0.437551362765081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789320.8446382431\n",
      "Sharpe:  -1.7860251104849267\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796945.73857371\n",
      "Sharpe:  -1.2827026293163328\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797403.7145903165\n",
      "Sharpe:  -0.9671245678639059\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 209          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011506088  |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.133       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | 0.0061818757 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00112      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751282.727925847\n",
      "Sharpe:  -1.1894873483795343\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798696.2804285636\n",
      "Sharpe:  -0.6702625494087788\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785371.3249491098\n",
      "Sharpe:  -1.6113277721795751\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786588.2923689951\n",
      "Sharpe:  -0.13555559621650562\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 210          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011221957  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.278        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.14        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    reward               | -0.023539763 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.001        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785982.5834839701\n",
      "Sharpe:  -0.7482372572844616\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796024.1734124924\n",
      "Sharpe:  -0.31350613283527007\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767681.2547937519\n",
      "Sharpe:  -2.286369580765591\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794337.9965009458\n",
      "Sharpe:  -1.0260097076975856\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009558594 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.155      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.001004914 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000918    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792700.7145056718\n",
      "Sharpe:  -0.23640449312815046\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782911.0242666713\n",
      "Sharpe:  -1.3484496060544797\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799796.6943811881\n",
      "Sharpe:  -0.6811864927196227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795754.3392993415\n",
      "Sharpe:  -0.4826484798282626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774589.6892706167\n",
      "Sharpe:  -1.098115750662925\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796722.8877085347\n",
      "Sharpe:  -2.1347853322502472\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 212           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 86            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012529024   |\n",
      "|    clip_fraction        | 0.15          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.658         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.159        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0152       |\n",
      "|    reward               | 0.00045271675 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000889      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794902.8269748209\n",
      "Sharpe:  -0.49451367437201194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799937.0431253427\n",
      "Sharpe:  -5.012892457177214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783013.5169374932\n",
      "Sharpe:  -1.4239223921920496\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799801.3081218335\n",
      "Sharpe:  -1.2145742567584241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747452.8729025924\n",
      "Sharpe:  -0.6759384395040079\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 214           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 95            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00999639    |\n",
      "|    clip_fraction        | 0.0979        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.144        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00957      |\n",
      "|    reward               | -0.0044487533 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000745      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783242.4267107846\n",
      "Sharpe:  -0.364058182745314\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788883.742894137\n",
      "Sharpe:  -2.1110691648130167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799187.0786815344\n",
      "Sharpe:  -1.3357046890270814\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795011.1485918888\n",
      "Sharpe:  -0.45164741932156877\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744999.6478194251\n",
      "Sharpe:  -2.168186698346639\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796756.3010938216\n",
      "Sharpe:  -3.5887554664973504\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797487.9770608483\n",
      "Sharpe:  -2.7981110282703363\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010586731  |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | -0.005842838 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00104      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772971.6755125365\n",
      "Sharpe:  -0.6666139147387254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782088.8874745887\n",
      "Sharpe:  -4.198919028488345\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769557.7622882472\n",
      "Sharpe:  -2.5836186545480624\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794496.5780268625\n",
      "Sharpe:  -1.4398373170961638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798279.8951958901\n",
      "Sharpe:  -3.597912171198846\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778497.7193660139\n",
      "Sharpe:  -1.29956658857483\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789399.8138792206\n",
      "Sharpe:  -1.1341832995140724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796873.7765758896\n",
      "Sharpe:  -1.0788553024180725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009851317 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.118      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.015331523 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000842    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799639.8903236997\n",
      "Sharpe:  -0.5982506926254024\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797831.0401426124\n",
      "Sharpe:  -1.8639225083671036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793441.1388581366\n",
      "Sharpe:  -1.8564726131185763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:732649.2192785216\n",
      "Sharpe:  -4.272374255581194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796986.7567323551\n",
      "Sharpe:  -1.2096342014631525\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766846.911990906\n",
      "Sharpe:  -0.4138889081738057\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015085784  |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.165       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    reward               | -0.010781486 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000527     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799160.6039139276\n",
      "Sharpe:  -0.45746192381369977\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792320.2740887562\n",
      "Sharpe:  -0.4660654871889788\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799479.2528205365\n",
      "Sharpe:  -0.9684236490900298\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798549.8722849323\n",
      "Sharpe:  -5.827192587881353\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794814.3317689587\n",
      "Sharpe:  -1.0964618159250916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796228.5628771791\n",
      "Sharpe:  -2.3303932463894523\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780561.1234491906\n",
      "Sharpe:  -1.1817478459721638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766804.8901284935\n",
      "Sharpe:  -1.6478717143812716\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012637011 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.165      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -0.00276849 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000734    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794255.7566916265\n",
      "Sharpe:  -0.5630463924933168\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795741.6300216828\n",
      "Sharpe:  -1.650754242930771\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787599.698724314\n",
      "Sharpe:  -3.495938621467223\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799975.8936409858\n",
      "Sharpe:  -0.5676778916427381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797594.4081278625\n",
      "Sharpe:  -1.4872218239507562\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770929.548282288\n",
      "Sharpe:  -1.503038845870982\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796093.2387336721\n",
      "Sharpe:  -2.4993326665857554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762998.9093252872\n",
      "Sharpe:  -0.8265102166750807\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 215           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 142           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0129767     |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.735         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.169        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.0155       |\n",
      "|    reward               | -0.0065188115 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000859      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799577.3838921633\n",
      "Sharpe:  -1.1373041729183309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772676.3009111234\n",
      "Sharpe:  -0.976258314735014\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790945.1307970231\n",
      "Sharpe:  -0.6132447937869847\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799738.2446684937\n",
      "Sharpe:  -1.4194941755524393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753124.7385848641\n",
      "Sharpe:  -4.015533233035244\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787363.6974711639\n",
      "Sharpe:  -3.4753579319809336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764277.1031859862\n",
      "Sharpe:  -1.9269266421957363\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776015.883804877\n",
      "Sharpe:  -10.451699301371717\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794436.6207799851\n",
      "Sharpe:  -3.4712118110413894\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012291677 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.145      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -0.04404305 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000611    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756728.2480604808\n",
      "Sharpe:  -1.5406787601534104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788167.5908191508\n",
      "Sharpe:  -7.154007079810639\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738197.109153918\n",
      "Sharpe:  -4.037369126292684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796225.9021212991\n",
      "Sharpe:  -0.34678835941443226\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797473.7872843411\n",
      "Sharpe:  -0.7666994382842129\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787494.9626187935\n",
      "Sharpe:  -0.8255474000157317\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797956.7325878904\n",
      "Sharpe:  -1.2671176923540086\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 216            |\n",
      "|    iterations           | 17             |\n",
      "|    time_elapsed         | 161            |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.011881248    |\n",
      "|    clip_fraction        | 0.152          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13            |\n",
      "|    explained_variance   | 0.879          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.121         |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.0151        |\n",
      "|    reward               | -0.00034689208 |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 0.00082        |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788592.9306898111\n",
      "Sharpe:  -0.6460260019601277\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781108.6439245803\n",
      "Sharpe:  -0.2882029150044472\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:731396.1164300814\n",
      "Sharpe:  -1.2306243462671271\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 170           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010956332   |\n",
      "|    clip_fraction        | 0.13          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.863         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.152        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.0123       |\n",
      "|    reward               | -0.0029717013 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000504      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:684720.8686234344\n",
      "Sharpe:  -0.25870219486321244\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789147.8193558216\n",
      "Sharpe:  -0.6823453899571529\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795764.1692343578\n",
      "Sharpe:  -1.366151763053274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762288.7504250578\n",
      "Sharpe:  -0.5604801139322192\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01167443   |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.17        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    reward               | 0.0040591364 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000861     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768600.3624549587\n",
      "Sharpe:  -2.089714476789495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780665.9095625625\n",
      "Sharpe:  -3.1195131205119924\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799923.6387846307\n",
      "Sharpe:  -1.7502780015502506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796373.0735088342\n",
      "Sharpe:  -0.7844544225730599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780960.5619844242\n",
      "Sharpe:  -5.676827578594338\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794830.8714060959\n",
      "Sharpe:  -5.9220659229799795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773864.8541462731\n",
      "Sharpe:  -0.8892866274652752\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:721755.4534094697\n",
      "Sharpe:  -0.4999435065009552\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013886321 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.166      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.01141258 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000897    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792404.7471989988\n",
      "Sharpe:  -3.4950861757837695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770851.8460960684\n",
      "Sharpe:  -1.8024234037710227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785667.0553358229\n",
      "Sharpe:  -1.298687554741194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797210.966712328\n",
      "Sharpe:  -3.990758933625123\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766896.3251870429\n",
      "Sharpe:  -0.45580524402390893\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747712.4003075357\n",
      "Sharpe:  -0.628270657894434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011424432 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.159      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.005172896 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000733    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798643.7960518888\n",
      "Sharpe:  -2.2516854655709633\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758387.2727732891\n",
      "Sharpe:  -2.3046997833115275\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795436.5261482877\n",
      "Sharpe:  -0.5847771319758421\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767233.7590505477\n",
      "Sharpe:  -0.5798760554335878\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787065.5782189054\n",
      "Sharpe:  -2.202119602286941\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795900.7744306044\n",
      "Sharpe:  -0.873282985341822\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015093747  |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.161       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    reward               | 0.0043759597 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000566     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789739.3034440228\n",
      "Sharpe:  -0.4110701473549085\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790779.0298090006\n",
      "Sharpe:  -1.0775732500982924\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780942.2189555241\n",
      "Sharpe:  -0.3859460695261477\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797577.0794591099\n",
      "Sharpe:  -1.2045827255415673\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 217           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015699198   |\n",
      "|    clip_fraction        | 0.167         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.812         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0155       |\n",
      "|    reward               | -0.0016290729 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.00068       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798463.699136885\n",
      "Sharpe:  -0.2488923778701417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798127.406075907\n",
      "Sharpe:  -0.8112068245021288\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796455.4920780545\n",
      "Sharpe:  -0.8020728599459415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784099.9235991497\n",
      "Sharpe:  -0.29442973602871386\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013503828 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.162      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.008847107 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000788    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:734238.7176414118\n",
      "Sharpe:  -1.0291856587331305\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789452.301231314\n",
      "Sharpe:  -0.8613805889556762\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799039.5992796668\n",
      "Sharpe:  -0.4516781136248844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775992.2153799317\n",
      "Sharpe:  -1.5811055740395412\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777047.1378332591\n",
      "Sharpe:  -1.3010794373692691\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01240315  |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.144      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.022562202 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00059     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1044811.9597943836\n",
      "Sharpe:  7.065738536599358\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.044811959794383904 -0.012219421922510623 7.0657385365993575 0\n",
      "2023-08-01 00:00:00 2023-09-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787245.7160863467\n",
      "Sharpe:  -0.4180577839854577\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798479.2447680259\n",
      "Sharpe:  -2.6680484656343237\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796849.7470672479\n",
      "Sharpe:  -3.0620129930994233\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789046.3847836278\n",
      "Sharpe:  -1.6309018716937405\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775643.9757711228\n",
      "Sharpe:  -4.866698190162445\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781019.2758875898\n",
      "Sharpe:  -2.035123808960977\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790574.6385795074\n",
      "Sharpe:  -1.3199628578777096\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784900.7755111234\n",
      "Sharpe:  -1.833421345014585\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 286          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.011132174 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797645.5210814764\n",
      "Sharpe:  -0.5379735196517812\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798587.8419820659\n",
      "Sharpe:  -0.6472910934819498\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797022.6966531376\n",
      "Sharpe:  -5.887909370282925\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775245.7020223975\n",
      "Sharpe:  -1.1193091077482276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793163.630452054\n",
      "Sharpe:  -3.4309867290108578\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772520.9382833436\n",
      "Sharpe:  -1.72881113219027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744588.3291280386\n",
      "Sharpe:  -1.2668122517974199\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509601 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -1.08       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.147      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.005637255 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00177     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796709.9076351662\n",
      "Sharpe:  -1.3303046075502185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792848.8415342186\n",
      "Sharpe:  -1.33599642303439\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:737052.5496899994\n",
      "Sharpe:  -6.934148308339437\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786584.8534076017\n",
      "Sharpe:  -2.4921997272483423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798048.3847450147\n",
      "Sharpe:  -1.555577120110174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793899.7994380179\n",
      "Sharpe:  -0.411991041239209\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791462.0566839983\n",
      "Sharpe:  -1.8614314883965002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006484214 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | -0.576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.125      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 0.004608004 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000785    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793704.7590589175\n",
      "Sharpe:  -0.15035915189522084\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799097.8068743163\n",
      "Sharpe:  -0.8736376403406171\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763449.5158018917\n",
      "Sharpe:  -0.5229110629274638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798504.3005747397\n",
      "Sharpe:  -1.8272065826201873\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799075.8605652066\n",
      "Sharpe:  -1.68918182675947\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 232           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010723008   |\n",
      "|    clip_fraction        | 0.12          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.283         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.133        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0122       |\n",
      "|    reward               | -0.0077083423 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00147       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718526.3247672186\n",
      "Sharpe:  -2.2584428931543266\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798308.8218722761\n",
      "Sharpe:  -0.3434048184982893\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794261.604040919\n",
      "Sharpe:  -2.6007832439032077\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794609.7606496052\n",
      "Sharpe:  -0.870939035455375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799812.3598579013\n",
      "Sharpe:  -0.8505847103766154\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799298.5925966988\n",
      "Sharpe:  -2.4492188952015126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798267.9387449444\n",
      "Sharpe:  -4.273250448287803\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 230          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00956979   |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.183       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -0.009266108 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000751     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794856.18835689\n",
      "Sharpe:  -4.134698347455201\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799610.0774249879\n",
      "Sharpe:  -2.7942534621859103\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799187.9008806852\n",
      "Sharpe:  -4.358278109737823\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795256.6735804807\n",
      "Sharpe:  -2.8924275996633417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799742.525780808\n",
      "Sharpe:  -1.1417002969512084\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797838.5584510277\n",
      "Sharpe:  -0.8843487436044964\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792347.355129535\n",
      "Sharpe:  -6.121608089977249\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797033.04644467\n",
      "Sharpe:  -0.5541726082874197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791753.3405175753\n",
      "Sharpe:  -3.686764273291622\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 228           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010761329   |\n",
      "|    clip_fraction        | 0.105         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.532         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.118        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.0081       |\n",
      "|    reward               | 0.00010016595 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000801      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798316.7710259153\n",
      "Sharpe:  -0.9553113187830671\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797603.4069556025\n",
      "Sharpe:  -0.533269600371334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793531.0868671362\n",
      "Sharpe:  -1.862878225115951\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797184.7794558629\n",
      "Sharpe:  -2.7345805710236815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793013.3227282062\n",
      "Sharpe:  -1.85837885096546\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775965.129528972\n",
      "Sharpe:  -7.489319678998083\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796032.6295080822\n",
      "Sharpe:  -0.5468009504316711\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 227          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011097357  |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -0.002875025 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0008       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799057.5593441107\n",
      "Sharpe:  -0.46413721332395513\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:743708.8362247811\n",
      "Sharpe:  -1.6444901862818184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798371.3842330795\n",
      "Sharpe:  -0.5259137145245081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797986.9939502063\n",
      "Sharpe:  -1.5522975464488171\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799749.5466116171\n",
      "Sharpe:  -2.433755723890458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772816.0701424386\n",
      "Sharpe:  -4.0078000943595455\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012794055  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.161       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | 0.0005767418 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00067      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770558.44284407\n",
      "Sharpe:  -0.2584995735799295\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791348.8450575055\n",
      "Sharpe:  -1.0520188171609206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799901.6917672142\n",
      "Sharpe:  -0.30728232641144054\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795890.4899506342\n",
      "Sharpe:  -0.5124456675667753\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791112.7144343827\n",
      "Sharpe:  -5.724971492614046\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110254735 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.154       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.0033166877 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00111      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774242.6602847262\n",
      "Sharpe:  -1.2433796407839712\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782769.8376123563\n",
      "Sharpe:  -2.9264736283234942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776063.2848239313\n",
      "Sharpe:  -0.540746914983147\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793965.3288797248\n",
      "Sharpe:  -2.490275927689229\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797208.5452158757\n",
      "Sharpe:  -1.688445880955339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790926.5606166306\n",
      "Sharpe:  -2.9048070246162303\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797968.4959595909\n",
      "Sharpe:  -0.940443866308088\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784133.1762387394\n",
      "Sharpe:  -5.103448067029739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010767418 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.146      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.013344105 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00108     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799463.948730602\n",
      "Sharpe:  -1.2607826660450792\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775091.6229020806\n",
      "Sharpe:  -0.42266571793772917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798840.675028637\n",
      "Sharpe:  -0.49224165690082883\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796694.4628817253\n",
      "Sharpe:  -1.1246551477590272\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 100           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011792809   |\n",
      "|    clip_fraction        | 0.129         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.774         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.0109       |\n",
      "|    reward               | -0.0008551124 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000646      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784632.804399332\n",
      "Sharpe:  -1.046151580765749\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797162.0416493552\n",
      "Sharpe:  -3.2261167244898425\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787673.4493647373\n",
      "Sharpe:  -1.3562671474683887\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791047.358584341\n",
      "Sharpe:  -2.7764769510840828\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774761.1163431084\n",
      "Sharpe:  -0.7170410125908474\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799842.9494685876\n",
      "Sharpe:  -4.64412908799033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799301.2214039037\n",
      "Sharpe:  -2.6613837598870567\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787788.7411534236\n",
      "Sharpe:  -0.8137128249715985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793151.1286094935\n",
      "Sharpe:  -1.1887312501054006\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129242055 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00994     |\n",
      "|    reward               | 0.0033600964 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000749     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797211.417752809\n",
      "Sharpe:  -4.178894641440842\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760707.9254541884\n",
      "Sharpe:  -0.615647967828915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750700.8557026733\n",
      "Sharpe:  -2.513248962973595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761247.0701886575\n",
      "Sharpe:  -1.4872951853903407\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791745.6715147657\n",
      "Sharpe:  -0.528675977328429\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790569.0193559601\n",
      "Sharpe:  -1.3553694336199125\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013502123  |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.166       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    reward               | 0.0036722363 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000557     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799558.8203558769\n",
      "Sharpe:  -0.6751318524555523\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794987.9566891924\n",
      "Sharpe:  -0.36245837025091276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797525.7340796321\n",
      "Sharpe:  -1.3464818763738544\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796025.2204817957\n",
      "Sharpe:  -0.5305496131622377\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 218           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 131           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0099328505  |\n",
      "|    clip_fraction        | 0.104         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.783         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.156        |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00678      |\n",
      "|    reward               | -0.0052932617 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000564      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797676.3118193437\n",
      "Sharpe:  -0.6230326747245403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799310.9786742647\n",
      "Sharpe:  -0.1590412368078968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790701.6754309871\n",
      "Sharpe:  -0.4510093445283959\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795485.3279686281\n",
      "Sharpe:  -4.719169743447057\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748212.4123477951\n",
      "Sharpe:  -2.033226568585486\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 218            |\n",
      "|    iterations           | 15             |\n",
      "|    time_elapsed         | 140            |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.010845737    |\n",
      "|    clip_fraction        | 0.126          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13            |\n",
      "|    explained_variance   | 0.787          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.137         |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.0136        |\n",
      "|    reward               | -0.00035685094 |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 0.000621       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744164.6484818361\n",
      "Sharpe:  -0.25222244876282485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798273.7589036599\n",
      "Sharpe:  -3.03792203407906\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784057.4222601232\n",
      "Sharpe:  -1.0281620084514045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798611.3276912057\n",
      "Sharpe:  -2.7536392622882624\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766440.2593921913\n",
      "Sharpe:  -2.5338707156207705\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795308.0838040268\n",
      "Sharpe:  -5.654499817263757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797103.5814050696\n",
      "Sharpe:  -1.1968180149455998\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014389167 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.141      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | 0.009388509 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00139     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754387.6007519709\n",
      "Sharpe:  -0.6583084732009348\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796119.912819285\n",
      "Sharpe:  -0.42284971683204886\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754953.430908755\n",
      "Sharpe:  -2.3162493992318485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791504.9677173804\n",
      "Sharpe:  -0.4177695908008189\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780669.8152920139\n",
      "Sharpe:  -5.818519970540044\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771037.8787558486\n",
      "Sharpe:  -6.364316234676123\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 218           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011360498   |\n",
      "|    clip_fraction        | 0.139         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.124        |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0131       |\n",
      "|    reward               | -0.0026265243 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00109       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799396.1007135202\n",
      "Sharpe:  -1.712677474924273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779316.0993521367\n",
      "Sharpe:  -0.9937397609142833\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796550.7703828784\n",
      "Sharpe:  -0.6943220678757074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791306.0490983288\n",
      "Sharpe:  -7.690514405776189\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740348.3975172612\n",
      "Sharpe:  -1.5016532250606953\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:708055.9268143952\n",
      "Sharpe:  -1.0649769919648329\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738981.9736271205\n",
      "Sharpe:  -0.860736184056204\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013159086  |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.13        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | -0.003531627 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00103      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776755.6971541765\n",
      "Sharpe:  -1.0372656507351559\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798380.429632714\n",
      "Sharpe:  -0.6327664955063547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794210.5631834917\n",
      "Sharpe:  -1.490606124212169\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799000.2530244113\n",
      "Sharpe:  -0.8913563138010872\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794566.6230885644\n",
      "Sharpe:  -0.7395858559641253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795951.0982545343\n",
      "Sharpe:  -13.80496497675478\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011553252  |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 0.0010091678 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000841     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797571.3228160256\n",
      "Sharpe:  -3.1763822081255584\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799030.235909015\n",
      "Sharpe:  -0.5822657508243235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778489.7884254152\n",
      "Sharpe:  -0.8216477215535759\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759210.8559086549\n",
      "Sharpe:  -1.5269667699662848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782346.490451794\n",
      "Sharpe:  -3.2703741472572805\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755943.827489065\n",
      "Sharpe:  -0.6938258617224129\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121219335 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | 0.0075332476 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000491     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786340.5745614796\n",
      "Sharpe:  -2.5642418013796915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789451.3994641782\n",
      "Sharpe:  -0.4037683600037057\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799992.3249033156\n",
      "Sharpe:  -1.1937071875241172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798578.3757114804\n",
      "Sharpe:  -1.745575997067239\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786244.2233416577\n",
      "Sharpe:  -0.4933073011056547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770080.6274681777\n",
      "Sharpe:  -3.26832920428837\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011241073  |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.147       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00979     |\n",
      "|    reward               | 0.0027184496 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000729     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777116.4285799173\n",
      "Sharpe:  -1.2937959710676714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784471.4775349172\n",
      "Sharpe:  -1.4529850591356026\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785541.9344930842\n",
      "Sharpe:  -0.4500653517514251\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795140.8565913317\n",
      "Sharpe:  -0.31166536742337986\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014952984 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.146      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 0.032092717 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000505    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749103.9745352821\n",
      "Sharpe:  -0.2710662444117467\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791178.6735960968\n",
      "Sharpe:  -1.7254795550306856\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797573.9039042597\n",
      "Sharpe:  -2.5960268010066376\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012480717  |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.14        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | -0.001371248 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000696     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796994.9757629466\n",
      "Sharpe:  -0.22104168198369967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795128.222225244\n",
      "Sharpe:  -0.9226002205539275\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780834.547756275\n",
      "Sharpe:  -1.2967317272505396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795657.8821195737\n",
      "Sharpe:  -0.7918950215867813\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762264.6067928089\n",
      "Sharpe:  -1.2252363480545614\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014136693   |\n",
      "|    clip_fraction        | 0.165         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.812         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0127       |\n",
      "|    reward               | -0.0013599315 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000751      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764564.3055012249\n",
      "Sharpe:  -0.39263869919398836\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789366.7696037204\n",
      "Sharpe:  -0.359255980047657\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:742959.7480443969\n",
      "Sharpe:  -0.6702833342776241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789872.5808395618\n",
      "Sharpe:  -3.0753445523095664\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794865.4653446442\n",
      "Sharpe:  -0.4671308697363425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 216         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013760734 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.009900615 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.000549    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1006151.2873473974\n",
      "Sharpe:  1.1258944403533846\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.006151287347397449 -0.014712730700808535 1.1258944403533846 0\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_9_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781511.2582744929\n",
      "Sharpe:  -1.5351716633504755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795459.8120893707\n",
      "Sharpe:  -4.644448736606585\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780544.3542070965\n",
      "Sharpe:  -2.762394022238843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793642.0632149288\n",
      "Sharpe:  -0.6672842907097866\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788513.4139022343\n",
      "Sharpe:  -4.063736232069709\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799627.5767683291\n",
      "Sharpe:  -1.5209106669546135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798738.3256620294\n",
      "Sharpe:  -1.478144901412074\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 271          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.024132436 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799765.7788117636\n",
      "Sharpe:  -0.6106551850727836\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793297.8053718093\n",
      "Sharpe:  -0.6727350657178406\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796970.546348315\n",
      "Sharpe:  -1.8008275473110336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754020.2716327354\n",
      "Sharpe:  -1.6451552554520228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785840.2849953289\n",
      "Sharpe:  -1.8001316670060854\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:733936.3693771921\n",
      "Sharpe:  -0.6378586859245735\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 241           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00861145    |\n",
      "|    clip_fraction        | 0.0801        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.545        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.146        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00984      |\n",
      "|    reward               | -0.0014833724 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00665       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789619.1361336155\n",
      "Sharpe:  -0.862441308687702\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797221.8828024379\n",
      "Sharpe:  -0.7683753604351894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790292.2338736223\n",
      "Sharpe:  -0.16182179317548276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760961.6528136444\n",
      "Sharpe:  -1.68697524560777\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 231          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009766143  |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | -0.005727889 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00479      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745998.1516356003\n",
      "Sharpe:  -0.6403302365206849\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794449.6537916296\n",
      "Sharpe:  -2.2887329612066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775694.6600278905\n",
      "Sharpe:  -1.437831631862822\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791338.0848219584\n",
      "Sharpe:  -3.0308284608695333\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796932.1458141237\n",
      "Sharpe:  -2.4993127515717344\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799714.3040179424\n",
      "Sharpe:  -0.461666980897061\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799291.0098465328\n",
      "Sharpe:  -2.1839561577344457\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010122767 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.13       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 0.01054844  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00224     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780352.1379410139\n",
      "Sharpe:  -2.1576137314054464\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790198.0318576687\n",
      "Sharpe:  -0.6117835013473135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796908.039371698\n",
      "Sharpe:  -1.7515658026783845\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793564.1704015333\n",
      "Sharpe:  -1.7665584165194648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786800.8966392862\n",
      "Sharpe:  -1.6433087335149927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791863.8694590252\n",
      "Sharpe:  -0.6224776297638844\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013693724  |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.161       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    reward               | -0.012102499 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00199      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790276.2135941203\n",
      "Sharpe:  -0.27283755618309774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791186.1613261658\n",
      "Sharpe:  -0.8542217656397229\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787350.1895426296\n",
      "Sharpe:  -3.873116879593416\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766065.8240705497\n",
      "Sharpe:  -1.6569465596516648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799776.0202680401\n",
      "Sharpe:  -1.478135726237616\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:743780.3017953153\n",
      "Sharpe:  -0.7046780396911148\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010611787  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.1         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | -0.001351584 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00131      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794010.6537697403\n",
      "Sharpe:  -1.7664964916937915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799434.8459206038\n",
      "Sharpe:  -2.6073760466982674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798088.5122642315\n",
      "Sharpe:  -0.38679929502333654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785988.4193500564\n",
      "Sharpe:  -0.7514376506233512\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766443.2089889597\n",
      "Sharpe:  -4.320388742601141\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796897.3943938771\n",
      "Sharpe:  -0.8197732646313296\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009974834 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.123      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.001042671 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000858    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796960.0621614114\n",
      "Sharpe:  -1.1038704987597612\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796319.2291486164\n",
      "Sharpe:  -4.153427446253204\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798111.1644625897\n",
      "Sharpe:  -3.128152521933276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799137.2035862211\n",
      "Sharpe:  -1.2978932940175716\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791237.6075850014\n",
      "Sharpe:  -1.3985251497351592\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798794.255215509\n",
      "Sharpe:  -4.560931222020661\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781474.5439877391\n",
      "Sharpe:  -0.46202143454666994\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795703.4840131223\n",
      "Sharpe:  -1.5862409434891511\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794795.5454611777\n",
      "Sharpe:  -3.311608314414521\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009812833  |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.123       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00932     |\n",
      "|    reward               | 0.0019471886 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00111      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791106.2705912212\n",
      "Sharpe:  -1.4500221911719164\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778040.631435766\n",
      "Sharpe:  -0.43944433997741317\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797465.6623356853\n",
      "Sharpe:  -0.6139168937031545\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790556.5157955589\n",
      "Sharpe:  -0.9985148529240166\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798168.0557019479\n",
      "Sharpe:  -3.9192576934814425\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784883.2081911358\n",
      "Sharpe:  -1.2849964717320483\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010320164 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.139      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.01789334 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000687    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794996.4524525455\n",
      "Sharpe:  -0.4840199097857194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784358.5044352842\n",
      "Sharpe:  -0.42383497694706945\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790921.527533319\n",
      "Sharpe:  -0.7416431804542902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768470.3023985889\n",
      "Sharpe:  -2.065750613537072\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011062529  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.158       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    reward               | -0.010460385 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00109      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797685.9630455347\n",
      "Sharpe:  -0.9077738334021875\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789850.8210440829\n",
      "Sharpe:  -1.7667627964177923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795390.5747020546\n",
      "Sharpe:  -3.160498959876403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792569.5970718903\n",
      "Sharpe:  -1.1795049607967563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795465.9258125322\n",
      "Sharpe:  -0.37180207501856644\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799210.7606942027\n",
      "Sharpe:  -1.6825744112987278\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752366.2249152043\n",
      "Sharpe:  -4.230839029461669\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749910.9973939173\n",
      "Sharpe:  -4.160657061216566\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 218         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010842222 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.009500436 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793160.2123105497\n",
      "Sharpe:  -0.797490682729629\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784114.9655200732\n",
      "Sharpe:  -0.7642407748588025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798042.6371420684\n",
      "Sharpe:  -0.6501282502571986\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794585.8716744672\n",
      "Sharpe:  -0.3269179344775188\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012046315  |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.132       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -0.010455326 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000911     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799454.7463924517\n",
      "Sharpe:  -1.3870453216272056\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786145.1712977518\n",
      "Sharpe:  -0.5356511410743434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752595.8760132566\n",
      "Sharpe:  -0.4827754644447164\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781130.2445411237\n",
      "Sharpe:  -7.77676052192868\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795705.6183790264\n",
      "Sharpe:  -2.013213527252521\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799715.6987722063\n",
      "Sharpe:  -3.3977794662334477\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008097803  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.165       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | 0.0030236102 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000652     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799875.7327564824\n",
      "Sharpe:  -0.8394430539316632\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751959.9631902075\n",
      "Sharpe:  -0.4604947701804002\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790186.7457717537\n",
      "Sharpe:  -1.8917833604917622\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771448.6919110791\n",
      "Sharpe:  -1.6477754413915116\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791621.8395454928\n",
      "Sharpe:  -7.540717431139616\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794546.7225973996\n",
      "Sharpe:  -1.1306193980262909\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794659.9690205213\n",
      "Sharpe:  -1.8096170892450396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794963.6406765749\n",
      "Sharpe:  -1.098236593732956\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011609063  |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | 0.0047010947 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000637     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780787.0257337954\n",
      "Sharpe:  -1.3892992080071846\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794734.4613737396\n",
      "Sharpe:  -0.5082760933745523\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799733.1695056983\n",
      "Sharpe:  -0.9560362965852376\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799916.3040569876\n",
      "Sharpe:  -0.6201275468409186\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754472.9445337655\n",
      "Sharpe:  -4.2498942807686175\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798193.4296139455\n",
      "Sharpe:  -2.017520208330039\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014155173  |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.164       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    reward               | 0.0007583144 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000623     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799780.0842069194\n",
      "Sharpe:  -0.8344482774129155\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790058.9640379993\n",
      "Sharpe:  -2.1053566955217367\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799049.2218777505\n",
      "Sharpe:  -1.0697976002400889\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788782.907338247\n",
      "Sharpe:  -1.8574771962867471\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796635.9707701084\n",
      "Sharpe:  -1.9395326074290955\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797184.1169698356\n",
      "Sharpe:  -0.41724193596560133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799309.6593041641\n",
      "Sharpe:  -1.837974769854267\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011902673   |\n",
      "|    clip_fraction        | 0.153         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.2         |\n",
      "|    explained_variance   | 0.871         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.176        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0138       |\n",
      "|    reward               | -0.0099675795 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.000638      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799626.5431192045\n",
      "Sharpe:  -0.5899175961316933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797162.9689421896\n",
      "Sharpe:  -0.5054065576731149\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782625.9330041491\n",
      "Sharpe:  -1.7793617130400983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759650.1749426028\n",
      "Sharpe:  -2.391448417748484\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797135.7784866836\n",
      "Sharpe:  -0.6328508075438645\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013780819  |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.159       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | 0.0020341452 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000546     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793188.5430002303\n",
      "Sharpe:  -0.35539442510128577\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799711.9313172966\n",
      "Sharpe:  -0.7208798307981029\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796302.7895283024\n",
      "Sharpe:  -3.0145696353599214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799208.0673721086\n",
      "Sharpe:  -0.38975666161521016\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796559.8546189307\n",
      "Sharpe:  -9.249691661978256\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767333.9125186163\n",
      "Sharpe:  -2.9904873302813852\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01171379   |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.158       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | -0.009651858 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000695     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799428.3968658794\n",
      "Sharpe:  -0.5104253440628757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792673.5529496846\n",
      "Sharpe:  -0.7459621858255626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755428.2944159554\n",
      "Sharpe:  -0.948767997648337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797112.1448508909\n",
      "Sharpe:  -2.2994178346799434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788911.9878743547\n",
      "Sharpe:  -0.8905659311159265\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774793.9323261373\n",
      "Sharpe:  -6.7517221703528865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789863.0737229456\n",
      "Sharpe:  -6.728534971454379\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014514126  |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | -0.014004879 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.000746     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769048.8803892445\n",
      "Sharpe:  -0.5426309569300363\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782086.9762191649\n",
      "Sharpe:  -0.9081308589926003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780458.0102081359\n",
      "Sharpe:  -2.812710424051479\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783604.0804379146\n",
      "Sharpe:  -0.7507649895084648\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010942217  |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.151       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -0.033959124 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.000538     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:716233.4007447958\n",
      "Sharpe:  -0.5667496655766178\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792747.5669158897\n",
      "Sharpe:  -0.7942016675529724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773924.8049316207\n",
      "Sharpe:  -0.459473299774774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791801.9413244398\n",
      "Sharpe:  -0.9377564837421098\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781770.6120496625\n",
      "Sharpe:  -0.5945532900049717\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 198           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01136335    |\n",
      "|    clip_fraction        | 0.134         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.855         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0101       |\n",
      "|    reward               | -0.0050105117 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000526      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787607.261324891\n",
      "Sharpe:  -1.289692364115843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758389.8206972043\n",
      "Sharpe:  -7.887810234008066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783812.0716920834\n",
      "Sharpe:  -2.0919285958062113\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786490.076150862\n",
      "Sharpe:  -0.6312439175594334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799856.6761538086\n",
      "Sharpe:  -1.9230113005499778\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779769.8795567808\n",
      "Sharpe:  -3.7713425632852196\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795036.8801512198\n",
      "Sharpe:  -2.854444162220815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794156.4622910958\n",
      "Sharpe:  -0.7312368772654597\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014331049  |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.165       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    reward               | -0.006657406 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00062      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787640.0881598003\n",
      "Sharpe:  -0.7434993382201537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796010.4533367237\n",
      "Sharpe:  -0.8518525876416165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799810.5133910445\n",
      "Sharpe:  -0.3146911325209081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796968.7178174679\n",
      "Sharpe:  -6.4384285708483375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791297.5128439184\n",
      "Sharpe:  -0.7986650850323695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799785.0011363579\n",
      "Sharpe:  -0.6045296029037476\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013566943  |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.3        |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.166       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    reward               | 0.0035859076 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.00043      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795313.0380924897\n",
      "Sharpe:  -0.5499348995661754\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797495.8329990436\n",
      "Sharpe:  -1.150902808153509\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777784.8084628335\n",
      "Sharpe:  -1.8936040387094049\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778850.2049375868\n",
      "Sharpe:  -0.8113993004202401\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790213.7953547529\n",
      "Sharpe:  -7.371375907293083\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791806.2362913435\n",
      "Sharpe:  -1.2829390827539597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767396.5241533023\n",
      "Sharpe:  -1.3871127429087926\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 217           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01750945    |\n",
      "|    clip_fraction        | 0.18          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.4         |\n",
      "|    explained_variance   | 0.805         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.153        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.015        |\n",
      "|    reward               | -0.0076285023 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.00107       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782458.3359610139\n",
      "Sharpe:  -0.7710445670045947\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799779.0888940024\n",
      "Sharpe:  -0.6013382794501274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772247.6227073063\n",
      "Sharpe:  -0.7407676905531758\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 217            |\n",
      "|    iterations           | 25             |\n",
      "|    time_elapsed         | 235            |\n",
      "|    total_timesteps      | 51200          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012738179    |\n",
      "|    clip_fraction        | 0.171          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.4          |\n",
      "|    explained_variance   | 0.87           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.132         |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | -0.012         |\n",
      "|    reward               | -0.00078872684 |\n",
      "|    std                  | 1.08           |\n",
      "|    value_loss           | 0.000722       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:988942.4545589723\n",
      "Sharpe:  -1.3732555008966414\n",
      "=================================\n",
      "hit end!\n",
      "ppo -0.011057545441027772 -0.04359311102977686 -1.3732555008966412 0\n",
      "2023-10-01 00:00:00 2023-11-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781323.4191949735\n",
      "Sharpe:  -2.160874889059791\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783585.6128900292\n",
      "Sharpe:  -1.1766155076595117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798945.4431241945\n",
      "Sharpe:  -0.920738100274049\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759560.8151536955\n",
      "Sharpe:  -0.5863769646917951\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798349.883803754\n",
      "Sharpe:  -1.8798944376782218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792285.8473770961\n",
      "Sharpe:  -0.9651170074170559\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794455.5183055068\n",
      "Sharpe:  -7.228964953807152\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 279           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 7             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0010832635 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:749571.9814821916\n",
      "Sharpe:  -2.228055838361533\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:742936.9386778477\n",
      "Sharpe:  -1.3286355327619395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761473.6120076049\n",
      "Sharpe:  -1.4229444143566554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762378.2383966031\n",
      "Sharpe:  -1.9807113329283073\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798416.230284178\n",
      "Sharpe:  -0.6578509676397404\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791769.8908401245\n",
      "Sharpe:  -1.0175137791034328\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 249          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008507689  |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.147       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -0.002394463 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.00544      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796702.2405005713\n",
      "Sharpe:  -1.2309985453757348\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799069.9798315996\n",
      "Sharpe:  -1.0892498064205698\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790271.1006914931\n",
      "Sharpe:  -3.5873311717369827\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798327.1597900128\n",
      "Sharpe:  -0.32390801889725546\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771891.4433994801\n",
      "Sharpe:  -0.3573460798581721\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798400.1643990548\n",
      "Sharpe:  -2.879004696961523\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097995605 |\n",
      "|    clip_fraction        | 0.089        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    reward               | 0.012855937  |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00235      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793284.8800071895\n",
      "Sharpe:  -1.499052492962403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746764.5616140688\n",
      "Sharpe:  -3.4978753618522163\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797495.484280686\n",
      "Sharpe:  -2.077770179687682\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798987.8347415209\n",
      "Sharpe:  -1.1508794146822428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780263.6702769207\n",
      "Sharpe:  -0.612175594491719\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789000.1382153273\n",
      "Sharpe:  -1.0628848349969044\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787313.7605359872\n",
      "Sharpe:  -1.0723078313614587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798365.8762721642\n",
      "Sharpe:  -2.961526153570008\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006844029  |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    reward               | 0.0052253082 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00199      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796324.0673288349\n",
      "Sharpe:  -0.6577391599485604\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796212.6289517658\n",
      "Sharpe:  -0.36827005319446393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798095.4638003986\n",
      "Sharpe:  -1.0779026663531606\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799305.1514354248\n",
      "Sharpe:  -4.328762455534335\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774926.2869657939\n",
      "Sharpe:  -1.65990554371932\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799244.3321757538\n",
      "Sharpe:  -0.8400242932195728\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797406.8924977124\n",
      "Sharpe:  -7.292743641882997\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772980.2879138766\n",
      "Sharpe:  -4.460380626455989\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 231          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010209821  |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.162       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | 0.0025183188 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00187      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795026.6585839717\n",
      "Sharpe:  -1.454422905116176\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799521.501443913\n",
      "Sharpe:  -0.5984370131706005\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792941.119396369\n",
      "Sharpe:  -3.202505794775843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793034.8206050949\n",
      "Sharpe:  -1.6839779197115683\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773210.8889325362\n",
      "Sharpe:  -1.0371503544135978\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793982.4576234266\n",
      "Sharpe:  -0.8759170004912765\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799125.3389308216\n",
      "Sharpe:  -1.9083862727265106\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 229           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008248091   |\n",
      "|    clip_fraction        | 0.0819        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.196         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.161        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00835      |\n",
      "|    reward               | -0.0053093107 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00179       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778516.0402336724\n",
      "Sharpe:  -1.6076949081181044\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736611.6012583164\n",
      "Sharpe:  -0.32003379911764335\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799406.5852241507\n",
      "Sharpe:  -0.3518016464454298\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798309.3297129052\n",
      "Sharpe:  -0.9942796203332537\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010737756 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.171      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | 0.008683188 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00119     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791049.5809946308\n",
      "Sharpe:  -1.4312152659254447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781884.1905064798\n",
      "Sharpe:  -3.95707770111998\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786373.2930853555\n",
      "Sharpe:  -1.625501983244838\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799957.9247401229\n",
      "Sharpe:  -3.059518713695196\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764273.6741532191\n",
      "Sharpe:  -1.1690858263605035\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799182.1944536703\n",
      "Sharpe:  -4.172304420226201\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782624.1710561794\n",
      "Sharpe:  -2.6275052654236037\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798564.2230130128\n",
      "Sharpe:  -1.5666845399834408\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786439.267772589\n",
      "Sharpe:  -3.756700974732869\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791413.4427521097\n",
      "Sharpe:  -1.9414670779741587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767471.1363240132\n",
      "Sharpe:  -1.6340828660571223\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 228           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011011403   |\n",
      "|    clip_fraction        | 0.114         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.0708        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.0113       |\n",
      "|    reward               | -0.0011749802 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.0011        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794184.5134282237\n",
      "Sharpe:  -0.3563845840525503\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788062.4682961629\n",
      "Sharpe:  -0.43547229913668756\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791644.7524534808\n",
      "Sharpe:  -0.41603364304647256\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009812308 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.181      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.007090032 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796512.9422182728\n",
      "Sharpe:  -0.8026564342046916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798454.582789083\n",
      "Sharpe:  -2.7333949451434516\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746747.3748234815\n",
      "Sharpe:  -1.585040817650767\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796770.9488204647\n",
      "Sharpe:  -0.984131867033058\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797788.954356428\n",
      "Sharpe:  -1.1095986730637235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747600.9640506986\n",
      "Sharpe:  -6.64721058681957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780237.8251579882\n",
      "Sharpe:  -0.6807405572898638\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 226           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 90            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011931632   |\n",
      "|    clip_fraction        | 0.139         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.511         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.0155       |\n",
      "|    reward               | -0.0034901618 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000875      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796386.8577810386\n",
      "Sharpe:  -0.4647479142325323\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798204.0732689892\n",
      "Sharpe:  -1.2361363670467678\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789209.4399077249\n",
      "Sharpe:  -1.009326001180653\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794133.5345194234\n",
      "Sharpe:  -1.3549567259059103\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759295.1080613983\n",
      "Sharpe:  -2.3562886265548326\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774211.59215622\n",
      "Sharpe:  -1.8756942872101943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741899.3256446058\n",
      "Sharpe:  -0.6592771197590388\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011250427  |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.155       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    reward               | 0.0025088459 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00125      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780325.6853508938\n",
      "Sharpe:  -0.3940768055262208\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799953.9658706132\n",
      "Sharpe:  -1.3157070890570537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767604.6442324651\n",
      "Sharpe:  -6.2553180340860095\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799494.3610093845\n",
      "Sharpe:  -0.988248391543023\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789047.12278174\n",
      "Sharpe:  -3.645496303356341\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798535.0074229024\n",
      "Sharpe:  -1.2823249834225479\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797604.3102910406\n",
      "Sharpe:  -5.35424001516335\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011364159  |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    reward               | -0.011094866 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00062      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794402.3972528356\n",
      "Sharpe:  -2.6816315107086592\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744716.925359223\n",
      "Sharpe:  -0.7429094399412762\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782554.9523984514\n",
      "Sharpe:  -0.9336635895596742\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799904.3696956566\n",
      "Sharpe:  -1.1304706898567554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799199.6262712723\n",
      "Sharpe:  -1.207554767191806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789042.0743639015\n",
      "Sharpe:  -1.0298958093982657\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009692727 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.146      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.015544666 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000782    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799070.2257961394\n",
      "Sharpe:  -1.256035934498787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795479.3610143963\n",
      "Sharpe:  -0.555747207262695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794247.7942715497\n",
      "Sharpe:  -1.66974983148872\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797378.7334599185\n",
      "Sharpe:  -1.6660721436341661\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799991.1476793307\n",
      "Sharpe:  -1.1823322126646738\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799109.219757193\n",
      "Sharpe:  -2.447494602750795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791907.2456153684\n",
      "Sharpe:  -1.6363228794716893\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755420.7659725071\n",
      "Sharpe:  -3.7684962371619415\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010990252 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.155      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -0.02118692 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000793    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782952.6367533403\n",
      "Sharpe:  -1.037157345624923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797587.1114487518\n",
      "Sharpe:  -1.990428153901144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735044.6494670735\n",
      "Sharpe:  -0.9112886003787933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799376.2490284656\n",
      "Sharpe:  -1.8422525043979534\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776381.5169107545\n",
      "Sharpe:  -1.893218134657824\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794466.6752525788\n",
      "Sharpe:  -0.7498340998587643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765030.8633633978\n",
      "Sharpe:  -2.0760930723395505\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011155824  |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.172       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00931     |\n",
      "|    reward               | 0.0023038546 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000499     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798387.1550315467\n",
      "Sharpe:  -1.2847531778422585\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794984.5114332875\n",
      "Sharpe:  -2.7017536992621367\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755652.3394593135\n",
      "Sharpe:  -0.8787719958389908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799234.8731047655\n",
      "Sharpe:  -1.9808534491147523\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786393.0343265736\n",
      "Sharpe:  -1.3073370581440353\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775954.0801249966\n",
      "Sharpe:  -0.43732937624416246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784695.8803813962\n",
      "Sharpe:  -4.091123808964527\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 146           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011832204   |\n",
      "|    clip_fraction        | 0.117         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.753         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0137       |\n",
      "|    reward               | -0.0030094592 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00058       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788558.5641643154\n",
      "Sharpe:  -1.4097326958745282\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770576.4844845618\n",
      "Sharpe:  -5.124533948081178\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:746513.3636301507\n",
      "Sharpe:  -1.6972894531080884\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786445.1997769462\n",
      "Sharpe:  -4.458985327538797\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787476.6568394393\n",
      "Sharpe:  -0.8955840141363489\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795679.3833498632\n",
      "Sharpe:  -0.962238567768757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798058.2175650954\n",
      "Sharpe:  -0.9464322718255527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788896.5135214656\n",
      "Sharpe:  -3.2048878081509997\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011975614 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.163      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.005832548 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000858    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759188.8377175771\n",
      "Sharpe:  -1.546473890696347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797189.2804510671\n",
      "Sharpe:  -0.9357073707910505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787770.5904633992\n",
      "Sharpe:  -0.4840634725107226\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797839.4915855788\n",
      "Sharpe:  -0.722891617047654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795282.8313999278\n",
      "Sharpe:  -0.8644160192746517\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010823289  |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    reward               | 0.0057920883 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000512     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796332.5481935316\n",
      "Sharpe:  -0.6217543721016825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783513.9541324376\n",
      "Sharpe:  -1.1496375232102451\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741730.9132784519\n",
      "Sharpe:  -6.159310338992597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781258.6300334485\n",
      "Sharpe:  -0.6878079572534382\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790354.6042155346\n",
      "Sharpe:  -0.9878789913822629\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793347.7699761365\n",
      "Sharpe:  -2.070724224940611\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797316.8300191363\n",
      "Sharpe:  -0.9181164149885882\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792733.6810042483\n",
      "Sharpe:  -1.5964923656303287\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01578631  |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.15       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.006943498 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000744    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797568.8055440823\n",
      "Sharpe:  -7.140197544730779\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799066.4747026023\n",
      "Sharpe:  -0.4772869820149665\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776051.8344575213\n",
      "Sharpe:  -0.7593491010271555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790053.5139893969\n",
      "Sharpe:  -0.7872285459063295\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745255.5282117123\n",
      "Sharpe:  -7.249748317824754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629894 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.129      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 0.013261516 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00069     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795696.8866021915\n",
      "Sharpe:  -0.32436179351133937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768201.6203445465\n",
      "Sharpe:  -1.504181428473836\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777191.1378491769\n",
      "Sharpe:  -0.7361757403386124\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796001.2574327417\n",
      "Sharpe:  -2.2136025372879002\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794425.1751489298\n",
      "Sharpe:  -2.633605881512337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794623.671449384\n",
      "Sharpe:  -7.086513288749147\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780944.3537334659\n",
      "Sharpe:  -2.978603707035398\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797813.0242894429\n",
      "Sharpe:  -0.524235417783635\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 193           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013955167   |\n",
      "|    clip_fraction        | 0.143         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.808         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.152        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0117       |\n",
      "|    reward               | 0.00015294924 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000849      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751181.8528599737\n",
      "Sharpe:  -0.974860168047615\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799501.867131793\n",
      "Sharpe:  -1.3694765394888144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797564.5794559448\n",
      "Sharpe:  -2.286218075019592\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777085.8391685496\n",
      "Sharpe:  -1.6152787029547169\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794438.2101755912\n",
      "Sharpe:  -0.14018481860534962\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 202           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012204127   |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.82          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.159        |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.0126       |\n",
      "|    reward               | -0.0061065773 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000734      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754536.6205285891\n",
      "Sharpe:  -1.347739758690626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740189.9891159586\n",
      "Sharpe:  -2.995497600221425\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773902.1837407928\n",
      "Sharpe:  -1.1351890370554363\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789904.7397205031\n",
      "Sharpe:  -0.3014531324638816\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766187.4369308498\n",
      "Sharpe:  -1.677780991700439\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 211           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010189539   |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.83          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.164        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0095       |\n",
      "|    reward               | 0.00062235753 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000964      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793851.4145600436\n",
      "Sharpe:  -0.688255107720607\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791160.9569290952\n",
      "Sharpe:  -4.099269511408221\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799295.5231022439\n",
      "Sharpe:  -0.5026310420054169\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780254.182763137\n",
      "Sharpe:  -3.233076936571678\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770753.8179925616\n",
      "Sharpe:  -4.699976324626127\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798793.1183646044\n",
      "Sharpe:  -1.5629798991776838\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798842.9903806669\n",
      "Sharpe:  -0.6356543395697181\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 220           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013757202   |\n",
      "|    clip_fraction        | 0.153         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.819         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.153        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0164       |\n",
      "|    reward               | -0.0022210793 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000729      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791605.9130206627\n",
      "Sharpe:  -0.5210161286452628\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790541.2796747329\n",
      "Sharpe:  -0.09331670276199018\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799869.4012527526\n",
      "Sharpe:  -0.8346048251930253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01149324  |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.131      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.006760404 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000537    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1001068.3365750274\n",
      "Sharpe:  0.17511530309686482\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.0010683365750276952 -0.017208365517791206 0.17511530309686482 0\n",
      "2023-11-01 00:00:00 2023-12-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_11_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795208.8920754938\n",
      "Sharpe:  -3.383961460016732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798992.7534087265\n",
      "Sharpe:  -0.9134464535297381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799142.0284568636\n",
      "Sharpe:  -1.7285116745391476\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797139.9042121781\n",
      "Sharpe:  -1.524292886166936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776017.2998384259\n",
      "Sharpe:  -1.48956856935942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792325.9504376983\n",
      "Sharpe:  -0.5498703210228194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766139.0974174397\n",
      "Sharpe:  -0.6682717968178269\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 280           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 7             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0141173825 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795494.6515782482\n",
      "Sharpe:  -1.7412644126402275\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787115.5512146404\n",
      "Sharpe:  -0.6084907136903943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794494.7391159441\n",
      "Sharpe:  -3.081352100490286\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785396.5047997257\n",
      "Sharpe:  -13.07367739121217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795681.6291619703\n",
      "Sharpe:  -0.8455251778102163\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:732438.4807711121\n",
      "Sharpe:  -0.882391378519337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:743184.9869584528\n",
      "Sharpe:  -1.8091075174223017\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773844.4366836302\n",
      "Sharpe:  -4.553953965918279\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084793335 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.135       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | 0.01669006   |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00306      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:742460.0192135321\n",
      "Sharpe:  -0.5068088977921259\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762801.4391632688\n",
      "Sharpe:  -0.28421055255558003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798953.9921765778\n",
      "Sharpe:  -2.8401068706790675\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799640.1142451247\n",
      "Sharpe:  -1.2204176265942488\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794699.9813309569\n",
      "Sharpe:  -1.3437897997869557\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009988788  |\n",
      "|    clip_fraction        | 0.087        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.166       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -0.003158059 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00161      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775387.7654390519\n",
      "Sharpe:  -0.960477234608283\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793884.2778926302\n",
      "Sharpe:  -3.182464844122638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791967.9617892765\n",
      "Sharpe:  -0.3662707345178021\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791417.0267182327\n",
      "Sharpe:  -2.6080053666039853\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735798.5902099003\n",
      "Sharpe:  -1.001486500817507\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791909.655277384\n",
      "Sharpe:  -3.287715688483047\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791776.1834836325\n",
      "Sharpe:  -1.926186441444421\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796137.6474382462\n",
      "Sharpe:  -2.6993149524386717\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 232           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009191266   |\n",
      "|    clip_fraction        | 0.103         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.204         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00954      |\n",
      "|    reward               | 0.00065966236 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00202       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798396.469280618\n",
      "Sharpe:  -2.202349286598229\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770830.4846163042\n",
      "Sharpe:  -0.7383260518236496\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790489.8699876317\n",
      "Sharpe:  -0.29225514551828735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745948.3605912337\n",
      "Sharpe:  -0.8140051035042537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799169.4972846162\n",
      "Sharpe:  -0.7010547351646184\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 229           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 44            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010114398   |\n",
      "|    clip_fraction        | 0.116         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.54          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.167        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0128       |\n",
      "|    reward               | -0.0034109275 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000834      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714259.9234288625\n",
      "Sharpe:  -0.6775992266115713\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799339.8997607677\n",
      "Sharpe:  -1.114319595042971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786242.6526096985\n",
      "Sharpe:  -0.9081243183514167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759153.1307388904\n",
      "Sharpe:  -4.276210106666876\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:641839.3298710147\n",
      "Sharpe:  -0.5925782454602048\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 228           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0104632     |\n",
      "|    clip_fraction        | 0.115         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.255         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.138        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.012        |\n",
      "|    reward               | -0.0039953846 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00127       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798407.5272482301\n",
      "Sharpe:  -1.0576540369567562\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794809.0157288073\n",
      "Sharpe:  -2.1158564452256394\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784128.7651855618\n",
      "Sharpe:  -1.158825477886334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755040.4370049047\n",
      "Sharpe:  -6.06564303576755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753825.4953329582\n",
      "Sharpe:  -2.323421575500391\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796110.2725377165\n",
      "Sharpe:  -0.8903482527972038\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787746.4139389991\n",
      "Sharpe:  -2.001254189844731\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798209.7762709587\n",
      "Sharpe:  -2.493838769910564\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:732215.7402452088\n",
      "Sharpe:  -1.0060518893073196\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 227          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011526032  |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.009488563 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00102      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796576.437439315\n",
      "Sharpe:  -2.384653244326819\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764570.6184060547\n",
      "Sharpe:  -1.5452066446925057\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760990.453946205\n",
      "Sharpe:  -3.5543438009998045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799912.5112287945\n",
      "Sharpe:  -2.0899665183709777\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782064.6118135614\n",
      "Sharpe:  -0.8311669507259747\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782532.6286970915\n",
      "Sharpe:  -0.7641583093839786\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774125.308772192\n",
      "Sharpe:  -0.9757103669393883\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014215074  |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.124       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | 0.0015796884 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000735     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760729.9055036475\n",
      "Sharpe:  -0.43143844530112774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785787.8375231789\n",
      "Sharpe:  -1.2754596105697555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726684.661381754\n",
      "Sharpe:  -3.9295879481190097\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789863.6713598078\n",
      "Sharpe:  -1.686085100688931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792601.7796913305\n",
      "Sharpe:  -0.5010267390193393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798538.6323030962\n",
      "Sharpe:  -1.062776074562469\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012198597   |\n",
      "|    clip_fraction        | 0.132         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.568         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.145        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0125       |\n",
      "|    reward               | -0.0012201604 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000825      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790920.8057182755\n",
      "Sharpe:  -1.3668761195617394\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793526.5101866971\n",
      "Sharpe:  -0.8869188226233217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798671.5080518596\n",
      "Sharpe:  -0.4249622773390892\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797805.6475915046\n",
      "Sharpe:  -0.40448161444436276\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009457175   |\n",
      "|    clip_fraction        | 0.121         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.671         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.0123       |\n",
      "|    reward               | -0.0055000773 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000695      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754968.0872800408\n",
      "Sharpe:  -0.4888626234857712\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:658353.7860504278\n",
      "Sharpe:  -0.8838840359488949\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789698.3360866441\n",
      "Sharpe:  -7.476265594895181\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798416.7979744123\n",
      "Sharpe:  -0.31434865592521577\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 101           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012544839   |\n",
      "|    clip_fraction        | 0.157         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.144        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.016        |\n",
      "|    reward               | -0.0034362013 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000624      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790858.5023509971\n",
      "Sharpe:  -0.9573649716178848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775080.8698035328\n",
      "Sharpe:  -1.7743583769979279\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789061.3903925753\n",
      "Sharpe:  -2.047356929395185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797300.7412033387\n",
      "Sharpe:  -1.4458028698961505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772915.7192497978\n",
      "Sharpe:  -0.8365945413118865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794652.0792229163\n",
      "Sharpe:  -0.46474538707360497\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 110           |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013463984   |\n",
      "|    clip_fraction        | 0.169         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.144        |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.0142       |\n",
      "|    reward               | -0.0040171924 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000982      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783294.6009518484\n",
      "Sharpe:  -1.1512930775178811\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764931.214206795\n",
      "Sharpe:  -2.138523897054398\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796316.6880471932\n",
      "Sharpe:  -0.8834705918442772\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782301.1304487817\n",
      "Sharpe:  -0.9478847779922785\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771961.5531644098\n",
      "Sharpe:  -2.0727297257801864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799219.0630614401\n",
      "Sharpe:  -0.7761236549561703\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765375.6352278215\n",
      "Sharpe:  -5.6369518371496214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783966.471138356\n",
      "Sharpe:  -4.172137817344948\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788727.674916753\n",
      "Sharpe:  -2.3183073103576257\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010756825  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00921     |\n",
      "|    reward               | -0.011455058 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000622     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794124.7641294672\n",
      "Sharpe:  -2.0801443881655994\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797139.5388879764\n",
      "Sharpe:  -0.7596994694944946\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767247.1895948888\n",
      "Sharpe:  -2.2884126153481117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783826.0643149036\n",
      "Sharpe:  -6.29395788437198\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795741.5721655362\n",
      "Sharpe:  -1.1036999798739873\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754719.8229792048\n",
      "Sharpe:  -1.936810185977404\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799096.773781538\n",
      "Sharpe:  -0.3545958185237564\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010419412  |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.157       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | 0.0009099826 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00105      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776766.4595238495\n",
      "Sharpe:  -0.5357770059738857\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787437.2244167809\n",
      "Sharpe:  -2.1458022240908505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:723477.0653085767\n",
      "Sharpe:  -0.7225819903757466\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789550.9057998633\n",
      "Sharpe:  -0.9880426679037422\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785479.8917960289\n",
      "Sharpe:  -3.1212305660088493\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799655.9516933864\n",
      "Sharpe:  -1.146419755383273\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122830495 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.154       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | -0.001535781 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000831     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799997.1081670112\n",
      "Sharpe:  -1.0135456610922282\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798580.6531415485\n",
      "Sharpe:  -3.8435250470074314\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780375.1856495475\n",
      "Sharpe:  -0.5073637012021381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785968.3528927661\n",
      "Sharpe:  -0.9571835242694493\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786749.7336568617\n",
      "Sharpe:  -5.561886307277336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798625.6350493835\n",
      "Sharpe:  -0.9185543488631256\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791188.9608979868\n",
      "Sharpe:  -3.4581593349965933\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 221           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 148           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013457755   |\n",
      "|    clip_fraction        | 0.157         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.127        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0109       |\n",
      "|    reward               | -0.0027578524 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00074       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785396.5271842714\n",
      "Sharpe:  -0.6290623969757525\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779854.1362916953\n",
      "Sharpe:  -1.7227877574854267\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796489.1455211092\n",
      "Sharpe:  -1.00958402544421\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799714.0141207253\n",
      "Sharpe:  -3.4087164649155173\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790454.415996643\n",
      "Sharpe:  -1.169996184669537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796181.9253826435\n",
      "Sharpe:  -0.46742956196131435\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765728.6188683959\n",
      "Sharpe:  -1.7388088273840143\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013016705  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.124       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -0.013190755 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000742     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738729.0696095066\n",
      "Sharpe:  -0.6089306259295681\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790760.9302438104\n",
      "Sharpe:  -0.5206496678642066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799385.9313199434\n",
      "Sharpe:  -0.4041206571085255\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771964.7333573425\n",
      "Sharpe:  -3.0701148664022537\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130008925 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.141       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    reward               | 0.01754223   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000655     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793683.0453889334\n",
      "Sharpe:  -0.8725123008854146\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785411.3893443545\n",
      "Sharpe:  -0.32787267234445955\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770345.7632650547\n",
      "Sharpe:  -0.5112161243774322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797646.4361110962\n",
      "Sharpe:  -1.5405668758447957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799970.9437506163\n",
      "Sharpe:  -4.237845400898595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799921.4160272877\n",
      "Sharpe:  -2.343413731409714\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138061885 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    reward               | 6.427509e-05 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00067      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762236.7640691088\n",
      "Sharpe:  -1.2754050026945514\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796678.1067846318\n",
      "Sharpe:  -0.6143804195470235\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794508.7601138497\n",
      "Sharpe:  -2.0885033905947927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798100.7089802733\n",
      "Sharpe:  -0.9514525565432052\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791740.486636874\n",
      "Sharpe:  -1.447565846032573\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781466.4138959588\n",
      "Sharpe:  -9.758724893486944\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013583275  |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.156       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    reward               | 0.0012956169 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000606     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794070.6213634772\n",
      "Sharpe:  -0.27390670491468005\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799585.4636624091\n",
      "Sharpe:  -0.4050630066188132\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786322.7548760708\n",
      "Sharpe:  -0.9282695308503854\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797669.9987619005\n",
      "Sharpe:  -1.0533334659917886\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012744743  |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | 0.0017034534 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000564     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775709.0444016269\n",
      "Sharpe:  -0.6060953607863262\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:747525.5784930126\n",
      "Sharpe:  -3.12634420019003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779614.5052716701\n",
      "Sharpe:  -1.3117006278107053\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788753.1180350275\n",
      "Sharpe:  -1.3543543453508466\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768040.398853097\n",
      "Sharpe:  -2.1064608566694827\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795779.2272189888\n",
      "Sharpe:  -0.3967904129202919\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012442002  |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.15        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    reward               | -0.005931109 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000484     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799524.5987181081\n",
      "Sharpe:  -1.9440947062137737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797497.0863136583\n",
      "Sharpe:  -0.7678590619636757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772614.1994966854\n",
      "Sharpe:  -1.7580247792851482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782492.249941139\n",
      "Sharpe:  -0.600182820482546\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010815665  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00961     |\n",
      "|    reward               | -0.005141522 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000614     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:609962.956638924\n",
      "Sharpe:  -0.30081689573752923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798252.5357921909\n",
      "Sharpe:  -2.2705610532857268\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781933.1060118756\n",
      "Sharpe:  -1.7444533474597903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781189.2214932996\n",
      "Sharpe:  -0.672174445044599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778243.6821721965\n",
      "Sharpe:  -0.42635871401012004\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 219           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 223           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012141645   |\n",
      "|    clip_fraction        | 0.148         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.711         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.108        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0105       |\n",
      "|    reward               | -0.0021466445 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000937      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789577.8335357794\n",
      "Sharpe:  -0.45878102373543367\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798355.9255804091\n",
      "Sharpe:  -0.2216539516363788\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790161.9857932011\n",
      "Sharpe:  -0.6801024666419503\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798958.7819945074\n",
      "Sharpe:  -2.166407287999083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010928001 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.106      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.008014517 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:989814.4149489866\n",
      "Sharpe:  -2.4599092533402827\n",
      "=================================\n",
      "hit end!\n",
      "ppo -0.010185585051013524 -0.014105093497027195 -2.4599092533402827 0\n",
      "2023-12-01 00:00:00 2024-01-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_12_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793494.8737477969\n",
      "Sharpe:  -1.3120208321812619\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757621.5976433589\n",
      "Sharpe:  -1.1322391468837856\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797954.0907369846\n",
      "Sharpe:  -2.1337379563658274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796691.578146479\n",
      "Sharpe:  -7.8103040663074355\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797576.7516577684\n",
      "Sharpe:  -1.9665069903641506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799155.3648966732\n",
      "Sharpe:  -0.4886391107688825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798526.8883099327\n",
      "Sharpe:  -4.1226621259682465\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783191.5032773409\n",
      "Sharpe:  -1.6464844151394855\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 276          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.010232157 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740768.2690795482\n",
      "Sharpe:  -1.8841275900114949\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750603.3739342608\n",
      "Sharpe:  -2.9717993065056727\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772829.7756830561\n",
      "Sharpe:  -1.5711048654836777\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793104.996327727\n",
      "Sharpe:  -0.4421686167928614\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776871.9211578929\n",
      "Sharpe:  -0.5567220529518806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794959.1887055079\n",
      "Sharpe:  -0.8292001387582457\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077356556 |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.452       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    reward               | 0.005731913  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00704      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750005.7747945195\n",
      "Sharpe:  -0.7469458366847761\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757185.898222468\n",
      "Sharpe:  -2.1921324808193274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799973.6370090975\n",
      "Sharpe:  -0.7011059451684449\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798176.3464467517\n",
      "Sharpe:  -1.070491915324793\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795335.0991729184\n",
      "Sharpe:  -2.9076722710328458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783740.8921430431\n",
      "Sharpe:  -0.32776412112328135\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009577109 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.128      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.02015424  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00527     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799430.4634329443\n",
      "Sharpe:  -0.9179500476588469\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765954.1596857535\n",
      "Sharpe:  -2.84199321275626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785891.5379856041\n",
      "Sharpe:  -3.8036126640339116\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766787.7908258225\n",
      "Sharpe:  -3.475186194380885\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799013.435083604\n",
      "Sharpe:  -2.132823923725095\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791810.3584822891\n",
      "Sharpe:  -2.2859408305362776\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786572.3410617803\n",
      "Sharpe:  -5.073516916528234\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798873.2210875198\n",
      "Sharpe:  -1.156708252027307\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797139.3229424255\n",
      "Sharpe:  -1.180444124618327\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793401.9165286988\n",
      "Sharpe:  -5.324446216714916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798786.7126513696\n",
      "Sharpe:  -3.287213744426848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794444.76133337\n",
      "Sharpe:  -3.513402324985395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775401.2627575751\n",
      "Sharpe:  -2.6063377299492614\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009952915 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.006605555 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00297     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780479.9673587127\n",
      "Sharpe:  -3.0648331686924157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787783.9884633956\n",
      "Sharpe:  -2.615066511646588\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795282.2943941089\n",
      "Sharpe:  -1.9430663902951009\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760443.0796042316\n",
      "Sharpe:  -1.0686521877718131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798579.3250858487\n",
      "Sharpe:  -2.008511460312537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725613.062811459\n",
      "Sharpe:  -0.42292756257948155\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756600.1479753293\n",
      "Sharpe:  -0.6997679662924087\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 45            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010266662   |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.453         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.159        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0137       |\n",
      "|    reward               | 0.00010743322 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00207       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789148.8138706152\n",
      "Sharpe:  -1.6720194937049027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794606.7931180281\n",
      "Sharpe:  -2.865779215353733\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798908.9659426309\n",
      "Sharpe:  -2.5519905277969097\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789855.1502558093\n",
      "Sharpe:  -2.1689414107275446\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783486.0552629638\n",
      "Sharpe:  -0.9299867649594541\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778111.8036385905\n",
      "Sharpe:  -3.245251403199612\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789771.3684872348\n",
      "Sharpe:  -4.970712385447562\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798542.1197329726\n",
      "Sharpe:  -1.889078800552563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789978.2774209712\n",
      "Sharpe:  -0.7289721718672029\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011043623  |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.15        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | -0.006988931 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00191      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796323.7781158356\n",
      "Sharpe:  -1.2146865856074005\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798648.069225946\n",
      "Sharpe:  -1.3609778138302389\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799147.929032356\n",
      "Sharpe:  -2.002017095589129\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782396.6828608207\n",
      "Sharpe:  -1.352328025816287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794995.9332303684\n",
      "Sharpe:  -1.3598388963736059\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799849.3061464409\n",
      "Sharpe:  -0.7991724986017655\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770587.7611912327\n",
      "Sharpe:  -1.7203490579965597\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780883.9965835597\n",
      "Sharpe:  -3.9905950668135306\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793698.0963103969\n",
      "Sharpe:  -7.703478824641495\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008744722  |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    reward               | -0.007962128 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00114      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799963.3201759586\n",
      "Sharpe:  -2.4835313673181947\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791454.1131942068\n",
      "Sharpe:  -1.4205896973570353\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768978.2947048882\n",
      "Sharpe:  -0.9081769238195643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795905.9713325173\n",
      "Sharpe:  -1.207373388195532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768521.5493258637\n",
      "Sharpe:  -3.4939569050279307\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740120.813925246\n",
      "Sharpe:  -6.398717526836159\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779693.7826188792\n",
      "Sharpe:  -2.4738558818359424\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774748.2835969599\n",
      "Sharpe:  -1.8171936450452615\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795501.2151057817\n",
      "Sharpe:  -3.8666846931110674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760460.444504973\n",
      "Sharpe:  -3.801708921963523\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 219           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 74            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009615125   |\n",
      "|    clip_fraction        | 0.114         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.011        |\n",
      "|    reward               | -0.0034676613 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00055       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790464.9146999274\n",
      "Sharpe:  -0.6288557024133988\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793478.5460421086\n",
      "Sharpe:  -1.7014503779496724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791142.7839376167\n",
      "Sharpe:  -1.1943246196095825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:703157.6762642865\n",
      "Sharpe:  -0.7699169542137914\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795039.044293686\n",
      "Sharpe:  -4.653564695622624\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009977547 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.113      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.009409936 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000822    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793777.3863936272\n",
      "Sharpe:  -0.43642298405470986\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793228.1961622206\n",
      "Sharpe:  -1.0341244208417695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751872.0015977806\n",
      "Sharpe:  -7.988462337183736\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750835.3212618884\n",
      "Sharpe:  -2.5005539637497347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764468.6803505735\n",
      "Sharpe:  -0.4599818147203627\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767201.5377858216\n",
      "Sharpe:  -3.5193257475174633\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797667.6892922751\n",
      "Sharpe:  -1.0534680072145013\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771278.8595630007\n",
      "Sharpe:  -3.4759569958015493\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773854.8271725061\n",
      "Sharpe:  -4.148852556115529\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 218           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 93            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009620599   |\n",
      "|    clip_fraction        | 0.127         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.841         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00962      |\n",
      "|    reward               | -0.0006719712 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000752      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775361.429591631\n",
      "Sharpe:  -2.627476303933665\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799982.7758021788\n",
      "Sharpe:  -1.8927314765633423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797863.0245203954\n",
      "Sharpe:  -3.144003993767438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791057.0939548902\n",
      "Sharpe:  -1.6150316930775064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791418.6240398368\n",
      "Sharpe:  -3.1538895700121894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796124.2126193709\n",
      "Sharpe:  -1.215430957337803\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799405.5777870829\n",
      "Sharpe:  -2.16039814320228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784200.5386747669\n",
      "Sharpe:  -14.134923296749758\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793582.6465275987\n",
      "Sharpe:  -0.4196325882965613\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796337.6462123161\n",
      "Sharpe:  -6.107333043420914\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 217            |\n",
      "|    iterations           | 11             |\n",
      "|    time_elapsed         | 103            |\n",
      "|    total_timesteps      | 22528          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.011216132    |\n",
      "|    clip_fraction        | 0.131          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.1          |\n",
      "|    explained_variance   | 0.824          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.16          |\n",
      "|    n_updates            | 100            |\n",
      "|    policy_gradient_loss | -0.0124        |\n",
      "|    reward               | -0.00027512774 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 0.000808       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765783.3798725463\n",
      "Sharpe:  -2.9754224843089867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781127.6411196141\n",
      "Sharpe:  -1.711700520199075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763152.3497470227\n",
      "Sharpe:  -0.21820255990967705\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796600.5432669172\n",
      "Sharpe:  -0.7627054450603893\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011209973 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.16       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.009904115 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000535    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799305.8785211494\n",
      "Sharpe:  -1.736276422642898\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796864.5187741243\n",
      "Sharpe:  -0.6295864449590639\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797694.4996831111\n",
      "Sharpe:  -0.5762856921153672\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794461.0848178514\n",
      "Sharpe:  -1.9120682363617116\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796165.7046600827\n",
      "Sharpe:  -0.3474510926471774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:721892.5644695618\n",
      "Sharpe:  -6.511318767430158\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120200785 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.135       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    reward               | -0.01976994  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000828     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:710387.3234625488\n",
      "Sharpe:  -0.34435166689562785\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796183.8469652203\n",
      "Sharpe:  -0.8106510909677415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799283.3420051658\n",
      "Sharpe:  -0.9234678651179556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787888.0774565218\n",
      "Sharpe:  -1.1065598631883091\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114392955 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.146       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    reward               | -0.004176043 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000705     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777245.7464848199\n",
      "Sharpe:  -0.6975341415196357\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796896.3970179174\n",
      "Sharpe:  -3.8017990274138653\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744025.695659329\n",
      "Sharpe:  -1.7641409267491919\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799507.2207182451\n",
      "Sharpe:  -2.132254030709598\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790548.7473677397\n",
      "Sharpe:  -3.0261301191694074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787349.2637795486\n",
      "Sharpe:  -1.3123828722614912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793201.1541309044\n",
      "Sharpe:  -0.7588837248856635\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012677495  |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.15        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    reward               | 0.0021823861 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000778     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796268.3152029352\n",
      "Sharpe:  -0.25809234973009115\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797457.2761497379\n",
      "Sharpe:  -1.0724546207902959\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785692.5752028915\n",
      "Sharpe:  -4.160416743163347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780034.3986796561\n",
      "Sharpe:  -0.500974565047107\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793020.911380711\n",
      "Sharpe:  -1.2176002492942337\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 216          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012937091  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.128       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | 0.0004857245 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000717     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782551.1481527973\n",
      "Sharpe:  -0.35027002809045754\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784159.7791061089\n",
      "Sharpe:  -0.9231120008070819\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794564.216979504\n",
      "Sharpe:  -0.9292781474129432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792922.9405298808\n",
      "Sharpe:  -0.36342348401396335\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784345.8975163837\n",
      "Sharpe:  -1.3770389613047864\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013415379 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.157      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 0.005914691 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00058     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789437.1073246707\n",
      "Sharpe:  -1.2946830544897714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777383.6316616458\n",
      "Sharpe:  -1.5668287032106316\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784885.8770001421\n",
      "Sharpe:  -0.8530284284315716\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786427.5432146703\n",
      "Sharpe:  -0.8294139954692209\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779773.2915266451\n",
      "Sharpe:  -2.6824473022897655\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798500.5662593285\n",
      "Sharpe:  -0.7262895351020556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782333.1925663834\n",
      "Sharpe:  -6.6175040356120105\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014090944  |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.154       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    reward               | -0.005998919 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000637     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796895.0843619294\n",
      "Sharpe:  -0.35328041939958343\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799723.0058188767\n",
      "Sharpe:  -2.7450504055730045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780155.5330360006\n",
      "Sharpe:  -2.2651402241980945\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794855.2336017397\n",
      "Sharpe:  -0.342880551331411\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783947.4406192327\n",
      "Sharpe:  -0.9572625044902227\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013319898 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.145      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.09220372 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.000606    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770997.4438672059\n",
      "Sharpe:  -3.1389032905767533\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799951.3062748061\n",
      "Sharpe:  -0.9523258717002755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795633.6005764266\n",
      "Sharpe:  -0.4851397104442926\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799427.7164357841\n",
      "Sharpe:  -1.0332751603859822\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798467.5722507794\n",
      "Sharpe:  -1.2922512404896571\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790598.8858995902\n",
      "Sharpe:  -1.829574146201109\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014525313  |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | -0.004394682 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.000764     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798504.7829618779\n",
      "Sharpe:  -1.3067432251896214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792671.2453441232\n",
      "Sharpe:  -0.608242167798123\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777360.6323875474\n",
      "Sharpe:  -1.5698936384946096\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762279.1913021398\n",
      "Sharpe:  -0.6375355497887281\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014914617 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.158      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 0.002404019 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.000427    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790216.9469750727\n",
      "Sharpe:  -0.46195913607852923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794545.1324113744\n",
      "Sharpe:  -0.2447324557832532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784749.4104645977\n",
      "Sharpe:  -0.5327121244212146\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763254.735535084\n",
      "Sharpe:  -2.453238632181722\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797967.5242858359\n",
      "Sharpe:  -1.027036098735552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797822.1084189459\n",
      "Sharpe:  -5.205678848792838\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 214            |\n",
      "|    iterations           | 22             |\n",
      "|    time_elapsed         | 209            |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.013590827    |\n",
      "|    clip_fraction        | 0.155          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.3          |\n",
      "|    explained_variance   | 0.849          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.144         |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -0.0103        |\n",
      "|    reward               | -0.00011225722 |\n",
      "|    std                  | 1.07           |\n",
      "|    value_loss           | 0.000425       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751081.577605261\n",
      "Sharpe:  -1.1285714499360517\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772764.1543624381\n",
      "Sharpe:  -2.1846420827819797\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798584.2490790696\n",
      "Sharpe:  -2.66077900303364\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792318.3829929461\n",
      "Sharpe:  -0.8560672944446719\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757318.922132289\n",
      "Sharpe:  -0.6751233906109573\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739266.0264594351\n",
      "Sharpe:  -0.5395658506828025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791453.5233082077\n",
      "Sharpe:  -2.0456587273823694\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 214           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 219           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014593707   |\n",
      "|    clip_fraction        | 0.182         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.878         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.162        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.014        |\n",
      "|    reward               | -0.0031265994 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.000559      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757003.9387996588\n",
      "Sharpe:  -1.2458713347980146\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:684359.9600604508\n",
      "Sharpe:  -0.5454685604503998\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763746.8065156841\n",
      "Sharpe:  -0.5195086371261102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798363.881031712\n",
      "Sharpe:  -0.8912043107479342\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 215           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 228           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011778068   |\n",
      "|    clip_fraction        | 0.147         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.4         |\n",
      "|    explained_variance   | 0.804         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.155        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0123       |\n",
      "|    reward               | -0.0035321573 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.000982      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798630.6687468339\n",
      "Sharpe:  -1.2357621372591454\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:689109.5016669219\n",
      "Sharpe:  -0.3075175628308595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745681.9637953416\n",
      "Sharpe:  -1.3474243779513326\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757941.5131329441\n",
      "Sharpe:  -3.5009827637505375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763730.8207265362\n",
      "Sharpe:  -0.6607284093366886\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012784271  |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.4        |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.163       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 0.0015245884 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.0011       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1029866.1623127948\n",
      "Sharpe:  2.5071884506216233\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.02986616231279471 -0.024058690587539688 2.5071884506216233 0\n",
      "2024-01-01 00:00:00 2024-02-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_13_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796156.4860485063\n",
      "Sharpe:  -1.6295113191780854\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:756830.2687113257\n",
      "Sharpe:  -1.1389891209792102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797245.1177328757\n",
      "Sharpe:  -1.0696562501063847\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799943.7452095194\n",
      "Sharpe:  -0.9149209890222899\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770572.2840569166\n",
      "Sharpe:  -1.443425794524224\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791686.3184990692\n",
      "Sharpe:  -2.2402589498919863\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785921.3159704531\n",
      "Sharpe:  -1.5044679222952624\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794488.4091262211\n",
      "Sharpe:  -1.3844679725726758\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 291          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0053859437 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772123.1411542791\n",
      "Sharpe:  -0.49628077229850953\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791400.3296484812\n",
      "Sharpe:  -0.42910293126837007\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796538.0604501783\n",
      "Sharpe:  -2.679888165077899\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792975.5411452211\n",
      "Sharpe:  -0.5480945173814162\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796437.1666233155\n",
      "Sharpe:  -6.836515003268431\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783899.4778429866\n",
      "Sharpe:  -2.225078843096737\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008546766   |\n",
      "|    clip_fraction        | 0.0818        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0395        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.155        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00846      |\n",
      "|    reward               | 0.00097368815 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.0124        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798891.8195647346\n",
      "Sharpe:  -1.1547223655391943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751205.4659263286\n",
      "Sharpe:  -2.2571602881704633\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776216.4555570687\n",
      "Sharpe:  -0.8168666243177755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751698.8642817654\n",
      "Sharpe:  -0.9719917716465492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796365.4415725882\n",
      "Sharpe:  -2.0157723148633897\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793770.5252567669\n",
      "Sharpe:  -2.65810459564399\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740956.094099068\n",
      "Sharpe:  -4.742865238377541\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789764.390899384\n",
      "Sharpe:  -6.805545244687595\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007688688  |\n",
      "|    clip_fraction        | 0.0709       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | -0.013935824 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00453      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787799.0105186396\n",
      "Sharpe:  -0.42978789682908336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:640021.9171175347\n",
      "Sharpe:  -0.8068989375037046\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775286.7962028212\n",
      "Sharpe:  -4.731307359230788\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796351.7875452744\n",
      "Sharpe:  -2.0895697257674026\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799715.0511112475\n",
      "Sharpe:  -1.4937452795907866\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789750.6489346185\n",
      "Sharpe:  -0.3847133734815795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798678.9742555486\n",
      "Sharpe:  -1.2157872963256844\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 237           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008949179   |\n",
      "|    clip_fraction        | 0.0869        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.415         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.144        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0115       |\n",
      "|    reward               | -0.0054705264 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00359       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760453.473686234\n",
      "Sharpe:  -1.3930908908911173\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795967.6173420815\n",
      "Sharpe:  -2.7793031359795157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791282.5606000007\n",
      "Sharpe:  -0.8624783598093977\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796953.7242242477\n",
      "Sharpe:  -1.0481019982564233\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782674.7436428765\n",
      "Sharpe:  -1.1804405547972263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793744.986750437\n",
      "Sharpe:  -1.3465581894301384\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768297.6519935885\n",
      "Sharpe:  -5.870928798124514\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792368.2355352442\n",
      "Sharpe:  -0.5770512086717384\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00897933   |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.154       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | -0.010408787 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00274      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796215.2507492353\n",
      "Sharpe:  -0.8838335389591535\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799689.1931674941\n",
      "Sharpe:  -1.3252055893748762\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782084.3884667801\n",
      "Sharpe:  -16.52635035680738\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753032.6448389473\n",
      "Sharpe:  -1.4577467554681072\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791451.0523144929\n",
      "Sharpe:  -1.9774801016675723\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796787.8790850808\n",
      "Sharpe:  -0.8487732485542892\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796935.7551154789\n",
      "Sharpe:  -0.7580055679418845\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799185.3610153301\n",
      "Sharpe:  -1.512376721198284\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 231          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009797331  |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.141       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | -0.000715592 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00195      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797033.346010094\n",
      "Sharpe:  -0.7639699113894953\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789207.3576654659\n",
      "Sharpe:  -8.206790721972267\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798129.2748399212\n",
      "Sharpe:  -0.5102767585075604\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788933.5865099462\n",
      "Sharpe:  -2.005061675531864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788734.9860352061\n",
      "Sharpe:  -1.9287522761535423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788867.6852246678\n",
      "Sharpe:  -0.826574453161925\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 229          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010623346  |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.141       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    reward               | 0.0065435925 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00133      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795016.1336328079\n",
      "Sharpe:  -0.4935713338612389\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799717.7911770015\n",
      "Sharpe:  -0.812279791254643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792204.7640325368\n",
      "Sharpe:  -1.7893748060087344\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796131.8594100943\n",
      "Sharpe:  -4.87575499849827\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778033.1931535916\n",
      "Sharpe:  -0.9393772664293802\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793688.6085917922\n",
      "Sharpe:  -0.6954289406517257\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 228           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011212836   |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.152        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.0123       |\n",
      "|    reward               | -0.0058358344 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000903      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750187.1661539993\n",
      "Sharpe:  -0.829077107172825\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799619.6542926605\n",
      "Sharpe:  -0.7889069684062945\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796252.35542904\n",
      "Sharpe:  -2.805369319845377\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796582.5535848761\n",
      "Sharpe:  -1.539812227174228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:707364.1087192748\n",
      "Sharpe:  -4.388225369501538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798494.037311319\n",
      "Sharpe:  -0.691010054615072\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 227           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 80            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011046436   |\n",
      "|    clip_fraction        | 0.132         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.19          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.117        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0122       |\n",
      "|    reward               | -0.0075165336 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000872      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:719532.8315933008\n",
      "Sharpe:  -0.6198626813545802\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792757.9750839452\n",
      "Sharpe:  -3.2970445016428513\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798595.9903561004\n",
      "Sharpe:  -0.4506590098762042\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797671.5680071637\n",
      "Sharpe:  -0.6577310446160154\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797663.678096563\n",
      "Sharpe:  -2.654330417180161\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774526.9973440688\n",
      "Sharpe:  -1.2860887461141406\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 227          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01122329   |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.106       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.109       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    reward               | 0.0008999855 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00103      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781774.65864003\n",
      "Sharpe:  -0.8518866310314102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797958.1119003287\n",
      "Sharpe:  -2.0282251485806584\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780072.7463281685\n",
      "Sharpe:  -0.7257331489828337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799752.035780917\n",
      "Sharpe:  -0.9883174982486858\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798929.165940042\n",
      "Sharpe:  -0.9245867613447483\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777051.4894018475\n",
      "Sharpe:  -1.794181620416391\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799734.3333606404\n",
      "Sharpe:  -0.9253390021241024\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 226           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 99            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013054563   |\n",
      "|    clip_fraction        | 0.134         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.329         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.153        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.012        |\n",
      "|    reward               | -0.0016457327 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00108       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797232.420209589\n",
      "Sharpe:  -0.8046198230521183\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:775168.8209499746\n",
      "Sharpe:  -1.6345709642397397\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789546.7143085194\n",
      "Sharpe:  -1.356653757426018\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793854.0154733845\n",
      "Sharpe:  -0.5297849375294281\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795246.5334411351\n",
      "Sharpe:  -1.144413732006207\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782968.7883048907\n",
      "Sharpe:  -1.960298072625934\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015314242  |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.124       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    reward               | 0.0023561937 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000622     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758732.6115778249\n",
      "Sharpe:  -1.1877232638141058\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794721.1095215201\n",
      "Sharpe:  -2.4221675524150403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799541.3527846576\n",
      "Sharpe:  -1.646675355299568\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791511.5542625058\n",
      "Sharpe:  -0.5695826604319215\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776887.5907145882\n",
      "Sharpe:  -3.3503646978385198\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797018.7441336046\n",
      "Sharpe:  -1.8118269645429748\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:722644.559740208\n",
      "Sharpe:  -0.82581590715917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464152 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.124      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | 0.011094004 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000706    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795552.464562137\n",
      "Sharpe:  -0.3771105573105931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797902.5671552346\n",
      "Sharpe:  -1.4802453250795384\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793007.0479156998\n",
      "Sharpe:  -1.102174728496719\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787493.1827853011\n",
      "Sharpe:  -1.5902178512433254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796676.5542073303\n",
      "Sharpe:  -0.9161825648332104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764958.6323866607\n",
      "Sharpe:  -0.5240356652495531\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011511516 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.169      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    reward               | 0.003230599 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000857    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796131.7497686051\n",
      "Sharpe:  -0.8124018531455255\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786315.6728921108\n",
      "Sharpe:  -2.940208766110794\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798139.2351304628\n",
      "Sharpe:  -0.6377037962003547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797164.8793677535\n",
      "Sharpe:  -1.1672281468740522\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797930.7376668521\n",
      "Sharpe:  -1.0177825032115433\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797771.6400573311\n",
      "Sharpe:  -1.1018003804634746\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135597 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.101      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.002695672 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.001       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798539.3250807148\n",
      "Sharpe:  -0.4371358503764694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794317.4302501928\n",
      "Sharpe:  -4.238641787509104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792290.1510192055\n",
      "Sharpe:  -2.4174686363151263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799316.760874795\n",
      "Sharpe:  -1.0001290729196832\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797605.3229777542\n",
      "Sharpe:  -0.646602918499682\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:754786.596703272\n",
      "Sharpe:  -3.660878585129353\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795230.5795363279\n",
      "Sharpe:  -1.4038950527928455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778956.2468821651\n",
      "Sharpe:  -2.6515979271220695\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013064378  |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    reward               | 0.0011024572 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.000653     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799082.5344407111\n",
      "Sharpe:  -2.410001502364559\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771577.9973630133\n",
      "Sharpe:  -0.5700397156988923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794961.4712670865\n",
      "Sharpe:  -0.9635583084040159\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797277.5581346585\n",
      "Sharpe:  -1.5087570152216618\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795890.2396286292\n",
      "Sharpe:  -3.207959761689418\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789892.7238374145\n",
      "Sharpe:  -0.9437976820931662\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013541523  |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.155       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    reward               | 0.0033593588 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000547     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799366.8723079714\n",
      "Sharpe:  -1.1736510031673364\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778178.7672479308\n",
      "Sharpe:  -2.0177848065592596\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799480.5790757963\n",
      "Sharpe:  -2.038733971847222\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793380.4575197145\n",
      "Sharpe:  -0.27101932458747036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787631.9424183173\n",
      "Sharpe:  -2.261274694035659\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795533.0731165084\n",
      "Sharpe:  -0.8651070590304881\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01129301   |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.154       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | -0.007421989 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000579     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799666.9689477972\n",
      "Sharpe:  -0.2900809360023601\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688184.6018699042\n",
      "Sharpe:  -0.887623886172721\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736025.0801205492\n",
      "Sharpe:  -1.6736426796697672\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799468.4689604926\n",
      "Sharpe:  -1.0738863569159436\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799291.5837611371\n",
      "Sharpe:  -4.937090849777684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792845.3850481096\n",
      "Sharpe:  -1.1066229900208464\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791013.7592553562\n",
      "Sharpe:  -1.7400443217696748\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:751438.1609792202\n",
      "Sharpe:  -7.77735818714887\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010899649  |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.1        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | 0.0028520552 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000905     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769972.8696347247\n",
      "Sharpe:  -1.265145759831805\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795345.731609331\n",
      "Sharpe:  -0.5268386846859027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799869.5748938897\n",
      "Sharpe:  -2.408818667514261\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796331.1145010971\n",
      "Sharpe:  -4.751326741225697\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785411.7256834266\n",
      "Sharpe:  -0.6063346045755894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791601.1517899864\n",
      "Sharpe:  -1.6203315822040185\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 182           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014597101   |\n",
      "|    clip_fraction        | 0.137         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.2         |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.137        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.0113       |\n",
      "|    reward               | -0.0021296341 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00118       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790537.5669152491\n",
      "Sharpe:  -0.2907251603542778\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798756.138342013\n",
      "Sharpe:  -2.8097045930110593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768301.779670123\n",
      "Sharpe:  -5.0844996661166135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782204.1526901905\n",
      "Sharpe:  -0.5345698494548309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794312.2172018255\n",
      "Sharpe:  -0.46766536015366617\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011815079  |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.164       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | 0.0058573014 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000761     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777593.6524297821\n",
      "Sharpe:  -1.5288211595717582\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763995.7082558211\n",
      "Sharpe:  -1.9566736191983887\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798485.9474270846\n",
      "Sharpe:  -0.9324440119779002\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791195.3230350151\n",
      "Sharpe:  -1.1167432300425923\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763543.057237287\n",
      "Sharpe:  -3.1240337826889952\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799024.1970478914\n",
      "Sharpe:  -1.4596495425345593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798041.3288277173\n",
      "Sharpe:  -0.4641697819171277\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 223            |\n",
      "|    iterations           | 22             |\n",
      "|    time_elapsed         | 201            |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012681312    |\n",
      "|    clip_fraction        | 0.164          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.2          |\n",
      "|    explained_variance   | 0.686          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.154         |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -0.00939       |\n",
      "|    reward               | -0.00020593297 |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 0.000944       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:762454.7571546433\n",
      "Sharpe:  -0.6442565442737983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714631.7429583013\n",
      "Sharpe:  -0.8517657085529909\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791827.8040907948\n",
      "Sharpe:  -0.21970020352502334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798413.5102268355\n",
      "Sharpe:  -1.829485926676655\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 211           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013174288   |\n",
      "|    clip_fraction        | 0.162         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.2         |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.165        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0127       |\n",
      "|    reward               | -0.0035353594 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000731      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796354.5355566018\n",
      "Sharpe:  -1.7587399822548602\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788361.2198234517\n",
      "Sharpe:  -1.1796313751642309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795145.0322906981\n",
      "Sharpe:  -0.28901006718989986\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794733.9620477394\n",
      "Sharpe:  -1.003897892259671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014383962 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.143      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.006586905 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00095     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777922.274239767\n",
      "Sharpe:  -0.5033176160382\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761358.8874751384\n",
      "Sharpe:  -2.6193846198800763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789287.4130010272\n",
      "Sharpe:  -5.277848714050811\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792349.6749500547\n",
      "Sharpe:  -2.553858013866195\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792009.7222162591\n",
      "Sharpe:  -1.0642574968042886\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794069.1365688896\n",
      "Sharpe:  -0.5255105854602065\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:701094.0660566895\n",
      "Sharpe:  -1.0599572706101743\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 229           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012630075   |\n",
      "|    clip_fraction        | 0.14          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.3         |\n",
      "|    explained_variance   | 0.743         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.123        |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.00823      |\n",
      "|    reward               | -0.0039771777 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.000754      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1001545.4872699999\n",
      "Sharpe:  0.3655940921967271\n",
      "=================================\n",
      "hit end!\n",
      "ppo 0.0015454872700000344 -0.014243341111763196 0.3655940921967271 0\n",
      "2024-02-01 00:00:00 2024-03-01 00:00:00\n",
      "ppo\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to logs\\ppo_14_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794917.4135145908\n",
      "Sharpe:  -1.9446456013807565\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780184.4720655621\n",
      "Sharpe:  -1.3663692068430202\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787197.2163183722\n",
      "Sharpe:  -0.324048658212019\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768872.9743715362\n",
      "Sharpe:  -0.8524096534982865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797026.0190218077\n",
      "Sharpe:  -2.0479742690867986\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799809.3684216171\n",
      "Sharpe:  -2.5830482690978602\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755712.8395284384\n",
      "Sharpe:  -2.8353124221927315\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 284          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 7            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.010672796 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797111.4100392042\n",
      "Sharpe:  -2.542954262771239\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789661.6595792323\n",
      "Sharpe:  -1.7841951799458724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794808.6540332321\n",
      "Sharpe:  -2.5105397373893186\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:757057.5711483563\n",
      "Sharpe:  -0.5439761004565213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763848.3884848194\n",
      "Sharpe:  -2.0503452384285343\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797798.2645470847\n",
      "Sharpe:  -0.957533403421964\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796819.3337016713\n",
      "Sharpe:  -1.5320100168875388\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008008942  |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.336       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    reward               | 0.0042492375 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00194      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789992.2972524602\n",
      "Sharpe:  -0.299701814819281\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783745.4194338176\n",
      "Sharpe:  -0.49184618118456075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797457.4566894369\n",
      "Sharpe:  -1.1283562380640113\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794565.1970363698\n",
      "Sharpe:  -4.895516486080966\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799209.8188384798\n",
      "Sharpe:  -0.8626167861000605\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009427708  |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.163       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 0.0010418826 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00112      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784904.1024598065\n",
      "Sharpe:  -0.8371310380749553\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799480.1403960832\n",
      "Sharpe:  -1.4493062115301143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774479.1808756972\n",
      "Sharpe:  -1.6139016822616452\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765150.9369928077\n",
      "Sharpe:  -1.111956378350478\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792839.4855586122\n",
      "Sharpe:  -0.7850076408680613\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 232           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010777287   |\n",
      "|    clip_fraction        | 0.113         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.302         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.154        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0107       |\n",
      "|    reward               | 0.00085355755 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00081       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795719.9609719982\n",
      "Sharpe:  -1.0461136744130373\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798154.5465576188\n",
      "Sharpe:  -1.248073043104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798081.0606849319\n",
      "Sharpe:  -2.471304163088298\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785262.5816027683\n",
      "Sharpe:  -1.1770307970025984\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793766.1566612469\n",
      "Sharpe:  -1.2344182998267674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791017.7512197788\n",
      "Sharpe:  -1.204642150922915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799943.1425784116\n",
      "Sharpe:  -0.8854142568600173\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 228          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008249011  |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.132       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | -7.59639e-05 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000776     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784059.8278875895\n",
      "Sharpe:  -1.1659858604942663\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:764173.7640192318\n",
      "Sharpe:  -1.4111273376358482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799854.7047515737\n",
      "Sharpe:  -0.9342432822484369\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789436.9141965465\n",
      "Sharpe:  -1.6048694897899118\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794256.033874344\n",
      "Sharpe:  -0.9523421789369536\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769420.1759040152\n",
      "Sharpe:  -0.5647128555844063\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 226           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 54            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008945052   |\n",
      "|    clip_fraction        | 0.108         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.427         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.149        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.0106       |\n",
      "|    reward               | -0.0032332104 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000612      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795791.4680448001\n",
      "Sharpe:  -0.25108754383567955\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798974.0513222885\n",
      "Sharpe:  -3.517582203586283\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790825.56873826\n",
      "Sharpe:  -9.555473432937918\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793701.5576395626\n",
      "Sharpe:  -0.30254059342951223\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797494.1240706162\n",
      "Sharpe:  -0.9561695515346864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796698.6154815484\n",
      "Sharpe:  -3.904944324167043\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011825891  |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.149       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    reward               | 0.0026975144 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000673     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799787.6454146681\n",
      "Sharpe:  -2.192739316906596\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798874.2776481223\n",
      "Sharpe:  -2.7639069925662425\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781547.7446380566\n",
      "Sharpe:  -0.3652195032694905\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799612.6590842186\n",
      "Sharpe:  -1.463731817659714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:778475.4848331768\n",
      "Sharpe:  -0.8928184852888258\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793476.4359049691\n",
      "Sharpe:  -1.0934903377459189\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011845748  |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.122       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    reward               | -0.019866975 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000666     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744766.3179876683\n",
      "Sharpe:  -2.5726885687054555\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:738902.3319314101\n",
      "Sharpe:  -1.4729146877101322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760034.142185779\n",
      "Sharpe:  -0.839452462699298\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791180.3255982192\n",
      "Sharpe:  -0.9542892770327379\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799488.8456994941\n",
      "Sharpe:  -1.3027416421479507\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798427.9247649325\n",
      "Sharpe:  -1.0547466856717533\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011145635   |\n",
      "|    clip_fraction        | 0.112         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.654         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.128        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0113       |\n",
      "|    reward               | -0.0004401593 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00071       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790617.359924551\n",
      "Sharpe:  -0.9518045661064045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:774454.4762182593\n",
      "Sharpe:  -0.9148322745042454\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776852.8325836569\n",
      "Sharpe:  -0.5322321125576568\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741058.515500768\n",
      "Sharpe:  -6.681494853143332\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797794.3132049579\n",
      "Sharpe:  -1.1595675806897814\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012668375  |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.114       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    reward               | 0.0013739679 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000697     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799710.7099119442\n",
      "Sharpe:  -0.7719590908663561\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779051.2920155048\n",
      "Sharpe:  -1.7033069944974435\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796120.7110561108\n",
      "Sharpe:  -0.8307224827583569\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797029.9437428948\n",
      "Sharpe:  -0.46242960743204853\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 100           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013179516   |\n",
      "|    clip_fraction        | 0.107         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.77          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.145        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00937      |\n",
      "|    reward               | -0.0024164233 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000686      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791677.2866141421\n",
      "Sharpe:  -0.18392205306323972\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799918.9003710542\n",
      "Sharpe:  -1.114193903678303\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763580.5862133836\n",
      "Sharpe:  -0.7563019702331121\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776020.8698233984\n",
      "Sharpe:  -0.9099835944550817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761988.598786124\n",
      "Sharpe:  -1.5098041318936803\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011358464  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | 0.0035693473 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000622     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789604.6440014916\n",
      "Sharpe:  -0.17546854921285893\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799731.1055648472\n",
      "Sharpe:  -1.0013880793738814\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011357205  |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.134       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    reward               | -0.009581532 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000686     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788181.4733252986\n",
      "Sharpe:  -0.24481129766360668\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797268.7965393952\n",
      "Sharpe:  -1.564833432354102\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739881.8971894813\n",
      "Sharpe:  -2.9061321048067064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776807.2358964107\n",
      "Sharpe:  -0.312745538628093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799808.3572668474\n",
      "Sharpe:  -1.0719626597165977\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:755466.469907341\n",
      "Sharpe:  -2.9550919739937966\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 129           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012604734   |\n",
      "|    clip_fraction        | 0.149         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.72          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.0106       |\n",
      "|    reward               | -0.0013079536 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.000958      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791132.2696656982\n",
      "Sharpe:  -1.5770735289878544\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767039.0759193974\n",
      "Sharpe:  -1.3538966506000158\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:705759.1813050149\n",
      "Sharpe:  -1.1039626119637698\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785279.4434630665\n",
      "Sharpe:  -0.591992167962414\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 221           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013583049   |\n",
      "|    clip_fraction        | 0.157         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.687         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.0124       |\n",
      "|    reward               | -0.0028438417 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.00086       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:697581.5728925908\n",
      "Sharpe:  -0.45779605105542737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763541.2214297253\n",
      "Sharpe:  -1.3345327756359073\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794319.0844829315\n",
      "Sharpe:  -3.3144740482761286\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797336.5403308094\n",
      "Sharpe:  -1.0822779397050253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782736.3862923705\n",
      "Sharpe:  -1.2598334498159507\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761310.6904406158\n",
      "Sharpe:  -3.685368214576285\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798610.4660499048\n",
      "Sharpe:  -0.4813887519496875\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015028758  |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    reward               | -0.009720778 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000754     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788143.6908410157\n",
      "Sharpe:  -0.5967652244830008\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:742364.0953100956\n",
      "Sharpe:  -4.572790294776196\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790298.0683870969\n",
      "Sharpe:  -1.695664112473431\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790323.7825676169\n",
      "Sharpe:  -0.48857068494835326\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752742.8744633561\n",
      "Sharpe:  -2.435502778049655\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 220           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 157           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013910467   |\n",
      "|    clip_fraction        | 0.153         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.768         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.11         |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0115       |\n",
      "|    reward               | -0.0006693186 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000977      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735524.6062669894\n",
      "Sharpe:  -0.37558514814809685\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773719.5268000138\n",
      "Sharpe:  -6.070338831541806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753242.9753298631\n",
      "Sharpe:  -1.3706047161355188\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:684144.1286875085\n",
      "Sharpe:  -0.30766543949735736\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794622.4936773982\n",
      "Sharpe:  -1.6232473516990922\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 220           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 167           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01706166    |\n",
      "|    clip_fraction        | 0.175         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | 0.815         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.0147       |\n",
      "|    reward               | -5.248225e-05 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000812      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798023.3924451342\n",
      "Sharpe:  -0.8108522531564537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780052.1770975377\n",
      "Sharpe:  -1.4780850460665473\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797317.4242288389\n",
      "Sharpe:  -1.09804941882219\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:765402.6777704506\n",
      "Sharpe:  -0.9124481456991369\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793712.9015577395\n",
      "Sharpe:  -1.1087811530474574\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796590.3565147417\n",
      "Sharpe:  -0.5488173225194853\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015899304 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.14       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 0.01204022  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:780784.0645713152\n",
      "Sharpe:  -1.563527166426038\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798544.3766190836\n",
      "Sharpe:  -1.691819490456929\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798574.611598262\n",
      "Sharpe:  -1.805764141287688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787745.4394980404\n",
      "Sharpe:  -3.99498299888843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:776322.0540516735\n",
      "Sharpe:  -0.8573635214805696\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798491.1292789328\n",
      "Sharpe:  -2.2253801826847273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784894.9893663722\n",
      "Sharpe:  -0.719234903865372\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 220            |\n",
      "|    iterations           | 20             |\n",
      "|    time_elapsed         | 186            |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012317051    |\n",
      "|    clip_fraction        | 0.153          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13.1          |\n",
      "|    explained_variance   | 0.751          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.142         |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.0115        |\n",
      "|    reward               | -0.00013947759 |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 0.00081        |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793917.0911685057\n",
      "Sharpe:  -0.3953627697204852\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791104.3466057036\n",
      "Sharpe:  -0.19259252908798177\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793514.6333223017\n",
      "Sharpe:  -0.953173094601616\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 220           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 195           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011662876   |\n",
      "|    clip_fraction        | 0.148         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13.1         |\n",
      "|    explained_variance   | 0.816         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.148        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0108       |\n",
      "|    reward               | -0.0013593002 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.000634      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793080.7255857163\n",
      "Sharpe:  -0.8425090824441066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788840.4681046017\n",
      "Sharpe:  -1.134747230100432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793217.7347596718\n",
      "Sharpe:  -0.5672182822059191\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787473.4908194812\n",
      "Sharpe:  -0.6728078891732576\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796697.086718999\n",
      "Sharpe:  -1.4660339530782747\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012707779  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.147       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    reward               | -0.010612462 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000765     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782768.3259169041\n",
      "Sharpe:  -0.7522399793284781\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748745.5655998492\n",
      "Sharpe:  -0.292788229316299\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009754419  |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.167       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00997     |\n",
      "|    reward               | 0.0049284277 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000618     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:795763.0942816653\n",
      "Sharpe:  -0.18983329885224134\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796245.6698486833\n",
      "Sharpe:  -0.6334868208505737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:782550.5057151086\n",
      "Sharpe:  -1.0690401741919544\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688056.5673072343\n",
      "Sharpe:  -0.9839253587346185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781454.9212257112\n",
      "Sharpe:  -2.0644762088649284\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783207.1346679828\n",
      "Sharpe:  -0.7156062701886037\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772454.0159701937\n",
      "Sharpe:  -1.837234186407341\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01671846   |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    reward               | 0.0035386453 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.000653     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:735210.7448216579\n",
      "Sharpe:  -0.9617216789840575\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794947.6138852889\n",
      "Sharpe:  -4.1056234621428205\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794176.6929153407\n",
      "Sharpe:  -0.7087401745984393\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793444.4912316886\n",
      "Sharpe:  -0.6720510235302891\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012281736 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.172      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.003848897 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:983347.6811426161\n",
      "Sharpe:  -3.186053238779502\n",
      "=================================\n",
      "hit end!\n",
      "ppo -0.016652318857384052 -0.0312178773153839 -3.1860532387795018 0\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_6_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1216778.4445977947\n",
      "Sharpe:  0.3517772330916938\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1404675.2819047482\n",
      "Sharpe:  0.5313780272411285\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1987206.9636800983\n",
      "Sharpe:  0.7064491893788779\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2071809.9003579917\n",
      "Sharpe:  0.7126967220380616\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 82           |\n",
      "|    time_elapsed    | 58           |\n",
      "|    total_timesteps | 4808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.134       |\n",
      "|    critic_loss     | 3.29e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4707         |\n",
      "|    reward          | 0.0052700937 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1604148.265077006\n",
      "Sharpe:  0.6470347521105924\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1810285.3506180018\n",
      "Sharpe:  0.7385337287646765\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2541803.4138459763\n",
      "Sharpe:  0.9571980257264694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1926696.7497987852\n",
      "Sharpe:  0.8222398745285688\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 119          |\n",
      "|    total_timesteps | 9734         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.143       |\n",
      "|    critic_loss     | 5.36e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 9633         |\n",
      "|    reward          | 0.0041501895 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2351114.8622524007\n",
      "Sharpe:  0.9143413788417686\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3159582.8464368717\n",
      "Sharpe:  1.2244942486861397\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2792261.687855368\n",
      "Sharpe:  1.0136188855441626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3155627.4525919897\n",
      "Sharpe:  1.1623509783573396\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 191          |\n",
      "|    total_timesteps | 15537        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.14        |\n",
      "|    critic_loss     | 3.1e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 15436        |\n",
      "|    reward          | 0.0039022146 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789267.2929642604\n",
      "Sharpe:  -5.788343349890283\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2221099.438861735\n",
      "Sharpe:  0.8335180477775387\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2422506.994752986\n",
      "Sharpe:  0.8280118718259668\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2193737.106009917\n",
      "Sharpe:  0.8472675181643223\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 245          |\n",
      "|    total_timesteps | 19834        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.125       |\n",
      "|    critic_loss     | 2.69e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 19733        |\n",
      "|    reward          | 0.0045960383 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2221997.3654910154\n",
      "Sharpe:  0.8929689823439244\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2424967.9541552057\n",
      "Sharpe:  0.9964677863488874\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3075763.4458482475\n",
      "Sharpe:  1.1394033663180436\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1994731.5952869225\n",
      "Sharpe:  0.9226173400629044\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 313          |\n",
      "|    total_timesteps | 25169        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.119       |\n",
      "|    critic_loss     | 1.78e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 25068        |\n",
      "|    reward          | 0.0038965547 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2003773.706000012\n",
      "Sharpe:  0.9586349452347932\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3507544.2311779326\n",
      "Sharpe:  1.252251939876567\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:763845.514449753\n",
      "Sharpe:  -6.021543144860679\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1846052.4647399364\n",
      "Sharpe:  0.8508295791998226\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 79          |\n",
      "|    time_elapsed    | 359         |\n",
      "|    total_timesteps | 28751       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.106      |\n",
      "|    critic_loss     | 2.37e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 28650       |\n",
      "|    reward          | 0.005870712 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4146229.7113068043\n",
      "Sharpe:  1.2519054263723635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3609586.4285007766\n",
      "Sharpe:  1.4759983469366658\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2253084.198589658\n",
      "Sharpe:  1.2060587401105516\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4287744.995637719\n",
      "Sharpe:  1.5584858103020711\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 426          |\n",
      "|    total_timesteps | 34057        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0987      |\n",
      "|    critic_loss     | 2.2e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 33956        |\n",
      "|    reward          | 0.0070171314 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3042817.5139658246\n",
      "Sharpe:  1.4116508175614568\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4782203.955286597\n",
      "Sharpe:  1.5817276011827908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2814520.0511732297\n",
      "Sharpe:  1.50968987714088\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2910033.1287612217\n",
      "Sharpe:  1.4517117976951721\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 487          |\n",
      "|    total_timesteps | 38888        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.106       |\n",
      "|    critic_loss     | 1.42e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 38787        |\n",
      "|    reward          | 0.0041453843 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4662101.695327829\n",
      "Sharpe:  1.6468161312932184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3458573.483512223\n",
      "Sharpe:  1.5505892509543133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4378929.595328138\n",
      "Sharpe:  1.5986437211632394\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2435146.3385965764\n",
      "Sharpe:  1.4199429239588275\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 548          |\n",
      "|    total_timesteps | 43843        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.111       |\n",
      "|    critic_loss     | 1.55e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 43742        |\n",
      "|    reward          | 0.0041474076 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2953326.001288445\n",
      "Sharpe:  1.590659012460983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4375972.121042227\n",
      "Sharpe:  1.6681770899356445\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6489647.4949285425\n",
      "Sharpe:  1.8189876114341166\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:783744.0215216168\n",
      "Sharpe:  -5.630288274266285\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 595          |\n",
      "|    total_timesteps | 47527        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.117       |\n",
      "|    critic_loss     | 1.55e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 47426        |\n",
      "|    reward          | -0.048266474 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798988.9288791779\n",
      "Sharpe:  -4.978880116056556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4933160.58107362\n",
      "Sharpe:  1.7742668131856183\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1029572.5814018901\n",
      "Sharpe:  4.412521038904815\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.029572581401889897 -0.012886396416761894 4.412521038904815 0\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2026473.3507608464\n",
      "Sharpe:  0.8625248336216041\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1584334.6064742075\n",
      "Sharpe:  0.88034834822125\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2578525.111507023\n",
      "Sharpe:  0.973504174245351\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1703519.5564590148\n",
      "Sharpe:  0.6371333637933039\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 62           |\n",
      "|    total_timesteps | 5030         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0346      |\n",
      "|    critic_loss     | 6.9e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4929         |\n",
      "|    reward          | 0.0006312185 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2070776.9759000165\n",
      "Sharpe:  0.7359431133951472\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2164991.390751985\n",
      "Sharpe:  0.7325230943370732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2484826.7467700155\n",
      "Sharpe:  0.8693058304837864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1604771.5166009865\n",
      "Sharpe:  0.6182831958707726\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 79            |\n",
      "|    time_elapsed    | 133           |\n",
      "|    total_timesteps | 10636         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0496       |\n",
      "|    critic_loss     | 3.96e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 10535         |\n",
      "|    reward          | 0.00063096406 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1401989.493671007\n",
      "Sharpe:  0.5258358811917864\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1878992.0276290143\n",
      "Sharpe:  0.6719525150182843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2276824.343435985\n",
      "Sharpe:  0.7789713838379069\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:766829.2902120004\n",
      "Sharpe:  -9.940007523212373\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 181          |\n",
      "|    total_timesteps | 14493        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0413      |\n",
      "|    critic_loss     | 3.18e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 14392        |\n",
      "|    reward          | -0.047912747 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2338599.484126021\n",
      "Sharpe:  0.8256257575923522\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1562500.627423991\n",
      "Sharpe:  0.5760680339240661\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:788645.3255970004\n",
      "Sharpe:  -2.966805030561939\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1653847.436788991\n",
      "Sharpe:  0.639695159645644\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 229          |\n",
      "|    total_timesteps | 18366        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0355      |\n",
      "|    critic_loss     | 3.17e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 18265        |\n",
      "|    reward          | 0.0006281299 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1568058.9581550157\n",
      "Sharpe:  0.5729411097700216\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2070776.9759000165\n",
      "Sharpe:  0.7359431133951472\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1671746.544133996\n",
      "Sharpe:  0.8227671388399227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1447724.2534559916\n",
      "Sharpe:  0.5712786448915009\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 283          |\n",
      "|    total_timesteps | 22712        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0396      |\n",
      "|    critic_loss     | 3.5e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 22611        |\n",
      "|    reward          | 0.0006304143 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779001.2852020005\n",
      "Sharpe:  -6.478305361071324\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2112091.165328016\n",
      "Sharpe:  0.7023120423022915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1738865.9594219879\n",
      "Sharpe:  0.6240808006733839\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1848155.52068298\n",
      "Sharpe:  0.6611458965061667\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 79            |\n",
      "|    time_elapsed    | 337           |\n",
      "|    total_timesteps | 26973         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.044        |\n",
      "|    critic_loss     | 7.16e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 26872         |\n",
      "|    reward          | 0.00062894466 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1781492.884270019\n",
      "Sharpe:  0.6299530316369297\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639768.6980649882\n",
      "Sharpe:  0.6016542176115868\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2002689.2006139883\n",
      "Sharpe:  0.7098456485947895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1457962.1148810084\n",
      "Sharpe:  0.5481059241278784\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 400          |\n",
      "|    total_timesteps | 31991        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0403      |\n",
      "|    critic_loss     | 1.14e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 31890        |\n",
      "|    reward          | 0.0006260176 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1429663.4717359946\n",
      "Sharpe:  0.5539516208913418\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1569426.6588019924\n",
      "Sharpe:  0.6202963787693733\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1736034.1342110133\n",
      "Sharpe:  0.6428734339654127\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1576064.4543439853\n",
      "Sharpe:  0.6135709880127757\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 458          |\n",
      "|    total_timesteps | 36315        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0336      |\n",
      "|    critic_loss     | 1.3e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 36214        |\n",
      "|    reward          | 0.0006291033 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:770594.934796\n",
      "Sharpe:  -3.8783072488733867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1510645.9254080127\n",
      "Sharpe:  0.5826581035034908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1517057.4774369965\n",
      "Sharpe:  0.5873082908455212\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1582146.1411659834\n",
      "Sharpe:  0.5964817860147472\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 500          |\n",
      "|    total_timesteps | 39578        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0338      |\n",
      "|    critic_loss     | 1.27e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 39477        |\n",
      "|    reward          | 0.0006280812 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1670012.8112960155\n",
      "Sharpe:  0.5846439988520107\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781890.5706140007\n",
      "Sharpe:  -3.1081143708508416\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2115216.62117498\n",
      "Sharpe:  0.7030334546466349\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2247377.022875017\n",
      "Sharpe:  0.7710979278633867\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 557          |\n",
      "|    total_timesteps | 44066        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0535      |\n",
      "|    critic_loss     | 1.42e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 43965        |\n",
      "|    reward          | 0.0006268508 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2231907.052214022\n",
      "Sharpe:  0.7504109441715072\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1470341.2145979959\n",
      "Sharpe:  0.5572722629014698\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2465749.562841015\n",
      "Sharpe:  0.8610624442361485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:791635.5976549999\n",
      "Sharpe:  -3.2594036123293826\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 79          |\n",
      "|    time_elapsed    | 608         |\n",
      "|    total_timesteps | 48210       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0504     |\n",
      "|    critic_loss     | 1.5e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 48109       |\n",
      "|    reward          | -0.04786055 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1678143.3050420058\n",
      "Sharpe:  0.6306983596293068\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777820.9603609996\n",
      "Sharpe:  -7.498042838327421\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1067440.8935759997\n",
      "Sharpe:  8.69757906200656\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.0674408935759998 -0.010853220319296178 8.69757906200656 0\n",
      "2023-08-01 00:00:00 2023-09-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1683913.1104084584\n",
      "Sharpe:  0.6603840423881485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1805188.0679997099\n",
      "Sharpe:  0.7151688792530829\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2833253.8884228696\n",
      "Sharpe:  1.0828097620828372\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2729119.992099379\n",
      "Sharpe:  0.9788433677982792\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 84          |\n",
      "|    time_elapsed    | 67          |\n",
      "|    total_timesteps | 5691        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.157      |\n",
      "|    critic_loss     | 6.16e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 5590        |\n",
      "|    reward          | 0.014579635 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1954373.5565234225\n",
      "Sharpe:  0.785261867045452\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3605545.934204879\n",
      "Sharpe:  1.219051882812183\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2557925.448186435\n",
      "Sharpe:  0.9250444153694006\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:769778.7287300001\n",
      "Sharpe:  -6.804560210194341\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 84          |\n",
      "|    time_elapsed    | 117         |\n",
      "|    total_timesteps | 9912        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.206      |\n",
      "|    critic_loss     | 5.02e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9811        |\n",
      "|    reward          | -0.07062272 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2166936.9405713906\n",
      "Sharpe:  0.921768317957197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1754708.2678501434\n",
      "Sharpe:  0.8347629177069298\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2466665.5351068857\n",
      "Sharpe:  1.010567756492351\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1792272.1409485955\n",
      "Sharpe:  0.8925812901044361\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 83          |\n",
      "|    time_elapsed    | 173         |\n",
      "|    total_timesteps | 14488       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.163      |\n",
      "|    critic_loss     | 3.37e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14387       |\n",
      "|    reward          | 0.012342861 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1849769.6074600557\n",
      "Sharpe:  0.9088097829923821\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2501012.0228287447\n",
      "Sharpe:  1.0998983337874202\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2558402.2878150134\n",
      "Sharpe:  1.0702663499570915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2696148.460122607\n",
      "Sharpe:  1.083087331448254\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 82          |\n",
      "|    time_elapsed    | 236         |\n",
      "|    total_timesteps | 19599       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.162      |\n",
      "|    critic_loss     | 3.5e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19498       |\n",
      "|    reward          | 0.012774315 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1852349.5502894446\n",
      "Sharpe:  0.7992454073583928\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3027848.0138037927\n",
      "Sharpe:  1.14320928388936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1503686.2920586783\n",
      "Sharpe:  0.7546185736540933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2662717.8044361146\n",
      "Sharpe:  1.1073764834654178\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 82          |\n",
      "|    time_elapsed    | 297         |\n",
      "|    total_timesteps | 24459       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.148      |\n",
      "|    critic_loss     | 3.01e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24358       |\n",
      "|    reward          | 0.013654935 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3419933.6543370835\n",
      "Sharpe:  1.262033655150921\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1889017.636966543\n",
      "Sharpe:  0.9877917254572162\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3408857.351501755\n",
      "Sharpe:  1.3274448378778143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302818.016642936\n",
      "Sharpe:  1.1222068447129663\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 360         |\n",
      "|    total_timesteps | 29580       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.122      |\n",
      "|    critic_loss     | 3.77e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29479       |\n",
      "|    reward          | 0.012364462 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2358535.786445737\n",
      "Sharpe:  1.172141484617582\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2474948.0089003257\n",
      "Sharpe:  1.0526183519330021\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4329482.636010976\n",
      "Sharpe:  1.562632088828892\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3228081.8721725456\n",
      "Sharpe:  1.4386249579024462\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 425         |\n",
      "|    total_timesteps | 34800       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.105      |\n",
      "|    critic_loss     | 1.93e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 34699       |\n",
      "|    reward          | 0.015676994 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4995064.291161706\n",
      "Sharpe:  1.6307153649750659\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3052415.6700815754\n",
      "Sharpe:  1.6203848973635304\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1922299.8952688558\n",
      "Sharpe:  1.1246534194144957\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6008638.775008406\n",
      "Sharpe:  1.8461135357328269\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 487         |\n",
      "|    total_timesteps | 39702       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.108      |\n",
      "|    critic_loss     | 2.21e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 39601       |\n",
      "|    reward          | 0.015784046 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5222507.683340875\n",
      "Sharpe:  1.5630056887707364\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5837928.55093943\n",
      "Sharpe:  1.743762085755414\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6240350.748628592\n",
      "Sharpe:  1.9061935430014287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3917039.4397778525\n",
      "Sharpe:  1.89518789593294\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 557         |\n",
      "|    total_timesteps | 45292       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.106      |\n",
      "|    critic_loss     | 1.89e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 45191       |\n",
      "|    reward          | 0.015781214 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2751932.4015014223\n",
      "Sharpe:  1.6467046371961045\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3681346.071466566\n",
      "Sharpe:  1.8640872641745725\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7016994.457163673\n",
      "Sharpe:  2.079957624912582\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4626237.371354378\n",
      "Sharpe:  2.204606208228333\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 80          |\n",
      "|    time_elapsed    | 614         |\n",
      "|    total_timesteps | 49740       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.121      |\n",
      "|    critic_loss     | 1.4e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 49639       |\n",
      "|    reward          | 0.014752047 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026737.646211\n",
      "Sharpe:  2.6002379379645384\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.026737646211000055 -0.024716681486381994 2.6002379379645384 0\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_9_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1439279.057528724\n",
      "Sharpe:  0.6826035408679674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2119673.0534929796\n",
      "Sharpe:  0.6871677437673037\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2157595.492051969\n",
      "Sharpe:  0.6989383540827286\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1912795.973229015\n",
      "Sharpe:  0.6777249778052865\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 66           |\n",
      "|    total_timesteps | 5350         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.155       |\n",
      "|    critic_loss     | 6.29e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5249         |\n",
      "|    reward          | 0.0015876141 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1558549.1105479845\n",
      "Sharpe:  0.7015053844734702\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:758471.6991540001\n",
      "Sharpe:  -4.0957089003780975\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1585443.3040529857\n",
      "Sharpe:  0.7246606703602936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2426289.633619989\n",
      "Sharpe:  0.8081994430106875\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 108          |\n",
      "|    total_timesteps | 8610         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.194       |\n",
      "|    critic_loss     | 0.000841     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8509         |\n",
      "|    reward          | 0.0028181204 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826088.2804770074\n",
      "Sharpe:  0.654687547230815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1507301.1459265044\n",
      "Sharpe:  0.585503903784732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760456.8122700005\n",
      "Sharpe:  -6.353267698529079\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1617612.1870920146\n",
      "Sharpe:  0.641045820188028\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 148          |\n",
      "|    total_timesteps | 11925        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.189       |\n",
      "|    critic_loss     | 5.07e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 11824        |\n",
      "|    reward          | 0.0014447477 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1726049.1655269852\n",
      "Sharpe:  0.646293568632143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1439223.2377749903\n",
      "Sharpe:  0.5135753154357889\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1624334.631956015\n",
      "Sharpe:  0.5806750014075448\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1899260.0804950201\n",
      "Sharpe:  0.6668212089930002\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 208          |\n",
      "|    total_timesteps | 16772        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.152       |\n",
      "|    critic_loss     | 1.88e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 16671        |\n",
      "|    reward          | 0.0022395665 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1418455.4387129943\n",
      "Sharpe:  0.590147128761909\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302855.383356021\n",
      "Sharpe:  0.7579628001419088\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1650202.615043008\n",
      "Sharpe:  0.6219250824709556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1749046.5471799872\n",
      "Sharpe:  0.6329604631964368\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 267          |\n",
      "|    total_timesteps | 21574        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.131       |\n",
      "|    critic_loss     | 2.35e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21473        |\n",
      "|    reward          | 0.0018745161 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787125.7502259995\n",
      "Sharpe:  -2.0889623422765426\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1735759.1132339796\n",
      "Sharpe:  0.5921487985027433\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779462.2577330001\n",
      "Sharpe:  -3.1851736280673806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1555059.105337992\n",
      "Sharpe:  0.6990396370364885\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 296          |\n",
      "|    total_timesteps | 23976        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.121       |\n",
      "|    critic_loss     | 3.16e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 23875        |\n",
      "|    reward          | 0.0018749423 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1491202.2313339924\n",
      "Sharpe:  0.5783683181891339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2282496.6656089723\n",
      "Sharpe:  0.7623825954750629\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1636546.1442469836\n",
      "Sharpe:  0.6483238423070011\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1697475.5577990157\n",
      "Sharpe:  0.665326402504145\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 354          |\n",
      "|    total_timesteps | 28689        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0947      |\n",
      "|    critic_loss     | 2.21e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 28588        |\n",
      "|    reward          | 0.0016510935 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2188459.730140983\n",
      "Sharpe:  0.7723853027870117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1898172.2121759832\n",
      "Sharpe:  0.7050672650792078\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1641558.699462992\n",
      "Sharpe:  0.7887146302736463\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1922573.1840309887\n",
      "Sharpe:  0.7282373231489904\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 80          |\n",
      "|    time_elapsed    | 415         |\n",
      "|    total_timesteps | 33597       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0838     |\n",
      "|    critic_loss     | 3.01e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 33496       |\n",
      "|    reward          | 0.001650408 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1989980.103715018\n",
      "Sharpe:  0.7147045466999359\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2131841.4829699835\n",
      "Sharpe:  0.7545933646678744\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1984630.9969099828\n",
      "Sharpe:  0.7133997617710228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1877190.1453319844\n",
      "Sharpe:  0.6987593312572721\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 484          |\n",
      "|    total_timesteps | 39134        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0845      |\n",
      "|    critic_loss     | 1.25e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 39033        |\n",
      "|    reward          | 0.0016500957 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1829542.9793430064\n",
      "Sharpe:  0.6855939896208185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1503381.5522780088\n",
      "Sharpe:  0.5829414589510299\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794638.6544169997\n",
      "Sharpe:  -3.0511925492950915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1669657.135257989\n",
      "Sharpe:  0.6653278632035835\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 526          |\n",
      "|    total_timesteps | 42500        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0774      |\n",
      "|    critic_loss     | 1.21e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 42399        |\n",
      "|    reward          | 0.0016508652 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2596206.819097973\n",
      "Sharpe:  0.8853210392426739\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794269.6613210001\n",
      "Sharpe:  -2.8103582669614724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2136833.165543021\n",
      "Sharpe:  0.7677932150450578\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2341283.179866982\n",
      "Sharpe:  0.7846114266743849\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 80         |\n",
      "|    time_elapsed    | 584        |\n",
      "|    total_timesteps | 47131      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.0725    |\n",
      "|    critic_loss     | 9.82e-06   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 47030      |\n",
      "|    reward          | 0.00164927 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2415810.710563021\n",
      "Sharpe:  0.8431555516094185\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759151.323269\n",
      "Sharpe:  -11.334012641126629\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1678123.3357590148\n",
      "Sharpe:  0.6617691260089305\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:984773.5625010002\n",
      "Sharpe:  -1.1496152957193804\n",
      "=================================\n",
      "hit end!\n",
      "ddpg -0.015226437498999879 -0.0609292692266375 -1.1496152957193804 0\n",
      "2023-10-01 00:00:00 2023-11-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1795713.3339357076\n",
      "Sharpe:  1.0192449947279638\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2045100.4549830158\n",
      "Sharpe:  1.0449444379274073\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2021303.866851598\n",
      "Sharpe:  1.1250886020593591\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2367277.8039864874\n",
      "Sharpe:  1.2198447768967378\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 81            |\n",
      "|    time_elapsed    | 62            |\n",
      "|    total_timesteps | 5096          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0438        |\n",
      "|    critic_loss     | 3.15e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 4995          |\n",
      "|    reward          | 0.00031314313 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1829946.7187683275\n",
      "Sharpe:  1.1425213943690595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1700728.565695032\n",
      "Sharpe:  1.1323199614085053\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1395379.3049527286\n",
      "Sharpe:  0.578645790015968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1713992.156517128\n",
      "Sharpe:  0.7938860681303606\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 118          |\n",
      "|    total_timesteps | 9504         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0177      |\n",
      "|    critic_loss     | 6.16e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 9403         |\n",
      "|    reward          | 0.0016590204 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1435891.3394676938\n",
      "Sharpe:  0.6450831114092327\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1648518.356799086\n",
      "Sharpe:  0.8490380871480433\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1904536.609305499\n",
      "Sharpe:  1.0357803395183145\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1580402.2384922602\n",
      "Sharpe:  0.9618396306707402\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 181          |\n",
      "|    total_timesteps | 14527        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0539      |\n",
      "|    critic_loss     | 3.17e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 14426        |\n",
      "|    reward          | 0.0021022551 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1952658.030077732\n",
      "Sharpe:  1.2148868024326844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1837444.7180893833\n",
      "Sharpe:  0.8919917265637279\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1943350.7937380294\n",
      "Sharpe:  0.9663575523103148\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1987069.4957446856\n",
      "Sharpe:  1.03087599265488\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 79           |\n",
      "|    time_elapsed    | 243          |\n",
      "|    total_timesteps | 19418        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0851      |\n",
      "|    critic_loss     | 4.38e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 19317        |\n",
      "|    reward          | 0.0022607548 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1875337.0553402698\n",
      "Sharpe:  1.370705533915484\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3044713.236455697\n",
      "Sharpe:  1.5340221336713684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3320293.4547716277\n",
      "Sharpe:  1.352971103697912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2124963.565816629\n",
      "Sharpe:  1.3611986533042382\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 300          |\n",
      "|    total_timesteps | 24097        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.112       |\n",
      "|    critic_loss     | 4.94e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 23996        |\n",
      "|    reward          | 0.0029508779 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1904053.2009252761\n",
      "Sharpe:  1.4630688275768573\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1941899.0445667568\n",
      "Sharpe:  1.0314153883197383\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3692761.4288893514\n",
      "Sharpe:  1.4851962932523337\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3589799.322406827\n",
      "Sharpe:  1.5766619324022233\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 359          |\n",
      "|    total_timesteps | 29007        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.116       |\n",
      "|    critic_loss     | 3.97e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 28906        |\n",
      "|    reward          | 0.0014983509 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3993658.0700466796\n",
      "Sharpe:  1.6263687087217702\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4013444.5029168017\n",
      "Sharpe:  1.468178542894663\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5335556.289899456\n",
      "Sharpe:  1.4379262879059331\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5029886.296802017\n",
      "Sharpe:  1.5796299325452539\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 431          |\n",
      "|    total_timesteps | 34926        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.11        |\n",
      "|    critic_loss     | 3.35e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 34825        |\n",
      "|    reward          | 0.0033307108 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3428589.982266873\n",
      "Sharpe:  1.832218245670374\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3347997.4580290443\n",
      "Sharpe:  1.7107487011008338\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3417727.115329271\n",
      "Sharpe:  1.7226891213447462\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2353642.9533649576\n",
      "Sharpe:  1.5920520110774128\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 80          |\n",
      "|    time_elapsed    | 485         |\n",
      "|    total_timesteps | 39309       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.129      |\n",
      "|    critic_loss     | 3.39e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 39208       |\n",
      "|    reward          | 0.002958114 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5343357.249089238\n",
      "Sharpe:  1.8490967247012602\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4139526.036508818\n",
      "Sharpe:  1.8348751925772602\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2626054.8849928756\n",
      "Sharpe:  1.7154364422590747\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6183343.993706401\n",
      "Sharpe:  1.713178419421741\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 80          |\n",
      "|    time_elapsed    | 545         |\n",
      "|    total_timesteps | 44191       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.132      |\n",
      "|    critic_loss     | 3.98e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 44090       |\n",
      "|    reward          | 0.002739429 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2587004.358653401\n",
      "Sharpe:  1.6878827507301972\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2525485.1247116188\n",
      "Sharpe:  1.8310388347845097\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9117004.78354987\n",
      "Sharpe:  1.9063638198290067\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2706460.291389915\n",
      "Sharpe:  1.8256149541504307\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 596          |\n",
      "|    total_timesteps | 48328        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.131       |\n",
      "|    critic_loss     | 4.55e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 48227        |\n",
      "|    reward          | 0.0026111398 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11344882.822722543\n",
      "Sharpe:  1.7710318813502162\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1033864.576538\n",
      "Sharpe:  3.27490890994682\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.0338645765379999 -0.02061465194547344 3.27490890994682 0\n",
      "2023-11-01 00:00:00 2023-12-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_11_1\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773124.4907868765\n",
      "Sharpe:  -4.3270512304728435\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2264534.273378567\n",
      "Sharpe:  0.9360172365932521\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2002402.2274850095\n",
      "Sharpe:  0.9255048394530698\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3359660.2396830274\n",
      "Sharpe:  1.240585763259209\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 82           |\n",
      "|    time_elapsed    | 51           |\n",
      "|    total_timesteps | 4231         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0396      |\n",
      "|    critic_loss     | 3.1e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4130         |\n",
      "|    reward          | -0.008036797 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639640.2523000147\n",
      "Sharpe:  0.7897418398131174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:785788.7948589998\n",
      "Sharpe:  -6.449239574087921\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1978362.883040016\n",
      "Sharpe:  0.9327582728950322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798492.9392049996\n",
      "Sharpe:  -5.46005610731301\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 78          |\n",
      "|    total_timesteps | 6434        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.038      |\n",
      "|    critic_loss     | 3.87e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 6333        |\n",
      "|    reward          | -0.06726039 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2149808.707194015\n",
      "Sharpe:  0.9655635819271408\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2143915.177848018\n",
      "Sharpe:  0.9609380130120488\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2000956.1918139844\n",
      "Sharpe:  0.9097674243974501\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1588640.5426879916\n",
      "Sharpe:  0.7467921413641362\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 137          |\n",
      "|    total_timesteps | 11141        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0575      |\n",
      "|    critic_loss     | 4.79e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 11040        |\n",
      "|    reward          | -0.007998984 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2373944.227493017\n",
      "Sharpe:  0.9524503168575094\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3142595.7839609524\n",
      "Sharpe:  1.1724897862899517\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1992465.0008239797\n",
      "Sharpe:  0.8865996420282808\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1931718.6699909843\n",
      "Sharpe:  0.9178351810591417\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 203          |\n",
      "|    total_timesteps | 16460        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0895      |\n",
      "|    critic_loss     | 3.07e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 16359        |\n",
      "|    reward          | -0.008679463 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1753380.54622299\n",
      "Sharpe:  1.068047003561281\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2064674.8554700136\n",
      "Sharpe:  1.030671871620243\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1996392.39114659\n",
      "Sharpe:  0.9144944195919895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1912337.2622780688\n",
      "Sharpe:  0.9112098902471639\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 260          |\n",
      "|    total_timesteps | 20992        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.111       |\n",
      "|    critic_loss     | 3.57e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 20891        |\n",
      "|    reward          | -0.008833689 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4370998.339423147\n",
      "Sharpe:  1.4991898115736928\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3613139.7782312613\n",
      "Sharpe:  1.4489903094714558\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2093316.3825976215\n",
      "Sharpe:  1.1907723366032148\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2006259.8668525126\n",
      "Sharpe:  1.0974639041667753\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 327          |\n",
      "|    total_timesteps | 26236        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0975      |\n",
      "|    critic_loss     | 2.1e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26135        |\n",
      "|    reward          | -0.008781367 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3473084.7706992286\n",
      "Sharpe:  1.4528359879602164\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2306121.96919372\n",
      "Sharpe:  1.3384344427671784\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4240961.774646103\n",
      "Sharpe:  1.6257358530842603\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3839402.3322298797\n",
      "Sharpe:  1.5347069872162131\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 395          |\n",
      "|    total_timesteps | 31799        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.093       |\n",
      "|    critic_loss     | 1.74e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 31698        |\n",
      "|    reward          | -0.008825072 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2808901.729715803\n",
      "Sharpe:  1.5238592418096462\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2889816.4284818927\n",
      "Sharpe:  1.5818269773785274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4322530.125937055\n",
      "Sharpe:  1.620025695586047\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2110445.240243648\n",
      "Sharpe:  1.4388293564997463\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 454          |\n",
      "|    total_timesteps | 36553        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.108       |\n",
      "|    critic_loss     | 1.63e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 36452        |\n",
      "|    reward          | -0.008787659 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4740893.8824144965\n",
      "Sharpe:  1.697267115858768\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2178823.867964681\n",
      "Sharpe:  1.4985342601463132\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2297633.461487829\n",
      "Sharpe:  1.6039671840740033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2322362.2477568346\n",
      "Sharpe:  1.6003992102565232\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 506          |\n",
      "|    total_timesteps | 40781        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.112       |\n",
      "|    critic_loss     | 1.64e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 40680        |\n",
      "|    reward          | -0.008636541 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3280136.8380306303\n",
      "Sharpe:  1.7691127317962547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4095551.026231419\n",
      "Sharpe:  1.8259339535864105\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3351500.107678773\n",
      "Sharpe:  1.9308787116873405\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2850866.360473675\n",
      "Sharpe:  1.8403934327627893\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 564          |\n",
      "|    total_timesteps | 45409        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.116       |\n",
      "|    critic_loss     | 1.09e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 45308        |\n",
      "|    reward          | -0.008807382 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3183054.213891932\n",
      "Sharpe:  1.835442329993153\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2608585.4497741326\n",
      "Sharpe:  1.1326622450821977\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2206021.7541238256\n",
      "Sharpe:  1.2340773042721485\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:975149.6167439998\n",
      "Sharpe:  -6.39229083973265\n",
      "=================================\n",
      "hit end!\n",
      "ddpg -0.02485038325600053 -0.026184992672472075 -6.39229083973265 0\n",
      "2023-12-01 00:00:00 2024-01-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_12_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1886312.7388768692\n",
      "Sharpe:  0.6727160414146316\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1791053.4935837528\n",
      "Sharpe:  0.5887785014398688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1405813.007408091\n",
      "Sharpe:  0.7022088247709946\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2177374.121318988\n",
      "Sharpe:  0.9869986135048808\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 63           |\n",
      "|    total_timesteps | 5211         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0668      |\n",
      "|    critic_loss     | 2.96e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5110         |\n",
      "|    reward          | -0.003402118 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2650512.3845375143\n",
      "Sharpe:  1.078110439161789\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1828663.9177416426\n",
      "Sharpe:  0.8317077944916023\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798832.8460276712\n",
      "Sharpe:  -11.6880818682488\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2026689.0079455648\n",
      "Sharpe:  0.9386015637660204\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 82            |\n",
      "|    time_elapsed    | 114           |\n",
      "|    total_timesteps | 9385          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0583       |\n",
      "|    critic_loss     | 2.8e-05       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 9284          |\n",
      "|    reward          | -0.0034008713 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2115926.18540289\n",
      "Sharpe:  0.9078372634587111\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1612239.0549754226\n",
      "Sharpe:  0.8912114836863815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1367019.206982541\n",
      "Sharpe:  0.6717304769704675\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2607424.090953128\n",
      "Sharpe:  1.0642774714034096\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 81            |\n",
      "|    time_elapsed    | 173           |\n",
      "|    total_timesteps | 14125         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0629       |\n",
      "|    critic_loss     | 1.67e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 14024         |\n",
      "|    reward          | -0.0034044362 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1863205.6784903319\n",
      "Sharpe:  0.8850718554963787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1678163.3503080243\n",
      "Sharpe:  0.8033160826157536\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1883017.8213342684\n",
      "Sharpe:  0.9137443346390701\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1890729.6414326832\n",
      "Sharpe:  0.9218801987589971\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 81            |\n",
      "|    time_elapsed    | 231           |\n",
      "|    total_timesteps | 18777         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0516       |\n",
      "|    critic_loss     | 1.39e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 18676         |\n",
      "|    reward          | -0.0034037516 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1905339.0844053596\n",
      "Sharpe:  0.9091837743537026\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797766.1803230814\n",
      "Sharpe:  -7.622622484499247\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1489113.9376281577\n",
      "Sharpe:  0.7834803782108651\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1469092.5225377409\n",
      "Sharpe:  0.650417133450804\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 270          |\n",
      "|    total_timesteps | 21914        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0669      |\n",
      "|    critic_loss     | 0.000144     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21813        |\n",
      "|    reward          | -0.004044129 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1300240.4336258986\n",
      "Sharpe:  0.5008874939718997\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1906347.6804363567\n",
      "Sharpe:  0.6821163787131805\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1611060.8983331027\n",
      "Sharpe:  0.5554359510855433\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1408811.6166212258\n",
      "Sharpe:  0.5251575755662202\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 331          |\n",
      "|    total_timesteps | 26828        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0752      |\n",
      "|    critic_loss     | 3.05e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26727        |\n",
      "|    reward          | -0.004048273 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1681924.263255702\n",
      "Sharpe:  0.5942903347702482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:773823.6852056162\n",
      "Sharpe:  -4.68642623727838\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1578522.9607989648\n",
      "Sharpe:  0.5880267813907307\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1868855.415581284\n",
      "Sharpe:  0.6695777816637878\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 80            |\n",
      "|    time_elapsed    | 385           |\n",
      "|    total_timesteps | 31151         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0727       |\n",
      "|    critic_loss     | 1.49e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 31050         |\n",
      "|    reward          | -0.0040482897 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1389407.275091588\n",
      "Sharpe:  0.608148851741151\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1679242.1580500805\n",
      "Sharpe:  0.5617539049471395\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1652299.7324200736\n",
      "Sharpe:  0.5508788299832947\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1953603.856454983\n",
      "Sharpe:  0.6579602098386619\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 452          |\n",
      "|    total_timesteps | 36436        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0603      |\n",
      "|    critic_loss     | 1.13e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 36335        |\n",
      "|    reward          | -0.004055203 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1663843.1959148492\n",
      "Sharpe:  0.5541513578157334\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1805024.850657346\n",
      "Sharpe:  0.6016342620807701\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786568.9445605478\n",
      "Sharpe:  -3.4209696836191297\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1597071.4681272097\n",
      "Sharpe:  0.5618041475780291\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 80            |\n",
      "|    time_elapsed    | 506           |\n",
      "|    total_timesteps | 40741         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0525       |\n",
      "|    critic_loss     | 2.95e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 40640         |\n",
      "|    reward          | -0.0040565613 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1785806.689749234\n",
      "Sharpe:  0.6089585064277978\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789628.6323577366\n",
      "Sharpe:  -0.32220787280985336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1583178.024709302\n",
      "Sharpe:  0.5370253611960242\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1791070.666610054\n",
      "Sharpe:  0.5987488408042688\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 565          |\n",
      "|    total_timesteps | 45577        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0405      |\n",
      "|    critic_loss     | 2.71e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 45476        |\n",
      "|    reward          | -0.004054871 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796618.3419149995\n",
      "Sharpe:  -11.105220564231377\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784738.4424993827\n",
      "Sharpe:  -3.2590569617667855\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1435392.1893175829\n",
      "Sharpe:  0.5873152085297089\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1331233.2361855854\n",
      "Sharpe:  0.5195194790878248\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 587          |\n",
      "|    total_timesteps | 47385        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0557      |\n",
      "|    critic_loss     | 2.89e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 47284        |\n",
      "|    reward          | -0.004044055 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1553878.5863763085\n",
      "Sharpe:  0.6133544402930372\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1507105.6883501904\n",
      "Sharpe:  0.5939281885871512\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:793761.0193826158\n",
      "Sharpe:  -5.305398372938641\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:980417.7836648624\n",
      "Sharpe:  -1.6703855243490222\n",
      "=================================\n",
      "hit end!\n",
      "ddpg -0.01958221633513768 -0.043835313523150884 -1.6703855243490222 0\n",
      "2024-01-01 00:00:00 2024-02-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_13_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2171704.74727181\n",
      "Sharpe:  0.837681799256763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1600407.2063310128\n",
      "Sharpe:  0.6700577864169354\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:750101.9914330001\n",
      "Sharpe:  -6.154671219582431\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779873.5886939995\n",
      "Sharpe:  -4.570989263255152\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 84          |\n",
      "|    time_elapsed    | 30          |\n",
      "|    total_timesteps | 2600        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0072     |\n",
      "|    critic_loss     | 3.19e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 2499        |\n",
      "|    reward          | -0.06627889 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2209553.997010013\n",
      "Sharpe:  0.7535200784307792\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2087928.01324\n",
      "Sharpe:  0.7067649114033895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1794034.418820989\n",
      "Sharpe:  0.6341790830624899\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1671355.936665017\n",
      "Sharpe:  0.738812900994984\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 96           |\n",
      "|    total_timesteps | 7926         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0296      |\n",
      "|    critic_loss     | 4.14e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 7825         |\n",
      "|    reward          | 0.0016840379 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1622803.3094770168\n",
      "Sharpe:  0.5771944205715438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1996517.774239987\n",
      "Sharpe:  0.6868768571265705\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1517781.740037986\n",
      "Sharpe:  0.5470309292162214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2552135.629476312\n",
      "Sharpe:  0.9105429360509166\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 164          |\n",
      "|    total_timesteps | 13377        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0344      |\n",
      "|    critic_loss     | 3.54e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 13276        |\n",
      "|    reward          | 0.0014413999 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1462939.7936900088\n",
      "Sharpe:  0.6816418686617053\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:759319.5109239997\n",
      "Sharpe:  -5.4579314126546175\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2590980.360338029\n",
      "Sharpe:  0.9295746307560149\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2300806.5627129916\n",
      "Sharpe:  0.8868044885684402\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 212          |\n",
      "|    total_timesteps | 17217        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0767      |\n",
      "|    critic_loss     | 8.62e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 17116        |\n",
      "|    reward          | 0.0014453607 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2930524.0771399126\n",
      "Sharpe:  1.0800924027928218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1947246.533284339\n",
      "Sharpe:  0.8958064306916627\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2246534.4048981247\n",
      "Sharpe:  1.1230315291907318\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1748165.5738675536\n",
      "Sharpe:  1.061826993172882\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 272          |\n",
      "|    total_timesteps | 22138        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.121       |\n",
      "|    critic_loss     | 4.68e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 22037        |\n",
      "|    reward          | 0.0013198219 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1744197.5245767836\n",
      "Sharpe:  0.9691114195282413\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2106674.1669712113\n",
      "Sharpe:  1.0791331907149524\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3269512.977293585\n",
      "Sharpe:  1.3602389455586934\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2796537.919871231\n",
      "Sharpe:  1.3686723874393025\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 330          |\n",
      "|    total_timesteps | 26965        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.157       |\n",
      "|    critic_loss     | 5.72e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26864        |\n",
      "|    reward          | 0.0010162694 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2272048.0401707627\n",
      "Sharpe:  1.7062384905103527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2786512.7832331983\n",
      "Sharpe:  1.4972769701939563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3456710.6448016553\n",
      "Sharpe:  1.340025177145456\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4659546.558694817\n",
      "Sharpe:  1.607160906248704\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 82            |\n",
      "|    time_elapsed    | 389           |\n",
      "|    total_timesteps | 32010         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.16         |\n",
      "|    critic_loss     | 5.01e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 31909         |\n",
      "|    reward          | 0.00088583224 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3095372.231119203\n",
      "Sharpe:  1.6623295451515645\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2918874.634145627\n",
      "Sharpe:  1.2347324163378517\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4343463.596254366\n",
      "Sharpe:  1.75867370293612\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2591763.688350414\n",
      "Sharpe:  1.559544698850647\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 32             |\n",
      "|    fps             | 82             |\n",
      "|    time_elapsed    | 450            |\n",
      "|    total_timesteps | 37156          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | -0.151         |\n",
      "|    critic_loss     | 4.35e-05       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 37055          |\n",
      "|    reward          | -0.00059740525 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4294394.351288103\n",
      "Sharpe:  1.6530953383406324\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5236991.624317303\n",
      "Sharpe:  1.828860628777008\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5023867.745073524\n",
      "Sharpe:  1.8980650288497478\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3890022.3364953874\n",
      "Sharpe:  1.6191946420913348\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 36             |\n",
      "|    fps             | 82             |\n",
      "|    time_elapsed    | 525            |\n",
      "|    total_timesteps | 43295          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | -0.164         |\n",
      "|    critic_loss     | 7.04e-05       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 43194          |\n",
      "|    reward          | -0.00025993283 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4340358.388129409\n",
      "Sharpe:  2.1613198718666666\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3179713.017738759\n",
      "Sharpe:  1.715881441045935\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5153371.00243968\n",
      "Sharpe:  2.0163074119101543\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3059965.984416934\n",
      "Sharpe:  1.9101396027549726\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 40             |\n",
      "|    fps             | 82             |\n",
      "|    time_elapsed    | 582            |\n",
      "|    total_timesteps | 47957          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | -0.155         |\n",
      "|    critic_loss     | 6.7e-05        |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 47856          |\n",
      "|    reward          | -0.00026490146 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5836437.142542914\n",
      "Sharpe:  1.9385541528561647\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1007607.0306099998\n",
      "Sharpe:  2.8795337375014167\n",
      "=================================\n",
      "hit end!\n",
      "ddpg 0.00760703061000001 -0.0069257247064599655 2.8795337375014163 0\n",
      "2024-02-01 00:00:00 2024-03-01 00:00:00\n",
      "ddpg\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\ddpg_14_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784997.2279132885\n",
      "Sharpe:  -0.48296198906735593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1953830.4066347792\n",
      "Sharpe:  0.8672588340674169\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1481425.568240796\n",
      "Sharpe:  0.7543385978860152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1881527.6478669886\n",
      "Sharpe:  0.6789589256798512\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 83           |\n",
      "|    time_elapsed    | 49           |\n",
      "|    total_timesteps | 4154         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.099       |\n",
      "|    critic_loss     | 4.51e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4053         |\n",
      "|    reward          | 0.0021680298 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794739.3007409998\n",
      "Sharpe:  -2.8460343770713767\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1710816.569599096\n",
      "Sharpe:  0.6710918536664764\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1703305.3249249805\n",
      "Sharpe:  0.693176166922492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1772911.9609588634\n",
      "Sharpe:  0.6980568436965573\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 82           |\n",
      "|    time_elapsed    | 102          |\n",
      "|    total_timesteps | 8450         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.109       |\n",
      "|    critic_loss     | 4.32e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8349         |\n",
      "|    reward          | 0.0012670845 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1579950.1476678376\n",
      "Sharpe:  0.6902754474769434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1797252.8286027827\n",
      "Sharpe:  0.7118220758579056\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1395522.522545514\n",
      "Sharpe:  0.682609975702285\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1566334.1252765006\n",
      "Sharpe:  0.689270334578839\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 160          |\n",
      "|    total_timesteps | 13146        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0907      |\n",
      "|    critic_loss     | 2.98e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 13045        |\n",
      "|    reward          | 0.0012669205 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1504869.6774972356\n",
      "Sharpe:  0.7821099007186921\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1880646.5673800262\n",
      "Sharpe:  0.7430194356261265\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1549130.5389875928\n",
      "Sharpe:  0.7078810016226945\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1732919.8045821371\n",
      "Sharpe:  0.6805294165455718\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 222          |\n",
      "|    total_timesteps | 18155        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0757      |\n",
      "|    critic_loss     | 2.55e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 18054        |\n",
      "|    reward          | 0.0012671873 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1547846.2121482699\n",
      "Sharpe:  0.8155390307522218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797611.0367711367\n",
      "Sharpe:  -8.608960451205752\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1538344.1121098886\n",
      "Sharpe:  0.6990278926845167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1700322.0808338206\n",
      "Sharpe:  0.7202184831680881\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 264          |\n",
      "|    total_timesteps | 21518        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0665      |\n",
      "|    critic_loss     | 2.01e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21417        |\n",
      "|    reward          | 0.0012677483 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1708988.4370760282\n",
      "Sharpe:  0.700469109651669\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1632502.622954635\n",
      "Sharpe:  0.7163846376381292\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1679835.5224094708\n",
      "Sharpe:  0.7317038661942165\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1580648.1210910645\n",
      "Sharpe:  0.6931950964738602\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 328          |\n",
      "|    total_timesteps | 26626        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0552      |\n",
      "|    critic_loss     | 1.78e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26525        |\n",
      "|    reward          | 0.0012669086 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1519349.9643651438\n",
      "Sharpe:  0.6578340746811878\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1416038.9575727775\n",
      "Sharpe:  0.7284790708807456\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1696189.9522727195\n",
      "Sharpe:  0.7085403248385349\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1550820.219379886\n",
      "Sharpe:  0.7045871521215792\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 383          |\n",
      "|    total_timesteps | 31020        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0448      |\n",
      "|    critic_loss     | 2.06e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 30919        |\n",
      "|    reward          | 0.0012670893 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1644824.0478819357\n",
      "Sharpe:  0.7258027649446024\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1692535.0492052543\n",
      "Sharpe:  0.717135211965479\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1707513.4002522826\n",
      "Sharpe:  0.7290817646005695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1683529.1484705117\n",
      "Sharpe:  0.6940913421933125\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 446          |\n",
      "|    total_timesteps | 36312        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0536      |\n",
      "|    critic_loss     | 1.28e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 36211        |\n",
      "|    reward          | 0.0012668995 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1662884.997908237\n",
      "Sharpe:  0.6820967266180197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799130.6988985614\n",
      "Sharpe:  -5.387518964902188\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787333.692051829\n",
      "Sharpe:  0.7072707649803548\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1613491.4567067146\n",
      "Sharpe:  0.6256137857044722\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 500          |\n",
      "|    total_timesteps | 40566        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0703      |\n",
      "|    critic_loss     | 3.18e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 40465        |\n",
      "|    reward          | 0.0017303507 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1659400.8392249923\n",
      "Sharpe:  0.5573900159098645\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2240219.447884017\n",
      "Sharpe:  0.7571268303293618\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2053877.4666830662\n",
      "Sharpe:  0.8667185430950599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2138233.4192108745\n",
      "Sharpe:  0.8302187101634433\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 575          |\n",
      "|    total_timesteps | 46447        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.082       |\n",
      "|    critic_loss     | 1.16e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 46346        |\n",
      "|    reward          | 0.0014081835 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1548118.3682938677\n",
      "Sharpe:  0.8100766247927258\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1933983.4665030616\n",
      "Sharpe:  1.09706825595382\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2001107.024777254\n",
      "Sharpe:  0.9948731041546469\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:987290.2557242456\n",
      "Sharpe:  -2.3249959716096966\n",
      "=================================\n",
      "hit end!\n",
      "ddpg -0.01270974427575422 -0.02777901968924695 -2.3249959716096966 0\n",
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_6_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1592044.79575092\n",
      "Sharpe:  0.6002158674460654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2068884.5680423747\n",
      "Sharpe:  0.7390542315002172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2362844.4651385443\n",
      "Sharpe:  0.8896735899485757\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2004054.4010450605\n",
      "Sharpe:  0.8733321776279999\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 83          |\n",
      "|    time_elapsed    | 63          |\n",
      "|    total_timesteps | 5323        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0382      |\n",
      "|    critic_loss     | 0.000128    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 5222        |\n",
      "|    reward          | 0.004941263 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2255934.9647177174\n",
      "Sharpe:  0.8863714364335049\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2472982.4910275517\n",
      "Sharpe:  0.9358021872091179\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1635089.8985500163\n",
      "Sharpe:  0.665433888728806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1737378.76258002\n",
      "Sharpe:  0.6974336131558775\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 83           |\n",
      "|    time_elapsed    | 125          |\n",
      "|    total_timesteps | 10429        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.041        |\n",
      "|    critic_loss     | 0.000133     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 10328        |\n",
      "|    reward          | 0.0049238545 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2052977.827159329\n",
      "Sharpe:  0.7952101579669915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2221757.959955205\n",
      "Sharpe:  0.9424422454171444\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1593966.1287062522\n",
      "Sharpe:  0.6127505726323763\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2429569.1190914256\n",
      "Sharpe:  0.971053365598015\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 85           |\n",
      "|    time_elapsed    | 183          |\n",
      "|    total_timesteps | 15634        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0566       |\n",
      "|    critic_loss     | 7.8e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 15533        |\n",
      "|    reward          | 0.0045323675 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1937532.708361063\n",
      "Sharpe:  0.8362204771795361\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3942070.1862237654\n",
      "Sharpe:  1.2939372853473117\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2132286.9967774656\n",
      "Sharpe:  1.0422920099975375\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2422301.978689011\n",
      "Sharpe:  1.0025467890965565\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 86           |\n",
      "|    time_elapsed    | 236          |\n",
      "|    total_timesteps | 20323        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0541       |\n",
      "|    critic_loss     | 6.36e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 20222        |\n",
      "|    reward          | 0.0049909335 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2043144.3798874088\n",
      "Sharpe:  0.981140815253296\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1429040.7258041594\n",
      "Sharpe:  0.6730717007984901\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2149458.341148853\n",
      "Sharpe:  1.0740866870367622\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3519291.030361817\n",
      "Sharpe:  1.2366966078525503\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 86          |\n",
      "|    time_elapsed    | 284         |\n",
      "|    total_timesteps | 24533       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0558      |\n",
      "|    critic_loss     | 7.73e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24432       |\n",
      "|    reward          | 0.006290151 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2529452.583890386\n",
      "Sharpe:  1.1394870021845311\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2421502.5264029456\n",
      "Sharpe:  1.1865284729455898\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8729171.64387567\n",
      "Sharpe:  1.2780621913757133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8622712.960580762\n",
      "Sharpe:  1.3213565533266127\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 86          |\n",
      "|    time_elapsed    | 339         |\n",
      "|    total_timesteps | 29426       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.039       |\n",
      "|    critic_loss     | 8.2e-05     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29325       |\n",
      "|    reward          | 0.007623142 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10291489.496033134\n",
      "Sharpe:  1.4557781005828279\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9481057.348818993\n",
      "Sharpe:  1.4449875981011784\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5149037.871062074\n",
      "Sharpe:  1.7822072342956787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4141846.857441311\n",
      "Sharpe:  1.6173456252196885\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 86           |\n",
      "|    time_elapsed    | 396          |\n",
      "|    total_timesteps | 34292        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0458       |\n",
      "|    critic_loss     | 9.82e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 34191        |\n",
      "|    reward          | 0.0076206475 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17081504.814123247\n",
      "Sharpe:  1.3275999223885881\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4790459.788416988\n",
      "Sharpe:  1.704252429532547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:20838296.020832818\n",
      "Sharpe:  1.391461221169759\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:22966410.216957707\n",
      "Sharpe:  1.4507878633562707\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 86        |\n",
      "|    time_elapsed    | 462       |\n",
      "|    total_timesteps | 39913     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 0.0185    |\n",
      "|    critic_loss     | 0.00024   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 39812     |\n",
      "|    reward          | 0.0075508 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:19237157.65385235\n",
      "Sharpe:  1.3641482675376633\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7335266.650136195\n",
      "Sharpe:  1.5803062165855954\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5742214.28061682\n",
      "Sharpe:  1.7249569561556257\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11972830.75605285\n",
      "Sharpe:  1.5953460828710009\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 36             |\n",
      "|    fps             | 86             |\n",
      "|    time_elapsed    | 523            |\n",
      "|    total_timesteps | 45158          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.0195         |\n",
      "|    critic_loss     | 0.000105       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 45057          |\n",
      "|    reward          | -4.9658327e-05 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6309675.216172819\n",
      "Sharpe:  1.7721362310635431\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18548458.88085631\n",
      "Sharpe:  1.7751067801364466\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:19827731.912284825\n",
      "Sharpe:  1.8348341346597885\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6082773.393248917\n",
      "Sharpe:  1.858500770095571\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 86           |\n",
      "|    time_elapsed    | 578          |\n",
      "|    total_timesteps | 49974        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.023        |\n",
      "|    critic_loss     | 6.85e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 49873        |\n",
      "|    reward          | 0.0035361545 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1050837.2753842329\n",
      "Sharpe:  5.587265501772454\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.050837275384233216 -0.0185548680876669 5.587265501772455 0\n",
      "2023-07-01 00:00:00 2023-08-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_7_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2069642.2858984137\n",
      "Sharpe:  0.5919604963227217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1728001.7460450141\n",
      "Sharpe:  0.5399062937747321\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:748538.1174750003\n",
      "Sharpe:  -3.9491122431097003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1993221.203074987\n",
      "Sharpe:  0.6026676374890025\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 89            |\n",
      "|    time_elapsed    | 48            |\n",
      "|    total_timesteps | 4332          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.00671      |\n",
      "|    critic_loss     | 0.000382      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 4231          |\n",
      "|    reward          | -0.0011992551 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:739133.7795949996\n",
      "Sharpe:  -4.398226651383125\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1547003.0748349936\n",
      "Sharpe:  0.471817887621335\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2193441.02357002\n",
      "Sharpe:  0.6564502431785907\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1912890.3372799852\n",
      "Sharpe:  0.5358648607598854\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 98            |\n",
      "|    total_timesteps | 8652          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0964        |\n",
      "|    critic_loss     | 0.000567      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 8551          |\n",
      "|    reward          | -0.0012044793 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:741365.0381300002\n",
      "Sharpe:  -3.3036547857439325\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:726395.2180300003\n",
      "Sharpe:  -6.372244133185078\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2044329.0014400114\n",
      "Sharpe:  0.6190779572773781\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2021866.2441100185\n",
      "Sharpe:  0.5777868117569765\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 134           |\n",
      "|    total_timesteps | 11749         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.159         |\n",
      "|    critic_loss     | 0.000479      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 11648         |\n",
      "|    reward          | -0.0012208647 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:753532.3881700004\n",
      "Sharpe:  -2.22607043932775\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1410588.74423999\n",
      "Sharpe:  0.4299987485303416\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796969.6419250004\n",
      "Sharpe:  -3.2832665318086396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760267.0691299996\n",
      "Sharpe:  -2.104744981787822\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 86          |\n",
      "|    time_elapsed    | 150         |\n",
      "|    total_timesteps | 13103       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.247       |\n",
      "|    critic_loss     | 0.000922    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 13002       |\n",
      "|    reward          | -0.08281504 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2055459.6180449848\n",
      "Sharpe:  0.6015128673307003\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1393615.3167050127\n",
      "Sharpe:  0.4300649780188514\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1680642.3991150137\n",
      "Sharpe:  0.527788508949951\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1463357.2486949898\n",
      "Sharpe:  0.4463875929148445\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 86            |\n",
      "|    time_elapsed    | 208           |\n",
      "|    total_timesteps | 18003         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.363         |\n",
      "|    critic_loss     | 0.000728      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 17902         |\n",
      "|    reward          | -0.0011909398 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1773702.9828999839\n",
      "Sharpe:  0.5549357104779714\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1676835.8886350126\n",
      "Sharpe:  0.5241239415391141\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787790.9736449999\n",
      "Sharpe:  -1.0325481094744988\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1669416.2204249816\n",
      "Sharpe:  0.5156967307844502\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 86          |\n",
      "|    time_elapsed    | 255         |\n",
      "|    total_timesteps | 22000       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.506       |\n",
      "|    critic_loss     | 0.00101     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21899       |\n",
      "|    reward          | -0.00120675 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:796462.4933849995\n",
      "Sharpe:  -0.9659545150745227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1773630.7461749872\n",
      "Sharpe:  0.5490093627459532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1967874.6276900107\n",
      "Sharpe:  0.6053385246626131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1595550.053959988\n",
      "Sharpe:  0.49313730143246187\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 86            |\n",
      "|    time_elapsed    | 301           |\n",
      "|    total_timesteps | 26096         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.556         |\n",
      "|    critic_loss     | 0.00101       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 25995         |\n",
      "|    reward          | -0.0012076003 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2264673.2531149844\n",
      "Sharpe:  0.6702739948620043\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2116297.8301649876\n",
      "Sharpe:  0.6402224097776776\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:771548.3974700012\n",
      "Sharpe:  -1.2857053480322755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1401422.68926999\n",
      "Sharpe:  0.4293715880167594\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 347           |\n",
      "|    total_timesteps | 30218         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.687         |\n",
      "|    critic_loss     | 0.00116       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 30117         |\n",
      "|    reward          | -0.0012101805 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1944020.627059988\n",
      "Sharpe:  0.6015161054988093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:733753.5713150001\n",
      "Sharpe:  -6.3429686866638955\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1856030.201104987\n",
      "Sharpe:  0.5145447111826545\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1455042.4372000124\n",
      "Sharpe:  0.4323035439092471\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 1             |\n",
      "|    time_elapsed    | 20701         |\n",
      "|    total_timesteps | 34388         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.853         |\n",
      "|    critic_loss     | 0.0019        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 34287         |\n",
      "|    reward          | -0.0012031947 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1447241.787039988\n",
      "Sharpe:  0.4285114781092317\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798882.9531999996\n",
      "Sharpe:  -3.4314889447512233\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1779402.295055012\n",
      "Sharpe:  0.5430799079237552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1664370.5320349901\n",
      "Sharpe:  0.514018576412366\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 1             |\n",
      "|    time_elapsed    | 20756         |\n",
      "|    total_timesteps | 38260         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.94          |\n",
      "|    critic_loss     | 0.00181       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 38159         |\n",
      "|    reward          | -0.0012170442 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767590.1234650002\n",
      "Sharpe:  -1.7631230087127643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1875566.74931001\n",
      "Sharpe:  0.5263548756205645\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2127507.0911400137\n",
      "Sharpe:  0.6330070606945414\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1982915.9741500162\n",
      "Sharpe:  0.6018329967710938\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 2            |\n",
      "|    time_elapsed    | 20805        |\n",
      "|    total_timesteps | 42847        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.13         |\n",
      "|    critic_loss     | 0.0105       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 42746        |\n",
      "|    reward          | -0.001208378 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740974.4903449995\n",
      "Sharpe:  -3.2103231464237614\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1921298.9561499907\n",
      "Sharpe:  0.5902564475695823\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772164.452094999\n",
      "Sharpe:  -1.1426006504848787\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1827859.308679987\n",
      "Sharpe:  0.5602678393895618\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 48            |\n",
      "|    fps             | 2             |\n",
      "|    time_elapsed    | 20836         |\n",
      "|    total_timesteps | 45832         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.24          |\n",
      "|    critic_loss     | 0.00333       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 45731         |\n",
      "|    reward          | -0.0012242312 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2076552.1375399877\n",
      "Sharpe:  0.6030918421221245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:736173.6573800003\n",
      "Sharpe:  -3.354957688566937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1997499.741940016\n",
      "Sharpe:  0.5710493264541732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1101314.005215\n",
      "Sharpe:  11.326172596877106\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.10131400521499967 -0.01630349595842782 11.326172596877107 0\n",
      "2023-08-01 00:00:00 2023-09-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_8_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1955768.695117788\n",
      "Sharpe:  0.8811259096013511\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1895933.1658006727\n",
      "Sharpe:  0.7535858122602772\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1867251.573949986\n",
      "Sharpe:  0.7618063126705312\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797018.712405\n",
      "Sharpe:  -1.6446706266269258\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 96           |\n",
      "|    time_elapsed    | 34           |\n",
      "|    total_timesteps | 3330         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0411       |\n",
      "|    critic_loss     | 0.000274     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 3229         |\n",
      "|    reward          | -0.050753627 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3086961.404379973\n",
      "Sharpe:  0.9598120123650307\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1951653.0742849843\n",
      "Sharpe:  0.821425928787741\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2971400.1779133286\n",
      "Sharpe:  1.0937515638887532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2610337.775009243\n",
      "Sharpe:  1.1114105136991508\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 93           |\n",
      "|    time_elapsed    | 93           |\n",
      "|    total_timesteps | 8743         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0452       |\n",
      "|    critic_loss     | 0.000212     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8642         |\n",
      "|    reward          | 0.0032915832 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5256092.422334109\n",
      "Sharpe:  1.5021034064579148\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1757198.9915965025\n",
      "Sharpe:  0.7450163137195741\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3137895.912895025\n",
      "Sharpe:  1.4809730198294355\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1964037.3176227445\n",
      "Sharpe:  1.2424915558441185\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 158          |\n",
      "|    total_timesteps | 14046        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0731       |\n",
      "|    critic_loss     | 8.25e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 13945        |\n",
      "|    reward          | 0.0040625217 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3652584.9496898446\n",
      "Sharpe:  1.5305363052718381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1628820.7395204217\n",
      "Sharpe:  1.248867156810162\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3457688.494494233\n",
      "Sharpe:  1.640311455078452\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1747300.4402217965\n",
      "Sharpe:  1.1641583845386085\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 84          |\n",
      "|    time_elapsed    | 223         |\n",
      "|    total_timesteps | 18865       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0831      |\n",
      "|    critic_loss     | 0.00013     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 18764       |\n",
      "|    reward          | 0.004061749 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3349427.215311372\n",
      "Sharpe:  1.5885578116634596\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3131904.4722361555\n",
      "Sharpe:  1.4996680471266637\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1704098.563133148\n",
      "Sharpe:  1.0871897422270875\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3078588.4021522445\n",
      "Sharpe:  1.5104682532716096\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 86         |\n",
      "|    time_elapsed    | 279        |\n",
      "|    total_timesteps | 24211      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.0903     |\n",
      "|    critic_loss     | 8.1e-05    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24110      |\n",
      "|    reward          | 0.00255978 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2421444.689955011\n",
      "Sharpe:  1.1527373301038812\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2369107.117989994\n",
      "Sharpe:  1.2437609012378583\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3018132.142190591\n",
      "Sharpe:  1.3638135714320676\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3593421.3947314406\n",
      "Sharpe:  1.522603663000276\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 87           |\n",
      "|    time_elapsed    | 334          |\n",
      "|    total_timesteps | 29291        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.111        |\n",
      "|    critic_loss     | 7.36e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 29190        |\n",
      "|    reward          | 0.0026009441 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1759753.0704450577\n",
      "Sharpe:  1.1206946799563122\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2339582.109656911\n",
      "Sharpe:  1.1496929788942143\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3883374.9277099553\n",
      "Sharpe:  1.4045443933760533\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1834647.6415721974\n",
      "Sharpe:  1.082810401635241\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 378          |\n",
      "|    total_timesteps | 33320        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.108        |\n",
      "|    critic_loss     | 8.21e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 33219        |\n",
      "|    reward          | 0.0026108702 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5320736.386282912\n",
      "Sharpe:  1.5477220202617323\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2234292.452749582\n",
      "Sharpe:  1.2483322795216347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3962837.774200557\n",
      "Sharpe:  1.360268570092731\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2627851.336334518\n",
      "Sharpe:  1.3441136770023656\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 88            |\n",
      "|    time_elapsed    | 427           |\n",
      "|    total_timesteps | 37918         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.151         |\n",
      "|    critic_loss     | 7.81e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 37817         |\n",
      "|    reward          | 0.00047117702 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5699115.568033623\n",
      "Sharpe:  1.4415514879676745\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2759036.1320949346\n",
      "Sharpe:  1.5216855684704134\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4005369.358989977\n",
      "Sharpe:  1.5166776465323228\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10086526.490202026\n",
      "Sharpe:  1.9094961780405535\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 89           |\n",
      "|    time_elapsed    | 480          |\n",
      "|    total_timesteps | 42931        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.145        |\n",
      "|    critic_loss     | 0.000115     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 42830        |\n",
      "|    reward          | 0.0030579062 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8315502.644703649\n",
      "Sharpe:  1.8922100373195911\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:12692656.18978486\n",
      "Sharpe:  2.0422309099189073\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5511531.928126063\n",
      "Sharpe:  1.8368287709986695\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4547214.085517962\n",
      "Sharpe:  1.5446217524069048\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 89          |\n",
      "|    time_elapsed    | 535         |\n",
      "|    total_timesteps | 48006       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.134       |\n",
      "|    critic_loss     | 0.000112    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 47905       |\n",
      "|    reward          | 0.005559161 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4867369.87770465\n",
      "Sharpe:  1.650047363797081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1041976.7753500001\n",
      "Sharpe:  4.696442904715724\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.041976775349999995 -0.015612773158211336 4.696442904715724 0\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_9_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1468630.144779627\n",
      "Sharpe:  0.6336571890186659\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1699640.3690716345\n",
      "Sharpe:  0.7751252966495287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1725909.749622684\n",
      "Sharpe:  0.821575614229879\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1559754.5097911633\n",
      "Sharpe:  0.7987896381271132\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 95            |\n",
      "|    time_elapsed    | 46            |\n",
      "|    total_timesteps | 4426          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0797        |\n",
      "|    critic_loss     | 0.000285      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 4325          |\n",
      "|    reward          | -0.0010558164 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1616406.1412340656\n",
      "Sharpe:  0.6011938193009639\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1911343.505410715\n",
      "Sharpe:  0.7648625742698613\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1529753.9553663211\n",
      "Sharpe:  0.675957069979647\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1893998.8508328479\n",
      "Sharpe:  0.9521477297625808\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 8              |\n",
      "|    fps             | 94             |\n",
      "|    time_elapsed    | 95             |\n",
      "|    total_timesteps | 9003           |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.092          |\n",
      "|    critic_loss     | 0.000204       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 8902           |\n",
      "|    reward          | -0.00085844944 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1686998.8998448523\n",
      "Sharpe:  0.7187222665407333\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1704326.3935663884\n",
      "Sharpe:  0.717118900473192\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1944522.6929650945\n",
      "Sharpe:  0.6796590694037922\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:745218.78545163\n",
      "Sharpe:  -5.442250060804707\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 94           |\n",
      "|    time_elapsed    | 135          |\n",
      "|    total_timesteps | 12731        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.107        |\n",
      "|    critic_loss     | 0.00012      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 12630        |\n",
      "|    reward          | -0.071930975 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1886232.906465854\n",
      "Sharpe:  0.7394472107697126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2333267.819841113\n",
      "Sharpe:  0.8472619106492051\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1773512.579469395\n",
      "Sharpe:  0.9839144820754995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1948945.5134593744\n",
      "Sharpe:  0.8077102368854766\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 16             |\n",
      "|    fps             | 93             |\n",
      "|    time_elapsed    | 187            |\n",
      "|    total_timesteps | 17557          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.137          |\n",
      "|    critic_loss     | 0.000121       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 17456          |\n",
      "|    reward          | -0.00065233273 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1695343.1564984366\n",
      "Sharpe:  0.7347541821017592\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2715952.094080157\n",
      "Sharpe:  0.9598967891880549\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2217741.316330097\n",
      "Sharpe:  0.8718193265903204\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1824464.6892934006\n",
      "Sharpe:  0.7396304146145185\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 20             |\n",
      "|    fps             | 93             |\n",
      "|    time_elapsed    | 242            |\n",
      "|    total_timesteps | 22656          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.168          |\n",
      "|    critic_loss     | 0.000149       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 22555          |\n",
      "|    reward          | -0.00090839795 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1581374.0184797957\n",
      "Sharpe:  0.7745933360782442\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2352903.1123442776\n",
      "Sharpe:  0.9149390305744183\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1523644.9412252577\n",
      "Sharpe:  0.7282636741152246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1800006.6615072398\n",
      "Sharpe:  0.7784834548174029\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 93           |\n",
      "|    time_elapsed    | 288          |\n",
      "|    total_timesteps | 26901        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.192        |\n",
      "|    critic_loss     | 0.000193     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 26800        |\n",
      "|    reward          | 0.0030306438 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1818405.8104793152\n",
      "Sharpe:  0.7828523485145482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2153620.406406252\n",
      "Sharpe:  0.9880306351465966\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2958766.4708729023\n",
      "Sharpe:  1.1570181843216387\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2120128.7237390443\n",
      "Sharpe:  1.0083252666754312\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 93           |\n",
      "|    time_elapsed    | 343          |\n",
      "|    total_timesteps | 31959        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.195        |\n",
      "|    critic_loss     | 0.000104     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 31858        |\n",
      "|    reward          | 0.0028496946 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2507265.7181779225\n",
      "Sharpe:  1.0054679299584057\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2032872.3096402932\n",
      "Sharpe:  0.8867120299756076\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2782274.503881563\n",
      "Sharpe:  1.0877672901349065\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2488152.526844062\n",
      "Sharpe:  0.9387603466592817\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 92           |\n",
      "|    time_elapsed    | 405          |\n",
      "|    total_timesteps | 37665        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.208        |\n",
      "|    critic_loss     | 0.000152     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 37564        |\n",
      "|    reward          | 0.0038186808 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2196547.7687358772\n",
      "Sharpe:  0.8483840136413908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:799985.422579877\n",
      "Sharpe:  -7.966249319316027\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2533864.235305012\n",
      "Sharpe:  0.8994525481210023\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2362335.309889556\n",
      "Sharpe:  1.1234894274083531\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 92         |\n",
      "|    time_elapsed    | 450        |\n",
      "|    total_timesteps | 41781      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.184      |\n",
      "|    critic_loss     | 8.43e-05   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 41680      |\n",
      "|    reward          | 0.00383007 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2471458.63788468\n",
      "Sharpe:  1.0171686096994\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1805718.8198495233\n",
      "Sharpe:  0.9633817114107529\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2901745.123430576\n",
      "Sharpe:  1.1234791286410255\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1911615.505681053\n",
      "Sharpe:  1.0002084146240793\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 92           |\n",
      "|    time_elapsed    | 502          |\n",
      "|    total_timesteps | 46503        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.182        |\n",
      "|    critic_loss     | 0.000112     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 46402        |\n",
      "|    reward          | 0.0028861314 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3767746.6464961544\n",
      "Sharpe:  1.349804072221411\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2851443.4206300317\n",
      "Sharpe:  1.2902046515756795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1668256.6923850635\n",
      "Sharpe:  1.1579567793041914\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:986635.7666356438\n",
      "Sharpe:  -1.407983882251828\n",
      "=================================\n",
      "hit end!\n",
      "td3 -0.013364233364356104 -0.053834396632559796 -1.407983882251828 0\n",
      "2023-10-01 00:00:00 2023-11-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1249834.6373251325\n",
      "Sharpe:  0.4614243372439227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1977577.3754313525\n",
      "Sharpe:  0.8908946977966632\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1669122.6648784801\n",
      "Sharpe:  0.7426016899585163\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2433196.449305669\n",
      "Sharpe:  1.023954000975163\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 92         |\n",
      "|    time_elapsed    | 47         |\n",
      "|    total_timesteps | 4397       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.0366    |\n",
      "|    critic_loss     | 7.25e-05   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4296       |\n",
      "|    reward          | 0.02282304 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1945250.6212059043\n",
      "Sharpe:  0.6528991654996096\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1589376.575466647\n",
      "Sharpe:  1.0075771758129524\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2342832.9940194245\n",
      "Sharpe:  1.0914508510197503\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1832944.6937007806\n",
      "Sharpe:  0.8566551084255117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 91          |\n",
      "|    time_elapsed    | 100         |\n",
      "|    total_timesteps | 9161        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0286     |\n",
      "|    critic_loss     | 7.57e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9060        |\n",
      "|    reward          | 0.015590548 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1481069.7320354753\n",
      "Sharpe:  0.5343244068502138\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2239077.875139866\n",
      "Sharpe:  0.7740288071045895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1463810.590189116\n",
      "Sharpe:  0.6705416398009634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1781716.5398972812\n",
      "Sharpe:  1.1255378485972303\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 146          |\n",
      "|    total_timesteps | 13340        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0293      |\n",
      "|    critic_loss     | 9.18e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 13239        |\n",
      "|    reward          | 0.0006865724 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1652281.7221056235\n",
      "Sharpe:  0.9089968417017724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826962.8282794247\n",
      "Sharpe:  0.9907957343372621\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1784700.5288399002\n",
      "Sharpe:  1.324819219102535\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2794041.5424201335\n",
      "Sharpe:  1.247377252567914\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 16             |\n",
      "|    fps             | 90             |\n",
      "|    time_elapsed    | 190            |\n",
      "|    total_timesteps | 17299          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | -0.0103        |\n",
      "|    critic_loss     | 9.07e-05       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 17198          |\n",
      "|    reward          | -0.00021741558 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3801603.26554332\n",
      "Sharpe:  1.4986860807128954\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:787235.0926139039\n",
      "Sharpe:  -7.255398552672364\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3561038.3230547314\n",
      "Sharpe:  1.3931539224181848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3272066.246951406\n",
      "Sharpe:  1.3177688003985553\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 237          |\n",
      "|    total_timesteps | 21517        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.00567     |\n",
      "|    critic_loss     | 8.62e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21416        |\n",
      "|    reward          | 0.0024218503 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781119.1140414523\n",
      "Sharpe:  -4.806045830955438\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4383780.18534816\n",
      "Sharpe:  1.3869545492780908\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4362389.210602537\n",
      "Sharpe:  1.3234392784180289\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781869.4225361919\n",
      "Sharpe:  -5.654727983852413\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 268          |\n",
      "|    total_timesteps | 24352        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0119      |\n",
      "|    critic_loss     | 0.000118     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 24251        |\n",
      "|    reward          | -0.052082743 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3487370.2344027986\n",
      "Sharpe:  1.6564468596178108\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3585014.446080288\n",
      "Sharpe:  1.381846475544634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8144002.024437861\n",
      "Sharpe:  1.5817591938492126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9769979.878186226\n",
      "Sharpe:  1.8236886387273885\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 324          |\n",
      "|    total_timesteps | 29358        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0048      |\n",
      "|    critic_loss     | 0.000124     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 29257        |\n",
      "|    reward          | 0.0005490086 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3210881.7259546886\n",
      "Sharpe:  1.7322051112967758\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10429390.328144807\n",
      "Sharpe:  1.441829376439133\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2826057.920627431\n",
      "Sharpe:  1.6852443563535822\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:20001875.11091354\n",
      "Sharpe:  1.6416728532509648\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 90          |\n",
      "|    time_elapsed    | 376         |\n",
      "|    total_timesteps | 34268       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0126     |\n",
      "|    critic_loss     | 0.00011     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 34167       |\n",
      "|    reward          | 0.004366227 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789248.5895309586\n",
      "Sharpe:  -6.047231405445833\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5695597.171274448\n",
      "Sharpe:  2.11333125768445\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:20969774.24507658\n",
      "Sharpe:  1.7997467355833134\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9638731.535563305\n",
      "Sharpe:  2.1150156424486397\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 415          |\n",
      "|    total_timesteps | 37860        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.00332     |\n",
      "|    critic_loss     | 0.000122     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 37759        |\n",
      "|    reward          | 0.0009871793 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4331182.828219126\n",
      "Sharpe:  2.092076418840604\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9977830.740162874\n",
      "Sharpe:  2.1606940159567354\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11804600.37009192\n",
      "Sharpe:  1.8410372744987726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3745539.792909915\n",
      "Sharpe:  2.1205411430923413\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 460          |\n",
      "|    total_timesteps | 41943        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0156      |\n",
      "|    critic_loss     | 0.000138     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 41842        |\n",
      "|    reward          | 0.0024894166 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24172819.54737488\n",
      "Sharpe:  1.727102131762646\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5575132.047986481\n",
      "Sharpe:  2.1280115835746676\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17691500.43500279\n",
      "Sharpe:  1.7404220335142997\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:17733002.01298604\n",
      "Sharpe:  1.8786864018565557\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 520          |\n",
      "|    total_timesteps | 47351        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0239      |\n",
      "|    critic_loss     | 0.000135     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 47250        |\n",
      "|    reward          | 0.0025332815 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15122727.469560113\n",
      "Sharpe:  2.0125846151061753\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6142052.0589890685\n",
      "Sharpe:  2.45581328768067\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1032728.8482065062\n",
      "Sharpe:  4.047729307719092\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.03272884820650712 -0.01584839385701255 4.0477293077190915 0\n",
      "2023-11-01 00:00:00 2023-12-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_11_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1746715.7453543022\n",
      "Sharpe:  0.685888912121198\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1746491.486893864\n",
      "Sharpe:  0.6510940948457865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2374283.9151999857\n",
      "Sharpe:  0.7707131515248403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787059.970980018\n",
      "Sharpe:  0.6400099770072681\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 93           |\n",
      "|    time_elapsed    | 55           |\n",
      "|    total_timesteps | 5218         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0596       |\n",
      "|    critic_loss     | 0.00047      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5117         |\n",
      "|    reward          | -0.008524538 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:740029.5242949999\n",
      "Sharpe:  -11.340640105907415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2287318.07714998\n",
      "Sharpe:  0.7471999995927457\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1623364.5061249868\n",
      "Sharpe:  0.5947442410783249\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1575190.7266300109\n",
      "Sharpe:  0.5832211774475293\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 93           |\n",
      "|    time_elapsed    | 95           |\n",
      "|    total_timesteps | 8870         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.109        |\n",
      "|    critic_loss     | 0.000235     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8769         |\n",
      "|    reward          | -0.008534334 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1605013.6381149876\n",
      "Sharpe:  0.5996205353583074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797948.7730899999\n",
      "Sharpe:  -9.931127648029046\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2456202.594080021\n",
      "Sharpe:  0.7895472679663151\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:760482.3452249996\n",
      "Sharpe:  -2.1223523541920697\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 92          |\n",
      "|    time_elapsed    | 125         |\n",
      "|    total_timesteps | 11607       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.145       |\n",
      "|    critic_loss     | 0.000306    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 11506       |\n",
      "|    reward          | -0.05488287 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2204174.566080025\n",
      "Sharpe:  0.7233817477632213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:752510.1483250003\n",
      "Sharpe:  -3.1861264539341194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2287089.061284981\n",
      "Sharpe:  0.7471274919874867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2413548.7378800153\n",
      "Sharpe:  0.7814797699225755\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 92           |\n",
      "|    time_elapsed    | 175          |\n",
      "|    total_timesteps | 16255        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.169        |\n",
      "|    critic_loss     | 0.000245     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 16154        |\n",
      "|    reward          | -0.008518847 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2111292.318645018\n",
      "Sharpe:  0.7054452603546062\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:786030.36952\n",
      "Sharpe:  -11.622723972540216\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2085991.6623449915\n",
      "Sharpe:  0.6948872475996047\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744552.6757499999\n",
      "Sharpe:  -8.730646436380919\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 92          |\n",
      "|    time_elapsed    | 208         |\n",
      "|    total_timesteps | 19190       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.185       |\n",
      "|    critic_loss     | 0.000303    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19089       |\n",
      "|    reward          | -0.07694765 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1963698.3020349885\n",
      "Sharpe:  0.689461050418843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2473691.3289300166\n",
      "Sharpe:  0.7964556568198814\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:772992.0868849998\n",
      "Sharpe:  -1.9581518933776116\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1845431.4780750081\n",
      "Sharpe:  0.6443525167719802\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 255          |\n",
      "|    total_timesteps | 23517        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.233        |\n",
      "|    critic_loss     | 0.000213     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 23416        |\n",
      "|    reward          | -0.008519079 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:744713.9915350003\n",
      "Sharpe:  -7.2570505699674595\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1778197.6533049815\n",
      "Sharpe:  0.630169130666867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2521476.900940012\n",
      "Sharpe:  0.8056911743488281\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1815486.9803672738\n",
      "Sharpe:  0.6184210974392959\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 91            |\n",
      "|    time_elapsed    | 301           |\n",
      "|    total_timesteps | 27721         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.294         |\n",
      "|    critic_loss     | 0.000763      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 27620         |\n",
      "|    reward          | -0.0070919897 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1677059.213898647\n",
      "Sharpe:  0.6870019877187976\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2291686.285294169\n",
      "Sharpe:  0.8426474154597692\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1766829.0864794368\n",
      "Sharpe:  0.6879653109833419\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2348918.1477114945\n",
      "Sharpe:  0.861257683062363\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 363          |\n",
      "|    total_timesteps | 33302        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.393        |\n",
      "|    critic_loss     | 0.000301     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 33201        |\n",
      "|    reward          | -0.007050751 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1824103.0226616405\n",
      "Sharpe:  0.7070685009562998\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763791.9750172498\n",
      "Sharpe:  0.6826002291416434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779459.3915813694\n",
      "Sharpe:  -11.352265463879357\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1585429.4893685088\n",
      "Sharpe:  0.6402591451075088\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 91          |\n",
      "|    time_elapsed    | 404         |\n",
      "|    total_timesteps | 37061       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.379       |\n",
      "|    critic_loss     | 0.000365    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 36960       |\n",
      "|    reward          | -0.00706608 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1671838.9919056108\n",
      "Sharpe:  0.6691728616408844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1394350.1851622546\n",
      "Sharpe:  0.6225919612050294\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1996685.2884871108\n",
      "Sharpe:  0.75009675526057\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1768954.941561364\n",
      "Sharpe:  0.6889730708345847\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 91           |\n",
      "|    time_elapsed    | 457          |\n",
      "|    total_timesteps | 41830        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.42         |\n",
      "|    critic_loss     | 0.000232     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 41729        |\n",
      "|    reward          | -0.007074589 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1662836.9831079692\n",
      "Sharpe:  0.6730860855461688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1508801.418306452\n",
      "Sharpe:  0.7010358196444946\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1447343.0172811567\n",
      "Sharpe:  0.553266711684347\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1684905.1425458805\n",
      "Sharpe:  0.6911369704010335\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 44            |\n",
      "|    fps             | 91            |\n",
      "|    time_elapsed    | 505           |\n",
      "|    total_timesteps | 46046         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.475         |\n",
      "|    critic_loss     | 0.000304      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 45945         |\n",
      "|    reward          | -0.0070372145 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1823072.6649062536\n",
      "Sharpe:  0.6819824936553539\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:784005.9708142463\n",
      "Sharpe:  -7.250650505655572\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1551353.1286150087\n",
      "Sharpe:  0.6347282100362853\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1770145.064601591\n",
      "Sharpe:  0.6873823260367404\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 48            |\n",
      "|    fps             | 90            |\n",
      "|    time_elapsed    | 548           |\n",
      "|    total_timesteps | 49808         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.5           |\n",
      "|    critic_loss     | 0.000529      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 49707         |\n",
      "|    reward          | -0.0070714387 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:981803.084497534\n",
      "Sharpe:  -2.589070940417695\n",
      "=================================\n",
      "hit end!\n",
      "td3 -0.018196915502465827 -0.023853838803024253 -2.589070940417695 0\n",
      "2023-12-01 00:00:00 2024-01-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_12_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1649404.2888708697\n",
      "Sharpe:  0.6839187872498541\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2183240.7708093286\n",
      "Sharpe:  0.827549021825734\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2151537.726329974\n",
      "Sharpe:  0.8411706664339936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2590666.5531089283\n",
      "Sharpe:  0.9632669598524877\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 56           |\n",
      "|    total_timesteps | 5003         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0148       |\n",
      "|    critic_loss     | 0.000251     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4902         |\n",
      "|    reward          | 0.0004258195 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2452256.172128155\n",
      "Sharpe:  1.035909729572098\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1701328.3151275564\n",
      "Sharpe:  0.8902129413598929\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2160080.5140510728\n",
      "Sharpe:  1.0963656470945715\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3330853.9615003457\n",
      "Sharpe:  1.234971415750478\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 88            |\n",
      "|    time_elapsed    | 117           |\n",
      "|    total_timesteps | 10399         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0376        |\n",
      "|    critic_loss     | 8.39e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 10298         |\n",
      "|    reward          | -0.0040015215 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2377160.8329797783\n",
      "Sharpe:  1.0194451771974844\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1435833.342112397\n",
      "Sharpe:  0.770876964301913\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2376711.373417166\n",
      "Sharpe:  1.0400062192959179\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2750047.4795600963\n",
      "Sharpe:  1.1276909427647244\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 176          |\n",
      "|    total_timesteps | 15637        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.073        |\n",
      "|    critic_loss     | 0.000189     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 15536        |\n",
      "|    reward          | -0.004002925 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1796697.8218263898\n",
      "Sharpe:  0.8376495177056241\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2363274.240458499\n",
      "Sharpe:  1.0331012637257995\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1792565.2912671012\n",
      "Sharpe:  0.9089874587244198\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1798167.152712362\n",
      "Sharpe:  0.9132160388266993\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 232          |\n",
      "|    total_timesteps | 20638        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.16         |\n",
      "|    critic_loss     | 0.000211     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 20537        |\n",
      "|    reward          | -0.004007319 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1426768.1494731433\n",
      "Sharpe:  0.7776484981609083\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2019209.6368684573\n",
      "Sharpe:  0.9538656526525886\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1852501.8174164398\n",
      "Sharpe:  0.8672286749452801\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2350519.887093273\n",
      "Sharpe:  0.9733832307623295\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 88            |\n",
      "|    time_elapsed    | 288           |\n",
      "|    total_timesteps | 25501         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.161         |\n",
      "|    critic_loss     | 0.000192      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 25400         |\n",
      "|    reward          | -0.0032681732 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3145304.8333423594\n",
      "Sharpe:  1.2909777397277056\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1669139.1516749565\n",
      "Sharpe:  0.853016819318458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1699023.4565293991\n",
      "Sharpe:  0.9098330045416277\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1699104.4379020182\n",
      "Sharpe:  0.9100392364996125\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 88            |\n",
      "|    time_elapsed    | 343           |\n",
      "|    total_timesteps | 30260         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.234         |\n",
      "|    critic_loss     | 0.000285      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 30159         |\n",
      "|    reward          | -0.0028122466 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2226884.6306968727\n",
      "Sharpe:  1.0682721154814936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1924805.7063033779\n",
      "Sharpe:  0.9462335414784352\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1514525.1858397943\n",
      "Sharpe:  0.9063592857449868\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2276217.1154457335\n",
      "Sharpe:  1.0134097747632151\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 399           |\n",
      "|    total_timesteps | 35114         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.282         |\n",
      "|    critic_loss     | 0.000314      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 35013         |\n",
      "|    reward          | -0.0033352152 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3276734.089352962\n",
      "Sharpe:  1.2036994549539966\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2663652.8281000266\n",
      "Sharpe:  1.0610814154589554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2379878.527649015\n",
      "Sharpe:  1.0099261543354654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787150.7286530025\n",
      "Sharpe:  1.0109983426141902\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 462           |\n",
      "|    total_timesteps | 40473         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.368         |\n",
      "|    critic_loss     | 0.000351      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 40372         |\n",
      "|    reward          | -0.0033344969 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1961601.1160379811\n",
      "Sharpe:  0.8684297186789126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1963344.509058011\n",
      "Sharpe:  0.8729375577792077\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792146.503364\n",
      "Sharpe:  -4.576214571377656\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1973979.969414992\n",
      "Sharpe:  0.8371281657612909\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 87            |\n",
      "|    time_elapsed    | 505           |\n",
      "|    total_timesteps | 44237         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.365         |\n",
      "|    critic_loss     | 0.000225      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 44136         |\n",
      "|    reward          | -0.0015907661 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1907986.5576059856\n",
      "Sharpe:  0.8260224100943547\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2286050.7867709887\n",
      "Sharpe:  0.9592690186889755\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2281993.741721998\n",
      "Sharpe:  0.9536363776641309\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768997.7594100003\n",
      "Sharpe:  -3.200931143040151\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 87          |\n",
      "|    time_elapsed    | 547         |\n",
      "|    total_timesteps | 48131       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.39        |\n",
      "|    critic_loss     | 0.000491    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 48030       |\n",
      "|    reward          | -0.04415345 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1741912.435739986\n",
      "Sharpe:  0.7920760707335782\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:768713.2814319999\n",
      "Sharpe:  -5.554418517053753\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1013922.2576260004\n",
      "Sharpe:  1.2997558319479623\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.0139222576260003 -0.03361342206087853 1.2997558319479625 0\n",
      "2024-01-01 00:00:00 2024-02-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_13_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2334608.102262916\n",
      "Sharpe:  0.8808533589003149\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2531180.9155492354\n",
      "Sharpe:  0.8920819379848423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1320479.407445552\n",
      "Sharpe:  0.4111889669171875\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1774137.9043643323\n",
      "Sharpe:  0.7540546379021815\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 93            |\n",
      "|    time_elapsed    | 55            |\n",
      "|    total_timesteps | 5144          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0608        |\n",
      "|    critic_loss     | 0.00011       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 5043          |\n",
      "|    reward          | 0.00046048503 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1831607.8163739168\n",
      "Sharpe:  0.7596486500182937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2020534.2900485056\n",
      "Sharpe:  0.8157042059358033\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2312160.330107023\n",
      "Sharpe:  0.9631854039801274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:792635.0076160567\n",
      "Sharpe:  -1.2029218229661691\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 92           |\n",
      "|    time_elapsed    | 95           |\n",
      "|    total_timesteps | 8896         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0493       |\n",
      "|    critic_loss     | 8.82e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 8795         |\n",
      "|    reward          | -0.055804048 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:777621.0573113007\n",
      "Sharpe:  -2.066151382575034\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1677578.6543617228\n",
      "Sharpe:  0.8230645578063968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3208133.3880062816\n",
      "Sharpe:  1.0847516255221403\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3229996.926012886\n",
      "Sharpe:  1.1322062116029934\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 92          |\n",
      "|    time_elapsed    | 140         |\n",
      "|    total_timesteps | 12965       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0364      |\n",
      "|    critic_loss     | 9.96e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 12864       |\n",
      "|    reward          | 0.001100114 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3569399.7153976546\n",
      "Sharpe:  1.4035772173368422\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2502430.4772277595\n",
      "Sharpe:  1.1504369418715807\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4111410.7928792113\n",
      "Sharpe:  1.3959813771536551\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2332904.553886231\n",
      "Sharpe:  1.4371843270109377\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 16             |\n",
      "|    fps             | 92             |\n",
      "|    time_elapsed    | 192            |\n",
      "|    total_timesteps | 17823          |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 0.0273         |\n",
      "|    critic_loss     | 8.39e-05       |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 17722          |\n",
      "|    reward          | -0.00047662307 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2837447.4748797663\n",
      "Sharpe:  1.4233818299334104\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6448550.666450426\n",
      "Sharpe:  1.850030719317383\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2649625.7815169943\n",
      "Sharpe:  1.4912604615316196\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2760373.1779303723\n",
      "Sharpe:  1.1265420411218574\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 91            |\n",
      "|    time_elapsed    | 252           |\n",
      "|    total_timesteps | 23052         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.0247        |\n",
      "|    critic_loss     | 5.97e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 22951         |\n",
      "|    reward          | -0.0011655946 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6471538.656725511\n",
      "Sharpe:  1.7939129667846285\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8017539.157822561\n",
      "Sharpe:  1.835817467553136\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4211193.680329006\n",
      "Sharpe:  1.587536507323815\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4463248.471635599\n",
      "Sharpe:  1.8567900588771369\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 312          |\n",
      "|    total_timesteps | 28204        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0163       |\n",
      "|    critic_loss     | 0.000185     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 28103        |\n",
      "|    reward          | 0.0024072705 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9562176.251975104\n",
      "Sharpe:  1.8237359403687488\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5493660.826759814\n",
      "Sharpe:  1.7876782435201157\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4483589.101901052\n",
      "Sharpe:  2.0763054844017415\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:9682312.997639019\n",
      "Sharpe:  1.9932625904430468\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 90           |\n",
      "|    time_elapsed    | 368          |\n",
      "|    total_timesteps | 33297        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0098       |\n",
      "|    critic_loss     | 7.33e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 33196        |\n",
      "|    reward          | -9.87381e-05 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5497845.963507011\n",
      "Sharpe:  2.239709612653043\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8607231.788679585\n",
      "Sharpe:  2.0471006217558982\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4607022.749139294\n",
      "Sharpe:  2.0913393502018396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13381645.27556054\n",
      "Sharpe:  2.182224969726049\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 90            |\n",
      "|    time_elapsed    | 418           |\n",
      "|    total_timesteps | 37704         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.00682      |\n",
      "|    critic_loss     | 0.000139      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 37603         |\n",
      "|    reward          | 1.4544761e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15195267.738200342\n",
      "Sharpe:  2.32682513052674\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:15410605.074933615\n",
      "Sharpe:  2.348574065203687\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:24431663.499409776\n",
      "Sharpe:  2.3690321138672616\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18908099.795721397\n",
      "Sharpe:  2.2526342021994368\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 89            |\n",
      "|    time_elapsed    | 483           |\n",
      "|    total_timesteps | 43463         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.00163       |\n",
      "|    critic_loss     | 8.21e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 43362         |\n",
      "|    reward          | 4.0246878e-06 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8607364.037651187\n",
      "Sharpe:  2.399647657688711\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:12959298.66505044\n",
      "Sharpe:  2.3395953445599447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:18826552.12129184\n",
      "Sharpe:  2.311840272557735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6943352.719221878\n",
      "Sharpe:  2.490881294668696\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 89            |\n",
      "|    time_elapsed    | 536           |\n",
      "|    total_timesteps | 47932         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0284       |\n",
      "|    critic_loss     | 0.0001        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 47831         |\n",
      "|    reward          | -3.280744e-05 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:14396614.033565927\n",
      "Sharpe:  2.5244781844195194\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1005074.1635140001\n",
      "Sharpe:  2.240755218416704\n",
      "=================================\n",
      "hit end!\n",
      "td3 0.005074163513999919 -0.005140228149095767 2.240755218416704 0\n",
      "2024-02-01 00:00:00 2024-03-01 00:00:00\n",
      "td3\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_14_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2222269.845666938\n",
      "Sharpe:  0.9851444854122938\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794824.2472055347\n",
      "Sharpe:  -5.527437936025392\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1756088.2066552213\n",
      "Sharpe:  0.6979771787808554\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2766614.825092627\n",
      "Sharpe:  1.0635177606711863\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 84           |\n",
      "|    time_elapsed    | 52           |\n",
      "|    total_timesteps | 4424         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0511      |\n",
      "|    critic_loss     | 0.000174     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 4323         |\n",
      "|    reward          | 0.0024522818 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1619054.2246902063\n",
      "Sharpe:  0.7162910330427218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1765682.340396706\n",
      "Sharpe:  0.8078260953886448\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1460301.1879566915\n",
      "Sharpe:  0.7239739431959631\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1818071.8019983475\n",
      "Sharpe:  0.8324764056220085\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 85          |\n",
      "|    time_elapsed    | 100         |\n",
      "|    total_timesteps | 8624        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0445     |\n",
      "|    critic_loss     | 7.53e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 8523        |\n",
      "|    reward          | 0.002624841 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1423729.6984325973\n",
      "Sharpe:  0.6419969012114678\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1884803.6948576733\n",
      "Sharpe:  0.8130517984948754\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2331790.482472675\n",
      "Sharpe:  0.9039685327530942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:779692.5524243154\n",
      "Sharpe:  -5.2311727786577435\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 12           |\n",
      "|    fps             | 85           |\n",
      "|    time_elapsed    | 143          |\n",
      "|    total_timesteps | 12283        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0218      |\n",
      "|    critic_loss     | 7.57e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 12182        |\n",
      "|    reward          | -0.060437337 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1792283.8220526674\n",
      "Sharpe:  1.2248111001044448\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1760226.8066449398\n",
      "Sharpe:  1.210164298244238\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2094323.8871193929\n",
      "Sharpe:  1.0424771158395092\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1635910.4760753901\n",
      "Sharpe:  1.0189057312716632\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 85           |\n",
      "|    time_elapsed    | 187          |\n",
      "|    total_timesteps | 16066        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.00311     |\n",
      "|    critic_loss     | 0.000137     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 15965        |\n",
      "|    reward          | 0.0026921115 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2051616.1615282719\n",
      "Sharpe:  1.1231728538371895\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3298146.079107039\n",
      "Sharpe:  1.4753798551689998\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3283285.484313021\n",
      "Sharpe:  1.3303493351660942\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1924045.5274463578\n",
      "Sharpe:  0.9671816218803632\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 85          |\n",
      "|    time_elapsed    | 245         |\n",
      "|    total_timesteps | 21136       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.039       |\n",
      "|    critic_loss     | 6.85e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21035       |\n",
      "|    reward          | 0.002718251 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2284844.3483354487\n",
      "Sharpe:  1.1379823932198931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:761622.2847615754\n",
      "Sharpe:  -9.199662820994167\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1802627.454835564\n",
      "Sharpe:  1.1723066464203242\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2328590.545654657\n",
      "Sharpe:  1.1852524687211394\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 86           |\n",
      "|    time_elapsed    | 284          |\n",
      "|    total_timesteps | 24553        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0423       |\n",
      "|    critic_loss     | 7.83e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 24452        |\n",
      "|    reward          | 0.0026823496 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:789750.8497517667\n",
      "Sharpe:  -4.746398439232537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3100933.724772006\n",
      "Sharpe:  1.291878113561663\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2139330.656345282\n",
      "Sharpe:  1.3630598530184097\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2463246.108952291\n",
      "Sharpe:  1.2920944982018898\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 86           |\n",
      "|    time_elapsed    | 326          |\n",
      "|    total_timesteps | 28300        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.071        |\n",
      "|    critic_loss     | 6.62e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 28199        |\n",
      "|    reward          | 0.0010689183 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3699679.6573216715\n",
      "Sharpe:  1.536786252801369\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1908487.5152037814\n",
      "Sharpe:  1.3788973457746792\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1962107.650768178\n",
      "Sharpe:  1.3626581466529968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3247043.8083813535\n",
      "Sharpe:  1.3270875509437747\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 87           |\n",
      "|    time_elapsed    | 381          |\n",
      "|    total_timesteps | 33282        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0827       |\n",
      "|    critic_loss     | 6.71e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 33181        |\n",
      "|    reward          | 0.0008769046 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3446969.6166891647\n",
      "Sharpe:  1.4285012072013072\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2635657.096463534\n",
      "Sharpe:  1.360164825666533\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3563779.8522453425\n",
      "Sharpe:  1.508288330970441\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1907003.8495081973\n",
      "Sharpe:  1.1869316688463731\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 87           |\n",
      "|    time_elapsed    | 440          |\n",
      "|    total_timesteps | 38716        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0835       |\n",
      "|    critic_loss     | 8.05e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 38615        |\n",
      "|    reward          | 0.0010906463 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4042848.192009963\n",
      "Sharpe:  1.6195614379267944\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1905677.7824601003\n",
      "Sharpe:  1.1940095750363846\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1925891.279573823\n",
      "Sharpe:  1.17789818277715\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1980185.203265586\n",
      "Sharpe:  1.450603341399025\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 88            |\n",
      "|    time_elapsed    | 489           |\n",
      "|    total_timesteps | 43043         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 0.106         |\n",
      "|    critic_loss     | 5.97e-05      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 42942         |\n",
      "|    reward          | 0.00087264634 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2639521.4812540864\n",
      "Sharpe:  1.3556464071237173\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4065204.7207347048\n",
      "Sharpe:  1.6600435784116676\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3119062.12648233\n",
      "Sharpe:  1.6418817932216982\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4635251.790547666\n",
      "Sharpe:  1.695955571664511\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 88           |\n",
      "|    time_elapsed    | 550          |\n",
      "|    total_timesteps | 48578        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.102        |\n",
      "|    critic_loss     | 6.38e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 48477        |\n",
      "|    reward          | 0.0008794722 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2843664.9080751683\n",
      "Sharpe:  1.5156142102572854\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:984895.9334595618\n",
      "Sharpe:  -3.1549402885003657\n",
      "=================================\n",
      "hit end!\n",
      "td3 -0.015104066540438388 -0.03016980829433364 -3.1549402885003657 0\n"
     ]
    }
   ],
   "source": [
    "algs = ['a2c','ppo','ddpg','td3']\n",
    "\n",
    "date_start = datetime.datetime(2023, 6, 1)\n",
    "\n",
    "res_df = pd.DataFrame(columns=[\"alg\", \"month\", \"res\", \"dd\", \"sharp\", \"day_ret\", \"actions\", \"total_commission\"])\n",
    "for alg in algs:\n",
    "  model = None\n",
    "  for i in range(9):\n",
    "    date0 = datetime.datetime(2016, 12, 1) + relativedelta(months = i)\n",
    "    date1 = date_start + relativedelta(months = i)\n",
    "    date2 = date_start + relativedelta(months = i + 1)\n",
    "\n",
    "    train = data_split(df, date0, date1) #'2016-05-10', date1)\n",
    "    trade = data_split(df, date1, date2)\n",
    "\n",
    "    print(date1, date2)\n",
    "    print(alg)\n",
    "    log_name = alg + '_' + str(6+i)\n",
    "    model, total_comm, df_daily_return, df_actions = train_trade(alg, train, trade, None, log_name=log_name, \n",
    "                                                                 size=[192,128], trained_model=None, steps=50_000)\n",
    "    res11 = get_result(df_daily_return)\n",
    "\n",
    "    print(alg, res11['Cumulative returns'], res11['Max drawdown'], res11['Sharpe ratio'], total_comm)\n",
    "    res_df.loc[-1] = [alg, str(i), res11['Cumulative returns'], res11['Max drawdown'], res11['Sharpe ratio'], df_daily_return, df_actions, total_comm]\n",
    "    res_df.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('50_9month_res_commiss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36 entries, 35 to 0\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   alg               36 non-null     object \n",
      " 1   month             36 non-null     object \n",
      " 2   res               36 non-null     float64\n",
      " 3   dd                36 non-null     float64\n",
      " 4   sharp             36 non-null     float64\n",
      " 5   day_ret           36 non-null     object \n",
      " 6   actions           36 non-null     object \n",
      " 7   total_commission  36 non-null     int64  \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "res_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['month'] = pd.to_numeric(res_df['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, какую доходность за эти же промежутки времени имели индекс и фонд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df2 = loader.LoadData()\n",
    "imoex = df2[df2['tic'] == 'IMOEX']\n",
    "imoex.index = imoex['date']\n",
    "grouped = imoex.groupby(pd.Grouper(freq='ME')).first()[['date','close']]\n",
    "grouped.index = range(len(grouped))\n",
    "grouped['change'] = grouped['close'].pct_change().shift(-1)\n",
    "\n",
    "mm = df2[df2['tic'] == 'MM']\n",
    "mm.index = mm['date']\n",
    "grouped2 = mm.groupby(pd.Grouper(freq='ME')).first()[['date','close']]\n",
    "grouped2.index = range(len(grouped2))\n",
    "grouped['change_MM'] = grouped2['close'].pct_change().shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = imoex.groupby(pd.Grouper(freq='ME'))\n",
    "max_dd = []\n",
    "for name, group in gr:\n",
    "    Roll_Max = group['close'].rolling(22, min_periods=1).max()\n",
    "    Daily_Drawdown = group['close']/Roll_Max - 1.0\n",
    "    Max_Daily_Drawdown = Daily_Drawdown.rolling(22, min_periods=1).min()    \n",
    "    max_dd.append(Max_Daily_Drawdown.min())\n",
    "grouped['max_dd'] = max_dd\n",
    "grouped['max_dd_MM'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_period = grouped.tail(13).head(9) #c 3.2023 и дальше\n",
    "tested_period.index = range(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "      <th>change_MM</th>\n",
       "      <th>max_dd</th>\n",
       "      <th>max_dd_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2721.73</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>-0.022052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>2793.93</td>\n",
       "      <td>0.107272</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>-0.012537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>3093.64</td>\n",
       "      <td>0.044514</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>3231.35</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>3132.33</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>-0.020892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>3206.52</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>-0.025392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>3142.29</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>-0.042469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>3130.23</td>\n",
       "      <td>0.031838</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>-0.008630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>3229.89</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>-0.038623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    close    change  change_MM    max_dd  max_dd_MM\n",
       "0 2023-06-01  2721.73  0.026527   0.004245 -0.022052          0\n",
       "1 2023-07-03  2793.93  0.107272   0.004025 -0.012537          0\n",
       "2 2023-08-01  3093.64  0.044514   0.005728 -0.033608          0\n",
       "3 2023-09-01  3231.35 -0.030644   0.006785 -0.076400          0\n",
       "4 2023-10-02  3132.33  0.023685   0.006930 -0.020892          0\n",
       "5 2023-11-01  3206.52 -0.020031   0.007743 -0.025392          0\n",
       "6 2023-12-01  3142.29 -0.003838   0.008776 -0.042469          0\n",
       "7 2024-01-03  3130.23  0.031838   0.007853 -0.008630          0\n",
       "8 2024-02-01  3229.89  0.011384   0.007792 -0.038623          0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним доходности индекса, фонда и каждого из алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns = {'imoex' : 0}\n",
    "all_returns['mm'] = tested_period['change_MM'].values - tested_period['change'].values\n",
    "for alg in algs:\n",
    "    all_returns[alg] = res_df[res_df['alg'] == alg].sort_values(by=['month'])['res'].values - tested_period['change'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns_df = pd.DataFrame(all_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bplot = ax.boxplot(all_returns_df.values)  # will be used to label x-ticks\n",
    "ax.set_xticklabels(all_returns_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](returns5.png \"Title2\")\n",
    "\n",
    "Видно, что доходности по фонду и алгоритмам в среднем ниже доходности по индексу. Более-менее сопостовима с индексом доходность TD3 (и всё стабильно - без выбросов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drawdown = {'imoex' : tested_period['max_dd']}\n",
    "all_drawdown['mm'] = 0\n",
    "for alg in algs:\n",
    "    all_drawdown[alg] = res_df[res_df['alg'] == alg].sort_values(by=['month'])['dd'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drawdown_df = pd.DataFrame(all_drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bplot = ax.boxplot(all_drawdown_df.values)  # will be used to label x-ticks\n",
    "ax.set_xticklabels(all_drawdown_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим максимальные просадки на месяцах, на которых проводили тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](max_dd5.png \"Title2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доходность за 9 месяцев и средняя просадка по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2, -0.031)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.prod(1 + tested_period['change'].to_numpy()), 2), np.round(np.average(tested_period['max_dd'].to_numpy()), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доходность за 9 месяцев и средняя просадка по фонду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.06, 0.0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.prod(1 + tested_period['change_MM'].to_numpy()), 2), np.round(np.average(tested_period['max_dd_MM'].to_numpy()), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2c 1.11 -0.023 1.84\n",
      "ddpg 1.09 -0.026 1.15\n",
      "ppo 1.07 -0.02 1.04\n",
      "td3 1.21 -0.024 2.45\n"
     ]
    }
   ],
   "source": [
    "for name, group in res_df.groupby(by=['alg']):\n",
    "    print(name[0], np.round(np.prod(group['res']+1),2), np.round(np.average(group['dd']), 3), np.round(np.average(group['sharp']), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При примерно той же доходности для TD3 видим, что средняя просадка меньше на 0.5%. Выбираю для дальнейшей работы TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>month</th>\n",
       "      <th>res</th>\n",
       "      <th>dd</th>\n",
       "      <th>sharp</th>\n",
       "      <th>day_ret</th>\n",
       "      <th>actions</th>\n",
       "      <th>total_commission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>td3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050837</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>5.587266</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>td3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101314</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>11.326173</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-07-03     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>td3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.041977</td>\n",
       "      <td>-0.015613</td>\n",
       "      <td>4.696443</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-08-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>td3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.053834</td>\n",
       "      <td>-1.407984</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-09-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>td3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032729</td>\n",
       "      <td>-0.015848</td>\n",
       "      <td>4.047729</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-10-02     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>td3</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.018197</td>\n",
       "      <td>-0.023854</td>\n",
       "      <td>-2.589071</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-11-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>td3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>-0.033613</td>\n",
       "      <td>1.299756</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-12-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>td3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>-0.005140</td>\n",
       "      <td>2.240755</td>\n",
       "      <td>date  daily_return\n",
       "0  2024-01-03     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>td3</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.015104</td>\n",
       "      <td>-0.030170</td>\n",
       "      <td>-3.154940</td>\n",
       "      <td>date  daily_return\n",
       "0  2024-02-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alg  month       res        dd      sharp  \\\n",
       "8  td3      0  0.050837 -0.018555   5.587266   \n",
       "7  td3      1  0.101314 -0.016303  11.326173   \n",
       "6  td3      2  0.041977 -0.015613   4.696443   \n",
       "5  td3      3 -0.013364 -0.053834  -1.407984   \n",
       "4  td3      4  0.032729 -0.015848   4.047729   \n",
       "3  td3      5 -0.018197 -0.023854  -2.589071   \n",
       "2  td3      6  0.013922 -0.033613   1.299756   \n",
       "1  td3      7  0.005074 -0.005140   2.240755   \n",
       "0  td3      8 -0.015104 -0.030170  -3.154940   \n",
       "\n",
       "                                             day_ret  \\\n",
       "8           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "7           date  daily_return\n",
       "0  2023-07-03     ...   \n",
       "6           date  daily_return\n",
       "0  2023-08-01     ...   \n",
       "5           date  daily_return\n",
       "0  2023-09-01     ...   \n",
       "4           date  daily_return\n",
       "0  2023-10-02     ...   \n",
       "3           date  daily_return\n",
       "0  2023-11-01     ...   \n",
       "2           date  daily_return\n",
       "0  2023-12-01     ...   \n",
       "1           date  daily_return\n",
       "0  2024-01-03     ...   \n",
       "0           date  daily_return\n",
       "0  2024-02-01     ...   \n",
       "\n",
       "                                             actions  total_commission  \n",
       "8           date                                 ...                 0  \n",
       "7           date                                 ...                 0  \n",
       "6           date                                 ...                 0  \n",
       "5           date                                 ...                 0  \n",
       "4           date                                 ...                 0  \n",
       "3           date                                 ...                 0  \n",
       "2           date                                 ...                 0  \n",
       "1           date                                 ...                 0  \n",
       "0           date                                 ...                 0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[res_df['alg'] == 'td3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n",
      "100%|██████████| 1974/1974 [00:20<00:00, 97.26it/s] \n"
     ]
    }
   ],
   "source": [
    "loader2 = DataLoader()\n",
    "df2 = loader2.LoadData()\n",
    "\n",
    "df2.index = range(len(df2))\n",
    "#df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "#df2 = df2.drop(df2[df2['tic'] == 'BZ'].index)\n",
    "#df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "df2 = df2.drop(df2[df2['tic'] == 'USD'].index)\n",
    "\n",
    "df2 = df2.astype({'volume' : 'double'})\n",
    "\n",
    "fa2 = FeaturesAdder(22)\n",
    "df2 = fa2.Process(df2)\n",
    "df2.index = df2.date.factorize()[0]\n",
    "\n",
    "i = 0\n",
    "date02 = datetime.datetime(2016, 12, 1) + relativedelta(months = i)\n",
    "date12 = date_start + relativedelta(months = i)\n",
    "date22 = date_start + relativedelta(months = i + 1)\n",
    "\n",
    "train2 = data_split(df2, date02, date12) #'2016-05-10', date1)\n",
    "trade2 = data_split(df2, date12, date22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем поварьировать параметры. Будем осуществлять подбор на месяце, который показал худший результат по просадке (09.23 - month=3)\n",
    "\n",
    "Чтобы в случайный процесс Орнштейна-Уленбека (в контексте FinRL) можно было передать сигму - немного подправил код библиотеки. Зашитый 0.1 исправил на значение параметра\n",
    "\n",
    "![alt text](action_noise0.JPG \"Title2\")\n",
    "![alt text](action_noise20.JPG \"Title2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-28 14:55:59,077] A new study created in memory with name: no-name-b11c89c1-c1da-4adf-a639-3dd2998eab92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_policy_noise': 0.5, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5])}\n",
      "Using cuda device\n",
      "Logging to logs\\objective_noise_normal0.52_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1148657.143302988\n",
      "Sharpe:  0.2739799154024772\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1539434.9767265355\n",
      "Sharpe:  0.5431110923985152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:797105.1235808517\n",
      "Sharpe:  -0.25327214324873915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:781437.2479220722\n",
      "Sharpe:  -0.27041547355497797\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 90          |\n",
      "|    time_elapsed    | 43          |\n",
      "|    total_timesteps | 3930        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0877     |\n",
      "|    critic_loss     | 0.000192    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3829        |\n",
      "|    reward          | -0.05744761 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1632533.6259408067\n",
      "Sharpe:  0.5469170019051651\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1515137.204682235\n",
      "Sharpe:  0.6144043725904741\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:790159.6570644934\n",
      "Sharpe:  -6.937803851195252\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1362436.7597819355\n",
      "Sharpe:  0.4858928537518499\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 84           |\n",
      "|    time_elapsed    | 92           |\n",
      "|    total_timesteps | 7793         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0644      |\n",
      "|    critic_loss     | 8.8e-05      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 7692         |\n",
      "|    reward          | 0.0032149458 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794371.6049196983\n",
      "Sharpe:  -2.607836628807549\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1317693.8698884507\n",
      "Sharpe:  0.4520750163835295\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1342015.8456365515\n",
      "Sharpe:  0.4427278541685212\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:767797.4481187867\n",
      "Sharpe:  -0.19938651900789325\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 83          |\n",
      "|    time_elapsed    | 130         |\n",
      "|    total_timesteps | 10866       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0587     |\n",
      "|    critic_loss     | 0.000156    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10765       |\n",
      "|    reward          | -0.07039112 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1320642.5350321773\n",
      "Sharpe:  0.3740299260832002\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:794429.2190057777\n",
      "Sharpe:  -0.38466653001776463\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1177200.5383174221\n",
      "Sharpe:  0.25604526702960684\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1553631.1291055342\n",
      "Sharpe:  0.5151797898564255\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 191          |\n",
      "|    total_timesteps | 15640        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0333      |\n",
      "|    critic_loss     | 8.73e-05     |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 15539        |\n",
      "|    reward          | 0.0044306684 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-28 14:59:21,171] Trial 0 failed with parameters: {'sigma': 0.5, 'noise': 'normal'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_13540\\1517043441.py\", line 15, in objective_noise\n",
      "    model, commission, df_daily_return, df_actions = train_trade('td3', train2, trade2, optuna_params, log_name, [192,128])\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_13540\\2215292903.py\", line 29, in train_trade\n",
      "    trained_model = agent.train_model(model = model,\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py\", line 117, in train_model\n",
      "    model = model.learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 222, in learn\n",
      "    return super().learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 328, in learn\n",
      "    rollout = self.collect_rollouts(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 557, in collect_rollouts\n",
      "    actions, buffer_actions = self._sample_action(learning_starts, action_noise, env.num_envs)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 390, in _sample_action\n",
      "    unscaled_action, _ = self.predict(self._last_obs, deterministic=False)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\", line 556, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 365, in predict\n",
      "    obs_tensor, vectorized_env = self.obs_to_tensor(observation)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 276, in obs_to_tensor\n",
      "    obs_tensor = obs_as_tensor(observation, self.device)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\utils.py\", line 485, in obs_as_tensor\n",
      "    return th.as_tensor(obs, device=device)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-28 14:59:21,176] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sum_reward, max_dd\n\u001b[0;32m     29\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 30\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[78], line 15\u001b[0m, in \u001b[0;36mobjective_noise\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     13\u001b[0m optuna_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_policy_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m: sigma, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m: noise}\n\u001b[0;32m     14\u001b[0m log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m noise \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(sigma) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m---> 15\u001b[0m model, commission, df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtd3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrade2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptuna_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m result \u001b[38;5;241m=\u001b[39m get_result(df_daily_return)\n\u001b[0;32m     18\u001b[0m reward \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[42], line 29\u001b[0m, in \u001b[0;36mtrain_trade\u001b[1;34m(alg, train, trade, optuna_params, log_name, size, trained_model, steps)\u001b[0m\n\u001b[0;32m     25\u001b[0m     model \u001b[38;5;241m=\u001b[39m trained_model\n\u001b[0;32m     26\u001b[0m     timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25_000\u001b[39m\n\u001b[1;32m---> 29\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m e_trade_gym2 \u001b[38;5;241m=\u001b[39m PortfolioEnv(df \u001b[38;5;241m=\u001b[39m trade, reset_to_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m     35\u001b[0m df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m DRLAgent\u001b[38;5;241m.\u001b[39mDRL_prediction(model\u001b[38;5;241m=\u001b[39mtrained_model,\n\u001b[0;32m     36\u001b[0m                     environment \u001b[38;5;241m=\u001b[39m e_trade_gym2)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    115\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    116\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:557\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mreset_noise(env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# Select action randomly or according to policy\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m    560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:390\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._sample_action\u001b[1;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# Note: when using continuous actions,\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself._last_obs was not set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 390\u001b[0m     unscaled_action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py:276\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_tensor, vectorized_env\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\utils.py:485\u001b[0m, in \u001b[0;36mobs_as_tensor\u001b[1;34m(obs, device)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03mMoves the observation to the given device.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m:return: PyTorch tensor of the observation on a desired device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th\u001b[38;5;241m.\u001b[39mas_tensor(_obs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective_noise(trial):\n",
    "    #size = trial.suggest_categorical('size', [[128, 64], [192,128], [256, 128]])\n",
    "\n",
    "    sigma = trial.suggest_categorical('sigma',[0.1, 0.3, 0.5, 0.7, 1])\n",
    "    noise = trial.suggest_categorical(\"noise\", [\"ornstein_uhlenbeck\", \"normal\"])\n",
    "    #gamma = trial.suggest_categorical('gamma',[0.99, 0.95])\n",
    "\n",
    "    #learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-3, log=True)\n",
    "\n",
    "    sum_reward = 0\n",
    "    sum_maxdd  = 0\n",
    "    #optuna_params = {\"learning_rate\": learning_rate, \"target_policy_noise\": sigma, \"action_noise\": noise, \"gamma\": gamma}\n",
    "    optuna_params = {\"target_policy_noise\": sigma, \"action_noise\": noise}\n",
    "    log_name = \"objective_noise\" + '_' + noise + str(sigma) + '2_' + str(i)\n",
    "    model, commission, df_daily_return, df_actions = train_trade('td3', train2, trade2, optuna_params, log_name, [192,128])\n",
    "    \n",
    "    result = get_result(df_daily_return)\n",
    "    reward = result['Cumulative returns']\n",
    "    max_dd = result['Max drawdown']\n",
    "    sharp  = result['Sharpe ratio']\n",
    "\n",
    "    print(\"Rew, DD, Sh, commiss\", reward, max_dd, sharp, commission)\n",
    "    sum_reward += reward\n",
    "    sum_maxdd += max_dd\n",
    "\n",
    "    print(\"Total\", sum_reward, sum_maxdd, sharp)\n",
    "    return sum_reward, max_dd\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
    "study.optimize(objective_noise, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>month</th>\n",
       "      <th>res</th>\n",
       "      <th>dd</th>\n",
       "      <th>sharp</th>\n",
       "      <th>day_ret</th>\n",
       "      <th>actions</th>\n",
       "      <th>total_commission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>a2c</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>-0.017458</td>\n",
       "      <td>3.097764</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027995</td>\n",
       "      <td>-0.012072</td>\n",
       "      <td>5.165934</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ddpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>4.412521</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>td3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050837</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>5.587266</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alg  month       res        dd     sharp  \\\n",
       "35   a2c      0  0.022154 -0.017458  3.097764   \n",
       "26   ppo      0  0.027995 -0.012072  5.165934   \n",
       "17  ddpg      0  0.029573 -0.012886  4.412521   \n",
       "8    td3      0  0.050837 -0.018555  5.587266   \n",
       "\n",
       "                                              day_ret  \\\n",
       "35           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "26           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "17           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "8            date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "\n",
       "                                              actions  total_commission  \n",
       "35           date                                 ...                 0  \n",
       "26           date                                 ...                 0  \n",
       "17           date                                 ...                 0  \n",
       "8            date                                 ...                 0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[res_df['month'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подборе параметров лучший результат показала итерация с параметрами\n",
    "lr=0.00024 sigma=0.5 (target_policy_noise) size=192,128 gamma=0.95\n",
    "\n",
    "Результат R=0.1% (положительный!), maxDD=-4.47% (при просадке индекса на -7.1% и лучше чем по всем алгоритмам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 00:00:00 2023-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "res = dict()\n",
    "ret = dict()\n",
    "act = dict()\n",
    "\n",
    "date_start = datetime.datetime(2023, 6, 1)\n",
    "date0 = datetime.datetime(2016, 12, 1) #date_start + relativedelta(months = -12 * i)\n",
    "date1 = date_start + relativedelta(months = 0)\n",
    "date2 = date_start + relativedelta(months = 0 + 1)\n",
    "\n",
    "print(date1, date2)\n",
    "train = data_split(df, date0, date1) #'2016-05-10', date1)\n",
    "trade = data_split(df, date1, date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import StopTrainingOnNoModelImprovement\n",
    "stop_train = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0006, 'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]), 'target_policy_noise': 0.5, 'gamma': 0.95}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_final_td3_256x128_6_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1366100.04215632\n",
      "Sharpe:  0.47435886270614985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3071316.3037507255\n",
      "Sharpe:  1.134251402974538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:798175.0345518225\n",
      "Sharpe:  -3.577449779779459\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2977409.0279262145\n",
      "Sharpe:  1.180278963723153\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 50           |\n",
      "|    total_timesteps | 4123         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.00843     |\n",
      "|    critic_loss     | 0.000192     |\n",
      "|    learning_rate   | 0.0006       |\n",
      "|    n_updates       | 4022         |\n",
      "|    reward          | 0.0021446028 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2172083.5761398096\n",
      "Sharpe:  0.8910268795162445\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3103816.308803918\n",
      "Sharpe:  1.0315051838193456\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1755733.053432948\n",
      "Sharpe:  0.8340001182084527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1862322.9956627018\n",
      "Sharpe:  0.9220130644432567\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 113          |\n",
      "|    total_timesteps | 9232         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0165      |\n",
      "|    critic_loss     | 0.000106     |\n",
      "|    learning_rate   | 0.0006       |\n",
      "|    n_updates       | 9131         |\n",
      "|    reward          | 0.0028530583 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1632277.8912311196\n",
      "Sharpe:  0.7250282370274865\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1712712.680184873\n",
      "Sharpe:  0.7625859090535748\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2572073.2459008214\n",
      "Sharpe:  0.9589964415964654\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2676761.9029083312\n",
      "Sharpe:  0.9977536719570334\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 80            |\n",
      "|    time_elapsed    | 180           |\n",
      "|    total_timesteps | 14524         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.0211       |\n",
      "|    critic_loss     | 6.97e-05      |\n",
      "|    learning_rate   | 0.0006        |\n",
      "|    n_updates       | 14423         |\n",
      "|    reward          | 0.00088411075 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1634144.842954439\n",
      "Sharpe:  0.7171221086012629\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1440995.1306557204\n",
      "Sharpe:  0.6304937686122954\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3072969.1194548076\n",
      "Sharpe:  1.251603520372571\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2569558.733335159\n",
      "Sharpe:  1.016181920780946\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 16           |\n",
      "|    fps             | 80           |\n",
      "|    time_elapsed    | 243          |\n",
      "|    total_timesteps | 19677        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0131      |\n",
      "|    critic_loss     | 8.81e-05     |\n",
      "|    learning_rate   | 0.0006       |\n",
      "|    n_updates       | 19576        |\n",
      "|    reward          | 0.0044537964 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3789321.8231740748\n",
      "Sharpe:  1.3398529632775409\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1459537.6312657592\n",
      "Sharpe:  0.6721121946069848\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2342725.3819553223\n",
      "Sharpe:  1.0442445854423634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1912002.698229563\n",
      "Sharpe:  1.1277553288907836\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 299         |\n",
      "|    total_timesteps | 24315       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0128     |\n",
      "|    critic_loss     | 3.57e-05    |\n",
      "|    learning_rate   | 0.0006      |\n",
      "|    n_updates       | 24214       |\n",
      "|    reward          | 0.006319555 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3130067.8764399695\n",
      "Sharpe:  1.1727979447682797\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1952464.2049246423\n",
      "Sharpe:  1.0344919383223685\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3773707.2275681077\n",
      "Sharpe:  1.3625775322548135\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3547638.2560838107\n",
      "Sharpe:  1.3277927769416757\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 362          |\n",
      "|    total_timesteps | 29541        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.00712     |\n",
      "|    critic_loss     | 2.66e-05     |\n",
      "|    learning_rate   | 0.0006       |\n",
      "|    n_updates       | 29440        |\n",
      "|    reward          | 0.0049324147 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3735489.929029431\n",
      "Sharpe:  1.574289058373482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2191209.9431936373\n",
      "Sharpe:  0.6896047694619784\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1904069.5125396594\n",
      "Sharpe:  0.8472861846810696\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2146676.996153104\n",
      "Sharpe:  0.9053615013841788\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 79         |\n",
      "|    time_elapsed    | 434        |\n",
      "|    total_timesteps | 34314      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.0119    |\n",
      "|    critic_loss     | 3.19e-05   |\n",
      "|    learning_rate   | 0.0006     |\n",
      "|    n_updates       | 34213      |\n",
      "|    reward          | 0.00620151 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3624667.907962219\n",
      "Sharpe:  1.1458832089699689\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6082409.094960206\n",
      "Sharpe:  1.4259876464786314\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4582260.831169312\n",
      "Sharpe:  1.2038022237046058\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:7674802.860768358\n",
      "Sharpe:  1.3680740853900337\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 78           |\n",
      "|    time_elapsed    | 514          |\n",
      "|    total_timesteps | 40451        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0127      |\n",
      "|    critic_loss     | 3.75e-05     |\n",
      "|    learning_rate   | 0.0006       |\n",
      "|    n_updates       | 40350        |\n",
      "|    reward          | 0.0064732367 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4753790.606984619\n",
      "Sharpe:  1.4368974362547635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13542218.397168735\n",
      "Sharpe:  1.5433444577975914\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5816473.609307942\n",
      "Sharpe:  1.3894135263094274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3939461.985414349\n",
      "Sharpe:  1.4025580193780163\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 78          |\n",
      "|    time_elapsed    | 577         |\n",
      "|    total_timesteps | 45641       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0206     |\n",
      "|    critic_loss     | 4.36e-05    |\n",
      "|    learning_rate   | 0.0006      |\n",
      "|    n_updates       | 45540       |\n",
      "|    reward          | 0.005549927 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:27551751.006709393\n",
      "Sharpe:  2.139711203332894\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4396467.56676654\n",
      "Sharpe:  1.6916082635588983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:8697699.526614714\n",
      "Sharpe:  2.037844164194299\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1009667.7652341791\n",
      "Sharpe:  1.5327735502676603\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "alg = 'td3'\n",
    "optuna_params = None\n",
    "optuna_params = {\"learning_rate\": 6e-4, \"action_noise\": \"ornstein_uhlenbeck\", \"target_policy_noise\" : 0.5, \"gamma\" : 0.95}\n",
    "#{\"use_sde\" : True}#\n",
    "\n",
    "log_name = alg + '_final_' + alg + '_256x128_' + str(6)\n",
    "model, commiss, df_daily_return, df_actions = train_trade(alg, train, trade, optuna_params, log_name=log_name, size=[256,128], \n",
    "                                                          trained_model=None, steps = 50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return          0.122385\n",
       "Cumulative returns     0.009668\n",
       "Annual volatility      0.077190\n",
       "Sharpe ratio           1.532774\n",
       "Calmar ratio           7.337376\n",
       "Stability              0.000638\n",
       "Max drawdown          -0.016680\n",
       "Omega ratio            1.301376\n",
       "Sortino ratio          2.618270\n",
       "Skew                   0.468810\n",
       "Kurtosis               0.269767\n",
       "Tail ratio             1.204741\n",
       "Daily value at risk   -0.009255\n",
       "Alpha                  0.000000\n",
       "Beta                   1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(df_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>month</th>\n",
       "      <th>res</th>\n",
       "      <th>dd</th>\n",
       "      <th>sharp</th>\n",
       "      <th>day_ret</th>\n",
       "      <th>actions</th>\n",
       "      <th>total_commission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>a2c</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037050</td>\n",
       "      <td>-0.023224</td>\n",
       "      <td>3.911956</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>-0.017872</td>\n",
       "      <td>4.491486</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ddpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>3.798652</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>td3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031701</td>\n",
       "      <td>-0.014878</td>\n",
       "      <td>3.633125</td>\n",
       "      <td>date  daily_return\n",
       "0  2023-06-01     ...</td>\n",
       "      <td>date                                 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alg  month       res        dd     sharp  \\\n",
       "35   a2c      0  0.037050 -0.023224  3.911956   \n",
       "26   ppo      0  0.034117 -0.017872  4.491486   \n",
       "17  ddpg      0  0.039359 -0.022248  3.798652   \n",
       "8    td3      0  0.031701 -0.014878  3.633125   \n",
       "\n",
       "                                              day_ret  \\\n",
       "35           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "26           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "17           date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "8            date  daily_return\n",
       "0  2023-06-01     ...   \n",
       "\n",
       "                                              actions  total_commission  \n",
       "35           date                                 ...                 0  \n",
       "26           date                                 ...                 0  \n",
       "17           date                                 ...                 0  \n",
       "8            date                                 ...                 0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[res_df['month'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df_actions['actions'].iloc[1], 3), np.round(df_actions['actions'].iloc[2], 3), np.round(df_actions['actions'].iloc[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С новыми параметрами не так хорошо всё на первом интервале. Видно что очень резко изменяется состав портфеля от шага к шагу. Попробуем провести несколько обучений с гораздо бОльшими комиссиями, посмотрим уменьшит ли разброс в бумагах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.00024, 'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]), 'target_policy_noise': 0.5, 'gamma': 0.95}\n",
      "Using cuda device\n",
      "Logging to logs\\td3_final_td3_192x128_0.26_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\PortfolioEnvBox.py:157: RuntimeWarning: invalid value encountered in cast\n",
      "  target_quantity = np.int32(money_per_security/close_prices * securities_to_be) #сколько должно быть бумаг\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:-1785674142673.3774\n",
      "Sharpe:  2.7079200229848075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:196136030934.97473\n",
      "Sharpe:  5.6585726834241346\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:162568388.6135661\n",
      "Sharpe:  6.596815042354246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:186967273.1087626\n",
      "Sharpe:  6.558743477259751\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 85          |\n",
      "|    time_elapsed    | 49          |\n",
      "|    total_timesteps | 4260        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.465      |\n",
      "|    critic_loss     | 0.0049      |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 4159        |\n",
      "|    reward          | 0.004004511 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:487005105752.3441\n",
      "Sharpe:  3.6776098033052964\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:330189326.91397107\n",
      "Sharpe:  8.648047286965154\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:30997794001.282578\n",
      "Sharpe:  8.728327239992804\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11492082024.40659\n",
      "Sharpe:  7.6968608306144635\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 83          |\n",
      "|    time_elapsed    | 116         |\n",
      "|    total_timesteps | 9731        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.312      |\n",
      "|    critic_loss     | 0.000762    |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 9630        |\n",
      "|    reward          | 0.005762512 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:21865210245.086372\n",
      "Sharpe:  8.480258934243636\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:13095077939.351084\n",
      "Sharpe:  8.07016805619943\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:199752765.9166042\n",
      "Sharpe:  6.449259023095604\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:125390464865.46729\n",
      "Sharpe:  8.520409603397859\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 82          |\n",
      "|    time_elapsed    | 187         |\n",
      "|    total_timesteps | 15421       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.335      |\n",
      "|    critic_loss     | 0.00177     |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 15320       |\n",
      "|    reward          | 0.024164418 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2188526042259.4077\n",
      "Sharpe:  3.906133514061813\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:-396947137534.09186\n",
      "Sharpe:  4.071832881472456\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:412536844540.3052\n",
      "Sharpe:  9.046546052106258\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1423756435.3226297\n",
      "Sharpe:  7.090886628227881\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 81         |\n",
      "|    time_elapsed    | 248        |\n",
      "|    total_timesteps | 20351      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.512     |\n",
      "|    critic_loss     | 0.00605    |\n",
      "|    learning_rate   | 0.00024    |\n",
      "|    n_updates       | 20250      |\n",
      "|    reward          | 0.01441015 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2808386719.438236\n",
      "Sharpe:  8.58355980778967\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:125915335571.92215\n",
      "Sharpe:  9.786489372395085\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:885792976929.5698\n",
      "Sharpe:  10.674866488327506\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:27171640887.271545\n",
      "Sharpe:  9.059863744208801\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 80          |\n",
      "|    time_elapsed    | 312         |\n",
      "|    total_timesteps | 25281       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.489      |\n",
      "|    critic_loss     | 0.00255     |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 25180       |\n",
      "|    reward          | 0.013893466 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:525951260838.0431\n",
      "Sharpe:  9.473836058874184\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:76444511054.36603\n",
      "Sharpe:  10.431943362063937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2325969937286.9106\n",
      "Sharpe:  3.698782844345174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1312528777168.143\n",
      "Sharpe:  2.3002344173532077\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 81         |\n",
      "|    time_elapsed    | 376        |\n",
      "|    total_timesteps | 30502      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -0.512     |\n",
      "|    critic_loss     | 0.00276    |\n",
      "|    learning_rate   | 0.00024    |\n",
      "|    n_updates       | 30401      |\n",
      "|    reward          | 0.00839422 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:389005410216.377\n",
      "Sharpe:  11.643399946688387\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:698509472833.0107\n",
      "Sharpe:  3.6473077423189273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1397490408422.3755\n",
      "Sharpe:  5.261677746131123\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1085364476115.1448\n",
      "Sharpe:  3.0478395685195747\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 429          |\n",
      "|    total_timesteps | 34924        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.458       |\n",
      "|    critic_loss     | 0.00387      |\n",
      "|    learning_rate   | 0.00024      |\n",
      "|    n_updates       | 34823        |\n",
      "|    reward          | 0.0058853375 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:231913928951.21017\n",
      "Sharpe:  10.35166271477251\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:256437207943.8669\n",
      "Sharpe:  10.80338432307038\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6440735439042.929\n",
      "Sharpe:  1.610524059297389\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1384857632999.2346\n",
      "Sharpe:  4.436052002773128\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 492         |\n",
      "|    total_timesteps | 39878       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.425      |\n",
      "|    critic_loss     | 0.00607     |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 39777       |\n",
      "|    reward          | 0.013844796 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:23003316800983.67\n",
      "Sharpe:  2.66122024491909\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:10584431433706.65\n",
      "Sharpe:  2.190711999491783\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:220386945941.90768\n",
      "Sharpe:  10.90676941495517\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2390417539987.0225\n",
      "Sharpe:  8.27757065934059\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 81          |\n",
      "|    time_elapsed    | 552         |\n",
      "|    total_timesteps | 44837       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.318      |\n",
      "|    critic_loss     | 0.00333     |\n",
      "|    learning_rate   | 0.00024     |\n",
      "|    n_updates       | 44736       |\n",
      "|    reward          | 0.009575961 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:274521378230.39862\n",
      "Sharpe:  10.805005077693563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:6803462811295.602\n",
      "Sharpe:  1.9511814698387449\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2687924810896.288\n",
      "Sharpe:  1.9315766689776608\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:107528592249.03249\n",
      "Sharpe:  10.42745406755539\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 81           |\n",
      "|    time_elapsed    | 608          |\n",
      "|    total_timesteps | 49389        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.362       |\n",
      "|    critic_loss     | 0.00252      |\n",
      "|    learning_rate   | 0.00024      |\n",
      "|    n_updates       | 49288        |\n",
      "|    reward          | 0.0064134523 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2023241.2011999995\n",
      "Sharpe:  12.567190996480937\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "#for i in range(20,19,-1):\n",
    "i = 20\n",
    "commiss = 0.01 * i\n",
    "env_kwargs = {\n",
    "    \"hmax\": 20,\n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": commiss, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": fa.indicators, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"cov_xtra_names\": fa.cov_xtra_names\n",
    "}\n",
    "\n",
    "optuna_params = {\"learning_rate\": 2.4e-4, \"action_noise\": \"ornstein_uhlenbeck\", \"target_policy_noise\" : 0.5, \"gamma\" : 0.95}\n",
    "    \n",
    "log_name = alg + '_final_' + alg + '_192x128_' + str(commiss) + str(6)\n",
    "model, commiss, df_daily_return, df_actions = train_trade(alg, train, trade, optuna_params, log_name=log_name, size=[192,128], trained_model=None, steps = 50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('start_rev_6_5.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.001, 0.   , 0.   , 0.204, 0.   , 0.204, 0.204, 0.204, 0.184],\n",
       "       dtype=float32),\n",
       " array([0.162, 0.   , 0.   , 0.203, 0.   , 0.203, 0.187, 0.203, 0.042],\n",
       "       dtype=float32),\n",
       " array([0.136, 0.   , 0.   , 0.196, 0.   , 0.196, 0.19 , 0.196, 0.085],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df_actions['actions'].iloc[1], 3), np.round(df_actions['actions'].iloc[2], 3), np.round(df_actions['actions'].iloc[3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\empyrical\\stats.py:799: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.divide(average_annual_return, annualized_downside_risk, out=out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Annual return          4704.133221\n",
       "Cumulative returns        1.023241\n",
       "Annual volatility         0.701154\n",
       "Sharpe ratio             12.567191\n",
       "Calmar ratio                   NaN\n",
       "Stability                 0.959702\n",
       "Max drawdown              0.000000\n",
       "Omega ratio                    NaN\n",
       "Sortino ratio                  inf\n",
       "Skew                      2.577366\n",
       "Kurtosis                  6.861365\n",
       "Tail ratio               68.689227\n",
       "Daily value at risk      -0.053371\n",
       "Alpha                     0.000000\n",
       "Beta                      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(df_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for commission in range(20,0,-1):\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 20,\n",
    "        \"initial_amount\": 1000000, \n",
    "        \"transaction_cost_pct\": 0.001, \n",
    "        \"state_space\": state_space, \n",
    "        \"stock_dim\": stock_dimension, \n",
    "        \"tech_indicator_list\": fa.indicators, \n",
    "        \"action_space\": stock_dimension, \n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"cov_xtra_names\": fa.cov_xtra_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GMKN', 'LKOH', 'MAGN', 'MM', 'MTSS', 'NVTK', 'ROSN', 'SBER',\n",
       "       'SNGS'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "state = e_trade_gym2.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), None)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, rew, term, _ = e_trade_gym2.step(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003297320236000116,\n",
       " array([0.00000000e+00, 2.25000000e-02, 2.24999976e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.25000000e-02, 0.00000000e+00, 2.25000000e-02,\n",
       "        6.70552254e-10, 5.26898889e-01, 8.95671276e-01, 6.71976567e-01,\n",
       "        1.00000000e+00, 8.37575875e-01, 6.85314562e-01, 7.99657240e-01,\n",
       "        7.93949291e-01, 5.97809204e-01, 4.17596976e-01, 6.30545238e-01,\n",
       "        5.28558044e-01, 1.00000000e+00, 7.43010357e-01, 5.75401456e-01,\n",
       "        7.00817979e-01, 6.25582041e-01, 4.74691856e-01, 5.26898889e-01,\n",
       "        6.30545238e-01, 6.71976567e-01, 1.00000000e+00, 8.37575875e-01,\n",
       "        6.85314562e-01, 7.99657240e-01, 6.45095332e-01, 5.97809204e-01]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = df_daily_return['daily_return'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00604526, -0.00158031,  0.00666416, -0.00342287,\n",
       "       -0.00092551,  0.00389716,  0.01388395, -0.00193682,  0.00575052,\n",
       "       -0.00026622, -0.00018848, -0.00224985, -0.0003685 , -0.0041405 ,\n",
       "       -0.01351069,  0.0027398 ,  0.00485066, -0.01434165,  0.0142861 ,\n",
       "        0.00073639])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0155489635145343"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(rt+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return           0.238035\n",
       "Cumulative returns      0.017953\n",
       "Annual volatility       0.092022\n",
       "Sharpe ratio            2.365222\n",
       "Calmar ratio           11.942949\n",
       "Stability               0.306204\n",
       "Max drawdown           -0.019931\n",
       "Omega ratio             1.556182\n",
       "Sortino ratio           3.663851\n",
       "Skew                   -0.432479\n",
       "Kurtosis                1.209552\n",
       "Tail ratio              1.492475\n",
       "Daily value at risk    -0.010730\n",
       "Alpha                   0.000000\n",
       "Beta                    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(df_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    GMKN\n",
       "0    LKOH\n",
       "0    MAGN\n",
       "0      MM\n",
       "0    MTSS\n",
       "0    NVTK\n",
       "0    ROSN\n",
       "0    SBER\n",
       "0    SNGS\n",
       "Name: tic, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.loc[0]['tic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>rsi_12</th>\n",
       "      <th>cci_12</th>\n",
       "      <th>dx_12</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>cov_xtra</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>10068.330000</td>\n",
       "      <td>10071.630000</td>\n",
       "      <td>10067.150000</td>\n",
       "      <td>10070.390000</td>\n",
       "      <td>25106100</td>\n",
       "      <td>GMKN</td>\n",
       "      <td>76.424845</td>\n",
       "      <td>215.142370</td>\n",
       "      <td>84.088373</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>8830.000000</td>\n",
       "      <td>8937.000000</td>\n",
       "      <td>8771.000000</td>\n",
       "      <td>8896.000000</td>\n",
       "      <td>1324998</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>83.042272</td>\n",
       "      <td>158.752567</td>\n",
       "      <td>82.638239</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>80.048000</td>\n",
       "      <td>80.078000</td>\n",
       "      <td>79.478000</td>\n",
       "      <td>79.818000</td>\n",
       "      <td>17212120</td>\n",
       "      <td>MAGN</td>\n",
       "      <td>75.466668</td>\n",
       "      <td>106.126368</td>\n",
       "      <td>65.791820</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>156.172603</td>\n",
       "      <td>1</td>\n",
       "      <td>MM</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>129.477912</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>545.110000</td>\n",
       "      <td>546.910000</td>\n",
       "      <td>543.110000</td>\n",
       "      <td>545.010000</td>\n",
       "      <td>4802040</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>45.977731</td>\n",
       "      <td>-40.534283</td>\n",
       "      <td>5.922008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.9573373323070703, 0.9443874258900921, 0.946...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>541.060000</td>\n",
       "      <td>542.110000</td>\n",
       "      <td>537.610000</td>\n",
       "      <td>538.710000</td>\n",
       "      <td>5301270</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>41.667802</td>\n",
       "      <td>-66.093117</td>\n",
       "      <td>33.558085</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>1987.820000</td>\n",
       "      <td>2004.020000</td>\n",
       "      <td>1970.620000</td>\n",
       "      <td>1984.620000</td>\n",
       "      <td>832522</td>\n",
       "      <td>NVTK</td>\n",
       "      <td>67.993667</td>\n",
       "      <td>72.748710</td>\n",
       "      <td>53.094191</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>731.690000</td>\n",
       "      <td>732.940000</td>\n",
       "      <td>728.040000</td>\n",
       "      <td>730.640000</td>\n",
       "      <td>2565110</td>\n",
       "      <td>ROSN</td>\n",
       "      <td>66.340793</td>\n",
       "      <td>120.269856</td>\n",
       "      <td>51.537526</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>363.420000</td>\n",
       "      <td>364.620000</td>\n",
       "      <td>362.670000</td>\n",
       "      <td>363.220000</td>\n",
       "      <td>21957550</td>\n",
       "      <td>SBER</td>\n",
       "      <td>58.652072</td>\n",
       "      <td>94.074527</td>\n",
       "      <td>13.929651</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>36.845000</td>\n",
       "      <td>37.050000</td>\n",
       "      <td>36.675000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>16758600</td>\n",
       "      <td>SNGS</td>\n",
       "      <td>60.599427</td>\n",
       "      <td>138.740569</td>\n",
       "      <td>51.294080</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.5870239002247921, 0.8765191268071332, 0.732...</td>\n",
       "      <td>tic             GD      GMKN    IMOEX    LKOH ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          open          high           low         close  \\\n",
       "0  2023-08-01  10068.330000  10071.630000  10067.150000  10070.390000   \n",
       "0  2023-08-01   8830.000000   8937.000000   8771.000000   8896.000000   \n",
       "0  2023-08-01     80.048000     80.078000     79.478000     79.818000   \n",
       "0  2023-08-01    156.172603    156.172603    156.172603    156.172603   \n",
       "0  2023-08-01    545.110000    546.910000    543.110000    545.010000   \n",
       "..        ...           ...           ...           ...           ...   \n",
       "22 2023-08-31    541.060000    542.110000    537.610000    538.710000   \n",
       "22 2023-08-31   1987.820000   2004.020000   1970.620000   1984.620000   \n",
       "22 2023-08-31    731.690000    732.940000    728.040000    730.640000   \n",
       "22 2023-08-31    363.420000    364.620000    362.670000    363.220000   \n",
       "22 2023-08-31     36.845000     37.050000     36.675000     36.790000   \n",
       "\n",
       "      volume   tic      rsi_12      cci_12       dx_12 cov_list  \\\n",
       "0   25106100  GMKN   76.424845  215.142370   84.088373       []   \n",
       "0    1324998  LKOH   83.042272  158.752567   82.638239       []   \n",
       "0   17212120  MAGN   75.466668  106.126368   65.791820       []   \n",
       "0          1    MM  100.000000  129.477912  100.000000       []   \n",
       "0    4802040  MTSS   45.977731  -40.534283    5.922008       []   \n",
       "..       ...   ...         ...         ...         ...      ...   \n",
       "22   5301270  MTSS   41.667802  -66.093117   33.558085       []   \n",
       "22    832522  NVTK   67.993667   72.748710   53.094191       []   \n",
       "22   2565110  ROSN   66.340793  120.269856   51.537526       []   \n",
       "22  21957550  SBER   58.652072   94.074527   13.929651       []   \n",
       "22  16758600  SNGS   60.599427  138.740569   51.294080       []   \n",
       "\n",
       "                                             cov_xtra  \\\n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "0   [0.9573373323070703, 0.9443874258900921, 0.946...   \n",
       "..                                                ...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "22  [0.5870239002247921, 0.8765191268071332, 0.732...   \n",
       "\n",
       "                                          return_list  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "0   tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "..                                                ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "22  tic             GD      GMKN    IMOEX    LKOH ...  \n",
       "\n",
       "[207 rows x 13 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to logs\\a2c_final_a2c_9_4\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | -193          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -4.47         |\n",
      "|    reward             | -0.0020968118 |\n",
      "|    value_loss         | 0.143         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:677590.5788263523\n",
      "Sharpe:  -0.7154921932669398\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 30           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -101         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | 0.0019480594 |\n",
      "|    value_loss         | 0.0532       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 29           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -393         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -7.79        |\n",
      "|    reward             | 0.0016521268 |\n",
      "|    value_loss         | 0.357        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:428203.7352053475\n",
      "Sharpe:  -0.8404597211894865\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 29            |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 67            |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | -1.42e+03     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -5.46         |\n",
      "|    reward             | -0.0022429526 |\n",
      "|    value_loss         | 0.194         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:658045.664396218\n",
      "Sharpe:  -0.746017116232962\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 29           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | -475         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -4.12        |\n",
      "|    reward             | 0.0031256576 |\n",
      "|    value_loss         | 0.12         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -894        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.942      |\n",
      "|    reward             | -0.01114825 |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714664.9753414551\n",
      "Sharpe:  -0.4718213975510272\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:639694.7563479333\n",
      "Sharpe:  -1.0899738888520887\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -1.83e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.255       |\n",
      "|    reward             | -0.007227374 |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:652614.2183674262\n",
      "Sharpe:  -0.7577239550993623\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | -31.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.712         |\n",
      "|    reward             | -0.0001371379 |\n",
      "|    value_loss         | 0.0043        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497518.51277105656\n",
      "Sharpe:  -1.438902858811296\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -1.44       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | 0.039199274 |\n",
      "|    value_loss         | 0.0281      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:685946.4418351555\n",
      "Sharpe:  -0.9400896570090742\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -22.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -3.16        |\n",
      "|    reward             | -0.012960385 |\n",
      "|    value_loss         | 0.0652       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:714296.8951707652\n",
      "Sharpe:  -0.6514035432924666\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1008047.9849799668\n",
      "Sharpe:  19.906367353196487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 192           |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | -247          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.927        |\n",
      "|    reward             | -0.0062725036 |\n",
      "|    value_loss         | 0.00715       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:643419.4187983955\n",
      "Sharpe:  -0.7841971678885284\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 209           |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.5         |\n",
      "|    explained_variance | -349          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -1.73         |\n",
      "|    reward             | -0.0026202763 |\n",
      "|    value_loss         | 0.0437        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -130         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -2.75        |\n",
      "|    reward             | 0.0044023623 |\n",
      "|    value_loss         | 0.0471       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495961.0961472174\n",
      "Sharpe:  -0.954831681224276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1079765.3558981188\n",
      "Sharpe:  2.2027888279320407\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -11.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.876      |\n",
      "|    reward             | 0.011851955 |\n",
      "|    value_loss         | 0.00861     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -540         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.557       |\n",
      "|    reward             | -0.010102015 |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497843.68854857713\n",
      "Sharpe:  -0.9036786732304378\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -221         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.772        |\n",
      "|    reward             | -0.026621936 |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:688534.3809074209\n",
      "Sharpe:  -0.6953503517238385\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -32.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -1.19        |\n",
      "|    reward             | -0.009795532 |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:644467.7441858157\n",
      "Sharpe:  -0.8065403651875281\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -1.39e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.592        |\n",
      "|    reward             | -0.005791324 |\n",
      "|    value_loss         | 0.0237       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -2.28        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.628       |\n",
      "|    reward             | 0.0103809815 |\n",
      "|    value_loss         | 0.00461      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -16.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.327       |\n",
      "|    reward             | -0.009229915 |\n",
      "|    value_loss         | 0.00532      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:493957.1615292946\n",
      "Sharpe:  -0.7682968122165356\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -131         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -1.03        |\n",
      "|    reward             | -0.002019496 |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 387          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -731         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -0.0143      |\n",
      "|    reward             | 0.0045856624 |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497102.7989185725\n",
      "Sharpe:  -0.8077251667884892\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | -397        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | 0.007662638 |\n",
      "|    value_loss         | 0.00988     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 422           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | -82.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 1.41          |\n",
      "|    reward             | -0.0013838344 |\n",
      "|    value_loss         | 0.0143        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:621588.0611263695\n",
      "Sharpe:  -0.5322213240157098\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -50.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.0536      |\n",
      "|    reward             | 0.0015799176 |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:718173.3471707416\n",
      "Sharpe:  -0.454710144839988\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 457           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -49.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -0.0333       |\n",
      "|    reward             | -0.0022115605 |\n",
      "|    value_loss         | 0.0012        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 476          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -43.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.43        |\n",
      "|    reward             | -0.009032664 |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 496          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -63.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.301        |\n",
      "|    reward             | -0.010511286 |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497677.4985161336\n",
      "Sharpe:  -0.6326117578831503\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 515           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -34.8         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | 0.628         |\n",
      "|    reward             | -0.0036314253 |\n",
      "|    value_loss         | 0.00332       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 532         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -0.145      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 0.318       |\n",
      "|    reward             | 0.011652762 |\n",
      "|    value_loss         | 0.000703    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498746.4519562575\n",
      "Sharpe:  -0.8604813205194255\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 549          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -62.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.365        |\n",
      "|    reward             | 0.0070009795 |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:497140.78115192073\n",
      "Sharpe:  -1.266965929824368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1092665.3715541777\n",
      "Sharpe:  2.7563045181404435\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 567          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -75.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.697        |\n",
      "|    reward             | 0.0043257996 |\n",
      "|    value_loss         | 0.0104       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 586          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -5.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.193        |\n",
      "|    reward             | -0.006376009 |\n",
      "|    value_loss         | 0.000438     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 603           |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -675          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.586         |\n",
      "|    reward             | -0.0035784396 |\n",
      "|    value_loss         | 0.00327       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:641225.7385239308\n",
      "Sharpe:  -0.35105541448570665\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 621          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -46.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.0855       |\n",
      "|    reward             | 0.0003475954 |\n",
      "|    value_loss         | 0.000951     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498772.8835908298\n",
      "Sharpe:  -1.0165774810731998\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 640         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | -0.189      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.026756251 |\n",
      "|    value_loss         | 0.0196      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:612514.5579370301\n",
      "Sharpe:  -1.1606286086963988\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 658          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -120         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.144        |\n",
      "|    reward             | 0.0037523352 |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 674          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -9.02        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.0139       |\n",
      "|    reward             | -0.006655269 |\n",
      "|    value_loss         | 0.000231     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:498550.9433546232\n",
      "Sharpe:  -0.8119287500809018\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 691           |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -3            |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | -0.0048318864 |\n",
      "|    value_loss         | 0.000191      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 708          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -0.568       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.611       |\n",
      "|    reward             | 0.0054282374 |\n",
      "|    value_loss         | 0.00241      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496524.137480398\n",
      "Sharpe:  -1.0195081776316404\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 725          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -9.51        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.462       |\n",
      "|    reward             | -0.009008461 |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 743          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -1.49        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | 0.0027022203 |\n",
      "|    value_loss         | 0.000851     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:495369.18271021824\n",
      "Sharpe:  -0.9363760189426903\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 28         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 760        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -0.508     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -0.0867    |\n",
      "|    reward             | 0.01506457 |\n",
      "|    value_loss         | 0.000165   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:617462.9781145933\n",
      "Sharpe:  -0.7082991346289276\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1079340.4636411471\n",
      "Sharpe:  2.4041830279625027\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 778          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -8.72        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | -0.16        |\n",
      "|    reward             | -0.012872042 |\n",
      "|    value_loss         | 0.000528     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.58        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | 0.009590331 |\n",
      "|    value_loss         | 0.000208    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:486391.2186962529\n",
      "Sharpe:  -1.0908673753965212\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 812           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -1.12         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -0.15         |\n",
      "|    reward             | -0.0015272818 |\n",
      "|    value_loss         | 0.000179      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 0.215       |\n",
      "|    reward             | 0.017340932 |\n",
      "|    value_loss         | 0.000342    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496707.2301635213\n",
      "Sharpe:  -0.877171472724079\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 847          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -4.64        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.156        |\n",
      "|    reward             | -0.005607592 |\n",
      "|    value_loss         | 0.00044      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -1.87         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0024429616 |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496283.8820606534\n",
      "Sharpe:  -0.9141457227795102\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 878         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -6.98       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.337      |\n",
      "|    reward             | 0.014959281 |\n",
      "|    value_loss         | 0.00111     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 895           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -4.72         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.0726        |\n",
      "|    reward             | -0.0048401505 |\n",
      "|    value_loss         | 4.02e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499667.8980029343\n",
      "Sharpe:  -0.6471923541601641\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 912          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -0.645       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.37        |\n",
      "|    reward             | 0.0009143865 |\n",
      "|    value_loss         | 0.000977     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 927          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0.347        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.010286457 |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:593048.4088688253\n",
      "Sharpe:  -0.6525219384947799\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 944         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -0.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.0984     |\n",
      "|    reward             | 0.011792672 |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:725575.7673331513\n",
      "Sharpe:  -0.4675438152118888\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 28             |\n",
      "|    iterations         | 5500           |\n",
      "|    time_elapsed       | 959            |\n",
      "|    total_timesteps    | 27500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.1          |\n",
      "|    explained_variance | -9.86          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5499           |\n",
      "|    policy_loss        | -0.402         |\n",
      "|    reward             | -0.00052906014 |\n",
      "|    value_loss         | 0.00178        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 28           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 976          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -0.156       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.16        |\n",
      "|    reward             | 0.0073924884 |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:496777.50096947484\n",
      "Sharpe:  -0.9124193301283512\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 992         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -1.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.677      |\n",
      "|    reward             | 0.010774162 |\n",
      "|    value_loss         | 0.00301     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1009        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.528       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.157       |\n",
      "|    reward             | 0.023440337 |\n",
      "|    value_loss         | 0.000482    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 28          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1027        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 0.0188      |\n",
      "|    reward             | 0.029501045 |\n",
      "|    value_loss         | 8.93e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:499557.4854872666\n",
      "Sharpe:  -0.7060795685181203\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1082190.131727652\n",
      "Sharpe:  1.7100913761963197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:932999.0766308173\n",
      "Sharpe:  -0.3251600599731243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 28            |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 1044          |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -2.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5999          |\n",
      "|    policy_loss        | 0.488         |\n",
      "|    reward             | -0.0026730748 |\n",
      "|    value_loss         | 0.00148       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e_train_gym = PortfolioEnv(df = train, **env_kwargs)\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "agent = DRLAgent(env = env_train)\n",
    "model = agent.get_model(model_name = alg, model_kwargs = optuna_params, policy_kwargs = None, tensorboard_log = 'logs')\n",
    "\n",
    "trained_a2c = agent.train_model(model = model, \n",
    "                                tb_log_name = log_name,\n",
    "                                total_timesteps = 30_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym2 = PortfolioEnv(df = trade, reset_to_zero=True, **env_kwargs)\n",
    "\n",
    "state = e_trade_gym2.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trained_a2c.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1],\n",
       "       dtype=int64),\n",
       " None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, rew, term, _ = e_trade_gym2.step(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007766173104209378"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[alg] = []\n",
    "ret[alg] = []\n",
    "act[alg] = []\n",
    "res[alg].append(get_result(df_daily_return))\n",
    "ret[alg].append(df_daily_return)\n",
    "act[alg].append(df_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'td3': [Annual return         -0.165986\n",
       "  Cumulative returns    -0.015012\n",
       "  Annual volatility      0.150527\n",
       "  Sharpe ratio          -1.133765\n",
       "  Calmar ratio          -2.711280\n",
       "  Stability              0.427691\n",
       "  Max drawdown          -0.061220\n",
       "  Omega ratio            0.842712\n",
       "  Sortino ratio         -1.616779\n",
       "  Skew                   0.319968\n",
       "  Kurtosis              -0.931438\n",
       "  Tail ratio             1.156678\n",
       "  Daily value at risk   -0.019642\n",
       "  Alpha                  0.000000\n",
       "  Beta                   1.000000\n",
       "  dtype: float64]}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of values (1999) does not match length of index (1997)\n",
      "Length of values (1999) does not match length of index (1997)\n",
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\meta\\preprocessor\\preprocessors.py:171: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill().bfill()\n",
      "100%|██████████| 1974/1974 [00:17<00:00, 114.48it/s]\n"
     ]
    }
   ],
   "source": [
    "loader2 = DataLoader()\n",
    "df2 = loader2.LoadData()\n",
    "\n",
    "df2.index = range(len(df2))\n",
    "#df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "df2 = df2.drop(df2[df2['tic'] == 'BZ'].index)\n",
    "#df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "df2 = df2.drop(df2[df2['tic'] == 'USD'].index)\n",
    "\n",
    "fa2 = FeaturesAdder(22)\n",
    "df2 = fa2.Process(df2)\n",
    "\n",
    "df2.index = df2.date.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 14:26:08,936] A new study created in memory with name: no-name-eda3bef4-e5cb-4542-9e78-966bed97e7fc\n",
      "c:\\Users\\Alex\\Documents\\Курсы\\Otus\\RL\\CP2\\DataLoader.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, dft[self.columns]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of values (1999) does not match length of index (1997)\n",
      "Length of values (1999) does not match length of index (1997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\meta\\preprocessor\\preprocessors.py:171: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill().bfill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:36<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1328804.5761858234\n",
      "Sharpe:  0.5611658994842432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1103836.133373412\n",
      "Sharpe:  4.10179896083965\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820169.431765897\n",
      "Sharpe:  0.7969255424660227\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1333812.7718168045\n",
      "Sharpe:  0.5996255303696812\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 44            |\n",
      "|    time_elapsed    | 67            |\n",
      "|    total_timesteps | 2982          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.47          |\n",
      "|    critic_loss     | 0.114         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 2881          |\n",
      "|    reward          | 0.00090358907 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1107334.4305786227\n",
      "Sharpe:  0.4024363943306529\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1018132.6075719056\n",
      "Sharpe:  0.16940039431961662\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1314329.019413037\n",
      "Sharpe:  0.5688173277248557\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1836113.4298092867\n",
      "Sharpe:  0.9592534866233956\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 8            |\n",
      "|    fps             | 45           |\n",
      "|    time_elapsed    | 124          |\n",
      "|    total_timesteps | 5603         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.5          |\n",
      "|    critic_loss     | 0.0437       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 5502         |\n",
      "|    reward          | 0.0013497723 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1183768.8523744675\n",
      "Sharpe:  0.5732399416389344\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4452795.7241544435\n",
      "Sharpe:  1.4460968664991039\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3911706.4369267942\n",
      "Sharpe:  1.4627118943964443\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1308272.3170993153\n",
      "Sharpe:  2.7214252270992954\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    episodes        | 12             |\n",
      "|    fps             | 46             |\n",
      "|    time_elapsed    | 202            |\n",
      "|    total_timesteps | 9405           |\n",
      "| train/             |                |\n",
      "|    actor_loss      | 1.6            |\n",
      "|    critic_loss     | 0.0302         |\n",
      "|    learning_rate   | 0.001          |\n",
      "|    n_updates       | 9304           |\n",
      "|    reward          | -0.00016633693 |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1950747.6560253352\n",
      "Sharpe:  0.9438175131643552\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:931776.6141189707\n",
      "Sharpe:  -0.06082695036405172\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2286935.25706349\n",
      "Sharpe:  1.0148677603491287\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3734946.56557794\n",
      "Sharpe:  0.8939118908196799\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 291           |\n",
      "|    total_timesteps | 13882         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 1.6           |\n",
      "|    critic_loss     | 0.0144        |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 13781         |\n",
      "|    reward          | 0.00042037814 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:866101.5160753474\n",
      "Sharpe:  -0.19551447644116093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:948033.2712875433\n",
      "Sharpe:  0.009076499221343346\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1054613.37315207\n",
      "Sharpe:  0.21426509150782927\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1766848.531771442\n",
      "Sharpe:  0.7470436385312387\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 20           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 343          |\n",
      "|    total_timesteps | 16544        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.54         |\n",
      "|    critic_loss     | 0.00874      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 16443        |\n",
      "|    reward          | 0.0026483552 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1405851.2925929574\n",
      "Sharpe:  0.6727306888880273\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1317100.7628776599\n",
      "Sharpe:  2.158521323948593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1173652.0588240025\n",
      "Sharpe:  1.405255983808238\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1241256.5282445773\n",
      "Sharpe:  4.067337457333297\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 24           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 367          |\n",
      "|    total_timesteps | 17823        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.5          |\n",
      "|    critic_loss     | 0.00713      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 17722        |\n",
      "|    reward          | 0.0026428201 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1562646.449235679\n",
      "Sharpe:  0.633380559038114\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1371502.4623127112\n",
      "Sharpe:  0.7367972783991253\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1131493.268291758\n",
      "Sharpe:  0.506987186004417\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2840504.064695686\n",
      "Sharpe:  1.0470695792709348\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 28           |\n",
      "|    fps             | 48           |\n",
      "|    time_elapsed    | 434          |\n",
      "|    total_timesteps | 21116        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.39         |\n",
      "|    critic_loss     | 0.00496      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 21015        |\n",
      "|    reward          | 0.0020960954 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1229490.3030663717\n",
      "Sharpe:  1.9275202386107841\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2350564.8189799865\n",
      "Sharpe:  0.8784439248881407\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1779692.974585341\n",
      "Sharpe:  0.9061137849874381\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985209.9501435242\n",
      "Sharpe:  0.9488682037418644\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 32           |\n",
      "|    fps             | 46           |\n",
      "|    time_elapsed    | 530          |\n",
      "|    total_timesteps | 24527        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.31         |\n",
      "|    critic_loss     | 0.00635      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 24426        |\n",
      "|    reward          | 0.0017521542 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2145723.507516834\n",
      "Sharpe:  1.0943008926440432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1640980.3131339182\n",
      "Sharpe:  0.8533855093449112\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302390.2088839714\n",
      "Sharpe:  1.0841225550505527\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1140036.191063451\n",
      "Sharpe:  0.5449064122400642\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 36           |\n",
      "|    fps             | 44           |\n",
      "|    time_elapsed    | 624          |\n",
      "|    total_timesteps | 27840        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 1.1          |\n",
      "|    critic_loss     | 0.00488      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 27739        |\n",
      "|    reward          | 0.0015436959 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820282.9834706066\n",
      "Sharpe:  1.136287235554368\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2087724.2145517007\n",
      "Sharpe:  0.9960445843173737\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1222077.6215655361\n",
      "Sharpe:  0.39000841688463\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4597006.341869871\n",
      "Sharpe:  1.1800078690405984\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 745         |\n",
      "|    total_timesteps | 32169       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1           |\n",
      "|    critic_loss     | 0.0016      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 32068       |\n",
      "|    reward          | 0.001156949 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1238201.3049344996\n",
      "Sharpe:  0.673218212597284\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2066941.5177945103\n",
      "Sharpe:  1.2845728730424915\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3844164.781967173\n",
      "Sharpe:  1.310752406598563\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1855496.6602841718\n",
      "Sharpe:  1.2141175271754308\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 825         |\n",
      "|    total_timesteps | 35492       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.937       |\n",
      "|    critic_loss     | 0.00239     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 35391       |\n",
      "|    reward          | 0.003426767 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1651215.5070773554\n",
      "Sharpe:  0.8494033512066217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2278208.5879557487\n",
      "Sharpe:  0.9854790050408566\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4646897.673596888\n",
      "Sharpe:  1.5165456763772365\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1320608.9145450208\n",
      "Sharpe:  0.9698333814310819\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 48           |\n",
      "|    fps             | 43           |\n",
      "|    time_elapsed    | 907          |\n",
      "|    total_timesteps | 39159        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.879        |\n",
      "|    critic_loss     | 0.0024       |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 39058        |\n",
      "|    reward          | 0.0059507755 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1749223.916471298\n",
      "Sharpe:  1.2687851074394052\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2442465.7781259767\n",
      "Sharpe:  0.9090291362699257\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3837056.12005318\n",
      "Sharpe:  1.3131053048946968\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2176718.1066348413\n",
      "Sharpe:  1.4801930383249173\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 52           |\n",
      "|    fps             | 43           |\n",
      "|    time_elapsed    | 992          |\n",
      "|    total_timesteps | 43036        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.715        |\n",
      "|    critic_loss     | 0.001        |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 42935        |\n",
      "|    reward          | 0.0013587814 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3191401.586089331\n",
      "Sharpe:  1.4663440412279218\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3308265.502584776\n",
      "Sharpe:  1.3216110845077496\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1307616.1815233608\n",
      "Sharpe:  0.82512987467599\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1486411.4193733486\n",
      "Sharpe:  4.3220076376745835\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 43          |\n",
      "|    time_elapsed    | 1044        |\n",
      "|    total_timesteps | 45535       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.697       |\n",
      "|    critic_loss     | 0.00145     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 45434       |\n",
      "|    reward          | 0.006437955 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3759366.43552654\n",
      "Sharpe:  1.3490063998292297\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1823268.7294768016\n",
      "Sharpe:  2.2979350642115075\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3014714.2876265454\n",
      "Sharpe:  1.3347472099476823\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5533166.629001392\n",
      "Sharpe:  1.3176004720572663\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1121        |\n",
      "|    total_timesteps | 49434       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.63        |\n",
      "|    critic_loss     | 0.00161     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 49333       |\n",
      "|    reward          | 0.006632961 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4185283.799920185\n",
      "Sharpe:  1.3267918395226979\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4404197.203408463\n",
      "Sharpe:  1.5992964363145732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3134807.76348591\n",
      "Sharpe:  1.4874607781870686\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5731460.443011691\n",
      "Sharpe:  1.4871835550367283\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1210        |\n",
      "|    total_timesteps | 53891       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.599       |\n",
      "|    critic_loss     | 0.000664    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 53790       |\n",
      "|    reward          | 0.010918282 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1097205.1922230008\n",
      "Sharpe:  5.3869663495769675\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1589799.2722708723\n",
      "Sharpe:  1.1901031529761137\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11653783.088012619\n",
      "Sharpe:  1.32633580425348\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1479095.5168959228\n",
      "Sharpe:  2.731231531937861\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 44          |\n",
      "|    time_elapsed    | 1257        |\n",
      "|    total_timesteps | 56212       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.567       |\n",
      "|    critic_loss     | 0.00144     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 56111       |\n",
      "|    reward          | 0.008054283 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5802240.705077837\n",
      "Sharpe:  1.6593319044434025\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1590381.2400240623\n",
      "Sharpe:  1.2398679002996726\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1269358.7614109737\n",
      "Sharpe:  6.056583828584722\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:11200082.426396014\n",
      "Sharpe:  1.5255659336941592\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 72           |\n",
      "|    fps             | 44           |\n",
      "|    time_elapsed    | 1329         |\n",
      "|    total_timesteps | 59740        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.479        |\n",
      "|    critic_loss     | 0.00173      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 59639        |\n",
      "|    reward          | 0.0014642718 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1026623.5309537264\n",
      "Sharpe:  3.1750684028905685\n",
      "=================================\n",
      "hit end!\n",
      "Rew, DD, Sh 0.026623530953725938 -0.021978134345193148 3.1750684028905685\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1318650.4135951765\n",
      "Sharpe:  0.5284407138969732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:892724.9130789972\n",
      "Sharpe:  -0.10934792520271971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1552342.927234988\n",
      "Sharpe:  0.5287890287253493\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:989830.0674499976\n",
      "Sharpe:  0.11941069750924747\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 50           |\n",
      "|    time_elapsed    | 56           |\n",
      "|    total_timesteps | 2869         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -4.04        |\n",
      "|    critic_loss     | 0.108        |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 2768         |\n",
      "|    reward          | -0.001113208 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:942752.0679029975\n",
      "Sharpe:  0.011518549135084648\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1727219.4953959861\n",
      "Sharpe:  0.5961475191083743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2021792.929268023\n",
      "Sharpe:  0.6245781748088858\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1925815.8233059854\n",
      "Sharpe:  0.6596968726619067\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 157           |\n",
      "|    total_timesteps | 7788          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.71         |\n",
      "|    critic_loss     | 0.032         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 7687          |\n",
      "|    reward          | -0.0011175167 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1093803.5097770034\n",
      "Sharpe:  0.2840936714628202\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1169744.3359430037\n",
      "Sharpe:  0.3146825275173701\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1762176.5433530144\n",
      "Sharpe:  0.6103728302174665\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1289147.692605001\n",
      "Sharpe:  1.351458514890795\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 12            |\n",
      "|    fps             | 49            |\n",
      "|    time_elapsed    | 220           |\n",
      "|    total_timesteps | 10888         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.22         |\n",
      "|    critic_loss     | 0.018         |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 10787         |\n",
      "|    reward          | -0.0011198022 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:993392.2602940019\n",
      "Sharpe:  0.12255996914877115\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:950135.7009329982\n",
      "Sharpe:  0.035656513885465174\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1923464.162117011\n",
      "Sharpe:  0.6082939194230987\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1470428.1125509874\n",
      "Sharpe:  0.5029518382425445\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 16            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 297           |\n",
      "|    total_timesteps | 14596         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -2.06         |\n",
      "|    critic_loss     | 0.00968       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 14495         |\n",
      "|    reward          | -0.0011183036 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1735315.4489900174\n",
      "Sharpe:  0.6007949153227594\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1614086.0805639846\n",
      "Sharpe:  0.544743725001608\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1247937.847477999\n",
      "Sharpe:  0.4802559689222678\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1237150.7732739984\n",
      "Sharpe:  1.2468082678442802\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 20            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 373           |\n",
      "|    total_timesteps | 18192         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.71         |\n",
      "|    critic_loss     | 0.00573       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 18091         |\n",
      "|    reward          | -0.0011154127 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1114069.550226006\n",
      "Sharpe:  0.26011612027899694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1244322.763987007\n",
      "Sharpe:  0.4646585636846666\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1664952.7403180155\n",
      "Sharpe:  0.5492730036980374\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1638604.0210619897\n",
      "Sharpe:  0.5716709746621218\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 24            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 464           |\n",
      "|    total_timesteps | 22420         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.56         |\n",
      "|    critic_loss     | 0.00839       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 22319         |\n",
      "|    reward          | -0.0011163533 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1932850.1361090194\n",
      "Sharpe:  0.598377879189032\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1535299.520385989\n",
      "Sharpe:  0.5132522902067653\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1495882.8542230136\n",
      "Sharpe:  0.5627564293187396\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1110201.4211619962\n",
      "Sharpe:  0.25420487383826385\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 28            |\n",
      "|    fps             | 48            |\n",
      "|    time_elapsed    | 566           |\n",
      "|    total_timesteps | 27232         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.3          |\n",
      "|    critic_loss     | 0.00503       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 27131         |\n",
      "|    reward          | -0.0011147878 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1241516.6333480063\n",
      "Sharpe:  0.4027941057764657\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1195504.4139590024\n",
      "Sharpe:  0.3990308243993078\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1958819.3341579859\n",
      "Sharpe:  0.6089566270503579\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020592.4795650021\n",
      "Sharpe:  0.17155607182293875\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 32            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 647           |\n",
      "|    total_timesteps | 30954         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -1.15         |\n",
      "|    critic_loss     | 0.00334       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 30853         |\n",
      "|    reward          | -0.0011157809 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1213795.1222939997\n",
      "Sharpe:  4.2627708481876985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985900.8927120143\n",
      "Sharpe:  0.6801195650826561\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1249927.3770069992\n",
      "Sharpe:  0.9833101736365217\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1536309.6517640078\n",
      "Sharpe:  0.5867192804524377\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 36            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 713           |\n",
      "|    total_timesteps | 33862         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.935        |\n",
      "|    critic_loss     | 0.00333       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 33761         |\n",
      "|    reward          | -0.0011153751 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1087180.7069060025\n",
      "Sharpe:  0.277307813094664\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:959282.6782200012\n",
      "Sharpe:  0.0566141239582126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1264610.6580320003\n",
      "Sharpe:  1.1310738346676652\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1713625.1904130196\n",
      "Sharpe:  0.5870395118556284\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 40            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 769           |\n",
      "|    total_timesteps | 36541         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.832        |\n",
      "|    critic_loss     | 0.00285       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 36440         |\n",
      "|    reward          | -0.0011179155 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639940.9394450155\n",
      "Sharpe:  0.5524960703176339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1731254.6139369896\n",
      "Sharpe:  0.539587476932397\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:988621.3274869996\n",
      "Sharpe:  0.11799788232764691\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:925659.1937699983\n",
      "Sharpe:  -0.021675332346362364\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 44           |\n",
      "|    fps             | 47           |\n",
      "|    time_elapsed    | 847          |\n",
      "|    total_timesteps | 40320        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.672       |\n",
      "|    critic_loss     | 0.00127      |\n",
      "|    learning_rate   | 0.001        |\n",
      "|    n_updates       | 40219        |\n",
      "|    reward          | -0.001119452 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1313052.9278640004\n",
      "Sharpe:  3.1983921016222214\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2099575.804508018\n",
      "Sharpe:  0.7230706691839036\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:910852.8165930018\n",
      "Sharpe:  -0.056161840191677956\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1268089.6348409979\n",
      "Sharpe:  1.2248250493316877\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 48            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 896           |\n",
      "|    total_timesteps | 42680         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.593        |\n",
      "|    critic_loss     | 0.00215       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 42579         |\n",
      "|    reward          | -0.0011163106 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1639940.9394450155\n",
      "Sharpe:  0.5524960703176339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2016135.0158219868\n",
      "Sharpe:  0.6362168328608206\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1605201.4504840157\n",
      "Sharpe:  0.5451501182272538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1105752.542209\n",
      "Sharpe:  5.410546062543867\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 52            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 988           |\n",
      "|    total_timesteps | 47029         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.56         |\n",
      "|    critic_loss     | 0.00182       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 46928         |\n",
      "|    reward          | -0.0011145849 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1728595.61942099\n",
      "Sharpe:  0.5970539282808451\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1645504.602556011\n",
      "Sharpe:  0.5697467917846732\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826298.8415059904\n",
      "Sharpe:  0.5905714113479494\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1914390.9274990133\n",
      "Sharpe:  0.6050803119208974\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 56            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1113          |\n",
      "|    total_timesteps | 52859         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.355        |\n",
      "|    critic_loss     | 0.000923      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 52758         |\n",
      "|    reward          | -0.0011181458 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1290451.2204399994\n",
      "Sharpe:  3.905267662114931\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1470437.2817110098\n",
      "Sharpe:  0.5206985137254035\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1493911.538356991\n",
      "Sharpe:  0.578964459334561\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1099304.4772550003\n",
      "Sharpe:  5.836169671119692\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 60            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1162          |\n",
      "|    total_timesteps | 55053         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.351        |\n",
      "|    critic_loss     | 0.000523      |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 54952         |\n",
      "|    reward          | -0.0011134197 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1246773.209804999\n",
      "Sharpe:  1.0761021014842138\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1498005.0572399872\n",
      "Sharpe:  0.5059413519968269\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1920694.7853860224\n",
      "Sharpe:  0.6353897047526376\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1235093.0817079986\n",
      "Sharpe:  0.4334555312275949\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 64            |\n",
      "|    fps             | 47            |\n",
      "|    time_elapsed    | 1242          |\n",
      "|    total_timesteps | 58841         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.228        |\n",
      "|    critic_loss     | 0.00126       |\n",
      "|    learning_rate   | 0.001         |\n",
      "|    n_updates       | 58740         |\n",
      "|    reward          | -0.0011152643 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1059357.054332\n",
      "Sharpe:  7.9081414301092865\n",
      "=================================\n",
      "hit end!\n",
      "Rew, DD, Sh 0.059357054332000114 -0.0156859275455648 7.9081414301092865\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to logs\\[128, 64]_22_2_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1980415.4168697067\n",
      "Sharpe:  0.8011031745757455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1717016.8685665885\n",
      "Sharpe:  0.9291492766166308\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1469591.0161674125\n",
      "Sharpe:  0.6434573503934055\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1150816.2652700073\n",
      "Sharpe:  0.4576295083108517\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 74          |\n",
      "|    total_timesteps | 3523        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.08        |\n",
      "|    critic_loss     | 0.049       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3422        |\n",
      "|    reward          | 0.017000806 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1826971.4826673293\n",
      "Sharpe:  0.7841686187813658\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1277429.8361853443\n",
      "Sharpe:  4.962211899346144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1219378.4685634286\n",
      "Sharpe:  5.080476036550634\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1020531.1939383592\n",
      "Sharpe:  0.15568747640714065\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 46         |\n",
      "|    time_elapsed    | 118        |\n",
      "|    total_timesteps | 5529       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2          |\n",
      "|    critic_loss     | 0.0244     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5428       |\n",
      "|    reward          | 0.01729235 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1352750.3238479511\n",
      "Sharpe:  2.4988336527294277\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1565224.3421228137\n",
      "Sharpe:  0.5215241504524739\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1607574.0297108036\n",
      "Sharpe:  0.5459016786875458\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1213905.4042664145\n",
      "Sharpe:  0.4830204056089441\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 192         |\n",
      "|    total_timesteps | 9129        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.84        |\n",
      "|    critic_loss     | 0.00935     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9028        |\n",
      "|    reward          | 0.017385758 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1160434.1764833617\n",
      "Sharpe:  0.45968397183500126\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1160079.37600498\n",
      "Sharpe:  0.5159266529223933\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1504260.3342921403\n",
      "Sharpe:  2.9072263392266953\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1479796.4251187576\n",
      "Sharpe:  2.5751521585398143\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 47          |\n",
      "|    time_elapsed    | 222         |\n",
      "|    total_timesteps | 10668       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.79        |\n",
      "|    critic_loss     | 0.0103      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10567       |\n",
      "|    reward          | 0.016845211 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1290989.9614684638\n",
      "Sharpe:  0.6782675543327175\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1754076.9596391807\n",
      "Sharpe:  0.9898743036814743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2302889.1195204086\n",
      "Sharpe:  0.998127576283723\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1494830.371760098\n",
      "Sharpe:  0.8503697580605752\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 294         |\n",
      "|    total_timesteps | 14268       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.65        |\n",
      "|    critic_loss     | 0.00698     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14167       |\n",
      "|    reward          | 0.014286233 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1340425.5091364323\n",
      "Sharpe:  0.5582988798355213\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1512652.3930290346\n",
      "Sharpe:  0.65647825457729\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2273424.7816010695\n",
      "Sharpe:  0.8275860314061532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2585173.1994123086\n",
      "Sharpe:  0.9515265430689012\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 392         |\n",
      "|    total_timesteps | 19196       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.54        |\n",
      "|    critic_loss     | 0.00514     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19095       |\n",
      "|    reward          | 0.013498942 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2607737.144842626\n",
      "Sharpe:  0.9795896351268775\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2685515.147204389\n",
      "Sharpe:  1.0758587479292743\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2064921.2023646967\n",
      "Sharpe:  1.0810350395018937\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1121428.1653979907\n",
      "Sharpe:  0.4675765734226979\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 479         |\n",
      "|    total_timesteps | 23451       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.44        |\n",
      "|    critic_loss     | 0.00233     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 23350       |\n",
      "|    reward          | 0.013867696 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3161265.846518264\n",
      "Sharpe:  1.3502794885210447\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2206221.4630808965\n",
      "Sharpe:  1.1664351549535428\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1279585.956290057\n",
      "Sharpe:  1.8619437686071902\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1093986.9465965494\n",
      "Sharpe:  0.34273262715183395\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 543         |\n",
      "|    total_timesteps | 26565       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.28        |\n",
      "|    critic_loss     | 0.00241     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 26464       |\n",
      "|    reward          | 0.004472833 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1163768.9956416213\n",
      "Sharpe:  0.488189278072325\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1828580.9724078616\n",
      "Sharpe:  1.1757119674074545\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1387406.908356824\n",
      "Sharpe:  0.7353214813069318\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3632183.1430810965\n",
      "Sharpe:  1.259179380249516\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 48          |\n",
      "|    time_elapsed    | 614         |\n",
      "|    total_timesteps | 29973       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.26        |\n",
      "|    critic_loss     | 0.00152     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 29872       |\n",
      "|    reward          | 0.012178719 |\n",
      "------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2351103.712811755\n",
      "Sharpe:  1.1933516368295358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4488292.261743441\n",
      "Sharpe:  1.4808219215027747\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1629886.4418955138\n",
      "Sharpe:  1.5121928479954903\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4050663.2348253275\n",
      "Sharpe:  1.2897595388574803\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 48         |\n",
      "|    time_elapsed    | 705        |\n",
      "|    total_timesteps | 34350      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.14       |\n",
      "|    critic_loss     | 0.00172    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 34249      |\n",
      "|    reward          | 0.01577032 |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-23 15:22:09,944] Trial 0 failed with parameters: {'bsize': 100000, 'noise': 'normal', 'learning_rate': 7.899454013765834e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_45272\\2432288324.py\", line 41, in objective\n",
      "    model, df_daily_return, df_actions = train_trade('td3', train, trade, None, log_name, size)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_45272\\1449868205.py\", line 23, in train_trade\n",
      "    trained_a2c = agent.train_model(model = model,\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py\", line 117, in train_model\n",
      "    model = model.learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 222, in learn\n",
      "    return super().learn(\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 347, in learn\n",
      "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 179, in train\n",
      "    current_q_values = self.critic(replay_data.observations, replay_data.actions)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py\", line 976, in forward\n",
      "    qvalue_input = th.cat([features, actions], dim=1)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-23 15:22:09,948] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sum_reward\n\u001b[0;32m     55\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 56\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[59], line 41\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#optuna_params = {\"learning_rate\": learning_rate}#, \"ent_coef\": ent_coef}# \"action_noise\": \"ornstein_uhlenbeck\"}\u001b[39;00m\n\u001b[0;32m     40\u001b[0m log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(lookback) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m---> 41\u001b[0m model, df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtd3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m result \u001b[38;5;241m=\u001b[39m get_result(df_daily_return)\n\u001b[0;32m     44\u001b[0m reward \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative returns\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[56], line 23\u001b[0m, in \u001b[0;36mtrain_trade\u001b[1;34m(alg, train, trade, optuna_params, log_name, size)\u001b[0m\n\u001b[0;32m     19\u001b[0m     log_name \u001b[38;5;241m=\u001b[39m alg\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_model(model_name \u001b[38;5;241m=\u001b[39m alg, model_kwargs \u001b[38;5;241m=\u001b[39m optuna_params, policy_kwargs \u001b[38;5;241m=\u001b[39m policy_kwargs, tensorboard_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m trained_a2c \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m e_trade_gym2 \u001b[38;5;241m=\u001b[39m PortfolioEnv(df \u001b[38;5;241m=\u001b[39m trade, reset_to_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m     29\u001b[0m df_daily_return, df_actions \u001b[38;5;241m=\u001b[39m DRLAgent\u001b[38;5;241m.\u001b[39mDRL_prediction(model\u001b[38;5;241m=\u001b[39mtrained_a2c,\n\u001b[0;32m     30\u001b[0m                     environment \u001b[38;5;241m=\u001b[39m e_trade_gym2)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:117\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    115\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    116\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:179\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    176\u001b[0m     target_q_values \u001b[38;5;241m=\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mdones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Get current Q-values estimates for each critic network\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m current_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Compute critic loss\u001b[39;00m\n\u001b[0;32m    182\u001b[0m critic_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(F\u001b[38;5;241m.\u001b[39mmse_loss(current_q, target_q_values) \u001b[38;5;28;01mfor\u001b[39;00m current_q \u001b[38;5;129;01min\u001b[39;00m current_q_values)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\FinRL\\lib\\site-packages\\stable_baselines3\\common\\policies.py:976\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor):\n\u001b[0;32m    975\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor)\n\u001b[1;32m--> 976\u001b[0m qvalue_input \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(q_net(qvalue_input) \u001b[38;5;28;01mfor\u001b[39;00m q_net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_networks)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    loader2 = DataLoader()\n",
    "    df2 = loader2.LoadData()\n",
    "\n",
    "    df2.index = range(len(df2))\n",
    "    #df = df.drop(df[df['tic'] == 'IMOEX'].index)\n",
    "    df2 = df2.drop(df2[df2['tic'] == 'BZ'].index)\n",
    "    #df = df.drop(df[df['tic'] == 'GD'].index)\n",
    "    df2 = df2.drop(df2[df2['tic'] == 'USD'].index)\n",
    "    lookback = 22#trial.suggest_categorical('lookback', [252])\n",
    "    fa2 = FeaturesAdder(lookback)\n",
    "    df2 = fa2.Process(df2)\n",
    "    #tau = trial.suggest_categorical('tau', [0.001, 0.005, 0.01])\n",
    "\n",
    "    #sigma = trial.suggest_float('sigma', 0, 1)\n",
    "    bsize = trial.suggest_categorical('bsize', [10000, 50000, 100000])\n",
    "    noise = trial.suggest_categorical('noise', [\"ornstein_uhlenbeck\", \"normal\"])\n",
    "\n",
    "    #n_actions = stock_dimension\n",
    "    #action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=sigma * np.ones(n_actions), theta=theta)\n",
    "    # size1 = trial.suggest_categorical('size1', [32, 64, 128])\n",
    "    # size2 = size1 * 2\n",
    "    size = [128, 64]\n",
    "    #ent_coef = trial.suggest_float('ent_coef', 0, 0.05)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-6, 5e-3, log=True)\n",
    "    #lookback = trial.suggest_categorical('lookback', [5, 10, 15, 22, 44, 66])\n",
    "\n",
    "    sum_reward = 0\n",
    "    sum_maxdd  = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        date1 = date_start + relativedelta(months = i)\n",
    "        date2 = date_start + relativedelta(months = i + 1)\n",
    "        train = data_split(df2, '2016-05-10', date1)\n",
    "        trade = data_split(df2, date1, date2)\n",
    "\n",
    "        optuna_params = {\"learning_rate\": learning_rate, \"buffer_size\": bsize, \"action_noise\": \"ornstein_uhlenbeck\"}\n",
    "        #optuna_params = {\"learning_rate\": learning_rate}#, \"ent_coef\": ent_coef}# \"action_noise\": \"ornstein_uhlenbeck\"}\n",
    "        log_name = str(size) + '_' + str(lookback) + '_' + str(i)\n",
    "        model, df_daily_return, df_actions = train_trade('td3', train, trade, None, log_name, size)\n",
    "        \n",
    "        result = get_result(df_daily_return)\n",
    "        reward = result['Cumulative returns']\n",
    "        max_dd = result['Max drawdown']\n",
    "        sharp  = result['Sharpe ratio']\n",
    "\n",
    "        print(\"Rew, DD, Sh\", reward, max_dd, sharp)\n",
    "        sum_reward += reward\n",
    "        sum_maxdd += max_dd\n",
    "\n",
    "    print(\"Total\", sum_reward, sum_maxdd, sharp)\n",
    "    return sum_reward\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\"])\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
